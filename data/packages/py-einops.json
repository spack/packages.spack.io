{
    "aliases": [],
    "build_system": "PythonPackage",
    "conflicts": [],
    "dependencies": [
        {
            "description": "Modern, extensible Python build backend.",
            "name": "py-hatchling"
        },
        {
            "description": "The PyPA recommended tool for installing Python packages.",
            "name": "py-pip"
        },
        {
            "description": "A Python utility that aids in the process of downloading, building,\nupgrading, installing, and uninstalling Python packages.",
            "name": "py-setuptools"
        },
        {
            "description": "A built-package format for Python.",
            "name": "py-wheel"
        },
        {
            "description": "The Python programming language.",
            "name": "python"
        },
        {
            "description": "A Spack managed Python virtual environment",
            "name": "python-venv"
        }
    ],
    "dependent_to": [
        {
            "description": "AlpacaFarm is a simulator that enables research and development on\nlearning from feedback at a fraction of the usual cost, promoting\naccessible research on instruction following and alignment.",
            "name": "py-alpaca-farm"
        },
        {
            "description": "BackPACK: Packing more into backprop.",
            "name": "py-backpack-for-pytorch"
        },
        {
            "description": "This repository contains an implementation for the Convolutive transfer\nfunction Invariant Signal-to-Distortion Ratio objective for PyTorch as\ndescribed in the publication Convolutive Transfer Function Invariant SDR\ntraining criteria for Multi-Channel Reverberant Speech Separation",
            "name": "py-ci-sdr"
        },
        {
            "description": "CoCa, Contrastive Captioners are Image-Text Foundation Models - Pytorch",
            "name": "py-coca-pytorch"
        },
        {
            "description": "scipy Linear operators for curvature matrices in PyTorch.",
            "name": "py-curvlinops-for-pytorch"
        },
        {
            "description": "Earth-2 Model Intercomparison Project (MIP). A python framework that\nenables climate researchers and scientists to explore and experiment\nwith AI models for weather and climate.",
            "name": "py-earth2mip"
        },
        {
            "description": "Convolutions as tensor contractions (einsums) for PyTorch.",
            "name": "py-einconv"
        },
        {
            "description": "Evolutionary Scale Modeling",
            "name": "py-fair-esm"
        },
        {
            "description": "Optimizing Protein Structure Prediction Model Training and Inference on\nGPU Clusters.",
            "name": "py-fastfold"
        },
        {
            "description": "This package provides the official implementation of FlashAttention.",
            "name": "py-flash-attn"
        },
        {
            "description": "Lighning-UQ-Box: A toolbox for uncertainty quantification in deep\nlearning.",
            "name": "py-lightning-uq-box"
        },
        {
            "description": "A standalone library for adding rotary embeddings to transformers in\nPytorch, following its success as relative positional encoding.\nSpecifically it will make rotating information into any axis of a tensor\neasy and efficient, whether they be fixed positional or learned. This\nlibrary will give you state of the art results for positional embedding,\nat little costs.",
            "name": "py-rotary-embedding-torch"
        },
        {
            "description": "TorchGeo: datasets, samplers, transforms, and pre-trained models for\ngeospatial data.",
            "name": "py-torchgeo"
        },
        {
            "description": "TorchSeg: Semantic Segmentation models for PyTorch.",
            "name": "py-torchseg"
        },
        {
            "description": "A vector quantization library originally transcribed from Deepmind's\ntensorflow implementation, made conveniently into a package. It uses\nexponential moving averages to update the dictionary.",
            "name": "py-vector-quantize-pytorch"
        },
        {
            "description": "A concise but complete implementation of CLIP with various experimental\nimprovements from recent papers",
            "name": "py-x-clip"
        }
    ],
    "description": "Flexible and powerful tensor operations for readable and reliable code.\nSupports numpy, pytorch, tensorflow, and others.\n",
    "homepage": "https://github.com/arogozhnikov/einops",
    "latest_version": "0.8.1",
    "maintainers": [
        "adamjstewart"
    ],
    "name": "py-einops",
    "patches": [],
    "resources": [],
    "variants": [
        {
            "default": "python_pip",
            "description": "Build systems supported by the package",
            "name": "build_system"
        }
    ],
    "versions": [
        {
            "name": "0.8.1",
            "sha256": "de5d960a7a761225532e0f1959e5315ebeafc0cd43394732f103ca44b9837e84"
        },
        {
            "name": "0.8.0",
            "sha256": "63486517fed345712a8385c100cb279108d9d47e6ae59099b07657e983deae85"
        },
        {
            "name": "0.7.0",
            "sha256": "b2b04ad6081a3b227080c9bf5e3ace7160357ff03043cd66cc5b2319eb7031d1"
        },
        {
            "name": "0.6.1",
            "sha256": "f95f8d00f4ded90dbc4b19b6f98b177332614b0357dde66997f3ae5d474dc8c8"
        },
        {
            "name": "0.6.0",
            "sha256": "6f6c78739316a2e3ccbce8052310497e69da092935e4173f2e76ec4e3a336a35"
        },
        {
            "name": "0.5.0",
            "sha256": "8b7a83cffc1ea88e306df099b7cbb9c3ba5003bd84d05ae44be5655864abb8d3"
        },
        {
            "name": "0.3.2",
            "sha256": "5200e413539f0377f4177ef00dc019968f4177c49b1db3e836c7883df2a5fe2e"
        }
    ],
    "versions_deprecated": []
}