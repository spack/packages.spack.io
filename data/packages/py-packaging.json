{
    "aliases": [],
    "build_system": "PythonPackage",
    "conflicts": [],
    "dependencies": [
        {
            "description": "Classes Without Boilerplate",
            "name": "py-attrs"
        },
        {
            "description": "Distribution-building parts of Flit.",
            "name": "py-flit-core"
        },
        {
            "description": "The PyPA recommended tool for installing Python packages.",
            "name": "py-pip"
        },
        {
            "description": "A Python Parsing Module.",
            "name": "py-pyparsing"
        },
        {
            "description": "A Python utility that aids in the process of downloading, building,\nupgrading, installing, and uninstalling Python packages.",
            "name": "py-setuptools"
        },
        {
            "description": "Python 2 and 3 compatibility utilities.",
            "name": "py-six"
        },
        {
            "description": "A built-package format for Python.",
            "name": "py-wheel"
        },
        {
            "description": "The Python programming language.",
            "name": "python"
        },
        {
            "description": "A Spack managed Python virtual environment",
            "name": "python-venv"
        }
    ],
    "dependent_to": [
        {
            "description": "A next-generation resource manager (pre-alpha)",
            "name": "flux-core"
        },
        {
            "description": "IsoQuant: Transcript discovery and quantification with long RNA reads",
            "name": "isoquant"
        },
        {
            "description": "Mesa is an open-source implementation of the OpenGL specification - a\nsystem for rendering interactive 3D graphics.",
            "name": "mesa"
        },
        {
            "description": "MongoDB is a source-available cross-platform document-oriented database\nprogram. Classified as a NoSQL database program, MongoDB uses JSON-like\ndocuments with optional schemas.",
            "name": "mongodb"
        },
        {
            "description": "N2p2 (The neural network potential package) provides ready-to-use\nsoftware for high-dimensional neural network potentials in computational\nphysics and chemistry.",
            "name": "n2p2"
        },
        {
            "description": "NEURON is a simulation environment for single and networks of neurons.\nNEURON is a simulation environment for modeling individual and networks\nof neurons. NEURON models individual neurons via the use of sections\nthat are automatically subdivided into individual compartments, instead\nof requiring the user to manually create compartments.",
            "name": "neuron"
        },
        {
            "description": "A python package with helper tools for the nf-core community.",
            "name": "nf-core-tools"
        },
        {
            "description": "pipx is a tool to install and run Python applications in isolated\nenvironments",
            "name": "pipx"
        },
        {
            "description": "A simple way to train and use PyTorch models with multi-GPU, TPU, mixed-\nprecision.",
            "name": "py-accelerate"
        },
        {
            "description": "Declarative statistical visualization library for Python",
            "name": "py-altair"
        },
        {
            "description": "AMReX Python Bindings with pybind11",
            "name": "py-amrex"
        },
        {
            "description": "anndata is a Python package for handling annotated data matrices in\nmemory and on disk, positioned between pandas and xarray.",
            "name": "py-anndata"
        },
        {
            "description": "Ansible is a radically simple IT automation platform that makes your\napplications and systems easier to deploy.",
            "name": "py-ansible"
        },
        {
            "description": "Python project for generating badges for your projects",
            "name": "py-anybadge"
        },
        {
            "description": "A pluggable API specification generator.",
            "name": "py-apispec"
        },
        {
            "description": "Build manual page from python's ArgumentParser object.",
            "name": "py-argparse-manpage"
        },
        {
            "description": "ArviZ (pronounced \"AR-vees\") is a Python package for exploratory\nanalysis of Bayesian models. Includes functions for posterior analysis,\nmodel checking, comparison and diagnostics.",
            "name": "py-arviz"
        },
        {
            "description": "The Advanced Scientific Data Format (ASDF) is a next-generation\ninterchange format for scientific data. This package contains the Python\nimplementation of the ASDF Standard.",
            "name": "py-asdf"
        },
        {
            "description": "ASDF serialization support for astropy",
            "name": "py-asdf-astropy"
        },
        {
            "description": "The Astropy Project is a community effort to develop a single core\npackage for Astronomy in Python and foster interoperability between\nPython astronomy packages.",
            "name": "py-astropy"
        },
        {
            "description": "Manipulate JSON-like data with NumPy-like idioms.",
            "name": "py-awkward"
        },
        {
            "description": "The matplotlib basemap toolkit is a library for plotting 2D data on maps\nin Python.",
            "name": "py-basemap"
        },
        {
            "description": "Black is the uncompromising Python code formatter. By using it, you\nagree to cede control over minutiae of hand-formatting. In return, Black\ngives you speed, determinism, and freedom from pycodestyle nagging about\nformatting.",
            "name": "py-black"
        },
        {
            "description": "An easy whitelist-based HTML-sanitizing tool.",
            "name": "py-bleach"
        },
        {
            "description": "Statistical and novel interactive HTML plots for Python",
            "name": "py-bokeh"
        },
        {
            "description": "A simple, correct PEP517 package builder.",
            "name": "py-build"
        },
        {
            "description": "Cartopy - a cartographic python library with matplotlib support.",
            "name": "py-cartopy"
        },
        {
            "description": "CEKit is a Container image creation tool. CEKit helps to build container\nimages from image definition files with strong focus on modularity and\ncode reuse.",
            "name": "py-cekit"
        },
        {
            "description": "Colormaps for Oceanography.",
            "name": "py-cmocean"
        },
        {
            "description": "An integrated large-scale model training system with efficient\nparallelization techniques.",
            "name": "py-colossalai"
        },
        {
            "description": "CTGAN is a collection of Deep Learning based Synthetic Data Generators\nfor single table data, which are able to learn from real data and\ngenerate synthetic clones with high fidelity.",
            "name": "py-ctgan"
        },
        {
            "description": "Python Utilities and Autogenerated Classes for loading and parsing CWL\nv1.0, CWL v1.1, and CWL v1.2 documents.",
            "name": "py-cwl-utils"
        },
        {
            "description": "A workflow engine for cycling systems.",
            "name": "py-cylc-flow"
        },
        {
            "description": "Python utilities to interact with Darshan log records of HPC\napplications.",
            "name": "py-darshan"
        },
        {
            "description": "Dask is a flexible parallel computing library for analytics.",
            "name": "py-dask"
        },
        {
            "description": "Scalable Machine Learning with Dask.",
            "name": "py-dask-ml"
        },
        {
            "description": "An analysis environment for satellite and other earth observation data.",
            "name": "py-datacube"
        },
        {
            "description": "data distribution geared toward scientific datasets. DataLad makes data\nmanagement and data distribution more accessible. To do that, it stands\non the shoulders of Git and Git-annex to deliver a decentralized system\nfor data exchange. This includes automated ingestion of data from online\nportals and exposing it in readily usable form as Git(-annex)\nrepositories, so-called datasets. The actual data storage and permission\nmanagement, however, remains with the original data providers.",
            "name": "py-datalad"
        },
        {
            "description": "Datasets is a lightweight library providing two main features: one-line\ndataloaders for many public datasets and efficient data pre-processing.",
            "name": "py-datasets"
        },
        {
            "description": "Datashader is a data rasterization pipeline for automating the process\nof creating meaningful representations of large amounts of data",
            "name": "py-datashader"
        },
        {
            "description": "Reorganising NIfTI files from dcm2niix into the Brain Imaging Data\nStructure.",
            "name": "py-dcm2bids"
        },
        {
            "description": "Scalable asynchronous hyperparameter optimization, neural architecture\nsearch, and parallel ensemble of predictive models.",
            "name": "py-deephyper"
        },
        {
            "description": "DeepSpeed library. DeepSpeed enables world's most powerful language\nmodels like MT-530B and BLOOM. It is an easy-to-use deep learning\noptimization software suite that powers unprecedented scale and speed\nfor both training and inference.",
            "name": "py-deepspeed"
        },
        {
            "description": "The deprecation library provides a deprecated decorator and a\nfail_if_not_removed decorator for your tests.",
            "name": "py-deprecation"
        },
        {
            "description": "Wrapper providing support for deprecated aliases.",
            "name": "py-deprecation-alias"
        },
        {
            "description": "Diffusion MRI utilities in python. DIPY is the paragon 3D/4D+ imaging\nlibrary in Python. Contains generic methods for spatial normalization,\nsignal processing, machine learning, statistical analysis and\nvisualization of medical images. Additionally, it contains specialized\nmethods for computational anatomy including diffusion, perfusion and\nstructural imaging.",
            "name": "py-dipy"
        },
        {
            "description": "Parse and create Python distribution metadata.",
            "name": "py-dist-meta"
        },
        {
            "description": "Distributed scheduler for Dask",
            "name": "py-distributed"
        },
        {
            "description": "A Python library for the Docker Engine API.",
            "name": "py-docker"
        },
        {
            "description": "Dynamic version generation.",
            "name": "py-dunamai"
        },
        {
            "description": "Git for data scientists - manage your code and data together.",
            "name": "py-dvc"
        },
        {
            "description": "You can use fastai without any installation by using Google Colab. In\nfact, every page of this documentation is also available as an\ninteractive notebook - click \"Open in colab\" at the top of any page to\nopen it (be sure to change the Colab runtime to \"GPU\" to have it run\nfast!) See the fast.ai documentation on Using Colab for more\ninformation.",
            "name": "py-fastai"
        },
        {
            "description": "Python is a powerful, dynamic language. Rather than bake everything into\nthe language, it lets the programmer customize it to make it work for\nthem. fastcore uses this flexibility to add to Python features inspired\nby other languages we've loved, like multiple dispatch from Julia,\nmixins from Ruby, and currying, binding, and more from Haskell. It also\nadds some \"missing features\" and clean up some rough edges in the Python\nstandard library, such as simplifying parallel processing, and bringing\nideas from NumPy over to Python's list type.",
            "name": "py-fastcore"
        },
        {
            "description": "This package provides the official implementation of FlashAttention.",
            "name": "py-flash-attn"
        },
        {
            "description": "Fast & furious GroupBy operations for dask.array.",
            "name": "py-flox"
        },
        {
            "description": "A Language Server for Fortran providing code completion, diagnostics,\nhovering and more.",
            "name": "py-fortls"
        },
        {
            "description": "Galaxy Generic Utilities",
            "name": "py-galaxy-util"
        },
        {
            "description": "GeoPandas is an open source project to make working with geospatial data\nin python easier. GeoPandas extends the datatypes used by pandas to\nallow spatial operations on geometric types. Geometric operations are\nperformed by shapely. Geopandas further depends on fiona for file access\nand descartes and matplotlib for plotting.",
            "name": "py-geopandas"
        },
        {
            "description": "A Python library designed to make data analysis and visualization\nseamless and simple.",
            "name": "py-geoviews"
        },
        {
            "description": "Globus CLI is a standalone application that can be installed on the\nuser's machine and is used to access the Globus service. The CLI\nprovides an interface to Globus services from the shell, and is suited\nto both interactive and simple scripting use cases.",
            "name": "py-globus-cli"
        },
        {
            "description": "glymur contains a Python interface to the OpenJPEG library which allows\none to read and write JPEG 2000 files. glymur works on Python 3.7, 3.8,\n3.9, and 3.10.",
            "name": "py-glymur"
        },
        {
            "description": "Python bindings and ensemble workflow management for GROMACS. The\nGROMACS C++ API is affected by its package variants. You can specify a\nparticular GROMACS API by making the dependency variant explicit. E.g.\n``spack install gmxapi ^gromacs+mpi~double``",
            "name": "py-gmxapi"
        },
        {
            "description": "Python library for easily interacting with trained machine learning\nmodels",
            "name": "py-gradio-client"
        },
        {
            "description": "Project to generate recipes for conda packages.",
            "name": "py-grayskull"
        },
        {
            "description": "A Python interface for the netCDF4 file-format that reads and writes\nlocal or remote HDF5 files directly via h5py or h5pyd, without relying\non the Unidata netCDF library.",
            "name": "py-h5netcdf"
        },
        {
            "description": "Modern, extensible Python project management",
            "name": "py-hatch"
        },
        {
            "description": "Hatchling plugin to read project dependencies from requirements.txt",
            "name": "py-hatch-requirements-txt"
        },
        {
            "description": "Modern, extensible Python build backend.",
            "name": "py-hatchling"
        },
        {
            "description": "Validation schema and code for HEPdata submissions.",
            "name": "py-hepdata-validator"
        },
        {
            "description": "A Python library designed to make data analysis and visualization\nseamless and simple.",
            "name": "py-holoviews"
        },
        {
            "description": "Horovod is a distributed deep learning training framework for\nTensorFlow, Keras, PyTorch, and Apache MXNet.",
            "name": "py-horovod"
        },
        {
            "description": "Client library to download and publish models, datasets and other repos\non the huggingface.co hub.",
            "name": "py-huggingface-hub"
        },
        {
            "description": "A high-level plotting API for pandas, dask, xarray, and networkx built\non HoloViews.",
            "name": "py-hvplot"
        },
        {
            "description": "A framework for elegantly configuring complex applications.",
            "name": "py-hydra-core"
        },
        {
            "description": "IPython Kernel for Jupyter",
            "name": "py-ipykernel"
        },
        {
            "description": "IPython's architecture for parallel and distributed computing.",
            "name": "py-ipyparallel"
        },
        {
            "description": "Jupyter Packaging Utilities.",
            "name": "py-jupyter-packaging"
        },
        {
            "description": "The Jupyter Server provides the backend (i.e. the core services, APIs,\nand REST endpoints) for Jupyter web applications like Jupyter notebook,\nJupyterLab, and Voila.",
            "name": "py-jupyter-server"
        },
        {
            "description": "JupyterLab is the next-generation web-based user interface for Project\nJupyter.",
            "name": "py-jupyterlab"
        },
        {
            "description": "A set of server components for JupyterLab and JupyterLab like\napplications",
            "name": "py-jupyterlab-server"
        },
        {
            "description": "Jupyter Notebooks as Markdown Documents, Julia, Python or R scripts",
            "name": "py-jupytext"
        },
        {
            "description": "Multi-backend Keras. Keras 3 is a new multi-backend implementation of\nthe Keras API, with support for TensorFlow, JAX, and PyTorch.",
            "name": "py-keras"
        },
        {
            "description": "Open Source Differentiable Computer Vision Library for PyTorch.",
            "name": "py-kornia"
        },
        {
            "description": "Wavelet scattering transforms in Python with GPU acceleration.",
            "name": "py-kymatio"
        },
        {
            "description": "lazy_loader makes it easy to load subpackages and functions on demand.",
            "name": "py-lazy-loader"
        },
        {
            "description": "A python package for music and audio analysis.",
            "name": "py-librosa"
        },
        {
            "description": "The deep learning framework to pretrain, finetune and deploy AI models.",
            "name": "py-lightning"
        },
        {
            "description": "Fabric is the fast and lightweight way to scale PyTorch models without\nboilerplate.",
            "name": "py-lightning-fabric"
        },
        {
            "description": "LightningLite enables pure PyTorch users to scale their existing code on\nany kind of device while retaining full control over their own loops and\noptimization logic.",
            "name": "py-lightning-lite"
        },
        {
            "description": "Common Python utilities and GitHub Actions in Lightning Ecosystem",
            "name": "py-lightning-utilities"
        },
        {
            "description": "A module for connecting to mariaDB databases",
            "name": "py-mariadb"
        },
        {
            "description": "marshmallow is an ORM/ODM/framework-agnostic library for converting\ncomplex datatypes, such as objects, to and from native Python datatypes.",
            "name": "py-marshmallow"
        },
        {
            "description": "Matplotlib is a comprehensive library for creating static, animated, and\ninteractive visualizations in Python.",
            "name": "py-matplotlib"
        },
        {
            "description": "MDAnalysis is a Python toolkit to analyze molecular dynamics\ntrajectories generated by a wide range of popular simulation packages\nincluding DL_Poly, CHARMM, Amber, NAMD, LAMMPS, and Gromacs. (See the\nlists of supported trajectory formats and topology formats.)",
            "name": "py-mdanalysis"
        },
        {
            "description": "MolSSI Driver Interface (MDI) Library The MolSSI Driver Interface (MDI)\nproject provides a standardized API for fast, on-the-fly communication\nbetween computational chemistry codes. This greatly simplifies the\nprocess of implementing methods that require the cooperation of multiple\nsoftware packages and enables developers to write a single\nimplementation that works across many different codes.",
            "name": "py-mdi"
        },
        {
            "description": "Meson Python build backend (PEP 517).",
            "name": "py-meson-python"
        },
        {
            "description": "MkDocs is a fast, simple and downright gorgeous static site generator\nthat's geared towards building project documentation.",
            "name": "py-mkdocs"
        },
        {
            "description": "MLflow: A Platform for ML Development and Productionization.",
            "name": "py-mlflow"
        },
        {
            "description": "MNE python project for MEG and EEG data analysis.",
            "name": "py-mne"
        },
        {
            "description": "Modin: Make your pandas code run faster by changing one line of code.",
            "name": "py-modin"
        },
        {
            "description": "Matplotlib styles for HEP",
            "name": "py-mplhep"
        },
        {
            "description": "MultiQC is a tool to aggregate bioinformatics results across many\nsamples into a single report. It is written in Python and contains\nmodules for a large number of common bioinformatics tools.",
            "name": "py-multiqc"
        },
        {
            "description": "Minimalistic large language model 3D-parallelism training.",
            "name": "py-nanotron"
        },
        {
            "description": "Jupyter Notebook Conversion",
            "name": "py-nbconvert"
        },
        {
            "description": "Neo is a package for representing electrophysiology data in Python,\ntogether with support for reading a wide range of neurophysiology file\nformats",
            "name": "py-neo"
        },
        {
            "description": "Flexible metadata store for MLOps, built for research and production\nteams that run a lot of experiments.",
            "name": "py-neptune-client"
        },
        {
            "description": "Access a multitude of neuroimaging data formats",
            "name": "py-nibabel"
        },
        {
            "description": "Statistical learning for neuroimaging in Python.",
            "name": "py-nilearn"
        },
        {
            "description": "Neuroimaging in Python: Pipelines and Interfaces.",
            "name": "py-nipype"
        },
        {
            "description": "Common workflows for MRI (anatomical, functional, diffusion, etc)",
            "name": "py-niworkflows"
        },
        {
            "description": "Fast numerical expression evaluator for NumPy",
            "name": "py-numexpr"
        },
        {
            "description": "ONNX Runtime is a performance-focused complete scoring engine for Open\nNeural Network Exchange (ONNX) models, with an open extensible\narchitecture to continually address the latest developments in AI and\nDeep Learning. ONNX Runtime stays up to date with the ONNX standard with\ncomplete implementation of all ONNX operators, and supports all ONNX\nreleases (1.2+) with both future and backwards compatibility.",
            "name": "py-onnxruntime"
        },
        {
            "description": "This project provides classes and utility functions for working with\nread fast5 files. It provides an abstraction layer between the\nunderlying h5py library and the various concepts central to read fast5\nfiles, such as \"reads\", \"analyses\", \"analysis summaries\", and \"analysis\ndatasets\". Ideally all interaction with a read fast5 file should be\npossible via this API, without having to directly invoke the h5py\nlibrary.",
            "name": "py-ont-fast5-api"
        },
        {
            "description": "Optuna is an automatic hyperparameter optimization software framework,\nparticularly designed for machine learning. It features an imperative,\ndefine-by-run style user API. Thanks to our define-by-run API, the code\nwritten with Optuna enjoys high modularity, and the user of Optuna can\ndynamically construct the search spaces for the hyperparameters.",
            "name": "py-optuna"
        },
        {
            "description": "The oslo.utils library provides support for common utility type\nfunctions, such as encoding, exception handling, string manipulation,\nand time handling.",
            "name": "py-oslo-utils"
        },
        {
            "description": "A high level app and dashboarding solution for Python.",
            "name": "py-panel"
        },
        {
            "description": "PennyLane is a Python quantum machine learning library by Xanadu Inc.",
            "name": "py-pennylane"
        },
        {
            "description": "Petastorm is a library enabling the use of Parquet storage from\nTensorflow, Pytorch, and other Python-based ML training frameworks.",
            "name": "py-petastorm"
        },
        {
            "description": "Pint is a Python package to define, operate and manipulate physical\nquantities: the product of a numerical value and a unit of measurement.\nIt allows arithmetic operations between them and conversions from and to\ndifferent units.",
            "name": "py-pint"
        },
        {
            "description": "An interactive, browser-based graphing library for Python",
            "name": "py-plotly"
        },
        {
            "description": "Python dependency management and packaging made easy.",
            "name": "py-poetry"
        },
        {
            "description": "Pooch manages your Python library's sample data files: it automatically\ndownloads and stores them in a local directory, with support for\nversioning and corruption checks.",
            "name": "py-pooch"
        },
        {
            "description": "PSI/J is an abstraction layer over cluster schedulers to write scheduler\nagnostic HPC applications.",
            "name": "py-psij-python"
        },
        {
            "description": "A clean, three-column, Bootstrap-based Sphinx theme by and for the\nPyData community.",
            "name": "py-pydata-sphinx-theme"
        },
        {
            "description": "PyERFA is the Python wrapper for the ERFA library (Essential Routines\nfor Fundamental Astronomy), a C library containing key algorithms for\nastronomy, which is based on the SOFA library published by the\nInternational Astronomical Union (IAU). All C routines are wrapped as\nNumpy universal functions, so that they can be called with scalar or\narray inputs.",
            "name": "py-pyerfa"
        },
        {
            "description": "pyfaidx: efficient pythonic random access to fasta subsequences",
            "name": "py-pyfaidx"
        },
        {
            "description": "A Python interface for the Generic Mapping Tools.",
            "name": "py-pygmt"
        },
        {
            "description": "Vectorized spatial vector file format I/O using GDAL/OGR",
            "name": "py-pyogrio"
        },
        {
            "description": "This package provides python language bindings for the C++ library\npreCICE.",
            "name": "py-pyprecice"
        },
        {
            "description": "PEP 621 metadata parsing.",
            "name": "py-pyproject-metadata"
        },
        {
            "description": "Parser for 'pyproject.toml'",
            "name": "py-pyproject-parser"
        },
        {
            "description": "The PEP 517 compliant PyQt build system.",
            "name": "py-pyqt-builder"
        },
        {
            "description": "A Python validator for SHACL.",
            "name": "py-pyshacl"
        },
        {
            "description": "Python bindings for Qt.",
            "name": "py-pyside2"
        },
        {
            "description": "pytest: simple powerful testing with Python.",
            "name": "py-pytest"
        },
        {
            "description": "Pytest plugin with advanced doctest features.",
            "name": "py-pytest-doctestplus"
        },
        {
            "description": "Pytest plugin for controlling remote data access.",
            "name": "py-pytest-remotedata"
        },
        {
            "description": "PyTorch Lightning is the lightweight PyTorch wrapper for ML researchers.",
            "name": "py-pytorch-lightning"
        },
        {
            "description": "PyZMQ: Python bindings for zeromq.",
            "name": "py-pyzmq"
        },
        {
            "description": "QuTiP: The Quantum Toolbox in Python",
            "name": "py-qutip"
        },
        {
            "description": "The QuTiP quantum information processing package",
            "name": "py-qutip-qip"
        },
        {
            "description": "Create masks of geospatial regions for arbitrary grids",
            "name": "py-regionmask"
        },
        {
            "description": "rasterio xarray extension.",
            "name": "py-rioxarray"
        },
        {
            "description": "Convert reStructured Text to PDF via ReportLab. The usual way of\ncreating PDF from reStructuredText is by going through LaTeX. This tool\nprovides an alternative by producing PDF directly using the ReportLab\nlibrary.",
            "name": "py-rst2pdf"
        },
        {
            "description": "Rucio Client Lite Package",
            "name": "py-rucio-clients"
        },
        {
            "description": "Scanpy is a scalable toolkit for analyzing single-cell gene expression\ndata built jointly with anndata.",
            "name": "py-scanpy"
        },
        {
            "description": "scikit-build is an improved build system generator for CPython\nC/C++/Fortran/Cython extensions. It provides better support for\nadditional compilers, build systems, cross compilation, and locating\ndependencies and their associated build requirements. The scikit-build\npackage is fundamentally just glue between the setuptools Python module\nand CMake.",
            "name": "py-scikit-build"
        },
        {
            "description": "scikit-build-core is a doubly improved build system generator for\nCPython C/C++/Fortran/Cython extensions. It features several\nimprovements over the classic scikit-build build system generator.",
            "name": "py-scikit-build-core"
        },
        {
            "description": "Image processing algorithms for SciPy, including IO, morphology,\nfiltering, warping, color manipulation, object detection, etc.",
            "name": "py-scikit-image"
        },
        {
            "description": "This is a Python implementation of Seriation algorithm. Seriation is an\napproach for ordering elements in a set so that the sum of the\nsequential pairwise distances is minimal. We state this task as a\nTravelling Salesman Problem (TSP) and leverage the powerful Google's or-\ntools to do heavy-lifting. Since TSP is NP-hard, it is not possible to\ncalculate the precise solution for a big number of elements. However,\nthe or-tools' heuristics work very well in practice, and they are used\nin e.g. Google Maps.",
            "name": "py-seriate"
        },
        {
            "description": "Simplified packaging for pybind11-based C++ extensions",
            "name": "py-setuptools-cpp"
        },
        {
            "description": "Use git repo data for building a version number according PEP-440",
            "name": "py-setuptools-git-versioning"
        },
        {
            "description": "The blessed package to manage your versions by scm tags.",
            "name": "py-setuptools-scm"
        },
        {
            "description": "SHAP (SHapley Additive exPlanations): a unified approach to explain the\noutput of any machine learning model.",
            "name": "py-shap"
        },
        {
            "description": "Utilities for handling packages.",
            "name": "py-shippinglabel"
        },
        {
            "description": "A Python bindings generator for C/C++ libraries.",
            "name": "py-sip"
        },
        {
            "description": "Convert scikit-learn models to ONNX",
            "name": "py-skl2onnx"
        },
        {
            "description": "Pandas extension arrays for spatial/geometric operations.",
            "name": "py-spatialpandas"
        },
        {
            "description": "Sphinx Documentation Generator.",
            "name": "py-sphinx"
        },
        {
            "description": "A tool for authoring Sphinx themes with a simple (opinionated) workflow.",
            "name": "py-sphinx-theme-builder"
        },
        {
            "description": "Statistical computations and models for use with SciPy",
            "name": "py-statsmodels"
        },
        {
            "description": "The fastest way to build data apps in Python.",
            "name": "py-streamlit"
        },
        {
            "description": "Missing widgets and components for PyQt/PySide",
            "name": "py-superqt"
        },
        {
            "description": "PyTables is a package for managing hierarchical datasets and designed to\nefficiently and easily cope with extremely large amounts of data.",
            "name": "py-tables"
        },
        {
            "description": "TensorBoard is a suite of web applications for inspecting and\nunderstanding your TensorFlow runs and graphs.",
            "name": "py-tensorboard"
        },
        {
            "description": "The purpose of this package is to let researchers use a simple interface\nto log events within PyTorch (and then show visualization in\ntensorboard). This package currently supports logging scalar, image,\naudio, histogram, text, embedding, and the route of back-propagation.",
            "name": "py-tensorboardx"
        },
        {
            "description": "TensorFlow is an open source machine learning framework for everyone.",
            "name": "py-tensorflow"
        },
        {
            "description": "A PyTorch Extension: Tools for easy mixed precision and distributed\ntraining in Pytorch",
            "name": "py-torch-nvidia-apex"
        },
        {
            "description": "TorchGeo: datasets, samplers, transforms, and pre-trained models for\ngeospatial data.",
            "name": "py-torchgeo"
        },
        {
            "description": "Machine learning metrics for distributed, scalable PyTorch applications.",
            "name": "py-torchmetrics"
        },
        {
            "description": "tox is a generic virtualenv management and test command line tool.",
            "name": "py-tox"
        },
        {
            "description": "A library for accelerating Transformer models on NVIDIA GPUs, including\nfp8 precision on Hopper GPUs.",
            "name": "py-transformer-engine"
        },
        {
            "description": "State-of-the-art Natural Language Processing for TensorFlow 2.0 and\nPyTorch",
            "name": "py-transformers"
        },
        {
            "description": "Experiments with new file format for tractography.",
            "name": "py-trx-python"
        },
        {
            "description": "Twine is a utility for publishing Python packages on PyPI.",
            "name": "py-twine"
        },
        {
            "description": "N-dimensional unfold (im2col) and fold (col2im) in PyTorch.",
            "name": "py-unfoldnd"
        },
        {
            "description": "ROOT I/O in pure Python and NumPy. Uproot is a reader and a writer of\nthe ROOT file format using only Python and Numpy. Unlike the standard\nC++ ROOT implementation, Uproot is only an I/O library, primarily\nintended to stream data into machine learning libraries in Python.\nUnlike PyROOT and root_numpy, Uproot does not depend on C++ ROOT.\nInstead, it uses Numpy to cast blocks of data from the ROOT file as\nNumpy arrays.",
            "name": "py-uproot"
        },
        {
            "description": "Vector classes and utilities",
            "name": "py-vector"
        },
        {
            "description": "Python library for parsing and validating HTTP request objects, with\nbuilt-in support for popular web frameworks, including Flask, Django,\nBottle, Tornado, Pyramid, Falcon, and aiohttp.",
            "name": "py-webargs"
        },
        {
            "description": "A simple Python wheel builder for simple projects.",
            "name": "py-whey"
        },
        {
            "description": "N-D labeled arrays and datasets in Python",
            "name": "py-xarray"
        },
        {
            "description": "Volumetric Data Analysis yt is a python package for analyzing and\nvisualizing volumetric, multi-resolution data from astrophysical\nsimulations, radio telescopes, and a burgeoning interdisciplinary\ncommunity.",
            "name": "py-yt"
        },
        {
            "description": "Zarr is a Python package providing an implementation of chunked,\ncompressed, N-dimensional arrays.",
            "name": "py-zarr"
        },
        {
            "description": "Workflow management system to create reproducible and scalable data\nanalyses.",
            "name": "snakemake"
        },
        {
            "description": "Survey is a high level performance tool product from Trenza, Inc. The\nsurvey collector/analytics framework is a new generation, high level,\nlightweight multiplatform Linux tool set that targets metric collection\nfor high level performance analysis of applications running on both\nsingle node and on large scale platforms, including the Cray platforms.\nThe collector is designed to work on sequential, MPI, OpenMP, and hybrid\ncodes and directly leverages several interfaces available for tools\ninside current MPI implementations including: MPICH, MVAPICH, MPT, and\nOpenMPI. It also supports multiple architectures and has been tested on\nmachines based on Intel, AMD, ARM, and IBM P8/9 processors and\nintegrated AMD and NVIDIA GPUs. Survey is a licensed product with the\nsource not openly available. To access the survey source and build with\nspack please contact: Trenza Inc. via: dmont@trenzasynergy.com or\njeg@trenzasynergy.com",
            "name": "survey"
        }
    ],
    "description": "Core utilities for Python packages.\n",
    "homepage": "https://github.com/pypa/packaging",
    "latest_version": "25.0",
    "maintainers": [],
    "name": "py-packaging",
    "patches": [],
    "resources": [],
    "variants": [
        {
            "default": "python_pip",
            "description": "Build systems supported by the package",
            "name": "build_system"
        }
    ],
    "versions": [
        {
            "name": "25.0",
            "sha256": "d443872c98d677bf60f6a1f2f8c1cb748e8fe762d2bf9d3148b5599295b0fc4f"
        },
        {
            "name": "24.2",
            "sha256": "c228a6dc5e932d346bc5739379109d49e8853dd8223571c7c5b55260edc0b97f"
        },
        {
            "name": "24.1",
            "sha256": "026ed72c8ed3fcce5bf8950572258698927fd1dbda10a5e981cdf0ac37f4f002"
        },
        {
            "name": "23.2",
            "sha256": "048fb0e9405036518eaaf48a55953c750c11e1a1b68e0dd1a9d62ed0c092cfc5"
        },
        {
            "name": "23.1",
            "sha256": "a392980d2b6cffa644431898be54b0045151319d1e7ec34f0cfed48767dd334f"
        },
        {
            "name": "23.0",
            "sha256": "b6ad297f8907de0fa2fe1ccbd26fdaf387f5f47c7275fedf8cce89f99446cf97"
        },
        {
            "name": "21.3",
            "sha256": "dd47c42927d89ab911e606518907cc2d3a1f38bbd026385970643f9c5b8ecfeb"
        },
        {
            "name": "21.0",
            "sha256": "7dc96269f53a4ccec5c0670940a4281106dd0bb343f47b7471f779df49c2fbe7"
        },
        {
            "name": "20.9",
            "sha256": "5b327ac1320dc863dca72f4514ecc086f31186744b84a230374cc1fd776feae5"
        },
        {
            "name": "19.2",
            "sha256": "28b924174df7a2fa32c1953825ff29c61e2f5e082343165438812f00d3a7fc47"
        },
        {
            "name": "19.1",
            "sha256": "c491ca87294da7cc01902edbe30a5bc6c4c28172b5138ab4e4aa1b9d7bfaeafe"
        },
        {
            "name": "19.0",
            "sha256": "0c98a5d0be38ed775798ece1b9727178c4469d9c3b4ada66e8e6b7849f8732af"
        },
        {
            "name": "17.1",
            "sha256": "f019b770dd64e585a99714f1fd5e01c7a8f11b45635aa953fd41c689a657375b"
        },
        {
            "name": "16.8",
            "sha256": "5d50835fdf0a7edf0b55e311b7c887786504efea1177abd7e69329a8e5ea619e"
        }
    ],
    "versions_deprecated": []
}