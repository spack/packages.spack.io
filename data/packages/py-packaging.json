{
    "aliases": [],
    "build_system": "PythonPackage",
    "conflicts": [],
    "dependencies": [
        {
            "description": "Classes Without Boilerplate",
            "name": "py-attrs"
        },
        {
            "description": "Distribution-building parts of Flit.",
            "name": "py-flit-core"
        },
        {
            "description": "The PyPA recommended tool for installing Python packages.",
            "name": "py-pip"
        },
        {
            "description": "A Python Parsing Module.",
            "name": "py-pyparsing"
        },
        {
            "description": "A Python utility that aids in the process of downloading, building,\nupgrading, installing, and uninstalling Python packages.",
            "name": "py-setuptools"
        },
        {
            "description": "Python 2 and 3 compatibility utilities.",
            "name": "py-six"
        },
        {
            "description": "A built-package format for Python.",
            "name": "py-wheel"
        },
        {
            "description": "The Python programming language.",
            "name": "python"
        },
        {
            "description": "A Spack managed Python virtual environment",
            "name": "python-venv"
        }
    ],
    "dependent_to": [
        {
            "description": "MongoDB is a source-available cross-platform document-oriented database\nprogram. Classified as a NoSQL database program, MongoDB uses JSON-like\ndocuments with optional schemas.",
            "name": "mongodb"
        },
        {
            "description": "N2p2 (The neural network potential package) provides ready-to-use\nsoftware for high-dimensional neural network potentials in computational\nphysics and chemistry.",
            "name": "n2p2"
        },
        {
            "description": "NEURON is a simulation environment for single and networks of neurons.\nNEURON is a simulation environment for modeling individual and networks\nof neurons. NEURON models individual neurons via the use of sections\nthat are automatically subdivided into individual compartments, instead\nof requiring the user to manually create compartments.",
            "name": "neuron"
        },
        {
            "description": "A python package with helper tools for the nf-core community.",
            "name": "nf-core-tools"
        },
        {
            "description": "pipx is a tool to install and run Python applications in isolated\nenvironments",
            "name": "pipx"
        },
        {
            "description": "A simple way to train and use PyTorch models with multi-GPU, TPU, mixed-\nprecision.",
            "name": "py-accelerate"
        },
        {
            "description": "Declarative statistical visualization library for Python",
            "name": "py-altair"
        },
        {
            "description": "AMReX Python Bindings with pybind11",
            "name": "py-amrex"
        },
        {
            "description": "anndata is a Python package for handling annotated data matrices in\nmemory and on disk, positioned between pandas and xarray.",
            "name": "py-anndata"
        },
        {
            "description": "Ansible is a radically simple IT automation platform that makes your\napplications and systems easier to deploy.",
            "name": "py-ansible"
        },
        {
            "description": "Python project for generating badges for your projects",
            "name": "py-anybadge"
        },
        {
            "description": "A pluggable API specification generator.",
            "name": "py-apispec"
        },
        {
            "description": "Build manual page from python's ArgumentParser object.",
            "name": "py-argparse-manpage"
        },
        {
            "description": "ArviZ (pronounced \"AR-vees\") is a Python package for exploratory\nanalysis of Bayesian models. Includes functions for posterior analysis,\nmodel checking, comparison and diagnostics.",
            "name": "py-arviz"
        },
        {
            "description": "The Advanced Scientific Data Format (ASDF) is a next-generation\ninterchange format for scientific data. This package contains the Python\nimplementation of the ASDF Standard.",
            "name": "py-asdf"
        },
        {
            "description": "The Astropy Project is a community effort to develop a single core\npackage for Astronomy in Python and foster interoperability between\nPython astronomy packages.",
            "name": "py-astropy"
        },
        {
            "description": "Manipulate JSON-like data with NumPy-like idioms.",
            "name": "py-awkward"
        },
        {
            "description": "Black is the uncompromising Python code formatter. By using it, you\nagree to cede control over minutiae of hand-formatting. In return, Black\ngives you speed, determinism, and freedom from pycodestyle nagging about\nformatting.",
            "name": "py-black"
        },
        {
            "description": "An easy whitelist-based HTML-sanitizing tool.",
            "name": "py-bleach"
        },
        {
            "description": "Statistical and novel interactive HTML plots for Python",
            "name": "py-bokeh"
        },
        {
            "description": "A simple, correct PEP517 package builder.",
            "name": "py-build"
        },
        {
            "description": "Cartopy - a cartographic python library with matplotlib support.",
            "name": "py-cartopy"
        },
        {
            "description": "CEKit is a Container image creation tool. CEKit helps to build container\nimages from image definition files with strong focus on modularity and\ncode reuse.",
            "name": "py-cekit"
        },
        {
            "description": "Colormaps for Oceanography.",
            "name": "py-cmocean"
        },
        {
            "description": "An integrated large-scale model training system with efficient\nparallelization techniques.",
            "name": "py-colossalai"
        },
        {
            "description": "CTGAN is a collection of Deep Learning based Synthetic Data Generators\nfor single table data, which are able to learn from real data and\ngenerate synthetic clones with high fidelity.",
            "name": "py-ctgan"
        },
        {
            "description": "Python Utilities and Autogenerated Classes for loading and parsing CWL\nv1.0, CWL v1.1, and CWL v1.2 documents.",
            "name": "py-cwl-utils"
        },
        {
            "description": "Python utilities to interact with Darshan log records of HPC\napplications.",
            "name": "py-darshan"
        },
        {
            "description": "Dask is a flexible parallel computing library for analytics.",
            "name": "py-dask"
        },
        {
            "description": "Scalable Machine Learning with Dask.",
            "name": "py-dask-ml"
        },
        {
            "description": "data distribution geared toward scientific datasets. DataLad makes data\nmanagement and data distribution more accessible. To do that, it stands\non the shoulders of Git and Git-annex to deliver a decentralized system\nfor data exchange. This includes automated ingestion of data from online\nportals and exposing it in readily usable form as Git(-annex)\nrepositories, so-called datasets. The actual data storage and permission\nmanagement, however, remains with the original data providers.",
            "name": "py-datalad"
        },
        {
            "description": "Datasets is a lightweight library providing two main features: one-line\ndataloaders for many public datasets and efficient data pre-processing.",
            "name": "py-datasets"
        },
        {
            "description": "Reorganising NIfTI files from dcm2niix into the Brain Imaging Data\nStructure.",
            "name": "py-dcm2bids"
        },
        {
            "description": "Scalable asynchronous neural architecture and hyperparameter search for\ndeep neural networks.",
            "name": "py-deephyper"
        },
        {
            "description": "DeepSpeed library. DeepSpeed enables world's most powerful language\nmodels like MT-530B and BLOOM. It is an easy-to-use deep learning\noptimization software suite that powers unprecedented scale and speed\nfor both training and inference.",
            "name": "py-deepspeed"
        },
        {
            "description": "The deprecation library provides a deprecated decorator and a\nfail_if_not_removed decorator for your tests.",
            "name": "py-deprecation"
        },
        {
            "description": "Wrapper providing support for deprecated aliases.",
            "name": "py-deprecation-alias"
        },
        {
            "description": "Diffusion MRI utilities in python. DIPY is the paragon 3D/4D+ imaging\nlibrary in Python. Contains generic methods for spatial normalization,\nsignal processing, machine learning, statistical analysis and\nvisualization of medical images. Additionally, it contains specialized\nmethods for computational anatomy including diffusion, perfusion and\nstructural imaging.",
            "name": "py-dipy"
        },
        {
            "description": "Parse and create Python distribution metadata.",
            "name": "py-dist-meta"
        },
        {
            "description": "Distributed scheduler for Dask",
            "name": "py-distributed"
        },
        {
            "description": "A Python library for the Docker Engine API.",
            "name": "py-docker"
        },
        {
            "description": "Dynamic version generation.",
            "name": "py-dunamai"
        },
        {
            "description": "Git for data scientists - manage your code and data together.",
            "name": "py-dvc"
        },
        {
            "description": "You can use fastai without any installation by using Google Colab. In\nfact, every page of this documentation is also available as an\ninteractive notebook - click \"Open in colab\" at the top of any page to\nopen it (be sure to change the Colab runtime to \"GPU\" to have it run\nfast!) See the fast.ai documentation on Using Colab for more\ninformation.",
            "name": "py-fastai"
        },
        {
            "description": "Python is a powerful, dynamic language. Rather than bake everything into\nthe language, it lets the programmer customize it to make it work for\nthem. fastcore uses this flexibility to add to Python features inspired\nby other languages we've loved, like multiple dispatch from Julia,\nmixins from Ruby, and currying, binding, and more from Haskell. It also\nadds some \"missing features\" and clean up some rough edges in the Python\nstandard library, such as simplifying parallel processing, and bringing\nideas from NumPy over to Python's list type.",
            "name": "py-fastcore"
        },
        {
            "description": "This package provides the official implementation of FlashAttention.",
            "name": "py-flash-attn"
        },
        {
            "description": "A Language Server for Fortran providing code completion, diagnostics,\nhovering and more.",
            "name": "py-fortls"
        },
        {
            "description": "Galaxy Generic Utilities",
            "name": "py-galaxy-util"
        },
        {
            "description": "GeoPandas is an open source project to make working with geospatial data\nin python easier. GeoPandas extends the datatypes used by pandas to\nallow spatial operations on geometric types. Geometric operations are\nperformed by shapely. Geopandas further depends on fiona for file access\nand descartes and matplotlib for plotting.",
            "name": "py-geopandas"
        },
        {
            "description": "Globus CLI is a standalone application that can be installed on the\nuser's machine and is used to access the Globus service. The CLI\nprovides an interface to Globus services from the shell, and is suited\nto both interactive and simple scripting use cases.",
            "name": "py-globus-cli"
        },
        {
            "description": "glymur contains a Python interface to the OpenJPEG library which allows\none to read and write JPEG 2000 files. glymur works on Python 3.7, 3.8,\n3.9, and 3.10.",
            "name": "py-glymur"
        },
        {
            "description": "Python bindings and ensemble workflow management for GROMACS. The\nGROMACS C++ API is affected by its package variants. You can specify a\nparticular GROMACS API by making the dependency variant explicit. E.g.\n``spack install gmxapi ^gromacs+mpi~double``",
            "name": "py-gmxapi"
        },
        {
            "description": "Python library for easily interacting with trained machine learning\nmodels",
            "name": "py-gradio-client"
        },
        {
            "description": "Project to generate recipes for conda packages.",
            "name": "py-grayskull"
        },
        {
            "description": "A Python interface for the netCDF4 file-format that reads and writes\nlocal or remote HDF5 files directly via h5py or h5pyd, without relying\non the Unidata netCDF library.",
            "name": "py-h5netcdf"
        },
        {
            "description": "Hatchling plugin to read project dependencies from requirements.txt",
            "name": "py-hatch-requirements-txt"
        },
        {
            "description": "Modern, extensible Python build backend.",
            "name": "py-hatchling"
        },
        {
            "description": "Validation schema and code for HEPdata submissions.",
            "name": "py-hepdata-validator"
        },
        {
            "description": "Horovod is a distributed deep learning training framework for\nTensorFlow, Keras, PyTorch, and Apache MXNet.",
            "name": "py-horovod"
        },
        {
            "description": "This library allows anyone to work with the Hub repositories: you can\nclone them, create them and upload your models to them.",
            "name": "py-huggingface-hub"
        },
        {
            "description": "A framework for elegantly configuring complex applications.",
            "name": "py-hydra-core"
        },
        {
            "description": "IPython Kernel for Jupyter",
            "name": "py-ipykernel"
        },
        {
            "description": "IPython's architecture for parallel and distributed computing.",
            "name": "py-ipyparallel"
        },
        {
            "description": "Jupyter Packaging Utilities.",
            "name": "py-jupyter-packaging"
        },
        {
            "description": "The Jupyter Server provides the backend (i.e. the core services, APIs,\nand REST endpoints) for Jupyter web applications like Jupyter notebook,\nJupyterLab, and Voila.",
            "name": "py-jupyter-server"
        },
        {
            "description": "JupyterLab is the next-generation web-based user interface for Project\nJupyter.",
            "name": "py-jupyterlab"
        },
        {
            "description": "A set of server components for JupyterLab and JupyterLab like\napplications",
            "name": "py-jupyterlab-server"
        },
        {
            "description": "Jupyter Notebooks as Markdown Documents, Julia, Python or R scripts",
            "name": "py-jupytext"
        },
        {
            "description": "Multi-backend Keras. Keras 3 is a new multi-backend implementation of\nthe Keras API, with support for TensorFlow, JAX, and PyTorch.",
            "name": "py-keras"
        },
        {
            "description": "Open Source Differentiable Computer Vision Library for PyTorch.",
            "name": "py-kornia"
        },
        {
            "description": "lazy_loader makes it easy to load subpackages and functions on demand.",
            "name": "py-lazy-loader"
        },
        {
            "description": "A python package for music and audio analysis.",
            "name": "py-librosa"
        },
        {
            "description": "The deep learning framework to pretrain, finetune and deploy AI models.",
            "name": "py-lightning"
        },
        {
            "description": "Fabric is the fast and lightweight way to scale PyTorch models without\nboilerplate.",
            "name": "py-lightning-fabric"
        },
        {
            "description": "LightningLite enables pure PyTorch users to scale their existing code on\nany kind of device while retaining full control over their own loops and\noptimization logic.",
            "name": "py-lightning-lite"
        },
        {
            "description": "Common Python utilities and GitHub Actions in Lightning Ecosystem",
            "name": "py-lightning-utilities"
        },
        {
            "description": "A module for connecting to mariaDB databases",
            "name": "py-mariadb"
        },
        {
            "description": "marshmallow is an ORM/ODM/framework-agnostic library for converting\ncomplex datatypes, such as objects, to and from native Python datatypes.",
            "name": "py-marshmallow"
        },
        {
            "description": "Matplotlib is a comprehensive library for creating static, animated, and\ninteractive visualizations in Python.",
            "name": "py-matplotlib"
        },
        {
            "description": "MDAnalysis is a Python toolkit to analyze molecular dynamics\ntrajectories generated by a wide range of popular simulation packages\nincluding DL_Poly, CHARMM, Amber, NAMD, LAMMPS, and Gromacs. (See the\nlists of supported trajectory formats and topology formats.)",
            "name": "py-mdanalysis"
        },
        {
            "description": "Meson Python build backend (PEP 517).",
            "name": "py-meson-python"
        },
        {
            "description": "MkDocs is a fast, simple and downright gorgeous static site generator\nthat's geared towards building project documentation.",
            "name": "py-mkdocs"
        },
        {
            "description": "MLflow: A Platform for ML Development and Productionization.",
            "name": "py-mlflow"
        },
        {
            "description": "MNE python project for MEG and EEG data analysis.",
            "name": "py-mne"
        },
        {
            "description": "Modin: Make your pandas code run faster by changing one line of code.",
            "name": "py-modin"
        },
        {
            "description": "Matplotlib styles for HEP",
            "name": "py-mplhep"
        },
        {
            "description": "MultiQC is a tool to aggregate bioinformatics results across many\nsamples into a single report. It is written in Python and contains\nmodules for a large number of common bioinformatics tools.",
            "name": "py-multiqc"
        },
        {
            "description": "Jupyter Notebook Conversion",
            "name": "py-nbconvert"
        },
        {
            "description": "Neo is a package for representing electrophysiology data in Python,\ntogether with support for reading a wide range of neurophysiology file\nformats",
            "name": "py-neo"
        },
        {
            "description": "Flexible metadata store for MLOps, built for research and production\nteams that run a lot of experiments.",
            "name": "py-neptune-client"
        },
        {
            "description": "Access a multitude of neuroimaging data formats",
            "name": "py-nibabel"
        },
        {
            "description": "Statistical learning for neuroimaging in Python.",
            "name": "py-nilearn"
        },
        {
            "description": "Neuroimaging in Python: Pipelines and Interfaces.",
            "name": "py-nipype"
        },
        {
            "description": "Common workflows for MRI (anatomical, functional, diffusion, etc)",
            "name": "py-niworkflows"
        },
        {
            "description": "Fast numerical expression evaluator for NumPy",
            "name": "py-numexpr"
        },
        {
            "description": "ONNX Runtime is a performance-focused complete scoring engine for Open\nNeural Network Exchange (ONNX) models, with an open extensible\narchitecture to continually address the latest developments in AI and\nDeep Learning. ONNX Runtime stays up to date with the ONNX standard with\ncomplete implementation of all ONNX operators, and supports all ONNX\nreleases (1.2+) with both future and backwards compatibility.",
            "name": "py-onnxruntime"
        },
        {
            "description": "This project provides classes and utility functions for working with\nread fast5 files. It provides an abstraction layer between the\nunderlying h5py library and the various concepts central to read fast5\nfiles, such as \"reads\", \"analyses\", \"analysis summaries\", and \"analysis\ndatasets\". Ideally all interaction with a read fast5 file should be\npossible via this API, without having to directly invoke the h5py\nlibrary.",
            "name": "py-ont-fast5-api"
        },
        {
            "description": "Optuna is an automatic hyperparameter optimization software framework,\nparticularly designed for machine learning. It features an imperative,\ndefine-by-run style user API. Thanks to our define-by-run API, the code\nwritten with Optuna enjoys high modularity, and the user of Optuna can\ndynamically construct the search spaces for the hyperparameters.",
            "name": "py-optuna"
        },
        {
            "description": "The oslo.utils library provides support for common utility type\nfunctions, such as encoding, exception handling, string manipulation,\nand time handling.",
            "name": "py-oslo-utils"
        },
        {
            "description": "A high level app and dashboarding solution for Python.",
            "name": "py-panel"
        },
        {
            "description": "PennyLane is a Python quantum machine learning library by Xanadu Inc.",
            "name": "py-pennylane"
        },
        {
            "description": "Petastorm is a library enabling the use of Parquet storage from\nTensorflow, Pytorch, and other Python-based ML training frameworks.",
            "name": "py-petastorm"
        },
        {
            "description": "Pint is a Python package to define, operate and manipulate physical\nquantities: the product of a numerical value and a unit of measurement.\nIt allows arithmetic operations between them and conversions from and to\ndifferent units.",
            "name": "py-pint"
        },
        {
            "description": "An interactive, browser-based graphing library for Python",
            "name": "py-plotly"
        },
        {
            "description": "Python dependency management and packaging made easy.",
            "name": "py-poetry"
        },
        {
            "description": "Pooch manages your Python library's sample data files: it automatically\ndownloads and stores them in a local directory, with support for\nversioning and corruption checks.",
            "name": "py-pooch"
        },
        {
            "description": "A clean, three-column, Bootstrap-based Sphinx theme by and for the\nPyData community.",
            "name": "py-pydata-sphinx-theme"
        },
        {
            "description": "PyERFA is the Python wrapper for the ERFA library (Essential Routines\nfor Fundamental Astronomy), a C library containing key algorithms for\nastronomy, which is based on the SOFA library published by the\nInternational Astronomical Union (IAU). All C routines are wrapped as\nNumpy universal functions, so that they can be called with scalar or\narray inputs.",
            "name": "py-pyerfa"
        },
        {
            "description": "A Python interface for the Generic Mapping Tools.",
            "name": "py-pygmt"
        },
        {
            "description": "This package provides python language bindings for the C++ library\npreCICE.",
            "name": "py-pyprecice"
        },
        {
            "description": "PEP 621 metadata parsing.",
            "name": "py-pyproject-metadata"
        },
        {
            "description": "Parser for 'pyproject.toml'",
            "name": "py-pyproject-parser"
        },
        {
            "description": "The PEP 517 compliant PyQt build system.",
            "name": "py-pyqt-builder"
        },
        {
            "description": "A Python validator for SHACL.",
            "name": "py-pyshacl"
        },
        {
            "description": "Python bindings for Qt.",
            "name": "py-pyside2"
        },
        {
            "description": "pytest: simple powerful testing with Python.",
            "name": "py-pytest"
        },
        {
            "description": "Pytest plugin with advanced doctest features.",
            "name": "py-pytest-doctestplus"
        },
        {
            "description": "Pytest plugin for controlling remote data access.",
            "name": "py-pytest-remotedata"
        },
        {
            "description": "PyTorch Lightning is the lightweight PyTorch wrapper for ML researchers.",
            "name": "py-pytorch-lightning"
        },
        {
            "description": "PyZMQ: Python bindings for zeromq.",
            "name": "py-pyzmq"
        },
        {
            "description": "QuTiP: The Quantum Toolbox in Python",
            "name": "py-qutip"
        },
        {
            "description": "The QuTiP quantum information processing package",
            "name": "py-qutip-qip"
        },
        {
            "description": "RADICAL Ensemble Toolkit is used for developing and executing large-\nscale ensemble-based workflows.",
            "name": "py-radical-entk"
        },
        {
            "description": "rasterio xarray extension.",
            "name": "py-rioxarray"
        },
        {
            "description": "Convert reStructured Text to PDF via ReportLab. The usual way of\ncreating PDF from reStructuredText is by going through LaTeX. This tool\nprovides an alternative by producing PDF directly using the ReportLab\nlibrary.",
            "name": "py-rst2pdf"
        },
        {
            "description": "Scanpy is a scalable toolkit for analyzing single-cell gene expression\ndata built jointly with anndata.",
            "name": "py-scanpy"
        },
        {
            "description": "scikit-build is an improved build system generator for CPython\nC/C++/Fortran/Cython extensions. It provides better support for\nadditional compilers, build systems, cross compilation, and locating\ndependencies and their associated build requirements. The scikit-build\npackage is fundamentally just glue between the setuptools Python module\nand CMake.",
            "name": "py-scikit-build"
        },
        {
            "description": "scikit-build-core is a doubly improved build system generator for\nCPython C/C++/Fortran/Cython extensions. It features several\nimprovements over the classic scikit-build build system generator.",
            "name": "py-scikit-build-core"
        },
        {
            "description": "Image processing algorithms for SciPy, including IO, morphology,\nfiltering, warping, color manipulation, object detection, etc.",
            "name": "py-scikit-image"
        },
        {
            "description": "This is a Python implementation of Seriation algorithm. Seriation is an\napproach for ordering elements in a set so that the sum of the\nsequential pairwise distances is minimal. We state this task as a\nTravelling Salesman Problem (TSP) and leverage the powerful Google's or-\ntools to do heavy-lifting. Since TSP is NP-hard, it is not possible to\ncalculate the precise solution for a big number of elements. However,\nthe or-tools' heuristics work very well in practice, and they are used\nin e.g. Google Maps.",
            "name": "py-seriate"
        },
        {
            "description": "Simplified packaging for pybind11-based C++ extensions",
            "name": "py-setuptools-cpp"
        },
        {
            "description": "Use git repo data for building a version number according PEP-440",
            "name": "py-setuptools-git-versioning"
        },
        {
            "description": "The blessed package to manage your versions by scm tags.",
            "name": "py-setuptools-scm"
        },
        {
            "description": "SHAP (SHapley Additive exPlanations): a unified approach to explain the\noutput of any machine learning model.",
            "name": "py-shap"
        },
        {
            "description": "Utilities for handling packages.",
            "name": "py-shippinglabel"
        },
        {
            "description": "A Python bindings generator for C/C++ libraries.",
            "name": "py-sip"
        },
        {
            "description": "Convert scikit-learn models to ONNX",
            "name": "py-skl2onnx"
        },
        {
            "description": "Sphinx Documentation Generator.",
            "name": "py-sphinx"
        },
        {
            "description": "A tool for authoring Sphinx themes with a simple (opinionated) workflow.",
            "name": "py-sphinx-theme-builder"
        },
        {
            "description": "Statistical computations and models for use with SciPy",
            "name": "py-statsmodels"
        },
        {
            "description": "The fastest way to build data apps in Python.",
            "name": "py-streamlit"
        },
        {
            "description": "Missing widgets and components for PyQt/PySide",
            "name": "py-superqt"
        },
        {
            "description": "PyTables is a package for managing hierarchical datasets and designed to\nefficiently and easily cope with extremely large amounts of data.",
            "name": "py-tables"
        },
        {
            "description": "The purpose of this package is to let researchers use a simple interface\nto log events within PyTorch (and then show visualization in\ntensorboard). This package currently supports logging scalar, image,\naudio, histogram, text, embedding, and the route of back-propagation.",
            "name": "py-tensorboardx"
        },
        {
            "description": "TensorFlow is an open source machine learning framework for everyone.",
            "name": "py-tensorflow"
        },
        {
            "description": "A PyTorch Extension: Tools for easy mixed precision and distributed\ntraining in Pytorch",
            "name": "py-torch-nvidia-apex"
        },
        {
            "description": "TorchGeo: datasets, samplers, transforms, and pre-trained models for\ngeospatial data.",
            "name": "py-torchgeo"
        },
        {
            "description": "Machine learning metrics for distributed, scalable PyTorch applications.",
            "name": "py-torchmetrics"
        },
        {
            "description": "tox is a generic virtualenv management and test command line tool.",
            "name": "py-tox"
        },
        {
            "description": "A library for accelerating Transformer models on NVIDIA GPUs, including\nfp8 precision on Hopper GPUs.",
            "name": "py-transformer-engine"
        },
        {
            "description": "State-of-the-art Natural Language Processing for TensorFlow 2.0 and\nPyTorch",
            "name": "py-transformers"
        },
        {
            "description": "Experiments with new file format for tractography.",
            "name": "py-trx-python"
        },
        {
            "description": "ROOT I/O in pure Python and NumPy. Uproot is a reader and a writer of\nthe ROOT file format using only Python and Numpy. Unlike the standard\nC++ ROOT implementation, Uproot is only an I/O library, primarily\nintended to stream data into machine learning libraries in Python.\nUnlike PyROOT and root_numpy, Uproot does not depend on C++ ROOT.\nInstead, it uses Numpy to cast blocks of data from the ROOT file as\nNumpy arrays.",
            "name": "py-uproot"
        },
        {
            "description": "Vector classes and utilities",
            "name": "py-vector"
        },
        {
            "description": "Python library for parsing and validating HTTP request objects, with\nbuilt-in support for popular web frameworks, including Flask, Django,\nBottle, Tornado, Pyramid, Falcon, and aiohttp.",
            "name": "py-webargs"
        },
        {
            "description": "A simple Python wheel builder for simple projects.",
            "name": "py-whey"
        },
        {
            "description": "N-D labeled arrays and datasets in Python",
            "name": "py-xarray"
        },
        {
            "description": "Volumetric Data Analysis yt is a python package for analyzing and\nvisualizing volumetric, multi-resolution data from astrophysical\nsimulations, radio telescopes, and a burgeoning interdisciplinary\ncommunity.",
            "name": "py-yt"
        },
        {
            "description": "Workflow management system to create reproducible and scalable data\nanalyses.",
            "name": "snakemake"
        }
    ],
    "description": "Core utilities for Python packages.\n",
    "homepage": "https://github.com/pypa/packaging",
    "latest_version": "23.1",
    "maintainers": [],
    "name": "py-packaging",
    "patches": [],
    "resources": [],
    "variants": [
        {
            "default": "python_pip",
            "description": "Build systems supported by the package",
            "name": "build_system"
        }
    ],
    "versions": [
        {
            "name": "16.8",
            "sha256": "5d50835fdf0a7edf0b55e311b7c887786504efea1177abd7e69329a8e5ea619e"
        },
        {
            "name": "17.1",
            "sha256": "f019b770dd64e585a99714f1fd5e01c7a8f11b45635aa953fd41c689a657375b"
        },
        {
            "name": "19.0",
            "sha256": "0c98a5d0be38ed775798ece1b9727178c4469d9c3b4ada66e8e6b7849f8732af"
        },
        {
            "name": "19.1",
            "sha256": "c491ca87294da7cc01902edbe30a5bc6c4c28172b5138ab4e4aa1b9d7bfaeafe"
        },
        {
            "name": "19.2",
            "sha256": "28b924174df7a2fa32c1953825ff29c61e2f5e082343165438812f00d3a7fc47"
        },
        {
            "name": "20.9",
            "sha256": "5b327ac1320dc863dca72f4514ecc086f31186744b84a230374cc1fd776feae5"
        },
        {
            "name": "21.0",
            "sha256": "7dc96269f53a4ccec5c0670940a4281106dd0bb343f47b7471f779df49c2fbe7"
        },
        {
            "name": "21.3",
            "sha256": "dd47c42927d89ab911e606518907cc2d3a1f38bbd026385970643f9c5b8ecfeb"
        },
        {
            "name": "23.0",
            "sha256": "b6ad297f8907de0fa2fe1ccbd26fdaf387f5f47c7275fedf8cce89f99446cf97"
        },
        {
            "name": "23.1",
            "sha256": "a392980d2b6cffa644431898be54b0045151319d1e7ec34f0cfed48767dd334f"
        }
    ]
}