{
    "name": "r-broom",
    "aliases": [],
    "versions": [
        {
            "name": "0.7.12",
            "sha256": "04fac12b2546689603a474fb92a0572f4241ae87b51b21b0808814a489227bd9"
        },
        {
            "name": "0.7.11",
            "sha256": "9e3999d2635ac72e8f4c3a81decd50ee5d464c001c155375b5a970a629ba2e19"
        },
        {
            "name": "0.7.10",
            "sha256": "129fd5a53abef7f42b7efac6c64ebd71269b136aa648846d640562357927464f"
        },
        {
            "name": "0.7.9",
            "sha256": "1d5695f97b378b2b77fb8f64a4a54b72b278913d4adf9d61a7ca4f38a1c7c5fc"
        },
        {
            "name": "0.7.3",
            "sha256": "de5650e46ca6884876b63bc401d22bef9eace671147774466406d43324aebc2f"
        },
        {
            "name": "0.5.2",
            "sha256": "16af7b446b24bc14461efbda9bea1521cf738c778c5e48fcc7bad45660a4ac62"
        },
        {
            "name": "0.5.1",
            "sha256": "da9e6bf7cb8f960b83309cf107743976cc32b54524675f6471982abe3d1aae2e"
        },
        {
            "name": "0.4.2",
            "sha256": "9f409413623cf25e7110452e6215353af5114f7044d73af182bd6c10971c5a44"
        }
    ],
    "build_system": "RPackage",
    "conflicts": [],
    "variants": [],
    "homepage": "https://cloud.r-project.org/package=broom",
    "maintainers": [
        "glennpj"
    ],
    "patches": [],
    "resources": [],
    "description": "Convert Statistical Objects into Tidy Tibbles. Summarizes key\ninformation about statistical objects in tidy tibbles. This makes it\neasy to report results, create plots and consistently work with large\nnumbers of models at once. Broom provides three verbs that each provide\ndifferent types of information about a model. tidy() summarizes\ninformation about model components such as coefficients of a regression.\nglance() reports information about an entire model, such as goodness of\nfit measures like AIC and BIC. augment() adds information about\nindividual observations to a dataset, such as fitted values or influence\nmeasures.\n",
    "dependencies": [
        {
            "name": "r",
            "description": "R is 'GNU S', a freely available language and environment for\nstatistical computing and graphics which provides a wide variety of\nstatistical and graphical techniques: linear and nonlinear modelling,\nstatistical tests, time series analysis, classification, clustering,\netc. Please consult the R project homepage for further information."
        },
        {
            "name": "r-backports",
            "description": "Reimplementations of Functions Introduced Since R-3.0.0. Functions\nintroduced or changed since R v3.0.0 are re-implemented in this package.\nThe backports are conditionally exported in order to let R resolve the\nfunction name to either the implemented backport, or the respective base\nversion, if available. Package developers can make use of new functions\nor arguments by selectively importing specific backports to support\nolder installations."
        },
        {
            "name": "r-dplyr",
            "description": "A Grammar of Data Manipulation. A fast, consistent tool for working with\ndata frame like objects, both in memory and out of memory."
        },
        {
            "name": "r-ellipsis",
            "description": "Tools for Working with ... The ellipsis is a powerful tool for extending\nfunctions. Unfortunately this power comes at a cost: misspelled\narguments will be silently ignored. The ellipsis package provides a\ncollection of functions to catch problems and alert the user."
        },
        {
            "name": "r-generics",
            "description": "Common S3 Generics not Provided by Base R Methods Related to Model\nFitting. In order to reduce potential package dependencies and\nconflicts, generics provides a number of commonly used S3 generics."
        },
        {
            "name": "r-glue",
            "description": "Interpreted String Literals. An implementation of interpreted string\nliterals, inspired by Python's Literal String Interpolation\n<https://www.python.org/dev/peps/pep-0498/> and Docstrings\n<https://www.python.org/dev/peps/pep-0257/> and Julia's Triple-Quoted\nString Literals <https://docs.julialang.org/en/stable/\nmanual/strings/#triple-quoted-string-literals>."
        },
        {
            "name": "r-purrr",
            "description": "Functional Programming Tools. A complete and consistent functional\nprogramming toolkit for R."
        },
        {
            "name": "r-rlang",
            "description": "Functions for Base Types and Core R and 'Tidyverse' Features. A toolbox\nfor working with base types, core R features like the condition system,\nand core 'Tidyverse' features like tidy evaluation."
        },
        {
            "name": "r-stringr",
            "description": "Simple, Consistent Wrappers for Common String Operations. A consistent,\nsimple and easy to use set of wrappers around the fantastic 'stringi'\npackage. All function and argument names (and positions) are consistent,\nall functions deal with \"NA\"'s and zero length vectors in the same way,\nand the output from one function is easy to feed into the input of\nanother."
        },
        {
            "name": "r-tibble",
            "description": "Simple Data Frames. Provides a 'tbl_df' class (the 'tibble') that\nprovides stricter checking and better formatting than the traditional\ndata frame."
        },
        {
            "name": "r-tidyr",
            "description": "Tidy Messy Data. Tools to help to create tidy data, where each column is\na variable, each row is an observation, and each cell contains a single\nvalue. 'tidyr' contains tools for changing the shape (pivoting) and\nhierarchy (nesting and 'unnesting') of a dataset, turning deeply nested\nlists into rectangular data frames ('rectangling'), and extracting\nvalues out of string columns. It also includes tools for working with\nmissing values (both implicit and explicit)."
        },
        {
            "name": "r-ggplot2",
            "description": "Create Elegant Data Visualisations Using the Grammar of Graphics. A\nsystem for 'declaratively' creating graphics, based on \"The Grammar of\nGraphics\". You provide the data, tell 'ggplot2' how to map variables to\naesthetics, what graphical primitives to use, and it takes care of the\ndetails."
        },
        {
            "name": "r-plyr",
            "description": "Tools for Splitting, Applying and Combining Data. A set of tools that\nsolves a common set of problems: you need to break a big problem down\ninto manageable pieces, operate on each piece and then put all the\npieces back together. For example, you might want to fit a model to each\nspatial location or time point in your study, summarise data by panels\nor collapse high-dimensional arrays to simpler summary statistics. The\ndevelopment of 'plyr' has been generously supported by 'Becton\nDickinson'."
        },
        {
            "name": "r-psych",
            "description": "Procedures for Psychological, Psychometric, and Personality Research. A\ngeneral purpose toolbox for personality, psychometric theory and\nexperimental psychology. Functions are primarily for multivariate\nanalysis and scale construction using factor analysis, principal\ncomponent analysis, cluster analysis and reliability analysis, although\nothers provide basic descriptive statistics. Item Response Theory is\ndone using factor analysis of tetrachoric and polychoric correlations.\nFunctions for analyzing data at multiple levels include within and\nbetween group statistics, including correlations and factor analysis.\nFunctions for simulating and testing particular item and test structures\nare included. Several functions serve as a useful front end for\nstructural equation modeling. Graphical displays of path diagrams,\nfactor analysis and structural equation models are created using basic\ngraphics. Some of the functions are written to support a book on\npsychometric theory as well as publications in personality research. For\nmore information, see the <http://personality-project.org/r> web page."
        },
        {
            "name": "r-reshape2",
            "description": "Flexibly Reshape Data: A Reboot of the Reshape Package. Flexibly\nrestructure and aggregate data using just two functions: melt and dcast\n(or acast)."
        },
        {
            "name": "r-nlme",
            "description": "Linear and Nonlinear Mixed Effects Models. Fit and compare Gaussian\nlinear and nonlinear mixed-effects models."
        }
    ],
    "dependent_to": [
        {
            "name": "r-modelr",
            "description": "Modelling Functions that Work with the Pipe. Functions for modelling\nthat help you seamlessly integrate modelling into a pipeline of data\nmanipulation and visualisation."
        },
        {
            "name": "r-tidyverse",
            "description": "Easily Install and Load the 'Tidyverse'. The 'tidyverse' is a set of\npackages that work in harmony because they share common data\nrepresentations and 'API' design. This package is designed to make it\neasy to install and load multiple 'tidyverse' packages in a single step.\nLearn more about the 'tidyverse' at <https://tidyverse.org>."
        },
        {
            "name": "r-pbkrtest",
            "description": "Parametric Bootstrap, Kenward-Roger and Satterthwaite Based Methods for\nTest in Mixed Models. Test in mixed effects models. Attention is on\nmixed effects models as implemented in the 'lme4' package. For linear\nmixed models, this package implements (1) a parametric bootstrap test,\n(2) a Kenward-Roger-typ modification of F-tests for linear mixed effects\nmodels and (3) a Satterthwaite-type modification of F-tests for linear\nmixed effects models. The package also implements a parametric bootstrap\ntest for generalized linear mixed models. The facilities of the package\nare documented in the paper by Halehoh and Hojsgaard, (2012,\n<doi:10.18637/jss.v059.i09>). Please see 'citation(\"pbkrtest\")' for\ncitation details."
        },
        {
            "name": "r-mice",
            "description": "Multivariate Imputation by Chained Equations. Multiple imputation using\nFully Conditional Specification (FCS) implemented by the MICE algorithm\nas described in Van Buuren and Groothuis-Oudshoorn (2011)\n<doi:10.18637/jss.v045.i03>. Each variable has its own imputation model.\nBuilt-in imputation models are provided for continuous data (predictive\nmean matching, normal), binary data (logistic regression), unordered\ncategorical data (polytomous logistic regression) and ordered\ncategorical data (proportional odds). MICE can also impute continuous\ntwo-level data (normal model, pan, second-level variables). Passive\nimputation can be used to maintain consistency between variables.\nVarious diagnostic plots are available to inspect the quality of the\nimputations."
        },
        {
            "name": "r-rstatix",
            "description": "Pipe-Friendly Framework for Basic Statistical Tests. Provides a simple\nand intuitive pipe-friendly framework, coherent with the 'tidyverse'\ndesign philosophy, for performing basic statistical tests, including\nt-test, Wilcoxon test, ANOVA, Kruskal-Wallis and correlation analyses.\nThe output of each test is automatically transformed into a tidy data\nframe to facilitate visualization. Additional functions are available\nfor reshaping, reordering, manipulating and visualizing correlation\nmatrix. Functions are also included to facilitate the analysis of\nfactorial experiments, including purely 'within-Ss' designs (repeated\nmeasures), purely 'between-Ss' designs, and mixed 'within-and-between-\nSs' designs. It's also possible to compute several effect size metrics,\nincluding \"eta squared\" for ANOVA, \"Cohen's d\" for t-test and 'Cramer V'\nfor the association between categorical variables. The package contains\nhelper functions for identifying univariate and multivariate outliers,\nassessing normality and homogeneity of variances."
        }
    ]
}