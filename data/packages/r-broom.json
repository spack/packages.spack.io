{
    "name": "r-broom",
    "aliases": [],
    "versions": [
        {
            "name": "0.7.3",
            "sha256": "de5650e46ca6884876b63bc401d22bef9eace671147774466406d43324aebc2f"
        },
        {
            "name": "0.5.2",
            "sha256": "16af7b446b24bc14461efbda9bea1521cf738c778c5e48fcc7bad45660a4ac62"
        },
        {
            "name": "0.5.1",
            "sha256": "da9e6bf7cb8f960b83309cf107743976cc32b54524675f6471982abe3d1aae2e"
        },
        {
            "name": "0.4.2",
            "sha256": "9f409413623cf25e7110452e6215353af5114f7044d73af182bd6c10971c5a44"
        }
    ],
    "build_system": "RPackage",
    "conflicts": [],
    "variants": [],
    "homepage": "http://github.com/tidyverse/broom",
    "maintainers": [
        "glennpj"
    ],
    "patches": [],
    "resources": [],
    "description": "Convert Statistical Objects into Tidy Tibbles Summarizes key information\nabout statistical objects in tidy tibbles. This makes it easy to report\nresults, create plots and consistently work with large numbers of models\nat once. Broom provides three verbs that each provide different types of\ninformation about a model. tidy() summarizes information about model\ncomponents such as coefficients of a regression. glance() reports\ninformation about an entire model, such as goodness of fit measures like\nAIC and BIC. augment() adds information about individual observations to\na dataset, such as fitted values or influence measures.\n",
    "dependencies": [
        {
            "name": "r",
            "description": "R is 'GNU S', a freely available language and environment for\nstatistical computing and graphics which provides a wide variety of\nstatistical and graphical techniques: linear and nonlinear modelling,\nstatistical tests, time series analysis, classification, clustering,\netc. Please consult the R project homepage for further information."
        },
        {
            "name": "r-backports",
            "description": "Reimplementations of Functions Introduced Since R-3.0.0 Functions\nintroduced or changed since R v3.0.0 are re-implemented in this package.\nThe backports are conditionally exported in order to let R resolve the\nfunction name to either the implemented backport, or the respective base\nversion, if available. Package developers can make use of new functions\nor arguments by selectively importing specific backports to support\nolder installations."
        },
        {
            "name": "r-dplyr",
            "description": "A Grammar of Data Manipulation A fast, consistent tool for working with\ndata frame like objects, both in memory and out of memory."
        },
        {
            "name": "r-ellipsis",
            "description": "Tools for Working with ... The ellipsis is a powerful tool for extending\nfunctions. Unfortunately this power comes at a cost: misspelled\narguments will be silently ignored. The ellipsis package provides a\ncollection of functions to catch problems and alert the user."
        },
        {
            "name": "r-generics",
            "description": "Common S3 Generics not Provided by Base R Methods Related to Model\nFitting In order to reduce potential package dependencies and conflicts,\ngenerics provides a number of commonly used S3 generics."
        },
        {
            "name": "r-glue",
            "description": "Interpreted String Literals An implementation of interpreted string\nliterals, inspired by Python's Literal String Interpolation\n<https://www.python.org/dev/peps/pep-0498/> and Docstrings\n<https://www.python.org/dev/peps/pep-0257/> and Julia's Triple-Quoted\nString Literals <https://docs.julialang.org/en/stable/\nmanual/strings/#triple-quoted-string-literals>."
        },
        {
            "name": "r-purrr",
            "description": "A complete and consistent functional programming toolkit for R."
        },
        {
            "name": "r-rlang",
            "description": "Functions for Base Types and Core R and 'Tidyverse' Features A toolbox\nfor working with base types, core R features like the condition system,\nand core 'Tidyverse' features like tidy evaluation."
        },
        {
            "name": "r-stringr",
            "description": "A consistent, simple and easy to use set of wrappers around the\nfantastic 'stringi' package. All function and argument names (and\npositions) are consistent, all functions deal with \"NA\"'s and zero\nlength vectors in the same way, and the output from one function is easy\nto feed into the input of another."
        },
        {
            "name": "r-tibble",
            "description": "Simple Data Frames Provides a 'tbl_df' class (the 'tibble') that\nprovides stricter checking and better formatting than the traditional\ndata frame."
        },
        {
            "name": "r-tidyr",
            "description": "Tidy Messy Data Tools to help to create tidy data, where each column is\na variable, each row is an observation, and each cell contains a single\nvalue. 'tidyr' contains tools for changing the shape (pivoting) and\nhierarchy (nesting and 'unnesting') of a dataset, turning deeply nested\nlists into rectangular data frames ('rectangling'), and extracting\nvalues out of string columns. It also includes tools for working with\nmissing values (both implicit and explicit)."
        },
        {
            "name": "r-plyr",
            "description": "Tools for Splitting, Applying and Combining Data A set of tools that\nsolves a common set of problems: you need to break a big problem down\ninto manageable pieces, operate on each piece and then put all the\npieces back together. For example, you might want to fit a model to each\nspatial location or time point in your study, summarise data by panels\nor collapse high-dimensional arrays to simpler summary statistics. The\ndevelopment of 'plyr' has been generously supported by 'Becton\nDickinson'."
        },
        {
            "name": "r-psych",
            "description": "Procedures for Psychological, Psychometric, and Personality Research A\ngeneral purpose toolbox for personality, psychometric theory and\nexperimental psychology. Functions are primarily for multivariate\nanalysis and scale construction using factor analysis, principal\ncomponent analysis, cluster analysis and reliability analysis, although\nothers provide basic descriptive statistics. Item Response Theory is\ndone using factor analysis of tetrachoric and polychoric correlations.\nFunctions for analyzing data at multiple levels include within and\nbetween group statistics, including correlations and factor analysis.\nFunctions for simulating and testing particular item and test structures\nare included. Several functions serve as a useful front end for\nstructural equation modeling. Graphical displays of path diagrams,\nfactor analysis and structural equation models are created using basic\ngraphics. Some of the functions are written to support a book on\npsychometric theory as well as publications in personality research. For\nmore information, see the <http://personality-project.org/r> web page."
        },
        {
            "name": "r-reshape2",
            "description": "Flexibly Reshape Data: A Reboot of the Reshape Package Flexibly\nrestructure and aggregate data using just two functions: melt and dcast\n(or acast)."
        },
        {
            "name": "r-nlme",
            "description": "Fit and compare Gaussian linear and nonlinear mixed-effects models Fit\nand compare Gaussian linear and nonlinear mixed-effects models."
        }
    ],
    "dependent_to": [
        {
            "name": "r-mice",
            "description": "Multivariate Imputation by Chained Equations Multiple imputation using\nFully Conditional Specification (FCS) implemented by the MICE algorithm\nas described in Van Buuren and Groothuis-Oudshoorn (2011)\n<doi:10.18637/jss.v045.i03>. Each variable has its own imputation model.\nBuilt-in imputation models are provided for continuous data (predictive\nmean matching, normal), binary data (logistic regression), unordered\ncategorical data (polytomous logistic regression) and ordered\ncategorical data (proportional odds). MICE can also impute continuous\ntwo-level data (normal model, pan, second-level variables). Passive\nimputation can be used to maintain consistency between variables.\nVarious diagnostic plots are available to inspect the quality of the\nimputations."
        },
        {
            "name": "r-modelr",
            "description": "Modelling Functions that Work with the Pipe Functions for modelling that\nhelp you seamlessly integrate modelling into a pipeline of data\nmanipulation and visualisation."
        },
        {
            "name": "r-tidyverse",
            "description": "Easily Install and Load the 'Tidyverse' The 'tidyverse' is a set of\npackages that work in harmony because they share common data\nrepresentations and 'API' design. This package is designed to make it\neasy to install and load multiple 'tidyverse' packages in a single step.\nLearn more about the 'tidyverse' at <https://tidyverse.org>."
        },
        {
            "name": "r-pbkrtest",
            "description": "Parametric Bootstrap, Kenward-Roger and Satterthwaite Based Methods for\nTest in Mixed Models Test in mixed effects models. Attention is on mixed\neffects models as implemented in the 'lme4' package. For linear mixed\nmodels, this package implements (1) a parametric bootstrap test, (2) a\nKenward-Roger-typ modification of F-tests for linear mixed effects\nmodels and (3) a Satterthwaite-type modification of F-tests for linear\nmixed effects models. The package also implements a parametric bootstrap\ntest for generalized linear mixed models. The facilities of the package\nare documented in the paper by Halehoh and Hojsgaard, (2012,\n<doi:10.18637/jss.v059.i09>). Please see 'citation(\"pbkrtest\")' for\ncitation details."
        },
        {
            "name": "r-rstatix",
            "description": "Pipe-Friendly Framework for Basic Statistical Tests Provides a simple\nand intuitive pipe-friendly framework, coherent with the 'tidyverse'\ndesign philosophy, for performing basic statistical tests, including\nt-test, Wilcoxon test, ANOVA, Kruskal-Wallis and correlation analyses.\nThe output of each test is automatically transformed into a tidy data\nframe to facilitate visualization. Additional functions are available\nfor reshaping, reordering, manipulating and visualizing correlation\nmatrix. Functions are also included to facilitate the analysis of\nfactorial experiments, including purely 'within-Ss' designs (repeated\nmeasures), purely 'between-Ss' designs, and mixed 'within-and-between-\nSs' designs. It's also possible to compute several effect size metrics,\nincluding \"eta squared\" for ANOVA, \"Cohen's d\" for t-test and 'Cramer V'\nfor the association between categorical variables. The package contains\nhelper functions for identifying univariate and multivariate outliers,\nassessing normality and homogeneity of variances."
        }
    ]
}