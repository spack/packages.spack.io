{
    "aliases": [],
    "build_system": "PythonPackage",
    "conflicts": [
        {
            "description": "py-numpy: NumPy requires GCC >= 4.8",
            "name": "%gcc@:4.7",
            "spec": ""
        },
        {
            "description": null,
            "name": "%gcc@11",
            "spec": "@1.20:1.22.3"
        },
        {
            "description": null,
            "name": "%gcc@11:",
            "spec": "@1.21.0"
        },
        {
            "description": null,
            "name": "%intel",
            "spec": "@1.23.0:1.23.3"
        },
        {
            "description": null,
            "name": "%oneapi",
            "spec": "@1.23.0:1.23.3"
        },
        {
            "description": "py-numpy: NumPy requires GCC >= 6.5",
            "name": "%gcc@:6.4",
            "spec": "@1.23:"
        },
        {
            "description": null,
            "name": "%gcc@11",
            "spec": "@1.25"
        },
        {
            "description": "py-numpy: NumPy requires GCC >= 8.4",
            "name": "%gcc@:8.3",
            "spec": "@1.26:"
        },
        {
            "description": "py-numpy: NumPy requires at least vc142 (default with Visual Studio 2019) when building with MSVC",
            "name": "%msvc@:19.19",
            "spec": "@1.26:"
        },
        {
            "description": null,
            "name": "%oneapi",
            "spec": "@2:"
        },
        {
            "description": null,
            "name": "%nvhpc",
            "spec": "@:1.19"
        }
    ],
    "dependencies": [
        {
            "description": "Lightweight but flexible shim designed to rectify the incompatibilities\nbetween the Accelerate/vecLib BLAS and LAPACK libraries shipped with\nmacOS and FORTRAN code compiled with modern compilers such as GNU\nFortran.",
            "name": "blas"
        },
        {
            "description": "The NVIDIA HPC SDK is a comprehensive suite of compilers, libraries and\ntools essential to maximizing developer productivity and the performance\nand portability of HPC applications. The NVIDIA HPC SDK C, C++, and\nFortran compilers support GPU acceleration of HPC modeling and\nsimulation applications with standard C++ and Fortran, OpenACC\ndirectives, and CUDA. GPU-accelerated math libraries maximize\nperformance on common HPC algorithms, and optimized communications\nlibraries enable standards-based multi-GPU and scalable systems\nprogramming. Performance profiling and debugging tools simplify porting\nand optimization of HPC applications.",
            "name": "c"
        },
        {
            "description": "The NVIDIA HPC SDK is a comprehensive suite of compilers, libraries and\ntools essential to maximizing developer productivity and the performance\nand portability of HPC applications. The NVIDIA HPC SDK C, C++, and\nFortran compilers support GPU acceleration of HPC modeling and\nsimulation applications with standard C++ and Fortran, OpenACC\ndirectives, and CUDA. GPU-accelerated math libraries maximize\nperformance on common HPC algorithms, and optimized communications\nlibraries enable standards-based multi-GPU and scalable systems\nprogramming. Performance profiling and debugging tools simplify porting\nand optimization of HPC applications.",
            "name": "cxx"
        },
        {
            "description": "Lightweight but flexible shim designed to rectify the incompatibilities\nbetween the Accelerate/vecLib BLAS and LAPACK libraries shipped with\nmacOS and FORTRAN code compiled with modern compilers such as GNU\nFortran.",
            "name": "lapack"
        },
        {
            "description": "Ninja is a small build system with a focus on speed. It differs from\nother build systems in two major respects: it is designed to have its\ninput files generated by a higher-level build system, and it is designed\nto run builds as fast as possible.",
            "name": "ninja"
        },
        {
            "description": "pkgconf is a program which helps to configure compiler and linker flags\nfor development frameworks. It is similar to pkg-config from\nfreedesktop.org, providing additional functionality while also\nmaintaining compatibility.",
            "name": "pkgconfig"
        },
        {
            "description": "Cross-platform colored terminal text.",
            "name": "py-colorama"
        },
        {
            "description": "The Cython compiler for writing C extensions for the Python language.",
            "name": "py-cython"
        },
        {
            "description": "A library for property based testing.",
            "name": "py-hypothesis"
        },
        {
            "description": "Meson Python build backend (PEP 517).",
            "name": "py-meson-python"
        },
        {
            "description": "The PyPA recommended tool for installing Python packages.",
            "name": "py-pip"
        },
        {
            "description": "PEP 621 metadata parsing.",
            "name": "py-pyproject-metadata"
        },
        {
            "description": "pytest: simple powerful testing with Python.",
            "name": "py-pytest"
        },
        {
            "description": "A Python utility that aids in the process of downloading, building,\nupgrading, installing, and uninstalling Python packages.",
            "name": "py-setuptools"
        },
        {
            "description": "Tomli is a Python library for parsing TOML. Tomli is fully compatible\nwith TOML v1.0.0.",
            "name": "py-tomli"
        },
        {
            "description": "The typing_extensions module contains both backports of these changes as\nwell as experimental types that will eventually be added to the typing\nmodule, such as Protocol (see PEP 544 for details about protocols and\nstatic duck typing).",
            "name": "py-typing-extensions"
        },
        {
            "description": "A built-package format for Python.",
            "name": "py-wheel"
        },
        {
            "description": "The Python programming language.",
            "name": "python"
        },
        {
            "description": "A Spack managed Python virtual environment",
            "name": "python-venv"
        }
    ],
    "dependent_to": [
        {
            "description": "The Adaptable Input Output System version 2, developed in the Exascale\nComputing Program",
            "name": "adios2"
        },
        {
            "description": "Akantu means a little element in Kinyarwanda, a Bantu language. From\nnow on it is also an opensource object-oriented Finite Element library\nwhich has the ambition to be generic and efficient.",
            "name": "akantu"
        },
        {
            "description": "The ALPS project (Algorithms and Libraries for Physics Simulations)\naims at providing generic parallel algorithms for classical and quantum\nlattice models and provides utility classes and algorithm for many\nothers.",
            "name": "alps"
        },
        {
            "description": "AmberTools is a free, useful standalone package and a prerequisite for\ninstalling Amber itself. The AmberTools suite is free of charge, and its\ncomponents are mostly released under the GNU General Public License\n(GPL). A few components are included that are in the public domain or\nwhich have other, open-source, licenses. The libsander and libpbsa\nlibraries use the LGPL license.",
            "name": "ambertools"
        },
        {
            "description": "AMR-Wind is a massively parallel, block-structured adaptive-mesh,\nincompressible flow sover for wind turbine and wind farm simulations.",
            "name": "amr-wind"
        },
        {
            "description": "The AOCL Data Analytics Library (AOCL-DA) is a data analytics library\nproviding optimized building blocks for data analysis. It is written\nwith a C-compatible interface to make it as seamless as possible to\nintegrate with the library from whichever programming language you are\nusing. The intended workflow for using the library is as follows: \u2022 load\ndata from memory by reading CSV files or using the in-built da_datastore\nobject \u2022 preprocess the data by removing missing values, standardizing,\nand selecting certain subsets of the data, before extracting contiguous\narrays of data from the da_datastore objects \u2022 data processing (e.g.\nprincipal component analysis, linear model fitting, etc.) C++ example\nprograms can be found in the examples folder of your installation.",
            "name": "aocl-da"
        },
        {
            "description": "Arbor is a high-performance library for computational neuroscience\nsimulations.",
            "name": "arbor"
        },
        {
            "description": "A cross-language development platform for in-memory data. This package\ncontains the C++ bindings.",
            "name": "arrow"
        },
        {
            "description": "Ascent is an open source many-core capable lightweight in situ\nvisualization and analysis infrastructure for multi-physics HPC\nsimulations.",
            "name": "ascent"
        },
        {
            "description": "ASDF - Advanced Scientific Data Format, a C++ implementation",
            "name": "asdf-cxx"
        },
        {
            "description": "BART: Toolbox for Computational Magnetic Resonance Imaging",
            "name": "bart"
        },
        {
            "description": "BerkeleyGW is a many-body perturbation theory code for excited states,\nusing the GW method and the GW plus Bethe-Salpeter equation (GW-BSE)\nmethod to solve respectively for quasiparticle excitations and optical\nproperties of materials.",
            "name": "berkeleygw"
        },
        {
            "description": "Library for automatic acceleration of array operations",
            "name": "bohrium"
        },
        {
            "description": "Boost provides free peer-reviewed portable C++ source libraries,\nemphasizing libraries that work well with the C++ Standard Library.\nBoost libraries are intended to be widely useful, and usable across a\nbroad spectrum of applications. The Boost license encourages both\ncommercial and non-commercial use.",
            "name": "boost"
        },
        {
            "description": "The NOAA bufr library contains subroutines, functions and other\nutilities that can be used to read (decode) and write (encode) data in\nBUFR, which is a WMO standard format for the exchange of meteorological\ndata. This is part of the NCEPLIBS project. The library also includes a\nPython interface.",
            "name": "bufr"
        },
        {
            "description": "Caffe is a deep learning framework made with expression, speed, and\nmodularity in mind. It is developed by the Berkeley Vision and Learning\nCenter (BVLC) and by community contributors.",
            "name": "caffe"
        },
        {
            "description": "CallFlow is an interactive visual analysis tool that provides a high-\nlevel overview of CCTs together with semantic refinement operations to\nprogressively explore the CCTs.",
            "name": "callflow"
        },
        {
            "description": "Cantera is a suite of object-oriented software tools for problems\ninvolving chemical kinetics, thermodynamics, and/or transport processes.",
            "name": "cantera"
        },
        {
            "description": "A suite of c++ libraries for radio astronomy data processing.",
            "name": "casacore"
        },
        {
            "description": "A generalist algorithm for cell and nucleus segmentation that can be\noptimized for your own data",
            "name": "cellpose"
        },
        {
            "description": "Climate Model Output Rewriter is used to produce CF-compliant netCDF\nfiles. The structure of the files created by the library and the\nmetadata they contain fulfill the requirements of many of the climate\ncommunity's standard model experiments.",
            "name": "cmor"
        },
        {
            "description": "Conduit is an open source project from Lawrence Livermore National\nLaboratory that provides an intuitive model for describing hierarchical\nscientific data in C++, C, Fortran, and Python. It is used for data\ncoupling between packages in-core, serialization, and I/O tasks.",
            "name": "conduit"
        },
        {
            "description": "This is a an implementation of the CosmoFlow 3D convolutional neural\nnetwork for benchmarking. It is written in TensorFlow with the Keras API\nand uses Horovod for distributed training.",
            "name": "cosmoflow-benchmark"
        },
        {
            "description": "CosmoMC is a Fortran 2008 Markov-Chain Monte-Carlo (MCMC) engine for\nexploring cosmological parameter space, together with Fortran and python\ncode for analysing Monte-Carlo samples and importance sampling (plus a\nsuite of scripts for building grids of runs, plotting and presenting\nresults).",
            "name": "cosmomc"
        },
        {
            "description": "costo stand for COSimulation TOols. Its a layer above MPI to share data\nbetween meshes.",
            "name": "costo"
        },
        {
            "description": "CP2K is a quantum chemistry and solid state physics software package\nthat can perform atomistic simulations of solid state, liquid,\nmolecular, periodic, material, crystal, and biological systems",
            "name": "cp2k"
        },
        {
            "description": "CPAT is an alignment-free method to predict RNA coding potential using\nfour sequence features",
            "name": "cpat"
        },
        {
            "description": "CryoDRGN is a neural network based algorithm for heterogeneous cryo-EM\nreconstruction. In particular, the method models a continuous\ndistribution over 3D structures by using a neural network based\nrepresentation for the volume",
            "name": "cryodrgn"
        },
        {
            "description": "DFTB+ is an implementation of the Density Functional based Tight Binding\n(DFTB) method, containing many extensions to the original method.",
            "name": "dftbplus"
        },
        {
            "description": "DSQSS is a program package for solving quantum many-body problems\ndefined on lattices. It is based on the quantum Monte Carlo method in\nFeynman's path integral representation.",
            "name": "dsqss"
        },
        {
            "description": "ecFlow is a work flow package that enables users to run a large number\nof programs (with dependencies on each other and on time) in a\ncontrolled environment. It provides tolerance for hardware and software\nfailures, combined with good restart capabilities.",
            "name": "ecflow"
        },
        {
            "description": "EMBLmyGFF3 converts an assembly in FASTA format along with associated\nannotation in GFF3 format into the EMBL flat file format which is the\nrequired format for submitting annotated assemblies to ENA.",
            "name": "emblmygff3"
        },
        {
            "description": "The Earth System Modeling Framework (ESMF) is high-performance, flexible\nsoftware infrastructure for building and coupling weather, climate, and\nrelated Earth science applications. The ESMF defines an architecture for\ncomposing complex, coupled modeling systems and includes data structures\nand utilities for developing individual models. The National Unified\nOperational Prediction Capability (NUOPC) Layer defines a common model\narchitecture to support interoperable ESMF components. The NUOPC Layer\nis included with the ESMF package.",
            "name": "esmf"
        },
        {
            "description": "Faiss is a library for efficient similarity search and clustering of\ndense vectors. Faiss contains algorithms that search in sets of vectors\nof any size, up to ones that possibly do not fit in RAM. It also\ncontains supporting code for evaluation and parameter tuning. Faiss is\nwritten in C++ with complete wrappers for Python/numpy. Some of the most\nuseful algorithms are implemented on the GPU. It is developed by\nFacebook AI Research.",
            "name": "faiss"
        },
        {
            "description": "FLANN is a library for performing fast approximate nearest neighbor\nsearches in high dimensional spaces. It contains a collection of\nalgorithms we found to work best for nearest neighbor search and a\nsystem for automatically choosing the best algorithm and optimum\nparameters depending on the dataset. FLANN is written in C++ and\ncontains bindings for the following languages: C, MATLAB and Python.",
            "name": "flann"
        },
        {
            "description": "The FPLO(R) package is a full-potential local-orbital code to solve the\nKohn-Sham equations on a regular lattice or with free boundary\nconditions (finite systems). Relativistic effects are treated either in\na scalar-relativistic or a full 4-component formalism. Available\nfunctionals are LSDA, GGA (PBE 96) and LSDA/GGA+U. Orbital polarization\ncorrection can be applied.",
            "name": "fplo"
        },
        {
            "description": "Python tools for GATE, see https://github.com/OpenGATE/Gate",
            "name": "gatetools"
        },
        {
            "description": "GDAL: Geospatial Data Abstraction Library. GDAL is a translator library\nfor raster and vector geospatial data formats that is released under an\nMIT style Open Source License by the Open Source Geospatial Foundation.\nAs a library, it presents a single raster abstract data model and single\nvector abstract data model to the calling application for all supported\nformats. It also comes with a variety of useful command line utilities\nfor data translation and processing.",
            "name": "gdal"
        },
        {
            "description": "The Global Extensible Open Power Manager (GEOPM) Runtime is designed to\nenhance energy efficiency of applications through active hardware\nconfiguration.",
            "name": "geopm-runtime"
        },
        {
            "description": "Organelle Genome Assembly Toolkit (Chloroplast/Mitocondrial/ITS)",
            "name": "getorganelle"
        },
        {
            "description": "gnina (pronounced NEE-na) is a molecular docking program with integrated\nsupport for scoring and optimizing ligands using convolutional neural\nnetworks.",
            "name": "gnina"
        },
        {
            "description": "GNU Radio is a free & open-source software development toolkit that\nprovides signal processing blocks to implement software radios. It can\nbe used with readily-available, low-cost external RF hardware to create\nsoftware-defined radios, or without hardware in a simulation-like\nenvironment. It is widely used in hobbyist, academic, and commercial\nenvironments to support both wireless communications research and real-\nworld radio systems.",
            "name": "gnuradio"
        },
        {
            "description": "GPTune is an autotuning framework that relies on multitask and transfer\nlearnings to help solve the underlying black-box optimization problem\nusing Bayesian optimization methodologies.",
            "name": "gptune"
        },
        {
            "description": "Halide is a programming language designed to make it easier to write\nhigh-performance image and array processing code on modern machines.",
            "name": "halide"
        },
        {
            "description": "A Unified Release of the FTOOLS and XANADU Software Packages. XANADU:\nHigh-level, multi-mission tasks for X-ray astronomical spectral, timing,\nand imaging data analysis. FTOOLS: General and mission-specific tools to\nmanipulate FITS files. FITSIO: Core library responsible for reading and\nwriting FITS files. fv: General FITS file browser/editor/plotter with a\ngraphical user interface. XSTAR: Tool for calculating the physical\nconditions and emission spectra of photoionized gases",
            "name": "heasoft"
        },
        {
            "description": "Highly Efficient FFT for Exascale",
            "name": "heffte"
        },
        {
            "description": "HiCOPS is a software framework for accelerating database peptide search\nworkflows on supercomputers. HiCOPS provided algorithm-independent\nparallelizations and optimizations can be extended into new HPC database\nsearch algorithms or scalably accelerate the existing ones.",
            "name": "hicops"
        },
        {
            "description": "HOOMD-blue is a general-purpose particle simulation toolkit. It scales\nfrom a single CPU core to thousands of GPUs. You define particle initial\nconditions and interactions in a high-level python script. Then tell\nHOOMD-blue how you want to execute the job and it takes care of the\nrest. Python job scripts give you unlimited flexibility to create custom\ninitialization routines, control simulation parameters, and perform in\nsitu analysis.",
            "name": "hoomd-blue"
        },
        {
            "description": "Misc. reusable utilities used by IceBin.",
            "name": "ibmisc"
        },
        {
            "description": "Improved version of rDock. rDock is a fast and versatile Open Source\ndocking program that can be used to dock small molecules against\nproteins and nucleic acids. The original version is found at the\nfollowing URL:\nhttps://sourceforge.net/projects/rdock/files/rDock_2013.1_src.tar.gz",
            "name": "improved-rdock"
        },
        {
            "description": "A python pipeline to identify IS (Insertion Sequence) elements in genome\nand metagenome",
            "name": "isescan"
        },
        {
            "description": "IsoQuant: Transcript discovery and quantification with long RNA reads",
            "name": "isoquant"
        },
        {
            "description": "LAMMPS stands for Large-scale Atomic/Molecular Massively Parallel\nSimulator.",
            "name": "lammps"
        },
        {
            "description": "ldsc is a command line tool for estimating heritability and genetic\ncorrelation from GWAS summary statistics. ldsc also computes LD scores",
            "name": "ldsc"
        },
        {
            "description": "Legion is a data-centric parallel programming system for writing\nportable high performance programs targeted at distributed heterogeneous\narchitectures. Legion presents abstractions which allow programmers to\ndescribe properties of program data (e.g. independence, locality). By\nmaking the Legion programming system aware of the structure of program\ndata, it can automate many of the tedious tasks programmers currently\nface, including correctly extracting task- and data-level parallelism\nand moving data around complex memory hierarchies. A novel mapping\ninterface provides explicit programmer controlled placement of data in\nthe memory hierarchy and assignment of tasks to processors in a way that\nis orthogonal to correctness, thereby enabling easy porting and tuning\nof Legion applications to new architectures.",
            "name": "legion"
        },
        {
            "description": "Catalyst is an API specification developed for simulations (and other\nscientific data producers) to analyze and visualize data in situ.",
            "name": "libcatalyst"
        },
        {
            "description": "Library for analytical Gaussian integrals for quantum chemistry.",
            "name": "libcint"
        },
        {
            "description": "libmolgrid is a library to generate tensors from molecular data, with\nproperties that make its output particularly suited to machine learning.",
            "name": "libmolgrid"
        },
        {
            "description": "A generic abstraction for the compression of dense tensors",
            "name": "libpressio"
        },
        {
            "description": "Liftoff is a tool that accurately maps annotations in GFF or GTF between\nassemblies of the same, or closely-related species.",
            "name": "liftoff"
        },
        {
            "description": "LvArray portable HPC containers.",
            "name": "lvarray"
        },
        {
            "description": "MAPL is a foundation layer of the GEOS architecture, whose original\npurpose is to supplement the Earth System Modeling Framework (ESMF).\nMAPL fills in missing capabilities of ESMF, provides higher-level\ninterfaces for common boiler-plate logic, and enforces various\ncomponentization conventions across ESMF gridded components within GEOS.",
            "name": "mapl"
        },
        {
            "description": "Meep (or MEEP) is a free finite-difference time-domain (FDTD) simulation\nsoftware package developed at MIT to model electromagnetic systems.",
            "name": "meep"
        },
        {
            "description": "This pipeline will merge overlapping paired-end reads, calculate merge\nstatistics, and filter reads for quality.",
            "name": "mefit"
        },
        {
            "description": "MemSurfer is a tool to compute and analyze membrane surfaces found in a\nwide variety of large-scale molecular simulations.",
            "name": "memsurfer"
        },
        {
            "description": "Statistical tool that matches up grids with either gridded analyses or\npoint observations and applies configurable methods to compute\nstatistics and diagnostics",
            "name": "met"
        },
        {
            "description": "The MFrontGenericInterfaceSupport project (MGIS) provides helper\nfunctions for various solvers to interact with behaviour written using\nMFront generic interface. MGIS is written in C++. Bindings are provided\nfor C and fortran (2003). A FEniCS binding is also available.",
            "name": "mgis"
        },
        {
            "description": "miniGAN is a generative adversarial network code developed as part of\nthe Exascale Computing Project's (ECP) ExaLearn project at Sandia\nNational Laboratories.",
            "name": "minigan"
        },
        {
            "description": "MIVisionX toolkit is a set of comprehensive computer vision and machine\nintelligence libraries, utilities, and applications bundled into a\nsingle toolkit.",
            "name": "mivisionx"
        },
        {
            "description": "mlpack is an intuitive, fast, and flexible header-only C++ machine\nlearning library with bindings to other languages. It is meant to be a\nmachine learning analog to LAPACK, and aims to implement a wide array of\nmachine learning methods and functions as a \"swiss army knife\" for\nmachine learning researchers.",
            "name": "mlpack"
        },
        {
            "description": "PyTorch implementation for the climate segmentation benchmark, based on\nthe Exascale Deep Learning for Climate Analytics",
            "name": "mlperf-deepcam"
        },
        {
            "description": "MRtrix provides a set of tools to perform various advanced diffusion MRI\nanalyses, including constrained spherical deconvolution (CSD),\nprobabilistic tractography, track-density imaging, and apparent fibre\ndensity.",
            "name": "mrtrix3"
        },
        {
            "description": "MXNet is a deep learning framework designed for both efficiency and\nflexibility.",
            "name": "mxnet"
        },
        {
            "description": "Wavelet and simulated Annealing SliP inversion (WASP). This code uses a\nnonlinear simulated annealing inversion method to model slip amplitude,\nrake, rupture time, and rise time on a discretized fault plane, finding\nthe solution that best fits the observations in the wavelet domain.",
            "name": "neic-finitefault"
        },
        {
            "description": "NEST is a simulator for spiking neural network models It focuses on the\ndynamics, size and structure of neural systems rather than on the exact\nmorphology of individual neurons.",
            "name": "nest"
        },
        {
            "description": "NEURON is a simulation environment for single and networks of neurons.\nNEURON is a simulation environment for modeling individual and networks\nof neurons. NEURON models individual neurons via the use of sections\nthat are automatically subdivided into individual compartments, instead\nof requiring the user to manually create compartments.",
            "name": "neuron"
        },
        {
            "description": "NLopt is a free/open-source library for nonlinear optimization,\nproviding a common interface for a number of different free optimization\nroutines available online as well as original implementations of various\nother algorithms.",
            "name": "nlopt"
        },
        {
            "description": "Node Resource Manager",
            "name": "nrm"
        },
        {
            "description": "OCTA is an integrated simulation system for soft materials.",
            "name": "octa"
        },
        {
            "description": "A real-space finite-difference (time-dependent) density-functional\ntheory code.",
            "name": "octopus"
        },
        {
            "description": "Advanced Profiling and Analytics for AMD Hardware",
            "name": "omniperf"
        },
        {
            "description": "Open3D: A Modern Library for 3D Data Processing.",
            "name": "open3d"
        },
        {
            "description": "OpenCV (Open Source Computer Vision Library) is an open source computer\nvision and machine learning software library.",
            "name": "opencv"
        },
        {
            "description": "Reading, writing, and processing images in a wide variety of file\nformats, using a format-agnostic API, aimed at VFX applications.",
            "name": "openimageio"
        },
        {
            "description": "A high performance toolkit for molecular simulation. Use it as a\nlibrary, or as an application. We include extensive language bindings\nfor Python, C, C++, and even Fortran. The code is open source and\nactively maintained on Github, licensed under MIT and LGPL. Part of the\nOmnia suite of tools for predictive biomolecular simulation.",
            "name": "openmm"
        },
        {
            "description": "C++ & Python API for Scientific I/O",
            "name": "openpmd-api"
        },
        {
            "description": "OpenTURNS is a scientific C++ and Python library featuring an internal\ndata model and algorithms dedicated to the treatment of uncertainties.\nThe main goal of this library is to provide all functionalities needed\nto treat uncertainties in studies with industrial applications. Targeted\nusers are all engineers who want to introduce the probabilistic\ndimension in their so far deterministic studies.",
            "name": "openturns"
        },
        {
            "description": "OpenVDB - a sparse volume data format.",
            "name": "openvdb"
        },
        {
            "description": "OrthoFinder is a fast, accurate and comprehensive analysis tool for\ncomparative genomics. It finds orthologues and orthogroups infers rooted\ngene trees for all orthogroups and infers a rooted species tree for the\nspecies being analysed. OrthoFinder also provides comprehensive\nstatistics for comparative genomic analyses. OrthoFinder is simple to\nuse and all you need to run it is a set of protein sequence files (one\nper species) in FASTA format.",
            "name": "orthofinder"
        },
        {
            "description": "ParaView is an open-source, multi-platform data analysis and\nvisualization application. This package includes the Catalyst in-situ\nlibrary for versions 5.7 and greater, otherwise use the catalyst\npackage.",
            "name": "paraview"
        },
        {
            "description": "A library for numerically computing the Pfaffian of a real or complex\nskew-symmetric matrix. This is based on computing the tridiagonal form\nof the matrix under unitary congruence transformations.",
            "name": "pfapack"
        },
        {
            "description": "The Pipelined, Hybrid-parallel Iterative Solver Toolkit provides\nimplementations of and interfaces to block iterative solvers for sparse\nlinear and eigenvalue problems. In contrast to other libraries we\nsupport multiple backends (e.g. Trilinos, PETSc and our own optimized\nkernels), and interfaces in multiple languages such as C, C++, Fortran\n2003 and Python. PHIST has a clear focus on portability and hardware\nperformance: in particular support row-major storage of block vectors\nand using GPUs (via the ghost library or Trilinos/Tpetra).",
            "name": "phist"
        },
        {
            "description": "Parallel Ice Sheet Model",
            "name": "pism"
        },
        {
            "description": "Possvm (Phylogenetic Ortholog Sorting with Species oVerlap and MCL) is a\npython tool to analyse pre-computed gene trees and identify pairs and\nclusters of orthologous genes. It takes advantage of the species overlap\nalgorithm implemented in the ETE toolkit to parse the phylogeny and\nidentify orthologous gene pairs, and MCL clustering for orthogroup\nidentification.",
            "name": "possvm"
        },
        {
            "description": "preCICE (Precise Code Interaction Coupling Environment) is a coupling\nlibrary for partitioned multi-physics simulations. Partitioned means\nthat preCICE couples existing programs (solvers) capable of simulating a\nsubpart of the complete physics involved in a simulation.",
            "name": "precice"
        },
        {
            "description": "Standalone monitor for process resource consumption.",
            "name": "prmon"
        },
        {
            "description": "Psi4 is an open-source suite of ab initio quantum chemistry programs\ndesigned for efficient, high-accuracy simulations of a variety of\nmolecular properties.",
            "name": "psi4"
        },
        {
            "description": "ABCpy is a highly modular, scientific library for approximate Bayesian\ncomputation (ABC) written in Python. It is designed to run all included\nABC algorithms in parallel, either using multiple cores of a single\ncomputer or using an Apache Spark or MPI enabled cluster.",
            "name": "py-abcpy"
        },
        {
            "description": "Python package to automate ABINIT calculations and analyze the results.",
            "name": "py-abipy"
        },
        {
            "description": "A simple way to train and use PyTorch models with multi-GPU, TPU, mixed-\nprecision.",
            "name": "py-accelerate"
        },
        {
            "description": "An accelerated Image loader and preprocessor leveraging Intel IPP.\naccimage mimics the PIL API and can be used as a backend for\ntorchvision.",
            "name": "py-accimage"
        },
        {
            "description": "NumPy bindings of ADIOS1",
            "name": "py-adios"
        },
        {
            "description": "AHPy is an implementation of the Analytic Hierarchy Process (AHP), a\nmethod used to structure, synthesize and evaluate the elements of a\ndecision problem.",
            "name": "py-ahpy"
        },
        {
            "description": "AlphaFold is an AI system developed by DeepMind that predicts a\nprotein's 3D structure from its amino acid sequence. It regularly\nachieves accuracy competitive with experiment.",
            "name": "py-alphafold"
        },
        {
            "description": "Declarative statistical visualization library for Python",
            "name": "py-altair"
        },
        {
            "description": "Advanced Multilanguage Interface for CVODES and IDAS",
            "name": "py-amici"
        },
        {
            "description": "Provides typing hints to be shared between LCLS-II analysis packages.",
            "name": "py-amityping"
        },
        {
            "description": "AMReX Python Bindings with pybind11",
            "name": "py-amrex"
        },
        {
            "description": "ANGEL: Robust Open Reading Frame prediction",
            "name": "py-angel"
        },
        {
            "description": "anndata is a Python package for handling annotated data matrices in\nmemory and on disk, positioned between pandas and xarray.",
            "name": "py-anndata"
        },
        {
            "description": "Fix shapes that cross the antimeridian.",
            "name": "py-antimeridian"
        },
        {
            "description": "Advanced Normalization Tools in Python.",
            "name": "py-antspyx"
        },
        {
            "description": "ANUGA (pronounced \"AHnooGAH\") is open-source software for the simulation\nof the shallow water equation, in particular it can be used to model\ntsunamis and floods.",
            "name": "py-anuga"
        },
        {
            "description": "Anvi\u2019o is a comprehensive platform that brings together many aspects of\ntoday\u2019s cutting-edge computational strategies of data-enabled\nmicrobiology, including genomics, metagenomics, metatranscriptomics,\npangenomics, metapangenomics, phylogenomics, and microbial population\ngenetics in an integrated and easy-to-use fashion through extensive\ninteractive visualization capabilities.",
            "name": "py-anvio"
        },
        {
            "description": "Apache Beam is a unified programming model for Batch and Streaming.",
            "name": "py-apache-beam"
        },
        {
            "description": "ArcGIS API for Python.",
            "name": "py-arcgis"
        },
        {
            "description": "Autoregressive Conditional Heteroskedasticity (ARCH) and other tools for\nfinancial econometrics, written in Python (with Cython and/or Numba used\nto improve performance)",
            "name": "py-arch"
        },
        {
            "description": "This is the python client for Arkouda.",
            "name": "py-arkouda"
        },
        {
            "description": "Python ARM Radar Toolkit. A growing collection of weather radar\nalgorithms and utilities build on top of the Scientific Python stack and\ndistributed under the 3-Clause BSD license. Py-ART is used by the\nAtmospheric Radiation Measurement (ARM) Climate Research Facility for\nworking with data from a number of precipitation and cloud radars, but\nhas been designed so that it can be used by others in the radar and\natmospheric communities to examine, processes, and analyse data from\nmany types of weather radars.",
            "name": "py-arm-pyart"
        },
        {
            "description": "ArviZ (pronounced \"AR-vees\") is a Python package for exploratory\nanalysis of Bayesian models. Includes functions for posterior analysis,\nmodel checking, comparison and diagnostics.",
            "name": "py-arviz"
        },
        {
            "description": "The Advanced Scientific Data Format (ASDF) is a next-generation\ninterchange format for scientific data. This package contains the Python\nimplementation of the ASDF Standard.",
            "name": "py-asdf"
        },
        {
            "description": "ASDF serialization support for astropy",
            "name": "py-asdf-astropy"
        },
        {
            "description": "ASDL: Automatic Second-order Differentiation (for Fisher, Gradient\ncovariance, Hessian, Jacobian, and Kernel) Library.",
            "name": "py-asdfghjkl"
        },
        {
            "description": "The Atomic Simulation Environment (ASE) is a set of tools and Python\nmodules for setting up, manipulating, running, visualizing and analyzing\natomistic simulations.",
            "name": "py-ase"
        },
        {
            "description": "The Astropy Project is a community effort to develop a single core\npackage for Astronomy in Python and foster interoperability between\nPython astronomy packages.",
            "name": "py-astropy"
        },
        {
            "description": "HEALPix (Hierarchical Equal Area isoLatitude Pixelisation) is an\nalgorithm for pixellizing a sphere that is sometimes used in Astronomy\nto store data from all-sky surveys, but the general algorithm can apply\nto any field that has to deal with representing data on a sphere.",
            "name": "py-astropy-healpix"
        },
        {
            "description": "ATS - Automated Testing System - is an open-source, Python-based tool\nfor automating the running of tests of an application across a broad\nrange of high performance computers.",
            "name": "py-ats"
        },
        {
            "description": "Autograd can automatically differentiate native Python and Numpy code.\nIt can handle a large subset of Python's features, including loops, ifs,\nrecursion and closures, and it can even take derivatives of derivatives\nof derivatives. It supports reverse-mode differentiation (a.k.a.\nbackpropagation), which means it can efficiently take gradients of\nscalar-valued functions with respect to array-valued arguments, as well\nas forward-mode differentiation, and the two can be composed\narbitrarily. The main intended application of Autograd is gradient-based\noptimization. For more information, check out the tutorial and the\nexamples directory.",
            "name": "py-autograd"
        },
        {
            "description": "Manipulate JSON-like data with NumPy-like idioms.",
            "name": "py-awkward"
        },
        {
            "description": "py-awkward-cpp provides precompiled routines for the py-awkward package.\nIt is not useful on its own, only as a dependency for py-awkward.",
            "name": "py-awkward-cpp"
        },
        {
            "description": "Manipulate arrays of complex data structures as easily as Numpy. Awkward\nArray is a pure Python+Numpy library for manipulating complex data\nstructures as you would Numpy arrays.",
            "name": "py-awkward0"
        },
        {
            "description": "The purpose of this package is to coordinate dependencies within AzureML\npackages. It is not intended for public use.",
            "name": "py-azureml-dataset-runtime"
        },
        {
            "description": "The matplotlib basemap toolkit is a library for plotting 2D data on maps\nin Python.",
            "name": "py-basemap"
        },
        {
            "description": "Pure Python implementation of bayesian global optimization with gaussian\nprocesses.",
            "name": "py-bayesian-optimization"
        },
        {
            "description": "bcolz provides columnar and compressed data containers. Column storage\nallows for efficiently querying tables with a large number of columns.\nIt also allows for cheap addition and removal of column. In addition,\nbcolz objects are compressed by default for reducing memory/disk I/O\nneeds. The compression process is carried out internally by Blosc, a\nhigh-performance compressor that is optimized for binary data.",
            "name": "py-bcolz"
        },
        {
            "description": "Converts and organises raw MRI data-sets according to the Brain Imaging\nData Structure (BIDS).",
            "name": "py-bidscoin"
        },
        {
            "description": "Tools for DICOM to BIDS conversion.",
            "name": "py-bidskit"
        },
        {
            "description": "BigDFT: the python interface of BigDFT for electronic structure\ncalculation based on Daubechies wavelets.",
            "name": "py-bigdft"
        },
        {
            "description": "Biobb_structure_checking provides a series of functions to check the\nquality of a 3D structure intended to facilitate the setup of a\nmolecular dynamics simulation of protein or nucleic acids systems",
            "name": "py-biobb-structure-checking"
        },
        {
            "description": "The BIOM file format (canonically pronounced biome) is designed to be a\ngeneral-use format for representing biological sample by observation\ncontingency tables.",
            "name": "py-biom-format"
        },
        {
            "description": "Working with molecular structures in pandas DataFrames",
            "name": "py-biopandas"
        },
        {
            "description": "A distributed collaborative effort to develop Python libraries and\napplications which address the needs of current and future work in\nbioinformatics.",
            "name": "py-biopython"
        },
        {
            "description": "Biotite is your Swiss army knife for bioinformatics. Whether you want to\nidentify homologous sequence regions in a protein family or you would\nlike to find disulfide bonds in a protein structure: Biotite has the\nright tool for you. This package bundles popular tasks in computational\nmolecular biology into a uniform Python library.",
            "name": "py-biotite"
        },
        {
            "description": "Reading structures from trajectory files.",
            "name": "py-biotraj"
        },
        {
            "description": "Filter for improving compression of typed binary data.",
            "name": "py-bitshuffle"
        },
        {
            "description": "Cython BLIS: Fast BLAS-like operations from Python and Cython, without\nthe tears",
            "name": "py-blis"
        },
        {
            "description": "A Python wrapper for the extremely fast Blosc compression library",
            "name": "py-blosc"
        },
        {
            "description": "Python wrapper for the C-Blosc2 library.",
            "name": "py-blosc2"
        },
        {
            "description": "Blue Brain Python E-feature extraction",
            "name": "py-bluepyefe"
        },
        {
            "description": "Python library to optimize and evaluate electrical models.",
            "name": "py-bluepyemodel"
        },
        {
            "description": "Bluebrain Python Optimisation Library",
            "name": "py-bluepyopt"
        },
        {
            "description": "The Brain Modeling Toolkit",
            "name": "py-bmtk"
        },
        {
            "description": "Statistical and novel interactive HTML plots for Python",
            "name": "py-bokeh"
        },
        {
            "description": "The Boost::Histogram Python wrapper.",
            "name": "py-boost-histogram"
        },
        {
            "description": "A collection of fast NumPy array functions written in Cython.",
            "name": "py-bottleneck"
        },
        {
            "description": "Interactive plotting for the Jupyter notebook, using d3.js and\nipywidgets.",
            "name": "py-bqplot"
        },
        {
            "description": "Spatial indexer for geometries and morphologies",
            "name": "py-brain-indexer"
        },
        {
            "description": "A clock-driven simulator for spiking neural networks",
            "name": "py-brian"
        },
        {
            "description": "A clock-driven simulator for spiking neural networks",
            "name": "py-brian2"
        },
        {
            "description": "The bx-python project is a python library and associated set of scripts\nto allow for rapid implementation of genome scale analyses.",
            "name": "py-bx-python"
        },
        {
            "description": "A Simple Tool to Monitor and Log Function Calls",
            "name": "py-callmonitor"
        },
        {
            "description": "CANToolz is a framework for analysing CAN networks and devices. It\nprovides multiple modules that can be chained using CANToolz's pipe\nsystem and used by security researchers, automotive/OEM security testers\nin black-box analysis.",
            "name": "py-cantoolz"
        },
        {
            "description": "The carputils framework for running simulations with the openCARP\nsoftware.",
            "name": "py-carputils"
        },
        {
            "description": "Cartopy - a cartographic python library with matplotlib support.",
            "name": "py-cartopy"
        },
        {
            "description": "CasADi -- framework for algorithmic differentiation and numeric\noptimization",
            "name": "py-casadi"
        },
        {
            "description": "Open source library for parsing and interpreting the results of\ncomputational chemistry packages",
            "name": "py-cclib"
        },
        {
            "description": "CellProfiler cell image analysis software. CellProfiler is a free open-\nsource software designed to enable biologists without training in\ncomputer vision or programming to quantitatively measure phenotypes from\nthousands of images automatically.",
            "name": "py-cellprofiler"
        },
        {
            "description": "Core classes and components used by CellProfiler.",
            "name": "py-cellprofiler-core"
        },
        {
            "description": "An open source image processing library.",
            "name": "py-centrosome"
        },
        {
            "description": "Units of measure as required by the Climate and Forecast (CF) metadata\nconventions.",
            "name": "py-cf-units"
        },
        {
            "description": "Python interface to map GRIB files to the NetCDF Common Data Model\nfollowing the CF Convention using ecCodes.",
            "name": "py-cfgrib"
        },
        {
            "description": "Python library for decoding time units and variable values in a netCDF\nfile conforming to the Climate and Forecasting (CF) netCDF conventions",
            "name": "py-cftime"
        },
        {
            "description": "cgen offers a simple abstract syntax tree for C and related languages\n(C++/CUDA/OpenCL) to allow structured code generation from Python.",
            "name": "py-cgen"
        },
        {
            "description": "Chainer is a Python-based deep learning framework aiming at\nflexibility. It provides automatic differentiation APIs based on the\ndefine-by-run approach (a.k.a. dynamic computational graphs) as well as\nobject-oriented high-level APIs to build and train neural networks. It\nalso supports CUDA/cuDNN using CuPy for high performance training and\ninference.",
            "name": "py-chainer"
        },
        {
            "description": "A code generator that fuses subsequent batched matrix multiplications\n(GEMMs) into a single GPU kernel, holding intermediate results in shared\nmemory as long as necessary.",
            "name": "py-chainforgecodegen"
        },
        {
            "description": "Charm4py (Charm++ for Python) is a distributed computing and parallel\nprogramming framework for Python, for the productive development of\nfast, parallel and scalable applications. It is built on top of Charm++,\na C++ adaptive runtime system that has seen extensive use in the\nscientific and high-performance computing (HPC) communities across many\ndisciplines, and has been used to develop applications that run on a\nwide range of devices: from small multi-core devices up to the largest\nsupercomputers.",
            "name": "py-charm4py"
        },
        {
            "description": "Assess the quality of microbial genomes recovered from isolates, single\ncells, and metagenomes",
            "name": "py-checkm-genome"
        },
        {
            "description": "Python interface to chemfiles",
            "name": "py-chemfiles"
        },
        {
            "description": "Chex is a library of utilities for helping to write reliable JAX code.",
            "name": "py-chex"
        },
        {
            "description": "This repository contains an implementation for the Convolutive transfer\nfunction Invariant Signal-to-Distortion Ratio objective for PyTorch as\ndescribed in the publication Convolutive Transfer Function Invariant SDR\ntraining criteria for Multi-Channel Reverberant Speech Separation",
            "name": "py-ci-sdr"
        },
        {
            "description": "cinema_lib is a set of tools and library for interacting with a Cinema\ndatabase (currently Spec A and Spec D) through Python and the command\nline tool, cinema.",
            "name": "py-cinema-lib"
        },
        {
            "description": "ClimaX: A foundation model for weather and climate.",
            "name": "py-climax"
        },
        {
            "description": "Python implementation of CMA-ES Covariance Matrix Adaptation Evolution\nStr ategy for non-linear numerical optimization in Python",
            "name": "py-cma"
        },
        {
            "description": "Lightweight Covariance Matrix Adaptation Evolution Strategy (CMA-ES)\nimplementation.",
            "name": "py-cmaes"
        },
        {
            "description": "Colormaps for Oceanography.",
            "name": "py-cmocean"
        },
        {
            "description": "CMSeq is a set of commands to provide an interface to .bam files for\ncoverage and sequence consensus.",
            "name": "py-cmseq"
        },
        {
            "description": "Matplotlib colormaps from the yt project !",
            "name": "py-cmyt"
        },
        {
            "description": "Coclust provides both a Python package which implements several diagonal\nand non-diagonal co-clustering algorithms, and a ready to use script to\nperform co- clustering",
            "name": "py-coclust"
        },
        {
            "description": "An analysis tool providing insight into the portability and\nmaintainability of an application's source code.",
            "name": "py-codebasin"
        },
        {
            "description": "CodePy is a C metaprogramming toolkit for Python. It handles two aspects\nof metaprogramming: - Generating C source code. - Compiling this source\ncode and dynamically loading it into the Python interpreter.",
            "name": "py-codepy"
        },
        {
            "description": "Tools for color research",
            "name": "py-colorio"
        },
        {
            "description": "Color math and conversion library.",
            "name": "py-colormath"
        },
        {
            "description": "ColorPy is a Python package to convert physical descriptions of light -\nspectra of light intensity vs. wavelength - into RGB colors that can be\ndrawn on a computer screen. It provides a nice set of attractive plots\nthat you can make of such spectra, and some other color related\nfunctions as well.",
            "name": "py-colorpy"
        },
        {
            "description": "A powerful, accurate, and easy-to-use Python library for doing\ncolorspace conversions.",
            "name": "py-colorspacious"
        },
        {
            "description": "An integrated large-scale model training system with efficient\nparallelization techniques.",
            "name": "py-colossalai"
        },
        {
            "description": "Creation and manipulation of parameter configuration spaces for\nautomated algorithm configuration and hyperparameter tuning.",
            "name": "py-configspace"
        },
        {
            "description": "A clean and simple data loading library for Continual Learning",
            "name": "py-continuum"
        },
        {
            "description": "Python library for calculating contours of 2D quadrilateral grids.",
            "name": "py-contourpy"
        },
        {
            "description": "The Python Control Systems Library is a Python module that implements\nbasic operations for analysis and design of feedback control systems.",
            "name": "py-control"
        },
        {
            "description": "Copulas is a Python library for modeling multivariate distributions and\nsampling from them using copula functions. Given a table containing\nnumerical data, we can use Copulas to learn the distribution and later\non generate new synthetic rows following the same statistical\nproperties.",
            "name": "py-copulas"
        },
        {
            "description": "A generic correction library",
            "name": "py-correctionlib"
        },
        {
            "description": "Blazing fast correlation functions on the CPU.",
            "name": "py-corrfunc"
        },
        {
            "description": "The crYOLO boxmanger was written to produce annotation data for crYOLO\nas deep learning based particle picking procedure for cryo electro\nmicroscopy.",
            "name": "py-cryolobm"
        },
        {
            "description": "CTGAN is a collection of Deep Learning based Synthetic Data Generators\nfor single table data, which are able to learn from real data and\ngenerate synthetic clones with high fidelity.",
            "name": "py-ctgan"
        },
        {
            "description": "Built based on the Apache Arrow columnar memory format, cuDF is a GPU\nDataFrame library for loading, joining, aggregating, filtering, and\notherwise manipulating data.",
            "name": "py-cudf"
        },
        {
            "description": "Productivity Tools for Plotly + Pandas. This library binds the power of\nplotly with the flexibility of pandas for easy plotting.",
            "name": "py-cufflinks"
        },
        {
            "description": "cuML is a suite of libraries that implement machine learning algorithms\nand mathematical primitives functions that share compatible APIs with\nother RAPIDS projects.",
            "name": "py-cuml"
        },
        {
            "description": "CuPy is an open-source array library accelerated with NVIDIA CUDA. CuPy\nprovides GPU accelerated computing with Python. CuPy uses CUDA-related\nlibraries including cuBLAS, cuDNN, cuRand, cuSolver, cuSPARSE, cuFFT and\nNCCL to make full use of the GPU architecture.",
            "name": "py-cupy"
        },
        {
            "description": "Module to easily plot the currents in electrical neuron models.",
            "name": "py-currentscape"
        },
        {
            "description": "Convex optimization, for everyone.",
            "name": "py-cvxpy"
        },
        {
            "description": "A Python interface for CLP, CBC, and CGL. CyLP is a Python interface to\nCOIN-OR's Linear and mixed-integer program solvers (CLP, CBC, and CGL).\nCyLP's unique feature is that you can use it to alter the solution\nprocess of the solvers from within Python.",
            "name": "py-cylp"
        },
        {
            "description": "cython_bbox is widely used in object detection tasks. To my best\nknowledge, it was first implemented in Faster-RCNN. Since then, almost\nall object detection projects use the source code directly. In order to\nuse it in standalone code snippets or small projects, I make it a pypi\nmodule. The cython_bbox.pyx is totally borrowed from Faster-RCNN. Thanks\nRBG!",
            "name": "py-cython-bbox"
        },
        {
            "description": "fast vcf parsing with cython + htslib",
            "name": "py-cyvcf2"
        },
        {
            "description": "DaCe is a fast parallel programming framework that takes code in\nPython/NumPy and other programming languages, and maps it to high-\nperformance CPU, GPU, and FPGA programs, which can be optimized\nprogrammatically or interactively.",
            "name": "py-dace"
        },
        {
            "description": "Fit population genetic models of demography and selection using\ndiffusion approximations to the allele frequency spectrum",
            "name": "py-dadi"
        },
        {
            "description": "Trans-Learn is a Transfer Learning library based on pure PyTorch with\nhigh performance and friendly API.",
            "name": "py-dalib"
        },
        {
            "description": "Pre- and post-processing tools for DAMASK",
            "name": "py-damask"
        },
        {
            "description": "Python utilities to interact with Darshan log records of HPC\napplications.",
            "name": "py-darshan"
        },
        {
            "description": "Dask is a flexible parallel computing library for analytics.",
            "name": "py-dask"
        },
        {
            "description": "Scalable Machine Learning with Dask.",
            "name": "py-dask-ml"
        },
        {
            "description": "An analysis environment for satellite and other earth observation data.",
            "name": "py-datacube"
        },
        {
            "description": "Datasets is a lightweight library providing two main features: one-line\ndataloaders for many public datasets and efficient data pre-processing.",
            "name": "py-datasets"
        },
        {
            "description": "Datashader is a data rasterization pipeline for automating the process\nof creating meaningful representations of large amounts of data",
            "name": "py-datashader"
        },
        {
            "description": "Distributed Evolutionary Algorithms in Python.",
            "name": "py-deap"
        },
        {
            "description": "DeepEcho is a Synthetic Data Generation Python library for mixed-type,\nmultivariate time series.",
            "name": "py-deepecho"
        },
        {
            "description": "Scalable asynchronous hyperparameter optimization, neural architecture\nsearch, and parallel ensemble of predictive models.",
            "name": "py-deephyper"
        },
        {
            "description": "deep-significance: Easy and Better Significance Testing for Deep Neural\nNetworks",
            "name": "py-deepsig"
        },
        {
            "description": "DeepSpeed library. DeepSpeed enables world's most powerful language\nmodels like MT-530B and BLOOM. It is an easy-to-use deep learning\noptimization software suite that powers unprecedented scale and speed\nfor both training and inference.",
            "name": "py-deepspeed"
        },
        {
            "description": "deepTools addresses the challenge of handling the large amounts of data\nthat are now routinely generated from DNA sequencing centers.",
            "name": "py-deeptools"
        },
        {
            "description": "Devito is a Python package to implement optimized stencil computation.\n(e.g., finite differences, image processing, machine learning) from\nhigh-level symbolic problem definitions. Devito builds on SymPy and\nemploys automated code generation and just-in-time compilation to\nexecute optimized computational kernels on several computer platforms,\nincluding CPUs, GPUs, and clusters thereof.",
            "name": "py-devito"
        },
        {
            "description": "Deep Graph Library (DGL). DGL is an easy-to-use, high performance and\nscalable Python package for deep learning on graphs. DGL is framework\nagnostic, meaning if a deep graph model is a component of an end-to-end\napplication, the rest of the logics can be implemented in any major\nframeworks, such as PyTorch, Apache MXNet or TensorFlow.",
            "name": "py-dgl"
        },
        {
            "description": "A Modified version of scikit-optimize a Sequential model-based\noptimization toolbox for DeepHyper. Scikit-Optimize, or skopt, is a\nsimple and efficient library to minimize (very) expensive and noisy\nblack-box functions. It implements several methods for sequential model-\nbased optimization. skopt aims to be accessible and easy to use in many\ncontexts. The library is built on top of NumPy, SciPy and Scikit-Learn.",
            "name": "py-dh-scikit-optimize"
        },
        {
            "description": "Dinosaur: differentiable dynamics for global atmospheric modeling.",
            "name": "py-dinosaur"
        },
        {
            "description": "Diffusion MRI utilities in python. DIPY is the paragon 3D/4D+ imaging\nlibrary in Python. Contains generic methods for spatial normalization,\nsignal processing, machine learning, statistical analysis and\nvisualization of medical images. Additionally, it contains specialized\nmethods for computational anatomy including diffusion, perfusion and\nstructural imaging.",
            "name": "py-dipy"
        },
        {
            "description": "DLCpar is a reconciliation method for inferring gene duplications,\nlosses, and coalescence (accounting for incomplete lineage sorting).",
            "name": "py-dlcpar"
        },
        {
            "description": "JAX-based neural network library",
            "name": "py-dm-haiku"
        },
        {
            "description": "dRep is a python program for rapidly comparing large numbers of genomes.\ndRep can also \"de-replicate\" a genome set by identifying groups of\nhighly similar genomes and choosing the best representative genome for\neach genome set.",
            "name": "py-drep"
        },
        {
            "description": "DXchange provides an interface with tomoPy and raw tomographic data\ncollected at different synchrotron facilities.",
            "name": "py-dxchange"
        },
        {
            "description": "dynim is a pure-python package to perform dynamic-importance (DynIm)\nsampling on a high-dimensional data set.",
            "name": "py-dynim"
        },
        {
            "description": "Earth-2 Model Intercomparison Project (MIP). A python framework that\nenables climate researchers and scientists to explore and experiment\nwith AI models for weather and climate.",
            "name": "py-earth2mip"
        },
        {
            "description": "Python interface to the ecCodes GRIB and BUFR decoder/encoder.",
            "name": "py-eccodes"
        },
        {
            "description": "This is the Python package for ECOS: Embedded Cone Solver.",
            "name": "py-ecos"
        },
        {
            "description": "Generic class for Edf files manipulation.",
            "name": "py-edffile"
        },
        {
            "description": "Read and write EDF/EDF+ files.",
            "name": "py-edfio"
        },
        {
            "description": "Library to read/write EDF+/BDF+ files written in pure Python by the same\nauthor as the original EDFlib.",
            "name": "py-edflib-python"
        },
        {
            "description": "I/O support for EEGLAB files in Python.",
            "name": "py-eeglabio"
        },
        {
            "description": "The Electrophys Feature Extract Library (eFEL) allows neuroscientists to\nautomatically extract features from time series data recorded from\nneurons (both in vitro and in silico). Examples are the action potential\nwidth and amplitude in voltage traces recorded during whole-cell patch\nclamp experiments. The user of the library provides a set of traces and\nselects the features to be calculated. The library will then extract the\nrequested features and return the values to the user.",
            "name": "py-efel"
        },
        {
            "description": "Elephant is a package for analysis of electrophysiology data in Python",
            "name": "py-elephant"
        },
        {
            "description": "Embedding reader is a module to make it easy to read efficiently a large\ncollection of embeddings stored in any file system.",
            "name": "py-embedding-reader"
        },
        {
            "description": "emcee is an MIT licensed pure-Python implementation of Goodman & Weare's\nAffine Invariant Markov chain Monte Carlo (MCMC) Ensemble sampler.",
            "name": "py-emcee"
        },
        {
            "description": "General Equation Parser and Evaluator",
            "name": "py-equation"
        },
        {
            "description": "ESPResSo is a highly versatile software package for performing and\nanalyzing scientific Molecular Dynamics many-particle simulations of\ncoarse-grained atomistic or bead-spring models as they are used in soft\nmatter research in physics, chemistry and molecular biology. It can be\nused to simulate systems such as polymers, liquid crystals, colloids,\npolyelectrolytes, ferrofluids and biological systems, for example DNA\nand lipid membranes. It also has a DPD and lattice Boltzmann solver for\nhydrodynamic interactions, and allows several particle couplings to the\nLB fluid.",
            "name": "py-espresso"
        },
        {
            "description": "ESPResSo++ is an extensible, flexible, fast and parallel simulation\nsoftware for soft matter research. It is a highly versatile software\npackage for the scientific simulation and analysis of coarse-grained\natomistic or bead-spring models as they are used in soft matter research",
            "name": "py-espressopp"
        },
        {
            "description": "The Environment for Tree Exploration (ETE) is a Python programming\ntoolkit that assists in the recontruction, manipulation, analysis and\nvisualization of phylogenetic trees (although clustering trees or any\nother tree-like data structure are also supported).",
            "name": "py-ete3"
        },
        {
            "description": "Python package for generation of protein sequences and evolutionary\nalignments via discrete diffusion models",
            "name": "py-evodiff"
        },
        {
            "description": "EWAH Bool Array utils for yt",
            "name": "py-ewah-bool-utils"
        },
        {
            "description": "f90wrap is a tool to automatically generate Python extension modules\nwhich interface to Fortran code that makes use of derived types.",
            "name": "py-f90wrap"
        },
        {
            "description": "FairScale is a PyTorch extension library for high performance and large\nscale training. This library extends basic PyTorch capabilities while\nadding new SOTA scaling techniques.",
            "name": "py-fairscale"
        },
        {
            "description": "Fast hierarchical clustering routines for R and Python.",
            "name": "py-fastcluster"
        },
        {
            "description": "Python implementation of FastDTW\n(http://cs.fit.edu/~pkc/papers/tdm04.pdf), which is an approximate\nDynamic Time Warping (DTW) algorithm that provides optimal or near-\noptimal alignments with an O(N) time and memory complexity.",
            "name": "py-fastdtw"
        },
        {
            "description": "Optimizing Protein Structure Prediction Model Training and Inference on\nGPU Clusters.",
            "name": "py-fastfold"
        },
        {
            "description": "A fast and simple progress bar for Jupyter Notebook and console. Created\nby Sylvain Gugger for fast.ai.",
            "name": "py-fastprogress"
        },
        {
            "description": "Renumber and relabel Numpy arrays at C++ speed and physically convert\nrectangular Numpy arrays between C and Fortran order using an in-place\ntransposition",
            "name": "py-fastremap"
        },
        {
            "description": "FastStructure is a fast algorithm for inferring population structure\nfrom large SNP genotype data.",
            "name": "py-faststructure"
        },
        {
            "description": "Python interface to Basix, a finite element definition and tabulation\nruntime library",
            "name": "py-fenics-basix"
        },
        {
            "description": "A Python module for distributed just-in-time shared library building",
            "name": "py-fenics-dijitso"
        },
        {
            "description": "Python interface to the next generation FEniCS problem solving\nenvironment",
            "name": "py-fenics-dolfinx"
        },
        {
            "description": "The FEniCS Form Compiler FFC is a compiler for finite element\nvariational forms, translating high-level mathematical descriptions of\nvariational forms into efficient low-level C++ code for finite element\nassembly.",
            "name": "py-fenics-ffc"
        },
        {
            "description": "Next generation FEniCS Form Compiler",
            "name": "py-fenics-ffcx"
        },
        {
            "description": "The FInite element Automatic Tabulator FIAT supports generation of\narbitrary order instances of the Lagrange elements on lines, triangles,\nand tetrahedra. It is also capable of generating arbitrary order\ninstances of Jacobi-type quadrature rules on the same element shapes.\nFurther, H(div) and H(curl) conforming finite element spaces such as the\nfamilies of Raviart-Thomas, Brezzi-Douglas-Marini and Nedelec are\nsupported on triangles and tetrahedra. Upcoming versions will also\nsupport Hermite and nonconforming elements",
            "name": "py-fenics-fiat"
        },
        {
            "description": "Instant is a Python module that allows for instant inlining of C and C++\ncode in Python. It is a small Python module built on top of SWIG and\nDistutils. Instant has been retired after 2017.2.0 release. It is no\nlonger needed in FEniCS and hence no longer maintained and tested.",
            "name": "py-fenics-instant"
        },
        {
            "description": "The Unified Form Language (UFL) is a domain specific language for\ndeclaration of finite element discretizations of variational forms. More\nprecisely, it defines a flexible interface for choosing finite element\nspaces and defining expressions for weak forms in a notation close to\nmathematical notation.",
            "name": "py-fenics-ufl"
        },
        {
            "description": "The Unified Form Language (UFL) is a domain specific language for\ndeclaration of finite element discretizations of variational forms. More\nprecisely, it defines a flexible interface for choosing finite element\nspaces and defining expressions for weak forms in a notation close to\nmathematical notation.",
            "name": "py-fenics-ufl-legacy"
        },
        {
            "description": "This library provides Kalman filtering and various related optimal and\nnon-optimal filtering software written in Python.",
            "name": "py-filterpy"
        },
        {
            "description": "Fisher's Exact Test. Simple, fast implementation of Fisher's exact test.",
            "name": "py-fisher"
        },
        {
            "description": "Tools for manipulating FITS images using primarily scipy & native python\nroutines",
            "name": "py-fits-tools"
        },
        {
            "description": "A python package for FITS input/output wrapping cfitsio",
            "name": "py-fitsio"
        },
        {
            "description": "fitter package provides a simple class to identify the distribution from\nwhich a data samples is generated from. It uses 80 distributions from\nScipy and allows you to plot the results to check what is the most\nprobable distribution and the best parameters.",
            "name": "py-fitter"
        },
        {
            "description": "Flax: A neural network library for JAX designed for flexibility.",
            "name": "py-flax"
        },
        {
            "description": "Fast & furious GroupBy operations for dask.array.",
            "name": "py-flox"
        },
        {
            "description": "Framework for studying fluid dynamics.",
            "name": "py-fluiddyn"
        },
        {
            "description": "Make beautiful maps with Leaflet.js & Python.",
            "name": "py-folium"
        },
        {
            "description": "Formulaic is a high-performance implementation of Wilkinson formulas for\nPython.",
            "name": "py-formulaic"
        },
        {
            "description": "This project is based upon the Fortran parser originally developed by\nPearu Peterson for the F2PY project, www.f2py.com. It provides a parser\nfor Fortran source code (up to and including F2008) implemented purely\nin Python with minimal dependencies.",
            "name": "py-fparser"
        },
        {
            "description": "Free Unified Rendering in Python.",
            "name": "py-fury"
        },
        {
            "description": "A Python package for interactive mapping using Google Earth Engine and\nipyleaflet.",
            "name": "py-geemap"
        },
        {
            "description": "GPU-GEMM generator for the Discontinuous Galerkin method",
            "name": "py-gemmforge"
        },
        {
            "description": "Gensim is a Python library for topic modelling, document indexing and\nsimilarity retrieval with large corpora. Target audience is the natural\nlanguage processing (NLP) and information retrieval (IR) community.",
            "name": "py-gensim"
        },
        {
            "description": "Tool to convert geopandas vector data into rasterized xarray data.",
            "name": "py-geocube"
        },
        {
            "description": "Object-oriented pure Python B-Spline and NURBS library.",
            "name": "py-geomdl"
        },
        {
            "description": "GeoPandas is an open source project to make working with geospatial data\nin python easier. GeoPandas extends the datatypes used by pandas to\nallow spatial operations on geometric types. Geometric operations are\nperformed by shapely. Geopandas further depends on fiona for file access\nand descartes and matplotlib for plotting.",
            "name": "py-geopandas"
        },
        {
            "description": "The Global Extensible Open Power Manager (GEOPM) Service provides a user\ninterface for accessing hardware telemetry and settings securely.",
            "name": "py-geopmpy"
        },
        {
            "description": "A Python library designed to make data analysis and visualization\nseamless and simple.",
            "name": "py-geoviews"
        },
        {
            "description": "Generator of Matrix Multiplication Kernels - GiMMiK - is a tool for\ngeneration of high performance matrix multiplication kernel code. for\nvarious accelerator platforms.",
            "name": "py-gimmik"
        },
        {
            "description": "This is a Python wrapper for the fortran library used in the R package\nglmnet.",
            "name": "py-glmnet"
        },
        {
            "description": "This is a python version of the popular glmnet library (beta release).\nGlmnet fits the entire lasso or elastic-net regularization path for\nlinear regression, logistic and multinomial regression models, poisson\nregression and the cox model.",
            "name": "py-glmnet-python"
        },
        {
            "description": "A toolbox for accurate single-trial estimates in fMRI time-series data.",
            "name": "py-glmsingle"
        },
        {
            "description": "GluonCV provides implementations of state-of-the-art (SOTA) deep\nlearning algorithms in computer vision. It aims to help engineers,\nresearchers, and students quickly prototype products, validate new ideas\nand learn computer vision.",
            "name": "py-gluoncv"
        },
        {
            "description": "glymur contains a Python interface to the OpenJPEG library which allows\none to read and write JPEG 2000 files. glymur works on Python 3.7, 3.8,\n3.9, and 3.10.",
            "name": "py-glymur"
        },
        {
            "description": "Interoperability between Python and Gmsh",
            "name": "py-gmsh-interop"
        },
        {
            "description": "Python bindings and ensemble workflow management for GROMACS. The\nGROMACS C++ API is affected by its package variants. You can specify a\nparticular GROMACS API by making the dependency variant explicit. E.g.\n``spack install gmxapi ^gromacs+mpi~double``",
            "name": "py-gmxapi"
        },
        {
            "description": "Gnuplot.py is a Python package that allows you to create graphs from\nwithin Python using the gnuplot plotting program.",
            "name": "py-gnuplot"
        },
        {
            "description": "Python scripts to find enrichment of GO terms",
            "name": "py-goatools"
        },
        {
            "description": "GPAW is a density-functional theory (DFT) Python code based on the\nprojector-augmented wave (PAW) method and the atomic simulation\nenvironment (ASE).",
            "name": "py-gpaw"
        },
        {
            "description": "The Gaussian Process Toolbox.",
            "name": "py-gpy"
        },
        {
            "description": "Performs global optimization with different acquisition functions. Among\nother functionalities, it is possible to use GPyOpt to optimize physical\nexperiments (sequentially or in batches) and tune the parameters of\nMachine Learning algorithms. It is able to handle large data sets via\nsparse Gaussian process models.",
            "name": "py-gpyopt"
        },
        {
            "description": "GPyTorch is a Gaussian process library implemented using PyTorch.\nGPyTorch is designed for creating scalable, flexible, and modular\nGaussian process models with ease.",
            "name": "py-gpytorch"
        },
        {
            "description": "Python library for easily interacting with trained machine learning\nmodels",
            "name": "py-gradio"
        },
        {
            "description": "GraphCast: Learning skillful medium-range global weather forecasting.",
            "name": "py-graphcast"
        },
        {
            "description": "The gridDataFormats package provides classes to unify reading and\nwriting n-dimensional datasets. One can read grid data from files, make\nthem available as a Grid object, and write out the data again.",
            "name": "py-griddataformats"
        },
        {
            "description": "The GSD file format is the native file format for HOOMD-blue. GSD files\nstore trajectories of the HOOMD-blue system state in a binary file with\nefficient random access to frames. GSD allows all particle and topology\nproperties to vary from one frame to the next. Use the GSD Python API to\nspecify the initial condition for a HOOMD-blue simulation or analyze\ntrajectory output with a script. Read a GSD trajectory with a\nvisualization tool to explore the behavior of the simulation.",
            "name": "py-gsd"
        },
        {
            "description": "GTDB-Tk is a software toolkit for assigning objective taxonomic\nclassifications to bacterial and archaeal genomes based on the Genome\nDatabase Taxonomy (GTDB).",
            "name": "py-gtdbtk"
        },
        {
            "description": "OpenAI Gym is a toolkit for developing and comparing reinforcement\nlearning algorithms. This is the gym open-source library, which gives\nyou access to a standardized set of environments.",
            "name": "py-gym"
        },
        {
            "description": "Python Objects Onto HDF5.",
            "name": "py-h5io"
        },
        {
            "description": "The h5py package provides both a high- and low-level interface to the\nHDF5 library from Python.",
            "name": "py-h5py"
        },
        {
            "description": "Shell-like environment for HDF5.",
            "name": "py-h5sh"
        },
        {
            "description": "Cloud-native genomic dataframes and batch computing (Python API)",
            "name": "py-hail"
        },
        {
            "description": "Hatchet is a performance tool for analyzing hierarchical performance\ndata using a graph-indexed Pandas dataframe.",
            "name": "py-hatchet"
        },
        {
            "description": "Hclust2 is a handy tool for plotting heat-maps with several useful\noptions to produce high quality figures that can be used in publication.",
            "name": "py-hclust2"
        },
        {
            "description": "HDBSCAN - Hierarchical Density-Based Spatial Clustering of Applications\nwith Noise. Performs DBSCAN over varying epsilon values and integrates\nthe result to find a clustering that gives the best stability over\nepsilon. This allows HDBSCAN to find clusters of varying densities\n(unlike DBSCAN), and be more robust to parameter selection. In practice\nthis means that HDBSCAN returns a good clustering straight away with\nlittle or no parameter tuning -- and the primary parameter, minimum\ncluster size, is intuitive and easy to select. HDBSCAN is ideal for\nexploratory data analysis; it's a fast and robust algorithm that you can\ntrust to return meaningful clusters (if there are any).",
            "name": "py-hdbscan"
        },
        {
            "description": "Python and C package for HEALPix discretisation of the sphere",
            "name": "py-healpix"
        },
        {
            "description": "healpy is a Python package to handle pixelated data on the sphere.",
            "name": "py-healpy"
        },
        {
            "description": "Heat is a flexible and seamless open-source software for high\nperformance data analytics and machine learning. It provides highly\noptimized algorithms and data structures for tensor computations using\nCPUs, GPUs and distributed cluster systems on top of MPI.",
            "name": "py-heat"
        },
        {
            "description": "Machine Learning for High Energy Physics",
            "name": "py-hep-ml"
        },
        {
            "description": "Library for getting your data into HEPData",
            "name": "py-hepdata-lib"
        },
        {
            "description": "hepstats is a library for statistical inference aiming to cover the\nneeds in High Energy Physics. It is part of the Scikit-HEP project.",
            "name": "py-hepstats"
        },
        {
            "description": "Hist classes and utilities",
            "name": "py-hist"
        },
        {
            "description": "Versatile, high-performance histogram toolkit for Numpy.",
            "name": "py-histbook"
        },
        {
            "description": "Composable histogram primitives for distributed data reduction.",
            "name": "py-histogrammar"
        },
        {
            "description": "Pretty print of NumPy (and other) histograms to the console",
            "name": "py-histoprint"
        },
        {
            "description": "hmmlearn is a set of algorithms for unsupervised learning and inference\nof Hidden Markov Models.",
            "name": "py-hmmlearn"
        },
        {
            "description": "A Python library designed to make data analysis and visualization\nseamless and simple.",
            "name": "py-holoviews"
        },
        {
            "description": "Horovod is a distributed deep learning training framework for\nTensorFlow, Keras, PyTorch, and Apache MXNet.",
            "name": "py-horovod"
        },
        {
            "description": "A distributed Hyperband implementation with lots of room for\nimprovement",
            "name": "py-hpbandster"
        },
        {
            "description": "HTSeq is a Python package that provides infrastructure to process data\nfrom high-throughput sequencing assays.",
            "name": "py-htseq"
        },
        {
            "description": "HTTP-based REST interface to Stan, a package for Bayesian inference.",
            "name": "py-httpstan"
        },
        {
            "description": "A high-level plotting API for pandas, dask, xarray, and networkx built\non HoloViews.",
            "name": "py-hvplot"
        },
        {
            "description": "Hyperopt is a Python library for serial and parallel optimization over\nawkward search spaces, which may include real-valued, discrete, and\nconditional dimensions.",
            "name": "py-hyperopt"
        },
        {
            "description": "A library for property based testing.",
            "name": "py-hypothesis"
        },
        {
            "description": "igor: interface for reading binary IGOR files.",
            "name": "py-igor"
        },
        {
            "description": "igor2: interface for reading binary IGOR files.",
            "name": "py-igor2"
        },
        {
            "description": "A library and collection of scripts to work with Illumina paired-end\ndata (for CASAVA 1.8+).",
            "name": "py-illumina-utils"
        },
        {
            "description": "The PyIlmBase libraries provides python bindings for the IlmBase\nlibraries.",
            "name": "py-ilmbase"
        },
        {
            "description": "Imagecodecs is a Python library that provides block-oriented, in-memory\nbuffer transformation, compression, and decompression functions for use\nin the tifffile, czifile, zarr, and other scientific image input/output\nmodules..",
            "name": "py-imagecodecs"
        },
        {
            "description": "A Python Perceptual Image Hashing Module",
            "name": "py-imagehash"
        },
        {
            "description": "Python library for reading and writing image data. Imageio is a Python\nlibrary that provides an easy interface to read and write a wide range\nof image data, including animated images, video, volumetric data, and\nscientific formats. It is cross-platform, runs on Python 2.7 and 3.4+,\nand is easy to install.",
            "name": "py-imageio"
        },
        {
            "description": "imbalanced-learn is a python package offering a number of re-sampling\ntechniques commonly used in datasets showing strong between-class\nimbalance. It is compatible with scikit-learn and is part of scikit-\nlearn-contrib projects.",
            "name": "py-imbalanced-learn"
        },
        {
            "description": "A library for image augmentation in machine learning experiments,\nparticularly convolutional neural networks. Supports the augmentation of\nimages, keypoints/landmarks, bounding boxes, heatmaps and segmentation\nmaps in a variety of different ways.",
            "name": "py-imgaug"
        },
        {
            "description": "Interactive IPython-Friendly Minimizer based on SEAL Minuit2.",
            "name": "py-iminuit"
        },
        {
            "description": "inStrain is python program for analysis of co-occurring genome\npopulations from metagenomes that allows highly accurate genome\ncomparisons, analysis of coverage, microdiversity, and linkage, and\nsensitive SNP detection with gene localization and synonymous non-\nsynonymous identification.",
            "name": "py-instrain"
        },
        {
            "description": "Normalize intensities of images from various MRI modalities",
            "name": "py-intensity-normalization"
        },
        {
            "description": "Interactive Canvas in Jupyter.",
            "name": "py-ipycanvas"
        },
        {
            "description": "Matplotlib Jupyter Extension.",
            "name": "py-ipympl"
        },
        {
            "description": "An interactive toolkit for assembly and analysis of restriction-site\nassociated genomic data sets (e.g., RAD, ddRAD, GBS) for population\ngenetic and phylogenetic studies.",
            "name": "py-ipyrad"
        },
        {
            "description": "Bacis iterative statistics implementation.",
            "name": "py-iterative-stats"
        },
        {
            "description": "Fast numerical derivatives for analytic functions with arbitrary round-\noff error and error propagation.",
            "name": "py-jacobi"
        },
        {
            "description": "Differentiate, compile, and transform Numpy code. JAX is a Python\nlibrary for accelerator-oriented array computation and program\ntransformation, designed for high-performance numerical computing and\nlarge-scale machine learning.",
            "name": "py-jax"
        },
        {
            "description": "XLA library for Jax. jaxlib is the support library for JAX. While JAX\nitself is a pure Python package, jaxlib contains the binary (C/C++)\nparts of the library, including Python bindings, the XLA compiler, the\nPJRT runtime, and a handful of handwritten kernels.",
            "name": "py-jaxlib"
        },
        {
            "description": "Type annotations and runtime checking for shape and dtype of JAX arrays,\nand PyTrees.",
            "name": "py-jaxtyping"
        },
        {
            "description": "JMP is a Mixed Precision library for JAX.",
            "name": "py-jmp"
        },
        {
            "description": "This package can load and use a Jet Propulsion Laboratory (JPL)\nephemeris for predicting the position and velocity of a planet or other\nSolar System body.",
            "name": "py-jplephem"
        },
        {
            "description": "JPype is an effort to allow python programs full access to java class\nlibraries.",
            "name": "py-jpype1"
        },
        {
            "description": "Jraph: A library for Graph Neural Networks in Jax.",
            "name": "py-jraph"
        },
        {
            "description": "A pure python module for reading and writing kaldi ark files",
            "name": "py-kaldiio"
        },
        {
            "description": "Python wrapper around kallisto | bustools for scRNA-seq analysis.",
            "name": "py-kb-python"
        },
        {
            "description": "Multi-backend Keras. Keras 3 is a new multi-backend implementation of\nthe Keras API, with support for TensorFlow, JAX, and PyTorch.",
            "name": "py-keras"
        },
        {
            "description": "Utilities for working with image data, text data, and sequence data.",
            "name": "py-keras-preprocessing"
        },
        {
            "description": "Converts Machine Learning models to ONNX for use in Windows ML",
            "name": "py-keras2onnx"
        },
        {
            "description": "Python implementations of the k-modes and k-prototypes clustering\nalgorithms for clustering categorical data.",
            "name": "py-kmodes"
        },
        {
            "description": "Kosh allows codes to store, query, share data via an easy-to-use Python\nAPI. Kosh lies on top of Sina and can use any database backend supported\nby Sina. In adition Kosh aims to make data access and sharing as simple\nas possible.",
            "name": "py-kosh"
        },
        {
            "description": "Wavelet scattering transforms in Python with GPU acceleration.",
            "name": "py-kymatio"
        },
        {
            "description": "lap is a linear assignment problem solver using Jonker-Volgenant\nalgorithm for dense (LAPJV) or sparse (LAPMOD) matrices.",
            "name": "py-lap"
        },
        {
            "description": "Native Python ASPRS LAS read/write library.",
            "name": "py-laspy"
        },
        {
            "description": "a Python package that provides a lazily-evaluated numerical array class,\nlarray, based on and compatible with NumPy arrays.",
            "name": "py-lazyarray"
        },
        {
            "description": "This Python module contain freestanding implementations of electrostatic\nforward models incorporated in LFPy",
            "name": "py-lfpykit"
        },
        {
            "description": "Latin Hypercube Sampling with Multi-Dimensional Uniformity (LHS-MDU)\nfrom Deutsch and Deutsch, Latin hypercube sampling with multidimensional\nuniformity.",
            "name": "py-lhsmdu"
        },
        {
            "description": "Library for managing ensemble-like collections of computations.",
            "name": "py-libensemble"
        },
        {
            "description": "A python package for music and audio analysis.",
            "name": "py-librosa"
        },
        {
            "description": "SONATA files reader",
            "name": "py-libsonata"
        },
        {
            "description": "Survival analysis was originally developed and applied heavily by the\nactuarial and medical community. Its purpose was to answer *why do\nevents occur now versus later* under uncertainty (where *events* might\nrefer to deaths, disease remission, etc.). *lifelines* is a pure Python\nimplementation of the best parts of survival analysis.",
            "name": "py-lifelines"
        },
        {
            "description": "LightGBM is a gradient boosting framework that uses tree based learning\nalgorithms.",
            "name": "py-lightgbm"
        },
        {
            "description": "A deep learning package for self-supervised learning.",
            "name": "py-lightly"
        },
        {
            "description": "A utility package for lightly.",
            "name": "py-lightly-utils"
        },
        {
            "description": "The deep learning framework to pretrain, finetune and deploy AI models.",
            "name": "py-lightning"
        },
        {
            "description": "Fabric is the fast and lightweight way to scale PyTorch models without\nboilerplate.",
            "name": "py-lightning-fabric"
        },
        {
            "description": "LightningLite enables pure PyTorch users to scale their existing code on\nany kind of device while retaining full control over their own loops and\noptimization logic.",
            "name": "py-lightning-lite"
        },
        {
            "description": "Lighning-UQ-Box: A toolbox for uncertainty quantification in deep\nlearning.",
            "name": "py-lightning-uq-box"
        },
        {
            "description": "A python library to build Model Trees with Linear Models at the leaves.",
            "name": "py-linear-tree"
        },
        {
            "description": "The line enhancer is only used by crYOLO internally",
            "name": "py-lineenhancer"
        },
        {
            "description": "The Deep Learning framework to train, deploy, and ship AI products\nLightning fast.",
            "name": "py-litdata"
        },
        {
            "description": "Least-Squares Minimization with Bounds and Constraints",
            "name": "py-lmfit"
        },
        {
            "description": "Tools for calculating sequence properties of disordered proteins",
            "name": "py-localcider"
        },
        {
            "description": "Work with Loom files for single-cell RNA-seq data.",
            "name": "py-loompy"
        },
        {
            "description": "LPIPS Similarity metric",
            "name": "py-lpips"
        },
        {
            "description": "Glue (Grid LSC User Environment) is a suite of python modules and\nprograms to allow users to run LSC codes on the grid. It also provides\ncertain metadata services, such as the LSC segment database.",
            "name": "py-lscsoft-glue"
        },
        {
            "description": "Python API for LVIS dataset.",
            "name": "py-lvis"
        },
        {
            "description": "Fast spectrogram phase recovery using Local Weighted Sums",
            "name": "py-lws"
        },
        {
            "description": "MACS2 Model-based Analysis of ChIP-Seq",
            "name": "py-macs2"
        },
        {
            "description": "MACS: Model-based Analysis for ChIP-Seq",
            "name": "py-macs3"
        },
        {
            "description": "Mahotas: Computer Vision Library.",
            "name": "py-mahotas"
        },
        {
            "description": "Python bindings for the C++ implementation of the Mapbox Earcut library,\nwhich provides very fast and quite robust triangulation of 2D polygons.",
            "name": "py-mapbox-earcut"
        },
        {
            "description": "Classification Schemes for Choropleth Maps.",
            "name": "py-mapclassify"
        },
        {
            "description": "Implementation of the Markov clustering (MCL) algorithm in python",
            "name": "py-markov-clustering"
        },
        {
            "description": "Matminer is a library for performing data mining in the field of\nmaterials science.",
            "name": "py-matminer"
        },
        {
            "description": "Matplotlib is a comprehensive library for creating static, animated, and\ninteractive visualizations in Python.",
            "name": "py-matplotlib"
        },
        {
            "description": "Mayavi: 3D visualization of scientific data in Python.",
            "name": "py-mayavi"
        },
        {
            "description": "MDAnalysis is a Python toolkit to analyze molecular dynamics\ntrajectories generated by a wide range of popular simulation packages\nincluding DL_Poly, CHARMM, Amber, NAMD, LAMMPS, and Gromacs. (See the\nlists of supported trajectory formats and topology formats.)",
            "name": "py-mdanalysis"
        },
        {
            "description": "Python package for multi-electrode array (MEA) handling and stimulation.",
            "name": "py-meautility"
        },
        {
            "description": "medaka is a tool to create consensus sequences and variant calls from\nnanopore sequencing data. This task is performed using neural networks\napplied a pileup of individual sequencing reads against a draft\nassembly. It provides state-of-the-art results outperforming sequence-\ngraph based methods and signal-based methods, whilst also being faster.",
            "name": "py-medaka"
        },
        {
            "description": "MELD is a tool for inferring the structure of biomolecules from sparse,\nambiguous, or noisy data.",
            "name": "py-meldmd"
        },
        {
            "description": "Melissa is a file-avoiding, adaptive, fault-tolerant and elastic\nframework, to run large-scale sensitivity analysis or deep-surrogate\ntraining on supercomputers. This package builds the launcher and server\nmodules.",
            "name": "py-melissa-core"
        },
        {
            "description": "Merlin Workflow for HPC.",
            "name": "py-merlin"
        },
        {
            "description": "MeshIO is a Python library to read and write many mesh formats.",
            "name": "py-meshio"
        },
        {
            "description": "Simplicial Mesh Generation from Python",
            "name": "py-meshpy"
        },
        {
            "description": "MetaPhlAn is a computational tool for profiling the composition of\nmicrobial communities (Bacteria, Archaea and Eukaryotes) from\nmetagenomic shotgun sequencing data (i.e. not 16S) with species-level.",
            "name": "py-metaphlan"
        },
        {
            "description": "Collection of tools for reading, visualizing and performing calculations\nwith weather data.",
            "name": "py-metpy"
        },
        {
            "description": "metric-learn contains efficient Python implementations of several\npopular supervised and weakly-supervised metric learning algorithms. As\npart of scikit-learn-contrib, the API of metric-learn is compatible with\nscikit-learn, the leading library for machine learning in Python. This\nallows to use all the scikit-learn routines (for pipelining, model\nselection, etc) with metric learning algorithms through a unified\ninterface.",
            "name": "py-metric-learn"
        },
        {
            "description": "Reader and Writer for Philips' MFF file format.",
            "name": "py-mffpy"
        },
        {
            "description": "Repository of scripts and libraries for using the MG-RAST API and MG-\nRAST data.",
            "name": "py-mg-rast-tools"
        },
        {
            "description": "METIS partitioner for mesh and graphMETIS partitioner for mesh and graph",
            "name": "py-mgmetis"
        },
        {
            "description": "Mikado is a lightweight Python3 pipeline whose purpose is to facilitate\nthe identification of expressed loci from RNA-Seq data * and to select\nthe best models in each locus.",
            "name": "py-mikado"
        },
        {
            "description": "MiniSom is a minimalistic and Numpy based implementation of the Self\nOrganizing Maps (SOM). SOM is a type of Artificial Neural Network able\nto convert complex, nonlinear statistical relationships between high-\ndimensional data items into simple geometric relationships on a low-\ndimensional display. Minisom is designed to allow researchers to easily\nbuild on top of it and to give students the ability to quickly grasp its\ndetails. The project initially aimed for a minimalistic implementation\nof the Self-Organizing Map (SOM) algorithm, focusing on simplicity in\nfeatures, dependencies, and code style. Although it has expanded in\nterms of features, it remains minimalistic by relying only on the numpy\nlibrary and emphasizing vectorization in coding style.",
            "name": "py-minisom"
        },
        {
            "description": "The MinkowskiEngine is an auto-differentiation library for sparse\ntensors.",
            "name": "py-minkowskiengine"
        },
        {
            "description": "MISO (Mixture of Isoforms) is a probabilistic framework that quantitates\nthe expression level of alternatively spliced genes from RNA-Seq data,\nand identifies differentially regulated isoforms or exons across\nsamples.",
            "name": "py-misopy"
        },
        {
            "description": "Mizani is a scales package for graphics. It is based on Hadley Wickham's\nScales package.",
            "name": "py-mizani"
        },
        {
            "description": "A stand-alone implementation of several NumPy dtype extensions used in\nmachine learning libraries.",
            "name": "py-ml-dtypes"
        },
        {
            "description": "MLflow: A Platform for ML Development and Productionization.",
            "name": "py-mlflow"
        },
        {
            "description": "Mlxtend (machine learning extensions) is a Python library of useful\ntools for the day-to-day data science tasks.",
            "name": "py-mlxtend"
        },
        {
            "description": "MMCV is a foundational python library for computer vision research and\nsupports many research projects in MMLAB, such as MMDetection and\nMMAction.",
            "name": "py-mmcv"
        },
        {
            "description": "MNE python project for MEG and EEG data analysis.",
            "name": "py-mne"
        },
        {
            "description": "MNE-BIDS: Organizing MEG, EEG, and iEEG data according to the BIDS\nspecification and facilitating their analysis with MNE-Python.",
            "name": "py-mne-bids"
        },
        {
            "description": "Packing methods used to encode and decode the data payloads of Met\nOffice Unified Model 'fields'",
            "name": "py-mo-pack"
        },
        {
            "description": "Basis Functions and Node Sets for Interpolation",
            "name": "py-modepy"
        },
        {
            "description": "Modin: Make your pandas code run faster by changing one line of code.",
            "name": "py-modin"
        },
        {
            "description": "Modred is a parallelized library for finding modal decompositions and\nreduced-order models.",
            "name": "py-modred"
        },
        {
            "description": "AI Toolkit for Healthcare Imaging",
            "name": "py-monai"
        },
        {
            "description": "Python morphology manipulation toolkit",
            "name": "py-morph-tool"
        },
        {
            "description": "Python library for reading / writing morphology files",
            "name": "py-morphio"
        },
        {
            "description": "The py-motmetrics library provides a Python implementation of metrics\nfor benchmarking multiple object trackers (MOT).",
            "name": "py-motmetrics"
        },
        {
            "description": "MoviePy is a Python module for video editing, which can be used for\nbasic operations (like cuts, concatenations, title insertions), video\ncompositing (a.k.a. non-linear editing), video processing, or to create\nadvanced effects. It can read and write the most common video formats,\nincluding GIF.",
            "name": "py-moviepy"
        },
        {
            "description": "Zero-copy MPI communication of JAX arrays, for turbo-charged HPC\napplications in Python.",
            "name": "py-mpi4jax"
        },
        {
            "description": "Matplotlib styles for HEP",
            "name": "py-mplhep"
        },
        {
            "description": "Python implementation of the MRC2014 file format, which is used in\nstructural biology to store image and volume data.",
            "name": "py-mrcfile"
        },
        {
            "description": "This package provides encoding and decoding routines that enable the\nserialization and deserialization of numerical and array data types\nprovided by numpy using the highly efficient msgpack format.\nSerialization of Python's native complex data types is also supported.",
            "name": "py-msgpack-numpy"
        },
        {
            "description": "Multi-class imbalance is a common problem occurring in real-world\nsupervised classifications tasks. While there has already been some\nresearch on the specialized methods aiming to tackle that challenging\nproblem, most of them still lack coherent Python implementation that is\nsimple, intuitive and easy to use. multi-imbalance is a python package\ntackling the problem of multi-class imbalanced datasets in machine\nlearnin",
            "name": "py-multi-imbalance"
        },
        {
            "description": "Combine multi-echoes from a multi-echo fMRI acquisition.",
            "name": "py-multiecho"
        },
        {
            "description": "MultiQC is a tool to aggregate bioinformatics results across many\nsamples into a single report. It is written in Python and contains\nmodules for a large number of common bioinformatics tools.",
            "name": "py-multiqc"
        },
        {
            "description": "Functions to extract information from Oxford Nanopore sequencing data\nand alignments",
            "name": "py-nanoget"
        },
        {
            "description": "A few simple math function for other Oxford Nanopore processing scripts",
            "name": "py-nanomath"
        },
        {
            "description": "Plotting scripts for long read sequencing data",
            "name": "py-nanoplot"
        },
        {
            "description": "Minimalistic large language model 3D-parallelism training.",
            "name": "py-nanotron"
        },
        {
            "description": "Background noise and signal reverberation due to reflections in an\nenclosure are the two main impairments in acoustic signal processing and\nfar-field speech recognition. This work addresses signal dereverberation\ntechniques based on WPE for speech recognition and other far-field\napplications. WPE is a compelling algorithm to blindly dereverberate\nacoustic signals based on long-term linear prediction.",
            "name": "py-nara-wpe"
        },
        {
            "description": "cftime support for matplotlib axis.",
            "name": "py-nc-time-axis"
        },
        {
            "description": "Neo is a package for representing electrophysiology data in Python,\ntogether with support for reading a wide range of neurophysiology file\nformats",
            "name": "py-neo"
        },
        {
            "description": "Nested sampling algorithms for evaluating Bayesian evidence.",
            "name": "py-nestle"
        },
        {
            "description": "Python interface to the netCDF Library.",
            "name": "py-netcdf4"
        },
        {
            "description": "NetKet is an open-source project, delivering cutting-edge methods for\nthe study of many-body quantum systems with artificial neural networks\nand machine learning techniques.",
            "name": "py-netket"
        },
        {
            "description": "Netpyne: A python package to facilitate the development, parallel\nsimulation, optimization and analysis of multiscale biological neuronal\nnetworks in NEURON.",
            "name": "py-netpyne"
        },
        {
            "description": "NetworKit is a growing open-source toolkit for large-scale network\nanalysis. Its aim is to provide tools for the analysis of large networks\nin the size range from thousands to billions of edges. For this purpose,\nit implements efficient graph algorithms, many of them parallel to\nutilize multicore architectures. These are meant to compute standard\nmeasures of network analysis, such as degree sequences, clustering\ncoefficients, and centrality measures. In this respect, NetworKit is\ncomparable to packages such as NetworkX, albeit with a focus on\nparallelism and scalability.",
            "name": "py-networkit"
        },
        {
            "description": "NetworkX is a Python package for the creation, manipulation, and study\nof the structure, dynamics, and functions of complex networks.",
            "name": "py-networkx"
        },
        {
            "description": "NeuralGCM: Hybrid ML + Physics model of Earth's atmosphere.",
            "name": "py-neuralgcm"
        },
        {
            "description": "The Python Toolbox for Neurophysiological Signal Processing. This\npackage is the continuation of NeuroKit 1. It's a user-friendly package\nproviding easy access to advanced biosignal processing routines.\nResearchers and clinicians without extensive knowledge of programming or\nbiomedical signal processing can analyze physiological data with only\ntwo lines of code.",
            "name": "py-neurokit2"
        },
        {
            "description": "Simple and powerfull neural network library for python",
            "name": "py-neurolab"
        },
        {
            "description": "Python library neuron morphology analysis",
            "name": "py-neurom"
        },
        {
            "description": "A Python Toolbox for Multimodal Neural Data Representation Analysis.",
            "name": "py-neurora"
        },
        {
            "description": "A collection of tools for representing and anlyzing neuroscientific\ndata.",
            "name": "py-neurotools"
        },
        {
            "description": "Jupyter widget to interactively view molecular structures and\ntrajectories.",
            "name": "py-nglview"
        },
        {
            "description": "Reusable tools for working with next-generation sequencing (NGS) data.",
            "name": "py-ngs-tools"
        },
        {
            "description": "Access a multitude of neuroimaging data formats",
            "name": "py-nibabel"
        },
        {
            "description": "BetaSeries Correlations implemented in Nipype.",
            "name": "py-nibetaseries"
        },
        {
            "description": "Statistical learning for neuroimaging in Python.",
            "name": "py-nilearn"
        },
        {
            "description": "Neuroimaging in Python: Pipelines and Interfaces.",
            "name": "py-nipype"
        },
        {
            "description": "Modeling and Statistical analysis of fMRI data in Python.",
            "name": "py-nistats"
        },
        {
            "description": "NiTransforms -- Neuroimaging spatial transforms in Python.",
            "name": "py-nitransforms"
        },
        {
            "description": "Common workflows for MRI (anatomical, functional, diffusion, etc)",
            "name": "py-niworkflows"
        },
        {
            "description": "non regression test tools.",
            "name": "py-non-regression-test-tools"
        },
        {
            "description": "Type hints for numpy",
            "name": "py-nptyping"
        },
        {
            "description": "Some useful extensions for NumPy",
            "name": "py-npx"
        },
        {
            "description": "NumPy aware dynamic Python compiler using LLVM",
            "name": "py-numba"
        },
        {
            "description": "Use numba-compiled kernels from within Jax",
            "name": "py-numba4jax"
        },
        {
            "description": "Numcodecs is a Python package providing buffer compression and\ntransformation codecs for use in data storage and communication\napplications.",
            "name": "py-numcodecs"
        },
        {
            "description": "Solves automatic numerical differentiation problems in one or more\nvariables.",
            "name": "py-numdifftools"
        },
        {
            "description": "Fast numerical expression evaluator for NumPy",
            "name": "py-numexpr"
        },
        {
            "description": "Numexpr3 is a fast numerical expression evaluator for NumPy. With it,\nexpressions that operate on arrays (like \"3*a+4*b\") are accelerated and\nuse less memory than doing the same calculation in Python. In addition,\nits multi-threaded capabilities can make use of all your cores, which\nmay accelerate computations, most specially if they are not memory-\nbounded (e.g. those using transcendental functions). Compared to NumExpr\n2.6, functions have been re-written in a fashion such that gcc can auto-\nvectorize them with SIMD instruction sets such as SSE2 or AVX2, if your\nprocessor supports them. Use of a newer version of gcc such as 5.4 is\nstrongly recommended.",
            "name": "py-numexpr3"
        },
        {
            "description": "This package consists of a couple of optimised tools for doing things\nthat can roughly be considered \"group-indexing operations\". The most\nprominent tool is `aggregate`. `aggregate` takes an array of values, and\nan array giving the group number for each of those values. It then\nreturns the sum (or mean, or std, or any, ...etc.) of the values in each\ngroup. You have probably come across this idea before, using `matlab`\naccumarray, `pandas` groupby, or generally MapReduce algorithms and\nhistograms. There are different implementations of `aggregate` provided,\nbased on plain `numpy`, `numba` and `weave`. Performance is a main\nconcern, and so far we comfortably beat similar implementations in other\npackages (check the benchmarks).",
            "name": "py-numpy-groupies"
        },
        {
            "description": "This package creates a quaternion type in python, and further enables\nnumpy to create and manipulate arrays of quaternions. The usual\nalgebraic operations (addition and multiplication) are available, along\nwith numerous properties like norm and various types of distance\nmeasures between two quaternions. There are also additional functions\nlike \"squad\" and \"slerp\" interpolation, and conversions to and from\naxis-angle, matrix, and Euler-angle representations of rotations. The\ncore of the code is written in C for speed.",
            "name": "py-numpy-quaternion"
        },
        {
            "description": "Library to make reading, writing and modifying both binary and ascii STL\nfiles easy",
            "name": "py-numpy-stl"
        },
        {
            "description": "A deep learning framework for AI-driven multi-physics systems.",
            "name": "py-nvidia-modulus"
        },
        {
            "description": "ObsPy is an open-source project dedicated to provide a Python framework\nfor processing seismological data",
            "name": "py-obspy"
        },
        {
            "description": "O-CNN is an octree-based sparse convolutional neural network framework\nfor 3D deep learning.",
            "name": "py-ocnn"
        },
        {
            "description": "Geometry Classes and Operations (opendatacube).",
            "name": "py-odc-geo"
        },
        {
            "description": "The Open Graph Benchmark (OGB) is a collection of benchmark datasets,\ndata loaders, and evaluators for graph machine learning. Datasets cover\na variety of graph machine learning tasks and real-world applications.\nThe OGB data loaders are fully compatible with popular graph deep\nlearning frameworks, including PyTorch Geometric and Deep Graph Library\n(DGL). They provide automatic dataset downloading, standardized dataset\nsplits, and unified performance evaluation.",
            "name": "py-ogb"
        },
        {
            "description": "Python and MATLAB wrappers for the Okada Green's function codes",
            "name": "py-okada-wrapper"
        },
        {
            "description": "Open Neural Network Exchange (ONNX) is an open ecosystem that empowers\nAI developers to choose the right tools as their project evolves. ONNX\nprovides an open source format for AI models, both deep learning and\ntraditional ML. It defines an extensible computation graph model, as\nwell as definitions of built-in operators and standard data types.\nCurrently we focus on the capabilities needed for inferencing (scoring).",
            "name": "py-onnx"
        },
        {
            "description": "ONNX flops / params counter.",
            "name": "py-onnx-opcounter"
        },
        {
            "description": "ONNX Converter and Optimization Tools",
            "name": "py-onnxconverter-common"
        },
        {
            "description": "Converts Machine Learning models to ONNX",
            "name": "py-onnxmltools"
        },
        {
            "description": "ONNX Runtime is a performance-focused complete scoring engine for Open\nNeural Network Exchange (ONNX) models, with an open extensible\narchitecture to continually address the latest developments in AI and\nDeep Learning. ONNX Runtime stays up to date with the ONNX standard with\ncomplete implementation of all ONNX operators, and supports all ONNX\nreleases (1.2+) with both future and backwards compatibility.",
            "name": "py-onnxruntime"
        },
        {
            "description": "This project provides classes and utility functions for working with\nread fast5 files. It provides an abstraction layer between the\nunderlying h5py library and the various concepts central to read fast5\nfiles, such as \"reads\", \"analyses\", \"analysis summaries\", and \"analysis\ndatasets\". Ideally all interaction with a read fast5 file should be\npossible via this API, without having to directly invoke the h5py\nlibrary.",
            "name": "py-ont-fast5-api"
        },
        {
            "description": "The OpenAI Python library provides convenient access to the OpenAI API\nfrom applications written in the Python language. It includes a pre-\ndefined set of classes for API resources that initialize themselves\ndynamically from API responses which makes it compatible with a wide\nrange of versions of the OpenAI API.",
            "name": "py-openai"
        },
        {
            "description": "OpenMC is a community-developed Monte Carlo neutron and photon transport\nsimulation code. It is capable of performing fixed source, k-eigenvalue,\nand subcritical multiplication calculations on models built using either\na constructive solid geometry or CAD representation. OpenMC supports\nboth continuous-energy and multigroup transport. The continuous-energy\nparticle interaction data is based on a native HDF5 format that can be\ngenerated from ACE files produced by NJOY. Parallelism is enabled via a\nhybrid MPI and OpenMP programming model.",
            "name": "py-openmc"
        },
        {
            "description": "A versatile halfedge-based data structure for representing and\nmanipulating polygon meshes",
            "name": "py-openmesh"
        },
        {
            "description": "Validator and Example Scripts for the openPMD markup. openPMD is an open\nstandard for particle-mesh data files.",
            "name": "py-openpmd-validator"
        },
        {
            "description": "Python visualization tools for openPMD files",
            "name": "py-openpmd-viewer"
        },
        {
            "description": "An extensible framework for program autotuning.",
            "name": "py-opentuner"
        },
        {
            "description": "The Output Parse-Plot Python (OPPPY) library is a python based data\nanalysis library designed to extract, store, and plot information from\noutput and dump files generated by scientific software packages.",
            "name": "py-opppy"
        },
        {
            "description": "Optimized Einsum: A tensor contraction order optimizer.",
            "name": "py-opt-einsum"
        },
        {
            "description": "A gradient processing and optimisation library in JAX.",
            "name": "py-optax"
        },
        {
            "description": "Optuna is an automatic hyperparameter optimization software framework,\nparticularly designed for machine learning. It features an imperative,\ndefine-by-run style user API. Thanks to our define-by-run API, the code\nwritten with Optuna enjoys high modularity, and the user of Optuna can\ndynamically construct the search spaces for the hyperparameters.",
            "name": "py-optuna"
        },
        {
            "description": "This project hosts operations research tools developed at Google and\nmade available as open source under the Apache 2.0 License.",
            "name": "py-or-tools"
        },
        {
            "description": "Orbax includes a checkpointing library oriented towards JAX users,\nsupporting a variety of different features required by different\nframeworks, including asynchronous checkpointing various types, and\nvarious storage formats. We aim to provide a highly customizable and\ncomposable API which maximizes flexibility for diverse use cases.",
            "name": "py-orbax-checkpoint"
        },
        {
            "description": "OSQP: The Operator Splitting QP Solver",
            "name": "py-osqp"
        },
        {
            "description": "A Bacterial Pangenome Analysis Pipeline",
            "name": "py-panaroo"
        },
        {
            "description": "pandas is a fast, powerful, flexible and easy to use open source data\nanalysis and manipulation tool, built on top of the Python programming\nlanguage.",
            "name": "py-pandas"
        },
        {
            "description": "These are public type stubs for pandas, following the convention of\nproviding stubs in a separate package, as specified in PEP 561. The\nstubs cover the most typical use cases of pandas. In general, these\nstubs are narrower than what is possibly allowed by pandas, but follow a\nconvention of suggesting best recommended practices for using pandas.",
            "name": "py-pandas-stubs"
        },
        {
            "description": "The Parameterization Framework.",
            "name": "py-paramz"
        },
        {
            "description": "Python Bindings for the Parasail C Library. Parasail is a SIMD C (C99)\nlibrary containing implementations of the Smith-Waterman (local),\nNeedleman-Wunsch (global), and semi-global pairwise sequence alignment\nalgorithms.",
            "name": "py-parasail"
        },
        {
            "description": "Key-value byte store with appendable values.",
            "name": "py-partd"
        },
        {
            "description": "Ancestral character reconstruction and visualisation for rooted\nphylogenetic trees.",
            "name": "py-pastml"
        },
        {
            "description": "An open-source toolkit for computational pathology and machine learning.",
            "name": "py-pathml"
        },
        {
            "description": "A Python package for describing statistical models and for building\ndesign matrices.",
            "name": "py-patsy"
        },
        {
            "description": "PDBFixer is an easy to use application for fixing problems in Protein\nData Bank files in preparation for simulating them.",
            "name": "py-pdbfixer"
        },
        {
            "description": "PennyLane is a Python quantum machine learning library by Xanadu Inc.",
            "name": "py-pennylane"
        },
        {
            "description": "The PennyLane-Lightning plugin provides a fast state-vector simulator\nwritten in C++.",
            "name": "py-pennylane-lightning"
        },
        {
            "description": "nose extends the test loading and running features of unittest, making\nit easier to write, find and run tests.",
            "name": "py-periodictable"
        },
        {
            "description": "Petastorm is a library enabling the use of Parquet storage from\nTensorflow, Pytorch, and other Python-based ML training frameworks.",
            "name": "py-petastorm"
        },
        {
            "description": "This package provides Python bindings for the PETSc package.",
            "name": "py-petsc4py"
        },
        {
            "description": "Phonopy is an open source package for phonon calculations at harmonic\nand quasi-harmonic levels.",
            "name": "py-phonopy"
        },
        {
            "description": "Photutils is an Astropy package for detection and photometry of\nastronomical sources.",
            "name": "py-photutils"
        },
        {
            "description": "phydms enables phylogenetic analyses using deep mutational scanning data\nto inform the substitution models. It implements Experimentally informed\ncodon models (ExpCM) for phylogenetic inference and the detection of\nbiologically interesting selection.",
            "name": "py-phydms"
        },
        {
            "description": "PhyloPhlAn 3.0 is an integrated pipeline for large-scale phylogenetic\nprofiling of genomes and metagenomes.",
            "name": "py-phylophlan"
        },
        {
            "description": "Standard input format for Particle-In-Cell codes",
            "name": "py-picmistandard"
        },
        {
            "description": "PICRUSt2 is a software for predicting functional abundances based only\non marker gene sequences.",
            "name": "py-picrust2"
        },
        {
            "description": "A convenience wrapper for using pint with xarray",
            "name": "py-pint-xarray"
        },
        {
            "description": "Automated pipeline for analyses of fungal ITS from the Illumina",
            "name": "py-pipits"
        },
        {
            "description": "plotnine is an implementation of a grammar of graphics in Python, it is\nbased on ggplot2. The grammar allows users to compose plots by\nexplicitly mapping data to the visual objects that make up the plot.",
            "name": "py-plotnine"
        },
        {
            "description": "Blazingly fast DataFrame library.",
            "name": "py-polars"
        },
        {
            "description": "Fast, flexible and easy to use probabilistic modelling in Python.",
            "name": "py-pomegranate"
        },
        {
            "description": "This repository contains a Python package named PostCactus for\npostprocessing data from numerical simulations performed with the\nEinstein Toolkit.",
            "name": "py-postcactus"
        },
        {
            "description": "This open source Python library provide several solvers for\noptimization problems related to Optimal Transport for signal, image\nprocessing and machine learning.",
            "name": "py-pot"
        },
        {
            "description": "ProjectQ is an open-source software framework for quantum computing\nstarted at ETH Zurich. It allows users to implement their quantum\nprograms in Python using a powerful and intuitive syntax. ProjectQ can\nthen translate these programs to any type of back-end, be it a simulator\nrun on a classical computer of an actual quantum chip.",
            "name": "py-projectq"
        },
        {
            "description": "Proper scoring rules in Python.",
            "name": "py-properscoring"
        },
        {
            "description": "LCLS II Developement: PSAna Python.",
            "name": "py-psana"
        },
        {
            "description": "Code Generator for Small Sparse Matrix Multiplication",
            "name": "py-pspamm"
        },
        {
            "description": "A Python package for forward and inverse Abel transforms.",
            "name": "py-pyabel"
        },
        {
            "description": "PyAMG is a library of Algebraic Multigrid (AMG) solvers with a\nconvenient Python interface.",
            "name": "py-pyamg"
        },
        {
            "description": "A cross-language development platform for in-memory data. This package\ncontains the Python bindings.",
            "name": "py-pyarrow"
        },
        {
            "description": "Python bindings for the Open Asset Import Library (ASSIMP)",
            "name": "py-pyassimp"
        },
        {
            "description": "Python wrapper -- and more -- for Aaron Quinlan's BEDTools",
            "name": "py-pybedtools"
        },
        {
            "description": "bids: interface with datasets conforming to BIDS",
            "name": "py-pybids"
        },
        {
            "description": "A package for accessing bigWig files using libBigWig.",
            "name": "py-pybigwig"
        },
        {
            "description": "Py-BOBYQA is a flexible package for solving bound-constrained general\nobjective minimization, without requiring derivatives of the objective.",
            "name": "py-pybobyqa"
        },
        {
            "description": "A lightweight I/O utility for the BrainVision data format.",
            "name": "py-pybv"
        },
        {
            "description": "PyCBC is a software package used to explore astrophysical sources of\ngravitational waves. It contains algorithms to analyze gravitational-\nwave data from the LIGO and Virgo detectors, detect coalescing compact\nbinaries, and measure the astrophysical parameters of detected sources.\nPyCBC was used in the first direct detection of gravitational waves and\nis used in the flagship analysis of LIGO and Virgo data.",
            "name": "py-pycbc"
        },
        {
            "description": "Multi-class confusion matrix library in Python.",
            "name": "py-pycm"
        },
        {
            "description": "Official APIs for the MS-COCO dataset.",
            "name": "py-pycocotools"
        },
        {
            "description": "Python library for reading and writing collada documents",
            "name": "py-pycollada"
        },
        {
            "description": "Python Cortical mapping software for fMRI data.",
            "name": "py-pycortex"
        },
        {
            "description": "pyCubexR is a Python package for reading the Cube4 file format.",
            "name": "py-pycubexr"
        },
        {
            "description": "PyCUDA gives you easy, Pythonic access to Nvidia's CUDA parallel\ncomputation API",
            "name": "py-pycuda"
        },
        {
            "description": "An implementation of the Data Access Protocol.",
            "name": "py-pydap"
        },
        {
            "description": "A script to remove facial structure from MRI images.",
            "name": "py-pydeface"
        },
        {
            "description": "Pure python package for DICOM medical file reading and writing pydicom\nis a pure Python package for working with DICOM files. It lets you read,\nmodify and write DICOM data in an easy \"pythonic\" way.",
            "name": "py-pydicom"
        },
        {
            "description": "PyDMD is a Python package that uses Dynamic Mode Decomposition for a\ndata-driven model simplification based on spatiotemporal coherent\nstructures.",
            "name": "py-pydmd"
        },
        {
            "description": "The pyDOE package is designed to help the scientist, engineer,\nstatistician, etc., to construct appropriate experimental designs",
            "name": "py-pydoe"
        },
        {
            "description": "pyDOE2 is a fork of the pyDOE package that is designed to help the\nscientist, engineer, statistician, etc., to construct appropriate\nexperimental designs.",
            "name": "py-pydoe2"
        },
        {
            "description": "Pyedr provides a means of reading a Gromacs EDR binary XDR file and\nreturn its contents as a dictionary of NumPy arrays",
            "name": "py-pyedr"
        },
        {
            "description": "PyERFA is the Python wrapper for the ERFA library (Essential Routines\nfor Fundamental Astronomy), a C library containing key algorithms for\nastronomy, which is based on the SOFA library published by the\nInternational Astronomical Union (IAU). All C routines are wrapped as\nNumpy universal functions, so that they can be called with scalar or\narray inputs.",
            "name": "py-pyerfa"
        },
        {
            "description": "The pyface project contains a toolkit-independent GUI abstraction layer,\nwhich is used to support the \"visualization\" features of the Traits\npackage. Thus, you can write code in terms of the Traits API (views,\nitems, editors, etc.), and let pyface and your selected toolkit and\nback-end take care of the details of displaying them.",
            "name": "py-pyface"
        },
        {
            "description": "Pyfasta: fast, memory-efficient, pythonic (and command-line) access to\nfasta sequence files",
            "name": "py-pyfasta"
        },
        {
            "description": "A pythonic wrapper around FFTW, the FFT library, presenting a unified\ninterface for all the supported transforms.",
            "name": "py-pyfftw"
        },
        {
            "description": "The PyFITS module is a Python library providing access to FITS(Flexible\nImage Transport System) files.",
            "name": "py-pyfits"
        },
        {
            "description": "PyFR is an open-source Python based framework for solving advection-\ndiffusion type problems on streaming architectures using the Flux\nReconstruction approach of Huynh.",
            "name": "py-pyfr"
        },
        {
            "description": "Virtualenv and setuptools friendly version of standard GDAL python\nbindings. This package is for you if you had problems installing GDAL in\nyour virtualenv. You can install GDAL into your virtualenv using this\npackage but you still need to install GDAL library and its header files\non your system.",
            "name": "py-pygdal"
        },
        {
            "description": "PyGEOS is a C/Python library with vectorized geometry functions. The\ngeometry operations are done in the open-source geometry library GEOS.\nPyGEOS wraps these operations in NumPy ufuncs providing a performance\nimprovement when operating on arrays of geometries.",
            "name": "py-pygeos"
        },
        {
            "description": "Easier Pythonic interface to GMSH.",
            "name": "py-pygmsh"
        },
        {
            "description": "A Python interface for the Generic Mapping Tools.",
            "name": "py-pygmt"
        },
        {
            "description": "pyGPs is a Python library for Gaussian Process (GP) Regression and\nClassification.",
            "name": "py-pygps"
        },
        {
            "description": "Python packge for the libgpuarray C library.",
            "name": "py-pygpu"
        },
        {
            "description": "Read and write H5MD files.",
            "name": "py-pyh5md"
        },
        {
            "description": "pyhdf is a python wrapper around the NCSA HDF version 4 library. The SD\n(Scientific Dataset), VS (Vdata) and V (Vgroup) APIs are currently\nimplemented. NetCDF files can also be read and modified.",
            "name": "py-pyhdf"
        },
        {
            "description": "CERN PyHEADTAIL numerical n-body simulation code for simulating macro-\nparticle beam dynamics with collective effects.",
            "name": "py-pyheadtail"
        },
        {
            "description": "Pyhull is a Python wrapper to Qhull (http://www.qhull.org/) for the\ncomputation of the convex hull, Delaunay triangulation and Voronoi\ndiagram. It is written as a Python C extension, with both high-level and\nlow-level interfaces to qhull.",
            "name": "py-pyhull"
        },
        {
            "description": "A Python library for creating LaTeX files and snippets",
            "name": "py-pylatex"
        },
        {
            "description": "Many useful operators, however, do not lend themselves to an explicit\nmatrix representation when used to solve large-scale problems. PyLops\noperators, on the other hand, still represent a matrix and can be\ntreated in a similar way, but do not rely on the explicit creation of a\ndense (or sparse) matrix itself. Conversely, the forward and adjoint\noperators are represented by small pieces of codes that mimic the effect\nof the matrix on a vector or another matrix.",
            "name": "py-pylops"
        },
        {
            "description": "Python Materials Genomics is a robust materials analysis code that\ndefines core object representations for structures and molecules with\nsupport for many electronic structure codes. It is currently the core\nanalysis code powering the Materials Project.",
            "name": "py-pymatgen"
        },
        {
            "description": "Convenient reader for Matlab mat files.",
            "name": "py-pymatreader"
        },
        {
            "description": "PyMC3 is a Python package for Bayesian statistical modeling and\nProbabilistic Machine Learning focusing on advanced Markov chain Monte\nCarlo (MCMC) and variational inference (VI) algorithms. Its flexibility\nand extensibility make it applicable to a large suite of problems.",
            "name": "py-pymc3"
        },
        {
            "description": "PyMOL is a Python-enhanced molecular graphics tool. It excels at 3D\nvisualization of proteins, small molecules, density, surfaces, and\ntrajectories. It also includes molecular editing, ray tracing, and\nmovies. Open Source PyMOL is free to everyone!",
            "name": "py-pymol"
        },
        {
            "description": "Multi-Objective Optimization in Python",
            "name": "py-pymoo"
        },
        {
            "description": "PyNIO (\"pie-nee-oh\") is a Python module that allows read and/or write\naccess to a variety of scientific data formats popular in climate and\nweather",
            "name": "py-pynio"
        },
        {
            "description": "A Python package for simulator-independent specification of neuronal\nnetwork models",
            "name": "py-pynn"
        },
        {
            "description": "Python library for reading and writing NRRD files into and from numpy\narrays",
            "name": "py-pynrrd"
        },
        {
            "description": "PyNucleus is a finite element code that specifically targets nonlocal\noperators.",
            "name": "py-pynucleus"
        },
        {
            "description": "Vectorized spatial vector file format I/O using GDAL/OGR",
            "name": "py-pyogrio"
        },
        {
            "description": "Pyomo is a Python-based open-source software package that supports a\ndiverse set of optimization capabilities for formulating and analyzing\noptimization models.",
            "name": "py-pyomo"
        },
        {
            "description": "Python wrapper for OpenCL.",
            "name": "py-pyopencl"
        },
        {
            "description": "Pypar is an efficient but easy-to-use module that allows programs\nwritten in Python to run in parallel on multiple processors and\ncommunicate using MPI.",
            "name": "py-pypar"
        },
        {
            "description": "This package provides python language bindings for the C++ library\npreCICE.",
            "name": "py-pyprecice"
        },
        {
            "description": "Pulse is a package used to handle PSRFITS files and perform subsequent\nanalyses on pulse profiles.",
            "name": "py-pypulse"
        },
        {
            "description": "PyQtGraph is a pure-python graphics and GUI library intended for use in\nmathematics, scientific, and engineering applications",
            "name": "py-pyqtgraph"
        },
        {
            "description": "Python morphology manipulation toolkit",
            "name": "py-pyquaternion"
        },
        {
            "description": "A Python library for probabilistic modeling and inference.",
            "name": "py-pyro-ppl"
        },
        {
            "description": "Pyrocko is an open source seismology toolbox and library, written in the\nPython programming language",
            "name": "py-pyrocko"
        },
        {
            "description": "3D mathematical functions using NumPy.",
            "name": "py-pyrr"
        },
        {
            "description": "PySCF is a collection of electronic structure programs powered by\nPython.",
            "name": "py-pyscf"
        },
        {
            "description": "Sequence Elements Enrichment Analysis (SEER), python implementation",
            "name": "py-pyseer"
        },
        {
            "description": "Pysolar is a collection of Python libraries for simulating the\nirradiation of any point on earth by the sun. It includes code for\nextremely precise ephemeris calculations, and more.",
            "name": "py-pysolar"
        },
        {
            "description": "Python bindings for Apache Spark",
            "name": "py-pyspark"
        },
        {
            "description": "Simulate electronic circuit using Python and the Ngspice / Xyce\nsimulators",
            "name": "py-pyspice"
        },
        {
            "description": "PyStan is a Python interface to Stan, a package for Bayesian inference.",
            "name": "py-pystan"
        },
        {
            "description": "Cortical neuroimaging visualization in Python.",
            "name": "py-pysurfer"
        },
        {
            "description": "The pytecplot library is a high level API that connects your Python\nscript to the power of the Tecplot 360 visualization engine. It offers\nline plotting, 2D and 3D surface plots in a variety of formats, and 3D\nvolumetric visualization. Familiarity with Tecplot 360 and the Tecplot\n360 macro language is helpful, but not required.",
            "name": "py-pytecplot"
        },
        {
            "description": "Pytest fixture extending Numpy's allclose function.",
            "name": "py-pytest-allclose"
        },
        {
            "description": "pytest plugin to help with comparing array output from tests",
            "name": "py-pytest-arraydiff"
        },
        {
            "description": "A set of command line utilities and Python modules that implement the\nFMASK algorithm for Landsat and Sentinel-2",
            "name": "py-python-fmask"
        },
        {
            "description": "The python-javabridge package makes it easy to start a Java virtual\nmachine (JVM) from Python and interact with it.",
            "name": "py-python-javabridge"
        },
        {
            "description": "This module implements community detection. It uses the louvain method\ndescribed in Fast unfolding of communities in large networks, Vincent D\nBlondel, Jean-Loup Guillaume, Renaud Lambiotte, Renaud Lefebvre, Journal\nof Statistical Mechanics: Theory and Experiment 2008(10), P10008 (12pp)",
            "name": "py-python-louvain"
        },
        {
            "description": "Preconditoned ICA for Real Data.",
            "name": "py-python-picard"
        },
        {
            "description": "Qt plotting widgets for Python",
            "name": "py-pythonqwt"
        },
        {
            "description": "Ahead of Time compiler for numeric kernels.",
            "name": "py-pythran"
        },
        {
            "description": "Provides the TNGFileIterator object to allow simple Pythonic access to\ndata contained within TNG files.",
            "name": "py-pytng"
        },
        {
            "description": "A collection of tools for Python",
            "name": "py-pytools"
        },
        {
            "description": "PyTorch Lightning is the lightweight PyTorch wrapper for ML researchers.",
            "name": "py-pytorch-lightning"
        },
        {
            "description": "pyts is a Python package for time series classification. It aims to make\ntime series classification easily accessible by providing preprocessing\nand utility tools, and implementations of state-of-the-art algorithms.\nMost of these algorithms transform time series, thus pyts provides\nseveral tools to perform these transformations.",
            "name": "py-pyts"
        },
        {
            "description": "Work with triangular unstructured grids and the data on them.",
            "name": "py-pyugrid"
        },
        {
            "description": "Easier Pythonic interface to VTK.",
            "name": "py-pyvista"
        },
        {
            "description": "Pyvolve is an open-source Python module for simulating sequences along a\nphylogenetic tree according to continuous-time Markov models of sequence\nevolution",
            "name": "py-pyvolve"
        },
        {
            "description": "PyWavelets is a free Open Source library for wavelet transforms in\nPython",
            "name": "py-pywavelets"
        },
        {
            "description": "pywcs is a set of routines for handling the FITS World Coordinate System\n(WCS) standard.",
            "name": "py-pywcs"
        },
        {
            "description": "PyWorld wrappers WORLD, which is a free software for high-quality speech\nanalysis, manipulation and synthesis. It can estimate fundamental\nfrequency (F0), aperiodicity and spectral envelope and also generate the\nspeech like input speech with only estimated parameters.i",
            "name": "py-pyworld"
        },
        {
            "description": "Python interface to the QDLDL free LDL factorization routine for quasi-\ndefinite linear systems: Ax = b.",
            "name": "py-qdldl"
        },
        {
            "description": "Aer is a high performance simulator for quantum circuits that includes\nnoise models",
            "name": "py-qiskit-aer"
        },
        {
            "description": "Qiskit IBM Quantum Provider for accessing the quantum devices and\nsimulators at IBM",
            "name": "py-qiskit-ibm-provider"
        },
        {
            "description": "Qiskit Nature is an open-source framework which supports solving quantum\nmechanical natural science problems using quantum computing algorithms",
            "name": "py-qiskit-nature"
        },
        {
            "description": "Qiskit is an open-source SDK for working with quantum computers at the\nlevel of extended quantum circuits, operators, and algorithms.",
            "name": "py-qiskit-terra"
        },
        {
            "description": "Unified interface to convex Quadratic Programming (QP) solvers available\nin Python.",
            "name": "py-qpsolvers"
        },
        {
            "description": "A fast and differentiable QP solver for PyTorch",
            "name": "py-qpth"
        },
        {
            "description": "Qsymm is a symmetry finder and symmetric Hamiltonian generator. It\nautomatically generates model Hamiltonians from symmetry constraints and\nfinds the full symmetry group of your Hamiltonian.",
            "name": "py-qsymm"
        },
        {
            "description": "Support for physical quantities with units, based on numpy",
            "name": "py-quantities"
        },
        {
            "description": "Blackbird is a quantum assembly language for continuous-variable quantum\ncomputation, that can be used to program Xanadu\u2019s quantum photonics\nhardware and Strawberry Fields simulator.",
            "name": "py-quantum-blackbird"
        },
        {
            "description": "Interpret numpy arrays as quaternionic arrays with numba acceleration",
            "name": "py-quaternionic"
        },
        {
            "description": "QuDiDA is a micro library for very naive though quick pixel level image\ndomain adaptation via scikit-learn transformers.",
            "name": "py-qudida"
        },
        {
            "description": "QuTiP: The Quantum Toolbox in Python",
            "name": "py-qutip"
        },
        {
            "description": "The QuTiP quantum information processing package",
            "name": "py-qutip-qip"
        },
        {
            "description": "Rasterio reads and writes geospatial raster data. Geographic information\nsystems use GeoTIFF and other formats to organize and store gridded, or\nraster, datasets. Rasterio reads and writes these formats and provides a\nPython API based on N-D arrays.",
            "name": "py-rasterio"
        },
        {
            "description": "rasterstats is a Python module for summarizing geospatial raster\ndatasets based on vector geometries. It includes functions for zonal\nstatistics and interpolated point queries. The command-line interface\nallows for easy interperability with other GeoJSON tools.",
            "name": "py-rasterstats"
        },
        {
            "description": "Ray provides a simple, universal API for building distributed\napplications.",
            "name": "py-ray"
        },
        {
            "description": "RDT is a Python library used to transform data for data science\nlibraries and preserve the transformations in order to revert them as\nneeded.",
            "name": "py-rdt"
        },
        {
            "description": "Create masks of geospatial regions for arbitrary grids",
            "name": "py-regionmask"
        },
        {
            "description": "An Astropy coordinated package for region handling",
            "name": "py-regions"
        },
        {
            "description": "The reproject package is a Python package to reproject astronomical\nimages using various techniques via a uniform interface. By\nreprojection, we mean the re-gridding of images from one world\ncoordinate system to another (for example changing the pixel resolution,\norientation, coordinate system). Currently, we have implemented\nreprojection of celestial images by interpolation (like SWARP), as well\nas by finding the exact overlap between pixels on the celestial sphere\n(like Montage). It can also reproject to/from HEALPIX projections by\nrelying on the astropy-healpix package.",
            "name": "py-reproject"
        },
        {
            "description": "Efficient sample rate conversion in python",
            "name": "py-resampy"
        },
        {
            "description": "This is a resizing packge for images or tensors, that supports both\nNumpy and PyTorch (fully differentiable) seamlessly. The main motivation\nfor creating this is to address some crucial incorrectness issues (see\nitem 3 in the list below) that exist in all other resizing packages I am\naware of. As far as I know, it is the only one that performs correctly\nin all cases. ResizeRight is specially made for machine learning, image\nenhancement and restoration challenges.",
            "name": "py-resize-right"
        },
        {
            "description": "A high performance Python graph library implemented in Rust.",
            "name": "py-retworkx"
        },
        {
            "description": "Raster I/O Simplification. A set of python modules which makes it easy\nto write raster processing code in Python. Built on top of GDAL, it\nhandles the details of opening and closing files, checking alignment of\nprojection and raster grid, stepping through the raster in small blocks,\netc., allowing the programmer to concentrate on the processing involved.",
            "name": "py-rios"
        },
        {
            "description": "rasterio xarray extension.",
            "name": "py-rioxarray"
        },
        {
            "description": "River is a Python library for online machine learning. It aims to be the\nmost user-friendly library for doing machine learning on streaming data.\nRiver is the result of a merge between creme and scikit-multiflow.",
            "name": "py-river"
        },
        {
            "description": "Robocrystallographer is a tool to generate text descriptions of crystal\nstructures. Similar to how a real-life crystallographer would analyse a\nstructure, robocrystallographer looks at the symmetry, local\nenvironment, and extended connectivity when generating a description.\nThe package includes utilities for identifying molecule names, component\norientations, heterostructure information, and more.",
            "name": "py-robocrys"
        },
        {
            "description": "Roifile is a Python library to read, write, create, and plot ImageJ ROIs",
            "name": "py-roifile"
        },
        {
            "description": "rpy2 is a redesign and rewrite of rpy. It is providing a low-level\ninterface to R from Python, a proposed high-level interface, including\nwrappers to graphical libraries, as well as R-like structures and\nfunctions.",
            "name": "py-rpy2"
        },
        {
            "description": "Representational Similarity Analysis (RSA) in Python.",
            "name": "py-rsatoolbox"
        },
        {
            "description": "RSeQC package provides a number of useful modules that can\ncomprehensively evaluate high throughput sequence data especially RNA-\nseq data.",
            "name": "py-rseqc"
        },
        {
            "description": "R-Tree spatial index for Python GIS.",
            "name": "py-rtree"
        },
        {
            "description": "Rustworkx was originally called retworkx and was was created initially\nto be a replacement for qiskit's previous (and current) networkx usage\n(hence the original name). The project was originally started to build a\nfaster directed graph to use as the underlying data structure for the\nDAG at the center of qiskit-terra's transpiler. However, since it's\ninitial introduction the project has grown substantially and now covers\nall applications that need to work with graphs which includes Qiskit.",
            "name": "py-rustworkx"
        },
        {
            "description": "SacreBLEU is a standard BLEU implementation that downloads and manages\nWMT datasets, produces scores on detokenized outputs, and reports a\nstring encapsulating BLEU parameters, facilitating the production of\nshareable, comparable BLEU scores.",
            "name": "py-sacrebleu"
        },
        {
            "description": "Python implementations of commonly used sensitivity analysis methods.",
            "name": "py-salib"
        },
        {
            "description": "Scanpy is a scalable toolkit for analyzing single-cell gene expression\ndata built jointly with anndata.",
            "name": "py-scanpy"
        },
        {
            "description": "ScientificPython is a collection of Python modules for scientific\ncomputing. It contains support for geometry, mathematical functions,\nstatistics, physical units, IO, visualization, and parallelization.",
            "name": "py-scientificpython"
        },
        {
            "description": "scikit-fmm is a Python extension module which implements the fast\nmarching method.",
            "name": "py-scikit-fmm"
        },
        {
            "description": "Fuzzy logic toolkit for SciPy",
            "name": "py-scikit-fuzzy"
        },
        {
            "description": "Image processing algorithms for SciPy, including IO, morphology,\nfiltering, warping, color manipulation, object detection, etc.",
            "name": "py-scikit-image"
        },
        {
            "description": "A set of python modules for machine learning and data mining.",
            "name": "py-scikit-learn"
        },
        {
            "description": "A set of useful tools compatible with scikit-learn scikit-learn-extra is\na Python module for machine learning that extends scikit-learn. It\nincludes algorithms that are useful but do not satisfy the scikit-learn\ninclusion criteria, for instance due to their novelty or lower citation\nnumber.",
            "name": "py-scikit-learn-extra"
        },
        {
            "description": "Scikit-Optimize, or skopt, is a simple and efficient library to minimize\n(very) expensive and noisy black-box functions. It implements several\nmethods for sequential model-based optimization. skopt aims to be\naccessible and easy to use in many contexts. The library is built on top\nof NumPy, SciPy and Scikit-Learn.",
            "name": "py-scikit-optimize"
        },
        {
            "description": "Sparse matrix tools extending scipy.sparse, but with incompatible\nlicenses",
            "name": "py-scikit-sparse"
        },
        {
            "description": "Odes is a scikit toolkit for scipy to add extra ode solvers.\nSpecifically it interfaces the Sundials solvers cvode, cvodes, ida and\nidas. It this way it provides extra modern ode and dae solvers you can\nuse, extending the capabilities offered in scipy.integrade.ode.",
            "name": "py-scikits-odes"
        },
        {
            "description": "Software driving the automated exploration of chemical reaction networks",
            "name": "py-scine-chemoton"
        },
        {
            "description": "Calculation handler for SCINE Chemoton",
            "name": "py-scine-puffin"
        },
        {
            "description": "Fundamental algorithms for scientific computing in Python.",
            "name": "py-scipy"
        },
        {
            "description": "SCS: splitting conic solver",
            "name": "py-scs"
        },
        {
            "description": "The SDMetrics library provides a set of dataset-agnostic tools for\nevaluating the quality of a synthetic database by comparing it to the\nreal database that it is modeled after.",
            "name": "py-sdmetrics"
        },
        {
            "description": "The Synthetic Data Vault (SDV) is a Synthetic Data Generation ecosystem\nof libraries that allows users to easily learn single-table, multi-table\nand timeseries datasets to later on generate new Synthetic Data that has\nthe same format and statistical properties as the original dataset.",
            "name": "py-sdv"
        },
        {
            "description": "Seaborn: statistical data visualization. Seaborn is a library for making\nattractive and informative statistical graphics in Python. It is built\non top of matplotlib and tightly integrated with the PyData stack,\nincluding support for numpy and pandas data structures and statistical\nroutines from scipy and statsmodels.",
            "name": "py-seaborn"
        },
        {
            "description": "SeeK-path is a python module to obtain band paths in the Brillouin zone\nof crystal structures.",
            "name": "py-seekpath"
        },
        {
            "description": "Python library with Neural Networks for Image Segmentation based on\nPyTorch.",
            "name": "py-segmentation-models-pytorch"
        },
        {
            "description": "seqeval is a Python framework for sequence labeling evaluation. seqeval\ncan evaluate the performance of chunking tasks such as named-entity\nrecognition, part-of-speech tagging, semantic role labeling and so on.",
            "name": "py-seqeval"
        },
        {
            "description": "This is a Python implementation of Seriation algorithm. Seriation is an\napproach for ordering elements in a set so that the sum of the\nsequential pairwise distances is minimal. We state this task as a\nTravelling Salesman Problem (TSP) and leverage the powerful Google's or-\ntools to do heavy-lifting. Since TSP is NP-hard, it is not possible to\ncalculate the precise solution for a big number of elements. However,\nthe or-tools' heuristics work very well in practice, and they are used\nin e.g. Google Maps.",
            "name": "py-seriate"
        },
        {
            "description": "SfePy (https://sfepy.org/) is a software for solving systems of coupled\npartial differential equations (PDEs) by the finite element method in\n1D, 2D and 3D. It can be viewed both as black-box PDE solver, and as a\nPython package which can be used for building custom applications.",
            "name": "py-sfepy"
        },
        {
            "description": "SHAP (SHapley Additive exPlanations): a unified approach to explain the\noutput of any machine learning model.",
            "name": "py-shap"
        },
        {
            "description": "Manipulation and analysis of geometric objects in the Cartesian plane.",
            "name": "py-shapely"
        },
        {
            "description": "Lightweight coordinate-only trajectory reader based on code from\nGROMACS, MDAnalysis and VMD.",
            "name": "py-simpletraj"
        },
        {
            "description": "Convert scikit-learn models to ONNX",
            "name": "py-skl2onnx"
        },
        {
            "description": "This package provides Python bindings for the SLEPc package.",
            "name": "py-slepc4py"
        },
        {
            "description": "SMAC is a tool for algorithm configuration to optimize the parameters of\narbitrary algorithms, including hyperparameter optimization of Machine\nLearning algorithms.",
            "name": "py-smac"
        },
        {
            "description": "A Python Interface for the SmartRedis Library Client",
            "name": "py-smartredis"
        },
        {
            "description": "Variants of the synthetic minority oversampling technique (SMOTE) for\nimbalanced learning",
            "name": "py-smote-variants"
        },
        {
            "description": "SNCosmo is a Python library for high-level supernova cosmology analysis.",
            "name": "py-sncosmo"
        },
        {
            "description": "Snuggs are s-expressions for Numpy",
            "name": "py-snuggs"
        },
        {
            "description": "Sobol sequence implementation in python",
            "name": "py-sobol-seq"
        },
        {
            "description": "SoundFile is an audio library based on libsndfile, CFFI and NumPy.",
            "name": "py-soundfile"
        },
        {
            "description": "This package is implementation of Improving spherical k-means for\ndocument clustering. Fast initialization, sparse centroid projection,\nand efficient cluster labeling (Kim et al., 2020).",
            "name": "py-soyclustering"
        },
        {
            "description": "spaCy is a library for advanced Natural Language Processing in Python\nand Cython.",
            "name": "py-spacy"
        },
        {
            "description": "This library provides multi-dimensional sparse arrays.",
            "name": "py-sparse"
        },
        {
            "description": "This package offers functionalities for user-friendly geo data\nprocessing using GDAL and OGR.",
            "name": "py-spatialist"
        },
        {
            "description": "Spectral Python (SPy) is a pure Python module for processing\nhyperspectral image data (imaging spectroscopy data). It has functions\nfor reading, displaying, manipulating, and classifying hyperspectral\nimagery. SPy is Free, Open Source Software (FOSS) distributed under the\nMIT License.",
            "name": "py-spectral"
        },
        {
            "description": "Reader for SPE files part of pyspec a set of python routines for data\nanalysis of x-ray scattering experiments",
            "name": "py-spefile"
        },
        {
            "description": "SPGL1 is a solver for large-scale one-norm regularized least squares. It\nis designed to solve any of the following three problems: Basis pursuit\ndenoise (BPDN): minimize ||x||_1 subject to ||Ax - b||_2 <= sigma, Basis\npursuit (BP): minimize ||x||_1 subject to Ax = b Lasso: minimize ||Ax -\nb||_2 subject to ||x||_1 <= tau, The matrix A can be defined explicitly,\nor as an operator that returns both both Ax and A'b. SPGL1 can solve\nthese three problems in both the real and complex domains.",
            "name": "py-spgl1"
        },
        {
            "description": "Python bindings for C library for finding and handling crystal\nsymmetries.",
            "name": "py-spglib"
        },
        {
            "description": "Evaluate and transform D matrices, 3-j symbols, and (scalar or spin-\nweighted) spherical harmonics",
            "name": "py-spherical"
        },
        {
            "description": "Fortran domain and autodoc extensions to Sphinx",
            "name": "py-sphinx-fortran"
        },
        {
            "description": "Python code for calculating non-parametric morphological diagnostics of\ngalaxy images.",
            "name": "py-statmorph"
        },
        {
            "description": "Statistical computations and models for use with SciPy",
            "name": "py-statsmodels"
        },
        {
            "description": "Vectorized interpolators that are especially useful for Nd vertical\ninterpolation/stratification of atmospheric and oceanographic datasets.",
            "name": "py-stratify"
        },
        {
            "description": "Open source library for continuous-variable quantum computation",
            "name": "py-strawberryfields"
        },
        {
            "description": "The fastest way to build data apps in Python.",
            "name": "py-streamlit"
        },
        {
            "description": "A collection of tools for manipulating and analyzing SVG Path objects\nand Bezier curves.",
            "name": "py-svgpathtools"
        },
        {
            "description": "Symbolic Fitting; fitting as it should be.",
            "name": "py-symfit"
        },
        {
            "description": "A python library to define the components of a synchrotron beamline and\ntheir positions. They can be read/write to json files. It is used by\nOASYS as a common tool to define sources and optical systems that are\nthen exported to the different add-ons.",
            "name": "py-syned"
        },
        {
            "description": "PyTables is a package for managing hierarchical datasets and designed to\nefficiently and easily cope with extremely large amounts of data.",
            "name": "py-tables"
        },
        {
            "description": "TensorBoard is a suite of web applications for inspecting and\nunderstanding your TensorFlow runs and graphs.",
            "name": "py-tensorboard"
        },
        {
            "description": "The purpose of this package is to let researchers use a simple interface\nto log events within PyTorch (and then show visualization in\ntensorboard). This package currently supports logging scalar, image,\naudio, histogram, text, embedding, and the route of back-propagation.",
            "name": "py-tensorboardx"
        },
        {
            "description": "TensorFlow is an open source machine learning framework for everyone.",
            "name": "py-tensorflow"
        },
        {
            "description": "tensorflow/datasets is a library of datasets ready to use with\nTensorFlow.",
            "name": "py-tensorflow-datasets"
        },
        {
            "description": "TensorFlow Estimator is a high-level API that encapsulates model\ntraining, evaluation, prediction, and exporting.",
            "name": "py-tensorflow-estimator"
        },
        {
            "description": "TensorFlow Hub is a library to foster the publication, discovery, and\nconsumption of reusable parts of machine learning models.",
            "name": "py-tensorflow-hub"
        },
        {
            "description": "TensorFlow Probability (TFP) is a Python library built on TensorFlow\nthat makes it easy to combine probabilistic models and deep learning on\nmodern hardware (TPU, GPU). It's for data scientists, statisticians, ML\nresearchers, and practitioners who want to encode domain knowledge to\nunderstand data and make predictions.",
            "name": "py-tensorflow-probability"
        },
        {
            "description": "TensorLy is a Python library that aims at making tensor learning simple\nand accessible. It allows to easily perform tensor decomposition, tensor\nlearning and tensor algebra. Its backend system allows to seamlessly\nperform computation with NumPy, PyTorch, JAX, MXNet, TensorFlow or CuPy,\nand run methods at scale on CPU or GPU.",
            "name": "py-tensorly"
        },
        {
            "description": "Read and write large, multi-dimensional arrays.",
            "name": "py-tensorstore"
        },
        {
            "description": "The TF-Keras library is a pure TensorFlow implementation of Keras, based\non the legacy tf.keras codebase. Note that the \"main\" version of Keras\nis now Keras 3 (formerly Keras Core), which is a multi-backend\nimplementation of Keras, supporting JAX, PyTorch, and TensorFlow. Keras\n3 is being developed at keras-team/keras.",
            "name": "py-tf-keras"
        },
        {
            "description": "Optimizing compiler for evaluating mathematical expressions on CPUs and\nGPUs.",
            "name": "py-theano"
        },
        {
            "description": "A library for the calculation of hafnians, Hermite polynomials and\nGaussian boson sampling.",
            "name": "py-thewalrus"
        },
        {
            "description": "Thinc: Practical Machine Learning for NLP in Python.",
            "name": "py-thinc"
        },
        {
            "description": "A tiny package to compute the dynamics of stochastic and molecular\nsimulations.",
            "name": "py-tidynamics"
        },
        {
            "description": "Read and write image data from and to TIFF files.",
            "name": "py-tifffile"
        },
        {
            "description": "PyTorch Image Models.",
            "name": "py-timm"
        },
        {
            "description": "TomoPy is an open-source Python package for tomographic data processing\nand image reconstruction.",
            "name": "py-tomopy"
        },
        {
            "description": "Python framework for doing ancestral sequence reconstruction.",
            "name": "py-topiary-asr"
        },
        {
            "description": "Tensors and Dynamic neural networks in Python with strong GPU\nacceleration.",
            "name": "py-torch"
        },
        {
            "description": "High-fidelity performance metrics for generative models in PyTorch",
            "name": "py-torch-fidelity"
        },
        {
            "description": "Graph Neural Network Library for PyTorch.",
            "name": "py-torch-geometric"
        },
        {
            "description": "A differentiable spherical harmonic transform for PyTorch.",
            "name": "py-torch-harmonics"
        },
        {
            "description": "A collection of open source benchmarks used to evaluate PyTorch\nperformance.",
            "name": "py-torchbenchmark"
        },
        {
            "description": "Mostly direct port of the torch7 Lua and C serialization implementation\nto Python, depending only on numpy (and the standard library: array and\nstruct). Sharing of objects including torch.Tensors is preserved.",
            "name": "py-torchfile"
        },
        {
            "description": "TorchGeo: datasets, samplers, transforms, and pre-trained models for\ngeospatial data.",
            "name": "py-torchgeo"
        },
        {
            "description": "A collection of extensions and data-loaders for few-shot learning &\nmeta-learning in PyTorch. Torchmeta contains popular meta-learning\nbenchmarks, fully compatible with both torchvision and PyTorch's\nDataLoader.",
            "name": "py-torchmeta"
        },
        {
            "description": "Machine learning metrics for distributed, scalable PyTorch applications.",
            "name": "py-torchmetrics"
        },
        {
            "description": "Keras has a neat API to view the visualization of the model which is\nvery helpful while debugging your network. Here is a barebone code to\ntry and mimic the same in PyTorch. The aim is to provide information\ncomplementary to, what is not provided by print(your_model) in PyTorch.",
            "name": "py-torchsummary"
        },
        {
            "description": "Text utilities, models, transforms, and datasets for PyTorch.",
            "name": "py-torchtext"
        },
        {
            "description": "Image and video datasets and models for torch deep learning.",
            "name": "py-torchvision"
        },
        {
            "description": "A modern plotting toolkit supporting electronic publishing and\nreproducibility.",
            "name": "py-toyplot"
        },
        {
            "description": "A minimalist tree manipulation and plotting library for use inside\njupyter notebooks. Toytree combines a popular tree data structure based\non the ete3 library with modern plotting tools based on the toyplot\nplotting library.",
            "name": "py-toytree"
        },
        {
            "description": "A Python Automated Machine Learning tool that optimizes machine\nlearning pipelines using genetic programming.",
            "name": "py-tpot"
        },
        {
            "description": "The TraitsUI project contains a toolkit-independent GUI abstraction\nlayer, which is used to support the \"visualization\" features of the\nTraits package. Thus, you can write model in terms of the Traits API and\nspecify a GUI in terms of the primitives supplied by TraitsUI (views,\nitems, editors, etc.), and let TraitsUI and your selected toolkit and\nback-end take care of the details of displaying them.",
            "name": "py-traitsui"
        },
        {
            "description": "State-of-the-art Natural Language Processing for TensorFlow 2.0 and\nPyTorch",
            "name": "py-transformers"
        },
        {
            "description": "Functions for 3D coordinate transformations.",
            "name": "py-transforms3d"
        },
        {
            "description": "Make your Python code fly at transonic speeds!",
            "name": "py-transonic"
        },
        {
            "description": "Python bindings to the triangle library",
            "name": "py-triangle"
        },
        {
            "description": "Import, export, process, analyze and view triangular meshes",
            "name": "py-trimesh"
        },
        {
            "description": "Experiments with new file format for tractography.",
            "name": "py-trx-python"
        },
        {
            "description": "TuiView is a lightweight raster GIS with powerful raster attribute table\nmanipulation abilities.",
            "name": "py-tuiview"
        },
        {
            "description": "UCSF pyem is a collection of Python modules and command-line utilities\nfor electron microscopy of biological samples.",
            "name": "py-ucsf-pyem"
        },
        {
            "description": "UCX-Py is the Python interface for UCX, a low-level high-performance\nnetworking library. UCX and UCX-Py supports several transport methods\nincluding InfiniBand and NVLink while still using traditional networking\nprotocols like TCP.",
            "name": "py-ucx-py"
        },
        {
            "description": "Unified Histogram Interface: tools to help library authors work with\nhistograms",
            "name": "py-uhi"
        },
        {
            "description": "Ultralytics YOLOv8, developed by Ultralytics, is a cutting-edge, state-\nof-the-art (SOTA) model that builds upon the success of previous YOLO\nversions and introduces new features and improvements to further boost\nperformance and flexibility. YOLOv8 is designed to be fast, accurate,\nand easy to use, making it an excellent choice for a wide range of\nobject detection, image segmentation and image classification tasks.",
            "name": "py-ultralytics"
        },
        {
            "description": "Uniform Manifold Approximation and Projection (UMAP) is a dimension\nreduction technique that can be used for visualisation similarly to\nt-SNE, but also for general non-linear dimension reduction.",
            "name": "py-umap-learn"
        },
        {
            "description": "Tools for handling Unique Molecular Identifiers in NGS data sets",
            "name": "py-umi-tools"
        },
        {
            "description": "Transparent calculations with uncertainties on the quantities involved\n(aka error propagation); fast calculation of derivatives",
            "name": "py-uncertainties"
        },
        {
            "description": "Uncertainty Toolbox: a python toolbox for predictive uncertainty\nquantification, calibration, metrics, and visualization.",
            "name": "py-uncertainty-toolbox"
        },
        {
            "description": "N-dimensional unfold (im2col) and fold (col2im) in PyTorch.",
            "name": "py-unfoldnd"
        },
        {
            "description": "A package for handling numpy arrays with units.",
            "name": "py-unyt"
        },
        {
            "description": "ROOT I/O in pure Python and NumPy. Uproot is a reader and a writer of\nthe ROOT file format using only Python and Numpy. Unlike the standard\nC++ ROOT implementation, Uproot is only an I/O library, primarily\nintended to stream data into machine learning libraries in Python.\nUnlike PyROOT and root_numpy, Uproot does not depend on C++ ROOT.\nInstead, it uses Numpy to cast blocks of data from the ROOT file as\nNumpy arrays.",
            "name": "py-uproot"
        },
        {
            "description": "ROOT I/O in pure Python and Numpy. uproot is a reader and a writer of\nthe ROOT file format using only Python and Numpy. Unlike the standard\nC++ ROOT implementation, uproot is only an I/O library, primarily\nintended to stream data into machine learning libraries in Python.\nUnlike PyROOT and root_numpy, uproot does not depend on C++ ROOT.\nInstead, it uses Numpy to cast blocks of data from the ROOT file as\nNumpy arrays.",
            "name": "py-uproot3"
        },
        {
            "description": "Pythonic mix-ins for ROOT classes. This package is typically used as a\ndependency for uproot 3.x, to define methods on the classes that are\nautomatically generated from ROOT files. This includes histograms (TH*)\nand physics objects like TLorentzVectors. The reason it's a separate\nlibrary is so that we can add physics-specific functionality on a\nshorter timescale than we can update Uproot 3 itself, which is purely an\nI/O package.",
            "name": "py-uproot3-methods"
        },
        {
            "description": "UVW is a small utility library to write VTK files from data contained\nin Numpy arrays.",
            "name": "py-uvw"
        },
        {
            "description": "Xarray extension for unstructured climate and global weather data\nanalysis and visualization",
            "name": "py-uxarray"
        },
        {
            "description": "Python library for reading, writing, and manipulating large-scale\nvasculature datasets",
            "name": "py-vascpy"
        },
        {
            "description": "VCF-kit is a command-line based collection of utilities for performing\nanalysis on Variant Call Format (VCF) files.",
            "name": "py-vcf-kit"
        },
        {
            "description": "Vector classes and utilities",
            "name": "py-vector"
        },
        {
            "description": "Visdom aims to facilitate visualization of (remote) data with an\nemphasis on supporting scientific experimentation.",
            "name": "py-visdom"
        },
        {
            "description": "WAVES (LANL code C23004) is a computational science and engineering\nworkflow tool that integrates parametric studies with traditional\nsoftware build systems.",
            "name": "py-waves"
        },
        {
            "description": "WCSAxes is a framework for making plots of Astronomical data in\nMatplotlib.",
            "name": "py-wcsaxes"
        },
        {
            "description": "Python-based I/O for deep learning problems.",
            "name": "py-webdataset"
        },
        {
            "description": "WebLogo is a web based application designed to make the generation of\nsequence logos as easy and painless as possible.",
            "name": "py-weblogo"
        },
        {
            "description": "High performance storage and I/O for deep learning and data processing.",
            "name": "py-wids"
        },
        {
            "description": "A little word cloud generator in Python.",
            "name": "py-wordcloud"
        },
        {
            "description": "wradlib is designed to assist you in the most important steps of\nprocessing weather radar data. These may include: reading common data\nformats, georeferencing, converting reflectivity to rainfall intensity,\nidentifying and correcting typical error sources (such as clutter or\nattenuation) and visualising the data.",
            "name": "py-wradlib"
        },
        {
            "description": "Bioinformatics tools and a software library developed by the Oxford\nNanopore Technologies Applications group.",
            "name": "py-wub"
        },
        {
            "description": "Common set of tools used in weather workflows. See\nhttps://wxflow.readthedocs.io/en/latest/ for documentation.",
            "name": "py-wxflow"
        },
        {
            "description": "wxPython plotting widgets using matplotlib.",
            "name": "py-wxmplot"
        },
        {
            "description": "Cross platform GUI toolkit for Python.",
            "name": "py-wxpython"
        },
        {
            "description": "The Xanadu Cloud Client (XCC) is a Python API and CLI for the Xanadu\nCloud.",
            "name": "py-xanadu-cloud-client"
        },
        {
            "description": "N-D labeled arrays and datasets in Python",
            "name": "py-xarray"
        },
        {
            "description": "Regridding utility for xarray",
            "name": "py-xarray-regrid"
        },
        {
            "description": "Xarray-TensorStore is a small library that allows opening Zarr arrays\ninto Xarray via TensorStore, instead of the standard Zarr-Python\nlibrary.",
            "name": "py-xarray-tensorstore"
        },
        {
            "description": "xdot.py is an interactive viewer for graphs written in Graphviz's dot\nlanguage.",
            "name": "py-xdot"
        },
        {
            "description": "Universal Regridder for Geospatial Data.",
            "name": "py-xesmf"
        },
        {
            "description": "XGBoost is an optimized distributed gradient boosting library designed\nto be highly efficient, flexible and portable.",
            "name": "py-xgboost"
        },
        {
            "description": "Fast, flexible, label-aware histograms for numpy and xarray.",
            "name": "py-xhistogram"
        },
        {
            "description": "Metrics for verifying forecasts.",
            "name": "py-xskillscore"
        },
        {
            "description": "Python API for the extended tight binding program package",
            "name": "py-xtb"
        },
        {
            "description": "YAHMM is a HMM package for Python, implemented in Cython for speed.",
            "name": "py-yahmm"
        },
        {
            "description": "Python library to read and process pulsar data in several different\nformats",
            "name": "py-your"
        },
        {
            "description": "Volumetric Data Analysis yt is a python package for analyzing and\nvisualizing volumetric, multi-resolution data from astrophysical\nsimulations, radio telescopes, and a burgeoning interdisciplinary\ncommunity.",
            "name": "py-yt"
        },
        {
            "description": "Ytopt package implements search using Random Forest (SuRF), an\nautotuning search method developed within Y-Tune ECP project.",
            "name": "py-ytopt"
        },
        {
            "description": "Zarr is a Python package providing an implementation of chunked,\ncompressed, N-dimensional arrays.",
            "name": "py-zarr"
        },
        {
            "description": "scalable pythonic model fitting for high energy physics",
            "name": "py-zfit"
        },
        {
            "description": "zfit model fitting interface for HEP",
            "name": "py-zfit-interface"
        },
        {
            "description": "Parallel Global Multiobjective Optimizer (and its Python alter ego\nPyGMO) is a C++ / Python platform to perform parallel computations of\noptimisation tasks (global and local) via the asynchronous generalized\nisland model.",
            "name": "pygmo"
        },
        {
            "description": "QMCPACK, is a modern high-performance open-source Quantum Monte Carlo\n(QMC) simulation code.",
            "name": "qmcpack"
        },
        {
            "description": "RDKit is a collection of cheminformatics and machine-learning software\nwritten in C++ and Python.",
            "name": "rdkit"
        },
        {
            "description": "REDItools: python scripts for RNA editing detection by RNA-Seq data.\nREDItools are simple python scripts conceived to facilitate the\ninvestigation of RNA editing at large-scale and devoted to research\ngroups that would to explore such phenomenon in own data but don't have\nsufficient bioinformatics skills. They work on main operating systems\n(although unix/linux-based OS are preferred), can handle reads from\nwhatever platform in the standard BAM format and implement a variety of\nfilters.",
            "name": "reditools"
        },
        {
            "description": "Redundans pipeline assists an assembly of heterozygous genomes.",
            "name": "redundans"
        },
        {
            "description": "MATS is a computational tool to detect differential alternative splicing\nevents from RNA-Seq data.",
            "name": "rmats"
        },
        {
            "description": "Rapid large-scale prokaryote pan genome analysis",
            "name": "roary"
        },
        {
            "description": "Advanced Profiling and Analytics for AMD Hardware",
            "name": "rocprofiler-compute"
        },
        {
            "description": "ROOT is a data analysis framework.",
            "name": "root"
        },
        {
            "description": "salome-medcoupling is a part of SALOME platform to manipulate meshes and\nfields in memory, and use salome-med format for files.",
            "name": "salome-medcoupling"
        },
        {
            "description": "Contains functionality which is used in most SCINE modules.",
            "name": "scine-utilities"
        },
        {
            "description": "Seissol - A scientific software for the numerical simulation of seismic\nwave phenomena and earthquake dynamics.",
            "name": "seissol"
        },
        {
            "description": "SENSEI is a platform for scalable in-situ analysis and visualization.\nIts design motto is \"Write once, run everywhere\", this means that once\nthe application is instrumented with SENSEI it can use existing and\nfuture analysis backends. Existing backends include: Paraview/Catalyst,\nVisit/Libsim, ADIOS, Python scripts, and so on.",
            "name": "sensei"
        },
        {
            "description": "Serialbox is a serialization library and tools for C/C++, Python3 and\nFortran. Serialbox is used in several projects for building validation\nframeworks against reference runs.",
            "name": "serialbox"
        },
        {
            "description": "SGpp is a library and framework for sparse grids in different flavors.\nSGpp supports both hierarchical spatially-adaptive sparse grids and the\ndimensionally-adaptive sparse grid combination technique.",
            "name": "sgpp"
        },
        {
            "description": "ShapeMapper automates the calculation of RNA structure probing\nreactivities from mutational profiling (MaP) experiments, in which\nchemical adducts on RNA are detected as internal mutations in cDNA\nthrough reverse transcription and read out by massively parallel\nsequencing.",
            "name": "shapemapper"
        },
        {
            "description": "SICER2: a redesigned and improved ChIP-seq broad peak calling tool",
            "name": "sicer2"
        },
        {
            "description": "SimulationIO: Efficient and convenient I/O for large PDE simulations",
            "name": "simulationio"
        },
        {
            "description": "Singularity-EOS: A collection of closure models and tools useful for\nmultiphysics codes.",
            "name": "singularity-eos"
        },
        {
            "description": "Domain specific library for electronic structure calculations",
            "name": "sirius"
        },
        {
            "description": "Sourmash: Quickly search, compare, and analyze genomic and metagenomic\ndata sets with k-mer sketches.",
            "name": "sourmash"
        },
        {
            "description": "small RNA-PARE Target Analyzer (sPARTA) is a tool which utilizes high-\nthroughput sequencing to profile genome-wide cleavage products.",
            "name": "sparta"
        },
        {
            "description": "SpatialData provides an interface to Proj.4 for converting coordinates\nSpatialdata is a C++ library for interpolating values for spatially\ndistributed data, converting coordinates among geographic projections\nusing Proj, nondimensionalization of quantities, specification of units\nvia Pyre (optional). This library is used in the finite-element code\nPyLith (https://github.com/geodynamics/pylith). The primary focus is\nspecification of parameters that vary in space, such as values for\nboundary conditions and parameters of constitutive models. This provides\na specification of these parameters independent of the discretization.",
            "name": "spatialdata"
        },
        {
            "description": "The SpECTRE numerical relativity code. SpECTRE is an open-source code\nfor multi-scale, multi-physics problems in astrophysics and\ngravitational physics. In the future, we hope that it can be applied to\nproblems across discipline boundaries in fluid dynamics, geoscience,\nplasma physics, nuclear physics, and engineering. It runs at petascale\nand is designed for future exascale computers. SpECTRE is being\ndeveloped in support of our collaborative Simulating eXtreme Spacetimes\n(SXS) research program into the multi-messenger astrophysics of neutron\nstar mergers, core-collapse supernovae, and gamma-ray bursts.",
            "name": "spectre"
        },
        {
            "description": "Spiner: Performance portable routines for generic, tabulated, multi-\ndimensional data",
            "name": "spiner"
        },
        {
            "description": "STochastic Engine for Pathway Simulation",
            "name": "steps"
        },
        {
            "description": "SU2 is a suite of open-source software tools written in C++ for the\nnumerical solution of partial differential equations (PDE) and\nperforming PDE constrained optimization.",
            "name": "su2"
        },
        {
            "description": "Error-bounded Lossy Compressor for HPC Data",
            "name": "sz"
        },
        {
            "description": "Tamaas is a C++ library with a Python interface that efficiently solves\ncontact mechanics problems with periodic rough surfaces, plasticity,\nadhesion and friction.",
            "name": "tamaas"
        },
        {
            "description": "Tandem is a scientific software for SEAS modelling and for solving\nPoisson and linear elasticity problems. It implements the Symmetric\nInterior Penalty Galerkin (SIPG) method using unstructured simplicial\nmeshes (triangle meshes in 2D, tetrahedral meshes in 3D).",
            "name": "tandem"
        },
        {
            "description": "The Toolkit for Adaptive Stochastic Modeling and Non-Intrusive\nApproximatioN is a robust library for high dimensional integration and\ninterpolation as well as parameter calibration.",
            "name": "tasmanian"
        },
        {
            "description": "Light-weight tight-binding framework",
            "name": "tblite"
        },
        {
            "description": "The TFEL project is a collaborative development of CEA (French\nAlternative Energies and Atomic Energy Commission) and EDF (Electricite\nde France). It mostly contains the MFront code generator which\ntranslates a set of closely related domain specific languages into plain\nC++ on top of the TFEL libraries. MFront handles material properties,\nmechanical behaviours and simple point-wise models. Interfaces are\nprovided for several finite element solvers, such as: Abaqus/Standard,\nAbaqus/Explicit, Ansys APDL, Cast3M, Europlexus, Code_Aster, CalculiX\nand a few others. MFront comes with an handy easy-to-use tool called\nMTest that can test the local behaviour of a material, by imposing\nindependent constraints on each component of the strain or the stress.",
            "name": "tfel"
        },
        {
            "description": "Modular profiling toolkit and suite of libraries and tools for\nC/C++/Fortran/CUDA/Python",
            "name": "timemory"
        },
        {
            "description": "Tiramisu is a polyhedral compiler for dense and sparse deep learning and\ndata parallel algorithms.It provides a simple C++ API for expressing\nalgorithms and how these algorithms should be optimized by the compiler.",
            "name": "tiramisu"
        },
        {
            "description": "topaz: Pipeline for particle picking in cryo-electron microscopy images\nusing convolutional neural networks trained from positive and unlabeled\nexamples. Also featuring micrograph and tomogram denoising with DNNs.",
            "name": "topaz"
        },
        {
            "description": "Treelite is a model compiler for efficient deployment of decision tree\nensembles.",
            "name": "treelite"
        },
        {
            "description": "The Trilinos Project is an effort to develop algorithms and enabling\ntechnologies within an object-oriented software framework for the\nsolution of large-scale, complex multi-physics engineering and\nscientific problems. A unique design feature of Trilinos is its focus on\npackages.",
            "name": "trilinos"
        },
        {
            "description": "Adapter for Trilinos Seacas Ioss and Paraview Catalyst",
            "name": "trilinos-catalyst-ioss-adapter"
        },
        {
            "description": "Trinity, developed at the Broad Institute and the Hebrew University of\nJerusalem, represents a novel method for the efficient and robust de\nnovo reconstruction of transcriptomes from RNA-seq data. Trinity\ncombines three independent software modules: Inchworm, Chrysalis, and\nButterfly, applied sequentially to process large volumes of RNA-seq\nreads. Trinity partitions the sequence data into many individual de\nBruijn graphs, each representing the transcriptional complexity at a\ngiven gene or locus, and then processes each graph independently to\nextract full-length splicing isoforms and to tease apart transcripts\nderived from paralogous genes.",
            "name": "trinity"
        },
        {
            "description": "Physics-based modeling and simulation of manufacturing processes.\nTruchas includes coupled physics models for incompressible multi-\nmaterial flow with interface tracking, heat transfer, phase change, view\nfactor thermal radiation, species advection-diffusion, elastic/plastic\nmechanics with contact, and electromagnetics. It employs finite volume,\nfinite element, and mimetic finite difference discretizations on 3-D\nunstructured meshes composed of mixed cell types.",
            "name": "truchas"
        },
        {
            "description": "The tskit library provides the underlying functionality used to load,\nexamine, and manipulate tree sequences",
            "name": "tskit"
        },
        {
            "description": "Sandia Uncertainty Quantification Toolkit. The UQ Toolkit (UQTk) is a\ncollection of libraries and tools for the quantification of uncertainty\nin numerical model predictions",
            "name": "uqtk"
        },
        {
            "description": "VAPOR is the Visualization and Analysis Platform for Ocean, Atmosphere,\nand Solar Researchers. VAPOR provides an interactive 3D visualization\nenvironment that can also produce animations and still frame images.",
            "name": "vapor"
        },
        {
            "description": "VIGRA stands for \"Vision with Generic Algorithms\". It's an image\nprocessing and analysis library that puts its main emphasis on\ncustomizable algorithms and data structures",
            "name": "vigra"
        },
        {
            "description": "WarpX is an advanced electromagnetic Particle-In-Cell code. It supports\nmany features including Perfectly-Matched Layers (PML) and mesh\nrefinement. In addition, WarpX is a highly-parallel and highly-optimized\ncode and features hybrid GPU/OpenMP/MPI parallelization and load\nbalancing capabilities.",
            "name": "warpx"
        },
        {
            "description": "Exchange-Correlation functionals with arbitrary order derivatives.",
            "name": "xcfun"
        },
        {
            "description": "Python bindings for the xtensor C++ multi-dimensional array library",
            "name": "xtensor-python"
        },
        {
            "description": "Yade is an free software for particle based simulations.",
            "name": "yade"
        },
        {
            "description": "zfp is a compressed number format for multidimensional floating-point\nand integer arrays. zfp provides compressed-array classes that support\nhigh throughput read and write random access to individual array\nelements. zfp also supports serial and parallel (OpenMP and CUDA)\ncompression of whole arrays.",
            "name": "zfp"
        }
    ],
    "description": "Fundamental package for array computing in Python.\n",
    "homepage": "https://numpy.org/",
    "latest_version": "2.2.6",
    "maintainers": [
        "adamjstewart",
        "rgommers"
    ],
    "name": "py-numpy",
    "patches": [
        {
            "level": 1,
            "owner": "builtin.py-numpy",
            "reverse": false,
            "sha256": "1c9cb080017e21e25ca92b70ce10ccf8ef6fcfd30dc936d832611db2f20da4c6",
            "url": "https://github.com/numpy/numpy/commit/7771624a4a4c662f936e07bbf74dd7d553225f23.patch?full_index=1",
            "version": "@2.0:2.2",
            "working_dir": "."
        },
        {
            "level": 1,
            "owner": "builtin.py-numpy",
            "relative_path": "add_fj_compiler.patch",
            "reverse": false,
            "sha256": "dbf1d0714f3ebcd583f5d613c0d6e3a4f89d48053b467bbba322ad985e89f796",
            "version": "@1.19.3:1.19.5 %fj",
            "working_dir": "."
        },
        {
            "level": 1,
            "owner": "builtin.py-numpy",
            "relative_path": "add_fj_compiler2.patch",
            "reverse": false,
            "sha256": "04ee8db2a60b27b43b7ac64bffaa08a5161336ee103aeca738fa21597ea6c895",
            "version": "@1.19.0:1.19.2 %fj",
            "working_dir": "."
        },
        {
            "level": 1,
            "owner": "builtin.py-numpy",
            "relative_path": "add_fj_compiler3.patch",
            "reverse": false,
            "sha256": "99104c19b82c9fabc977fa468368eae33a55fa1b95975ba6e7d211ff2ed6d8ef",
            "version": "@1.14.0:1.18.5 %fj",
            "working_dir": "."
        },
        {
            "level": 1,
            "owner": "builtin.py-numpy",
            "relative_path": "check_executables.patch",
            "reverse": false,
            "sha256": "873745d7b547857fcfec9cae90b09c133b42a4f0c23b6c2d84cf37e2dd816604",
            "version": "@1.20.0:",
            "working_dir": "."
        },
        {
            "level": 1,
            "owner": "builtin.py-numpy",
            "relative_path": "check_executables2.patch",
            "reverse": false,
            "sha256": "8a9d5d1b3f145c043b8b04869e7d46c6ff95c3f486d84f69693017c7e6190c7d",
            "version": "@1.19.0:1.19.5",
            "working_dir": "."
        },
        {
            "level": 1,
            "owner": "builtin.py-numpy",
            "relative_path": "check_executables3.patch",
            "reverse": false,
            "sha256": "cf407c1024b0878c4222dd352aa9dece412073bb15b138243a2893725434c7b6",
            "version": "@1.16.0:1.18.5",
            "working_dir": "."
        },
        {
            "level": 1,
            "owner": "builtin.py-numpy",
            "reverse": false,
            "sha256": "802970a9034d40a8a8f49a03f489d5361d5eabf69249621e6757651448910f1a",
            "url": "https://github.com/numpy/numpy/commit/932202d24c399f46161caa7464446b55e27fa947.patch?full_index=1",
            "version": "@1.20.3:1.22.1",
            "working_dir": "."
        },
        {
            "level": 1,
            "owner": "builtin.py-numpy",
            "reverse": false,
            "sha256": "e9508c3b3a1e1a24669014a0c1b9f3b009a149ea3886cf711eaef2a32b247fdb",
            "url": "https://github.com/numpy/numpy/commit/fdb5393dc518d57de411db1c364ec36a7192a5a4.patch?full_index=1",
            "version": "@1.22.0:1.22.3",
            "working_dir": "."
        },
        {
            "level": 1,
            "owner": "builtin.py-numpy",
            "reverse": false,
            "sha256": "fe42a018a69cfafb7c4efc183a7c73835a298e45a8f9a585cb411170871ff596",
            "url": "https://github.com/numpy/numpy/commit/953cc2dfc0f0e063a01778d1392c931d9031c469.patch?full_index=1",
            "version": "@1.26:1.26.3 ^intel-oneapi-compilers-classic",
            "working_dir": "."
        }
    ],
    "resources": [],
    "variants": [
        {
            "default": "python_pip",
            "description": "Build systems supported by the package",
            "name": "build_system"
        }
    ],
    "versions": [
        {
            "branch": "main",
            "name": "main"
        },
        {
            "name": "2.2.6",
            "sha256": "e29554e2bef54a90aa5cc07da6ce955accb83f21ab5de01a62c8478897b264fd"
        },
        {
            "name": "2.2.5",
            "sha256": "a9c0d994680cd991b1cb772e8b297340085466a6fe964bc9d4e80f5e2f43c291"
        },
        {
            "name": "2.2.4",
            "sha256": "9ba03692a45d3eef66559efe1d1096c4b9b75c0986b5dff5530c378fb8331d4f"
        },
        {
            "name": "2.2.3",
            "sha256": "dbdc15f0c81611925f382dfa97b3bd0bc2c1ce19d4fe50482cb0ddc12ba30020"
        },
        {
            "name": "2.2.2",
            "sha256": "ed6906f61834d687738d25988ae117683705636936cc605be0bb208b23df4d8f"
        },
        {
            "name": "2.2.1",
            "sha256": "45681fd7128c8ad1c379f0ca0776a8b0c6583d2f69889ddac01559dfe4390918"
        },
        {
            "name": "2.2.0",
            "sha256": "140dd80ff8981a583a60980be1a655068f8adebf7a45a06a6858c873fcdcd4a0"
        },
        {
            "name": "2.1.3",
            "sha256": "aa08e04e08aaf974d4458def539dece0d28146d866a39da5639596f4921fd761"
        },
        {
            "name": "2.1.2",
            "sha256": "13532a088217fa624c99b843eeb54640de23b3414b14aa66d023805eb731066c"
        },
        {
            "name": "2.1.1",
            "sha256": "d0cf7d55b1051387807405b3898efafa862997b4cba8aa5dbe657be794afeafd"
        },
        {
            "name": "2.1.0",
            "sha256": "7dc90da0081f7e1da49ec4e398ede6a8e9cc4f5ebe5f9e06b443ed889ee9aaa2"
        },
        {
            "name": "2.0.2",
            "sha256": "883c987dee1880e2a864ab0dc9892292582510604156762362d9326444636e78"
        },
        {
            "name": "2.0.1",
            "sha256": "485b87235796410c3519a699cfe1faab097e509e90ebb05dcd098db2ae87e7b3"
        },
        {
            "name": "2.0.0",
            "sha256": "cf5d1c9e6837f8af9f92b6bd3e86d513cdc11f60fd62185cc49ec7d1aba34864"
        },
        {
            "name": "1.26.4",
            "sha256": "2a02aba9ed12e4ac4eb3ea9421c420301a0c6460d9830d74a9df87efa4912010"
        },
        {
            "name": "1.26.3",
            "sha256": "697df43e2b6310ecc9d95f05d5ef20eacc09c7c4ecc9da3f235d39e71b7da1e4"
        },
        {
            "name": "1.26.2",
            "sha256": "f65738447676ab5777f11e6bbbdb8ce11b785e105f690bc45966574816b6d3ea"
        },
        {
            "name": "1.26.1",
            "sha256": "c8c6c72d4a9f831f328efb1312642a1cafafaa88981d9ab76368d50d07d93cbe"
        },
        {
            "name": "1.26.0",
            "sha256": "f93fc78fe8bf15afe2b8d6b6499f1c73953169fad1e9a8dd086cdff3190e7fdf"
        },
        {
            "name": "1.25.2",
            "sha256": "fd608e19c8d7c55021dffd43bfe5492fab8cc105cc8986f813f8c3c048b38760"
        },
        {
            "name": "1.25.1",
            "sha256": "9a3a9f3a61480cc086117b426a8bd86869c213fc4072e606f01c4e4b66eb92bf"
        },
        {
            "name": "1.25.0",
            "sha256": "f1accae9a28dc3cda46a91de86acf69de0d1b5f4edd44a9b0c3ceb8036dfff19"
        },
        {
            "name": "1.24.4",
            "sha256": "80f5e3a4e498641401868df4208b74581206afbee7cf7b8329daae82676d9463"
        },
        {
            "name": "1.24.3",
            "sha256": "ab344f1bf21f140adab8e47fdbc7c35a477dc01408791f8ba00d018dd0bc5155"
        },
        {
            "name": "1.24.2",
            "sha256": "003a9f530e880cb2cd177cba1af7220b9aa42def9c4afc2a2fc3ee6be7eb2b22"
        },
        {
            "name": "1.24.1",
            "sha256": "2386da9a471cc00a1f47845e27d916d5ec5346ae9696e01a8a34760858fe9dd2"
        },
        {
            "name": "1.24.0",
            "sha256": "c4ab7c9711fe6b235e86487ca74c1b092a6dd59a3cb45b63241ea0a148501853"
        },
        {
            "name": "1.23.5",
            "sha256": "1b1766d6f397c18153d40015ddfc79ddb715cabadc04d2d228d4e5a8bc4ded1a"
        },
        {
            "name": "1.23.4",
            "sha256": "ed2cc92af0efad20198638c69bb0fc2870a58dabfba6eb722c933b48556c686c"
        },
        {
            "name": "1.23.3",
            "sha256": "51bf49c0cd1d52be0a240aa66f3458afc4b95d8993d2d04f0d91fa60c10af6cd"
        },
        {
            "name": "1.23.2",
            "sha256": "b78d00e48261fbbd04aa0d7427cf78d18401ee0abd89c7559bbf422e5b1c7d01"
        },
        {
            "name": "1.23.1",
            "sha256": "d748ef349bfef2e1194b59da37ed5a29c19ea8d7e6342019921ba2ba4fd8b624"
        },
        {
            "name": "1.23.0",
            "sha256": "bd3fa4fe2e38533d5336e1272fc4e765cabbbde144309ccee8675509d5cd7b05"
        },
        {
            "name": "1.22.4",
            "sha256": "425b390e4619f58d8526b3dcf656dde069133ae5c240229821f01b5f44ea07af"
        },
        {
            "name": "1.22.3",
            "sha256": "dbc7601a3b7472d559dc7b933b18b4b66f9aa7452c120e87dfb33d02008c8a18"
        },
        {
            "name": "1.22.2",
            "sha256": "076aee5a3763d41da6bef9565fdf3cb987606f567cd8b104aded2b38b7b47abf"
        },
        {
            "name": "1.22.1",
            "sha256": "e348ccf5bc5235fc405ab19d53bec215bb373300e5523c7b476cc0da8a5e9973"
        },
        {
            "name": "1.22.0",
            "sha256": "a955e4128ac36797aaffd49ab44ec74a71c11d6938df83b1285492d277db5397"
        },
        {
            "name": "1.21.6",
            "sha256": "ecb55251139706669fdec2ff073c98ef8e9a84473e51e716211b41aa0f18e656"
        },
        {
            "name": "1.21.5",
            "sha256": "6a5928bc6241264dce5ed509e66f33676fc97f464e7a919edc672fb5532221ee"
        },
        {
            "name": "1.21.4",
            "sha256": "e6c76a87633aa3fa16614b61ccedfae45b91df2767cf097aa9c933932a7ed1e0"
        },
        {
            "name": "1.21.3",
            "sha256": "63571bb7897a584ca3249c86dd01c10bcb5fe4296e3568b2e9c1a55356b6410e"
        },
        {
            "name": "1.21.2",
            "sha256": "423216d8afc5923b15df86037c6053bf030d15cc9e3224206ef868c2d63dd6dc"
        },
        {
            "name": "1.21.1",
            "sha256": "dff4af63638afcc57a3dfb9e4b26d434a7a602d225b42d746ea7fe2edf1342fd"
        },
        {
            "name": "1.21.0",
            "sha256": "e80fe25cba41c124d04c662f33f6364909b985f2eb5998aaa5ae4b9587242cce"
        },
        {
            "name": "1.20.3",
            "sha256": "e55185e51b18d788e49fe8305fd73ef4470596b33fc2c1ceb304566b99c71a69"
        },
        {
            "name": "1.20.2",
            "sha256": "878922bf5ad7550aa044aa9301d417e2d3ae50f0f577de92051d739ac6096cee"
        },
        {
            "name": "1.20.1",
            "sha256": "3bc63486a870294683980d76ec1e3efc786295ae00128f9ea38e2c6e74d5a60a"
        },
        {
            "name": "1.20.0",
            "sha256": "3d8233c03f116d068d5365fed4477f2947c7229582dad81e5953088989294cec"
        },
        {
            "name": "1.19.5",
            "sha256": "a76f502430dd98d7546e1ea2250a7360c065a5fdea52b2dffe8ae7180909b6f4"
        },
        {
            "name": "1.19.4",
            "sha256": "141ec3a3300ab89c7f2b0775289954d193cc8edb621ea05f99db9cb181530512"
        },
        {
            "name": "1.19.3",
            "sha256": "35bf5316af8dc7c7db1ad45bec603e5fb28671beb98ebd1d65e8059efcfd3b72"
        }
    ],
    "versions_deprecated": [
        {
            "name": "1.19.2",
            "sha256": "0d310730e1e793527065ad7dde736197b705d0e4c9999775f212b03c44a8484c"
        },
        {
            "name": "1.19.1",
            "sha256": "b8456987b637232602ceb4d663cb34106f7eb780e247d51a260b84760fd8f491"
        },
        {
            "name": "1.19.0",
            "sha256": "76766cc80d6128750075378d3bb7812cf146415bd29b588616f72c943c00d598"
        },
        {
            "name": "1.18.5",
            "sha256": "34e96e9dae65c4839bd80012023aadd6ee2ccb73ce7fdf3074c62f301e63120b"
        },
        {
            "name": "1.18.4",
            "sha256": "bbcc85aaf4cd84ba057decaead058f43191cc0e30d6bc5d44fe336dc3d3f4509"
        },
        {
            "name": "1.18.3",
            "sha256": "e46e2384209c91996d5ec16744234d1c906ab79a701ce1a26155c9ec890b8dc8"
        },
        {
            "name": "1.18.2",
            "sha256": "e7894793e6e8540dbeac77c87b489e331947813511108ae097f1715c018b8f3d"
        },
        {
            "name": "1.18.1",
            "sha256": "b6ff59cee96b454516e47e7721098e6ceebef435e3e21ac2d6c3b8b02628eb77"
        },
        {
            "name": "1.18.0",
            "sha256": "a9d72d9abaf65628f0f31bbb573b7d9304e43b1e6bbae43149c17737a42764c4"
        },
        {
            "name": "1.17.5",
            "sha256": "16507ba6617f62ae3c6ab1725ae6f550331025d4d9a369b83f6d5a470446c342"
        },
        {
            "name": "1.17.4",
            "sha256": "f58913e9227400f1395c7b800503ebfdb0772f1c33ff8cb4d6451c06cabdf316"
        },
        {
            "name": "1.17.3",
            "sha256": "a0678793096205a4d784bd99f32803ba8100f639cf3b932dc63b21621390ea7e"
        }
    ]
}