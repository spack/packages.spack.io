{
    "aliases": [],
    "build_system": "RPackage",
    "conflicts": [],
    "dependencies": [
        {
            "description": "The NVIDIA HPC SDK is a comprehensive suite of compilers, libraries and\ntools essential to maximizing developer productivity and the performance\nand portability of HPC applications. The NVIDIA HPC SDK C, C++, and\nFortran compilers support GPU acceleration of HPC modeling and\nsimulation applications with standard C++ and Fortran, OpenACC\ndirectives, and CUDA. GPU-accelerated math libraries maximize\nperformance on common HPC algorithms, and optimized communications\nlibraries enable standards-based multi-GPU and scalable systems\nprogramming. Performance profiling and debugging tools simplify porting\nand optimization of HPC applications.",
            "name": "c"
        },
        {
            "description": "The NVIDIA HPC SDK is a comprehensive suite of compilers, libraries and\ntools essential to maximizing developer productivity and the performance\nand portability of HPC applications. The NVIDIA HPC SDK C, C++, and\nFortran compilers support GPU acceleration of HPC modeling and\nsimulation applications with standard C++ and Fortran, OpenACC\ndirectives, and CUDA. GPU-accelerated math libraries maximize\nperformance on common HPC algorithms, and optimized communications\nlibraries enable standards-based multi-GPU and scalable systems\nprogramming. Performance profiling and debugging tools simplify porting\nand optimization of HPC applications.",
            "name": "cxx"
        },
        {
            "description": "GNU internationalization (i18n) and localization (l10n) library.",
            "name": "gettext"
        },
        {
            "description": "R is 'GNU S', a freely available language and environment for\nstatistical computing and graphics which provides a wide variety of\nstatistical and graphical techniques: linear and nonlinear modelling,\nstatistical tests, time series analysis, classification, clustering,\netc. Please consult the R project homepage for further information.",
            "name": "r"
        },
        {
            "description": "Trellis Graphics for R. A powerful and elegant high-level data\nvisualization system inspired by Trellis graphics, with an emphasis on\nmultivariate data. Lattice is sufficient for typical graphics needs, and\nis also flexible enough to handle most nonstandard requirements. See\n?Lattice for an introduction.",
            "name": "r-lattice"
        }
    ],
    "dependent_to": [
        {
            "description": "Functions to accompany A. Gelman and J. Hill, Data Analysis Using\nRegression and Multilevel/Hierarchical Models, Cambridge University\nPress, 2007.",
            "name": "r-arm"
        },
        {
            "description": "Compiling Bioconductor to Handle Each Matrix Type. Provides a consistent\nC++ class interface for reading from and writing data to a variety of\ncommonly used matrix types. Ordinary matrices and several sparse/dense\nMatrix classes are directly supported, third-party S4 classes may be\nsupported by external linkage, while all other matrices are handled by\nDelayedArray block processing.",
            "name": "r-beachmat"
        },
        {
            "description": "Nearest Neighbor Detection for Bioconductor Packages. Implements exact\nand approximate methods for nearest neighbor detection, in a framework\nthat allows them to be easily switched within Bioconductor packages or\nworkflows. Exact searches can be performed using the k-means for\nk-nearest neighbors algorithm or with vantage point trees. Approximate\nsearches can be performed using the Annoy or HNSW libraries. Searching\non either Euclidean or Manhattan distances is supported. Parallelization\nis achieved for all methods by using BiocParallel. Functions are also\nprovided to search for all neighbors within a given distance.",
            "name": "r-biocneighbors"
        },
        {
            "description": "Singular Value Decomposition for Bioconductor Packages. Implements exact\nand approximate methods for singular value decomposition and principal\ncomponents analysis, in a framework that allows them to be easily\nswitched within Bioconductor packages or workflows. Where possible,\nparallelization is achieved using the BiocParallel framework.",
            "name": "r-biocsingular"
        },
        {
            "description": "An interface package for the BIOM file format. This is an R package for\ninterfacing with the BIOM format. This package includes basic tools for\nreading biom-format files, accessing and subsetting data tables from a\nbiom object (which is more complex than a single table), as well as\nlimited support for writing a biom-object back to a biom-format file.\nThe design of this API is intended to match the python API and other\ntools included with the biom-format project, but with a decidedly \"R\nflavor\" that should be familiar to R users. This includes S4 classes and\nmethods, as well as extensions of common core functions/methods.",
            "name": "r-biomformat"
        },
        {
            "description": "Bayesian Latent Variable Analysis. Fit a variety of Bayesian latent\nvariable models, including confirmatory factor analysis, structural\nequation models, and latent growth curve models. References: Merkle &\nRosseel (2018) <doi:10.18637/jss.v085.i04>; Merkle et al. (2021)\n<doi:10.18637/jss.v100.i06>.",
            "name": "r-blavaan"
        },
        {
            "description": "Generalized and Classical Blockmodeling of Valued Networks. This is\nprimarily meant as an implementation of generalized blockmodeling for\nvalued networks.",
            "name": "r-blockmodeling"
        },
        {
            "description": "Clustering Algorithms for Bioconductor. Wraps common clustering\nalgorithms in an easily extended S4 framework. Backends are implemented\nfor hierarchical, k-means and graph-based clustering. Several utilities\nare also provided to compare and evaluate clustering results.",
            "name": "r-bluster"
        },
        {
            "description": "Bridge Sampling for Marginal Likelihoods and Bayes Factors. Provides\nfunctions for estimating marginal likelihoods, Bayes factors, posterior\nmodel probabilities, and normalizing constants in general, via different\nversions of bridge sampling (Meng & Wong, 1996,\n<http://www3.stat.sinica.edu.tw/statistica/j6n4/j6n43/j6n43.htm>).\nGronau, Singmann, & Wagenmakers (2020) <doi:10.18637/jss.v092.i10>.",
            "name": "r-bridgesampling"
        },
        {
            "description": "Bayesian Regression Models using 'Stan'. Fit Bayesian generalized\n(non-)linear multivariate multilevel models using 'Stan' for full\nBayesian inference. A wide range of distributions and link functions are\nsupported, allowing users to fit - among others - linear, robust linear,\ncount data, survival, response times, ordinal, zero-inflated, hurdle,\nand even self-defined mixture models all in a multilevel context.\nFurther modeling options include non-linear and smooth terms, auto-\ncorrelation structures, censored data, meta-analytic standard errors,\nand quite a few more. In addition, all parameters of the response\ndistribution can be predicted in order to perform distributional\nregression. Prior specifications are flexible and explicitly encourage\nusers to apply prior distributions that actually reflect their beliefs.\nModel fit can easily be assessed and compared with posterior predictive\nchecks and leave-one-out cross-validation. References: Burkner (2017)\n<doi:10.18637/jss.v080.i01>; Burkner (2018) <doi:10.32614/RJ-2018-017>;\nCarpenter et al. (2017) <doi:10.18637/jss.v076.i01>.",
            "name": "r-brms"
        },
        {
            "description": "Very Large Numbers in R. Handles very large numbers in R. Real numbers\nare held using their natural logarithms, plus a logical flag indicating\nsign. The package includes a vignette that gives a step-by-step\nintroduction to using S4 methods.",
            "name": "r-brobdingnag"
        },
        {
            "description": "Computer Algebra. Computer algebra via the 'SymPy' library\n(<https://www.sympy.org/>). This makes it possible to solve equations\nsymbolically, find symbolic integrals, symbolic sums and other important\nquantities.",
            "name": "r-caracas"
        },
        {
            "description": "Category Analysis. A collection of tools for performing category (gene\nset enrichment) analysis.",
            "name": "r-category"
        },
        {
            "description": "Convolution-Type Smoothed Quantile Regression. Fast and accurate\nconvolution-type smoothed quantile regression. Implemented using\nBarzilai-Borwein gradient descent with a Huber regression warm start.\nConstruct confidence intervals for regression coefficients using\nmultiplier bootstrap.",
            "name": "r-conquer"
        },
        {
            "description": "Multivariate Dependence with Copulas. Classes (S4) of commonly used\nelliptical, Archimedean, extreme-value and other copula families, as\nwell as their rotations, mixtures and asymmetrizations. Nested\nArchimedean copulas, related tools and special functions. Methods for\ndensity, distribution, random number generation, bivariate dependence\nmeasures, Rosenblatt transform, Kendall distribution function,\nperspective and contour plots. Fitting of copula models with potentially\npartly fixed parameters, including standard errors. Serial independence\ntests, copula specification tests (independence, exchangeability, radial\nsymmetry, extreme-value dependence, goodness-of-fit) and model selection\nbased on cross-validation. Empirical copula, smoothed versions, and non-\nparametric estimators of the Pickands dependence function.",
            "name": "r-copula"
        },
        {
            "description": "Disciplined Convex Optimization. An object-oriented modeling language\nfor disciplined convex programming (DCP) as described in Fu, Narasimhan,\nand Boyd (2020, <doi:10.18637/jss.v094.i14>). It allows the user to\nformulate convex optimization problems in a natural way following\nmathematical convention and DCP rules. The system analyzes the problem,\nverifies its convexity, converts it into a canonical form, and hands it\noff to an appropriate solver to obtain the solution. Interfaces to\nsolvers on CRAN and elsewhere are provided, both commercial and open\nsource.",
            "name": "r-cvxr"
        },
        {
            "description": "A unified framework for working transparently with on-disk and in-memory\narray-like datasets. Wrapping an array-like object (typically an on-disk\nobject) in a DelayedArray object allows one to perform common array\noperations on it without loading the object in memory. In order to\nreduce memory usage and optimize performance, operations on the object\nare either delayed or executed using a block processing mechanism. Note\nthat this also works on in-memory array-like objects like DataFrame\nobjects (typically with Rle columns), Matrix objects, and ordinary\narrays and data frames.",
            "name": "r-delayedarray"
        },
        {
            "description": "Functions that Apply to Rows and Columns of 'DelayedMatrix' Objects. A\nport of the 'matrixStats' API for use with DelayedMatrix objects from\nthe 'DelayedArray' package. High-performing functions operating on rows\nand columns of DelayedMatrix objects, e.g. col / rowMedians(), col /\nrowRanks(), and col / rowSds(). Functions optimized per data type and\nfor subsetted calculations such that both memory usage and processing\ntime is minimized.",
            "name": "r-delayedmatrixstats"
        },
        {
            "description": "Diffusion Map. Implements diffusion map method of data parametrization,\nincluding creation and visualization of diffusion map, clustering with\ndiffusion K-means and regression using adaptive regression model.\nRichards (2009) <doi:10.1088/0004-637X/691/1/32>.",
            "name": "r-diffusionmap"
        },
        {
            "description": "Groupwise Statistics, LSmeans, Linear Estimates, Utilities. Utility\npackage containing: 1) Facilities for working with grouped data: 'do'\nsomething to data stratified 'by' some variables. 2) LSmeans (least-\nsquares means), general linear estimates. 3) Restrict functions to a\nsmaller domain. 4) Miscellaneous other utilities.",
            "name": "r-doby"
        },
        {
            "description": "Fit, Simulate and Diagnose Exponential-Family Models for Networks. An\nintegrated set of tools to analyze and simulate networks based on\nexponential-family random graph models (ERGMs). 'ergm' is a part of the\nStatnet suite of packages for network analysis. See Hunter, Handcock,\nButts, Goodreau, and Morris (2008) <doi:10.18637/jss.v024.i03> and\nKrivitsky, Hunter, Morris, and Klumb (2021) <arXiv:2106.04997>.",
            "name": "r-ergm"
        },
        {
            "description": "Matrix Exponential, Log, 'etc'. Computation of the matrix exponential,\nlogarithm, sqrt, and related quantities.",
            "name": "r-expm"
        },
        {
            "description": "Functional Data Analysis. These functions were developed to support\nfunctional data analysis as described in Ramsay, J. O. and Silverman, B.\nW. (2005) Functional Data Analysis. New York: Springer and in Ramsay, J.\nO., Hooker, Giles, and Graves, Spencer (2009).",
            "name": "r-fda"
        },
        {
            "description": "Fast Gene Set Enrichment Analysis. The package implements an algorithm\nfor fast gene set enrichment analysis. Using the fast algorithm allows\nto make more permutations and get more fine grained p-values, which\nallows to use accurate stantard approaches to multiple hypothesis\ncorrection.",
            "name": "r-fgsea"
        },
        {
            "description": "Generalized Additive Mixed Models using 'mgcv' and 'lme4'. Estimate\ngeneralized additive mixed models via a version of function gamm() from\n'mgcv', using 'lme4' for estimation.",
            "name": "r-gamm4"
        },
        {
            "description": "Geometric Morphometric Analyses of 2D/3D Landmark Data. Read,\nmanipulate, and digitize landmark data, generate shape variables via\nProcrustes analysis for points, curves and surfaces, perform shape\nanalyses, and provide graphical depictions of shapes and patterns of\nshape variation.",
            "name": "r-geomorph"
        },
        {
            "description": "Lasso and Elastic-Net Regularized Generalized Linear Models. Extremely\nefficient procedures for fitting the entire lasso or elastic-net\nregularization path for linear regression, logistic and multinomial\nregression models, Poisson regression and the Cox model. Two recent\nadditions are the multiple-response Gaussian, and the grouped\nmultinomial. The algorithm uses cyclical coordinate descent in a path-\nwise fashion, as described in the paper linked to via the URL below.",
            "name": "r-glmnet"
        },
        {
            "description": "A Package for Graphical Modelling in R. The 'gRbase' package provides\ngraphical modelling features used by e.g. the packages 'gRain', 'gRim'\nand 'gRc'. 'gRbase' implements graph algorithms including (i) maximum\ncardinality search (for marked and unmarked graphs). (ii) moralization,\n(iii) triangulation, (iv) creation of junction tree. 'gRbase'\nfacilitates array operations, 'gRbase' implements functions for testing\nfor conditional independence. 'gRbase' illustrates how hierarchical log-\nlinear models may be implemented and describes concept of graphical meta\ndata. The facilities of the package are documented in the book by\nHojsgaard, Edwards and Lauritzen (2012, <doi:10.1007/978-1-4614-2299-0>)\nand in the paper by Dethlefsen and Hojsgaard, (2005,\n<doi:10.18637/jss.v014.i17>). Please see 'citation(\"gRbase\")' for\ncitation details. NOTICE 'gRbase' requires that the packages graph,\n'Rgraphviz' and 'RBGL' are installed from 'bioconductor'; for\ninstallation instructions please refer to the web page given below.",
            "name": "r-grbase"
        },
        {
            "description": "HDF5 backend for DelayedArray objects. Implements the HDF5Array and\nTENxMatrix classes, 2 convenient and memory-efficient array-like\ncontainers for on-disk representation of HDF5 datasets. HDF5Array is for\ndatasets that use the conventional (i.e. dense) HDF5 representation.\nTENxMatrix is for datasets that use the HDF5-based sparse matrix\nrepresentation from 10x Genomics (e.g. the 1.3 Million Brain Cell\nDataset). Both containers being DelayedArray extensions, they support\nall operations supported by DelayedArray objects. These operations can\nbe either delayed or block-processed.",
            "name": "r-hdf5array"
        },
        {
            "description": "Network Analysis and Visualization. Routines for simple graphs and\nnetwork analysis. It can handle large graphs very well and provides\nfunctions for generating random and regular graphs, graph visualization,\ncentrality methods and much more.",
            "name": "r-igraph"
        },
        {
            "description": "Software Tools to Quantify Structural Importance of Nodes in a Network.\nProvides functionality to compute various node centrality measures on\nnetworks. Included are functions to compute betweenness centrality (by\nutilizing Madduri and Bader's SNAP library), implementations of Burt's\nconstraint and effective network size (ENS) metrics, Borgatti's\nalgorithm to identify key players, and Valente's bridging metric. On\nUnix systems, the betweenness, Key Players, and bridging implementations\nare parallelized with OpenMP, which may run faster on systems which have\nOpenMP configured.",
            "name": "r-influencer"
        },
        {
            "description": "Fast Truncated Singular Value Decomposition and Principal Components\nAnalysis for Large Dense and Sparse Matrices. Fast and memory efficient\nmethods for truncated singular value decomposition and principal\ncomponents analysis of large sparse and dense matrices.",
            "name": "r-irlba"
        },
        {
            "description": "Weighted k-Nearest Neighbors. Weighted k-Nearest Neighbors for\nClassification, Regression and Clustering.",
            "name": "r-kknn"
        },
        {
            "description": "Kernel Smoothing. Kernel smoothers for univariate and multivariate data,\nincluding densities, density derivatives, cumulative distributions,\nclustering, classification, density ridges, significant modal regions,\nand two-sample hypothesis tests. Chacon & Duong (2018)\n<doi:10.1201/9780429485572>.",
            "name": "r-ks"
        },
        {
            "description": "R Implementation of Leiden Clustering Algorithm. Implements the 'Python\nleidenalg' module to be called in R. Enables clustering using the leiden\nalgorithm for partition a graph into communities. See the 'Python'\nrepository for more details: <https://github.com/vtraag/leidenalg> Traag\net al (2018) From Louvain to Leiden: guaranteeing well-connected\ncommunities. <arXiv:1810.08473>.",
            "name": "r-leiden"
        },
        {
            "description": "Linear Group Fixed Effects. Transforms away factors with many levels\nprior to doing an OLS. Useful for estimating linear models with multiple\ngroup fixed effects, and for estimating linear models which uses factors\nwith many levels as pure control variables. See Gaure (2013)\n<doi:10.1016/j.csda.2013.03.024> Includes support for instrumental\nvariables, conditional F statistics for weak instruments, robust and\nmulti-way clustered standard errors, as well as limited mobility bias\ncorrection (Gaure 2014 <doi:10.1002/sta4.68>). WARNING: This package is\nNOT under active development anymore, no further improvements are to be\nexpected, and the package is at risk of being removed from CRAN.",
            "name": "r-lfe"
        },
        {
            "description": "Linear Mixed-Effects Models using 'Eigen' and S4. Fit linear and\ngeneralized linear mixed-effects models. The models and their components\nare represented using S4 classes and methods. The core computational\nalgorithms are implemented using the 'Eigen' C++ library for numerical\nlinear algebra and 'RcppEigen' \"glue\".",
            "name": "r-lme4"
        },
        {
            "description": "Modelling with Sparse and Dense Matrices. Modelling with sparse and\ndense 'Matrix' matrices, using modular prediction and response module\nclasses.",
            "name": "r-matrixmodels"
        },
        {
            "description": "Multinomial Logit Models, with or without Random Effects or\nOverdispersion. Provides estimators for multinomial logit models in\ntheir conditional logit and baseline logit variants, with or without\nrandom effects, with or without overdispersion. Random effects models\nare estimated using the PQL technique (based on a Laplace approximation)\nor the MQL technique (based on a Solomon-Cox approximation). Estimates\nshould be treated with caution if the group sizes are small.",
            "name": "r-mclogit"
        },
        {
            "description": "MCMC Generalised Linear Mixed Models. Fits Multivariate Generalised\nLinear Mixed Models (and related models) using Markov chain Monte Carlo\ntechniques (Hadfield 2010 J. Stat. Soft.).",
            "name": "r-mcmcglmm"
        },
        {
            "description": "Mendelian Randomization Package. Encodes several methods for performing\nMendelian randomization analyses with summarized data. Summarized data\non genetic associations with the exposure and with the outcome can be\nobtained from large consortia. These data can be used for obtaining\ncausal estimates using instrumental variable methods.",
            "name": "r-mendelianrandomization"
        },
        {
            "description": "Meta-Analysis Package for R. A comprehensive collection of functions for\nconducting meta-analyses in R. The package includes functions to\ncalculate various effect sizes or outcome measures, fit equal-, fixed-,\nrandom-, and mixed-effects models to such data, carry out moderator and\nmeta-regression analyses, and create various types of meta-analytical\nplots (e.g., forest, funnel, radial, L'Abbe, Baujat, bubble, and GOSH\nplots). For meta-analyses of binomial and person-time data, the package\nalso provides functions that implement specialized methods, including\nthe Mantel-Haenszel method, Peto's method, and a variety of suitable\ngeneralized linear (mixed-effects) models (i.e., mixed-effects logistic\nand Poisson regression models). Finally, the package provides\nfunctionality for fitting meta-analytic multivariate/multilevel models\nthat account for non-independent sampling errors and/or true effects\n(e.g., due to the inclusion of multiple treatment studies, multiple\nendpoints, or other forms of clustering). Network meta-analyses and\nmeta-analyses accounting for known correlation structures (e.g., due to\nphylogenetic relatedness) can also be conducted. An introduction to the\npackage can be found in Viechtbauer (2010) <doi:10.18637/jss.v036.i03>.",
            "name": "r-metafor"
        },
        {
            "description": "Mixed GAM Computation Vehicle with Automatic Smoothness Estimation.\nGeneralized additive (mixed) models, some of their extensions and other\ngeneralized ridge regression with multiple smoothing parameter\nestimation by (Restricted) Marginal Likelihood, Generalized Cross\nValidation and similar, or using iterated nested Laplace approximation\nfor fully Bayesian inference. See Wood (2017)\n<doi:10.1201/9781315370279> for an overview. Includes a gam() function,\na wide variety of smoothers, 'JAGS' support and distributions beyond the\nexponential family.",
            "name": "r-mgcv"
        },
        {
            "description": "Regression Models for Ordinal Data. Implementation of cumulative link\n(mixed) models also known as ordered regression models, proportional\nodds models, proportional hazards models for grouped survival times and\nordered logit/probit/... models. Estimation is via maximum likelihood\nand mixed models are fitted with the Laplace approximation and adaptive\nGauss-Hermite quadrature. Multiple random effect terms are allowed and\nthey may be nested, crossed or partially nested/crossed. Restrictions of\nsymmetry and equidistance can be imposed on the thresholds (cut-\npoints/intercepts). Standard model methods are available (summary,\nanova, drop-methods, step, confint, predict etc.) in addition to profile\nmethods and slice methods for visualizing the likelihood function and\nchecking convergence.",
            "name": "r-ordinal"
        },
        {
            "description": "Quadratic Programming Solver using the 'OSQP' Library. Provides bindings\nto the 'OSQP' solver. The 'OSQP' solver is a numerical optimization\npackage or solving convex quadratic programs written in 'C' and based on\nthe alternating direction method of multipliers. See <arXiv:1711.08013>\nfor details.",
            "name": "r-osqp"
        },
        {
            "description": "Parametric Bootstrap, Kenward-Roger and Satterthwaite Based Methods for\nTest in Mixed Models. Test in mixed effects models. Attention is on\nmixed effects models as implemented in the 'lme4' package. For linear\nmixed models, this package implements (1) a parametric bootstrap test,\n(2) a Kenward-Roger-typ modification of F-tests for linear mixed effects\nmodels and (3) a Satterthwaite-type modification of F-tests for linear\nmixed effects models. The package also implements a parametric bootstrap\ntest for generalized linear mixed models. The facilities of the package\nare documented in the paper by Halehoh and Hojsgaard, (2012,\n<doi:10.18637/jss.v059.i09>). Please see 'citation(\"pbkrtest\")' for\ncitation details.",
            "name": "r-pbkrtest"
        },
        {
            "description": "Phylogenetic Reconstruction and Analysis. Allows for estimation of\nphylogenetic trees and networks using Maximum Likelihood, Maximum\nParsimony, distance methods and Hadamard conjugation. Offers methods for\ntree comparison, model selection and visualization of phylogenetic\nnetworks as described in Schliep et al. (2017)\n<doi:10.1111/2041-210X.12760>.",
            "name": "r-phangorn"
        },
        {
            "description": "Quantile Regression. Estimation and inference methods for models of\nconditional quantiles: Linear and nonlinear parametric and non-\nparametric (total variation penalized) models for conditional quantiles\nof a univariate response and several methods for handling censored\nsurvival data. Portfolio selection methods based on expected shortfall\nrisk are also now included. See Koenker (2006)\n<doi:10.1017/CBO9780511754098> and Koenker et al. (2017)\n<doi:10.1201/9781315120256>.",
            "name": "r-quantreg"
        },
        {
            "description": "A Fast Implementation of Random Forests. A fast implementation of Random\nForests, particularly suited for high dimensional data. Ensembles of\nclassification, regression, survival and probability prediction trees\nare supported. Data from genome-wide association studies can be analyzed\nefficiently. In addition to data frames, datasets of class 'gwaa.data'\n(R package 'GenABEL') and 'dgCMatrix' (R package 'Matrix') can be\ndirectly analyzed.",
            "name": "r-ranger"
        },
        {
            "description": "'Blaze' is an open-source, high-performance C++ math library for dense\nand sparse arithmetic. With its state-of-the-art Smart Expression\nTemplate implementation 'Blaze' combines the elegance and ease of use of\na domain-specific language with 'HPC'-grade performance, making it one\nof the most intuitive and fastest C++ math libraries available. The\n'Blaze' library offers: - high performance through the integration of\n'BLAS' libraries and manually tuned 'HPC' math kernels - vectorization\nby 'SSE', 'SSE2', 'SSE3', 'SSSE3', 'SSE4', 'AVX', 'AVX2', 'AVX-512',\n'FMA', and 'SVML' - parallel execution by 'OpenMP', C++11 threads and\n'Boost' threads ('Boost' threads are disabled in 'RcppBlaze') - the\nintuitive and easy to use API of a domain specific language - unified\narithmetic with dense and sparse vectors and matrices - thoroughly\ntested matrix and vector arithmetic - completely portable, high quality\nC++ source code. The 'RcppBlaze' package includes the header files from\nthe 'Blaze' library with disabling some functionalities related to link\nto the thread and system libraries which make 'RcppBlaze' be a header-\nonly library. Therefore, users do not need to install 'Blaze' and the\ndependency 'Boost'. 'Blaze' is licensed under the New (Revised) BSD\nlicense, while 'RcppBlaze' (the 'Rcpp' bindings/bridge to 'Blaze') is\nlicensed under the GNU GPL version 2 or later, as is the rest of 'Rcpp'.\nNote that since 'Blaze' has committed to 'C++14' commit to 'C++14' which\ndoes not used by most R users from version 3.0, we will use the version\n2.6 of 'Blaze' which is 'C++98' compatible to support the most compilers\nand system.",
            "name": "r-rcppblaze"
        },
        {
            "description": "'Rcpp' Integration for the 'Eigen' Templated Linear Algebra Library. R\nand 'Eigen' integration using 'Rcpp'. 'Eigen' is a C++ template library\nfor linear algebra: matrices, vectors, numerical solvers and related\nalgorithms. It supports dense and sparse matrices on integer, floating\npoint and complex numbers, decompositions of such matrices, and\nsolutions of linear systems. Its performance on many algorithms is\ncomparable with some of the best implementations based on 'Lapack' and\nlevel-3 'BLAS'. The 'RcppEigen' package includes the header files from\nthe 'Eigen' C++ template library (currently version 3.2.8). Thus users\ndo not need to install 'Eigen' itself in order to use 'RcppEigen'. Since\nversion 3.1.1, 'Eigen' is licensed under the Mozilla Public License\n(version 2); earlier version were licensed under the GNU LGPL version 3\nor later. 'RcppEigen' (the 'Rcpp' bindings/bridge to 'Eigen') is\nlicensed under the GNU GPL version 2 or later, as is the rest of 'Rcpp'.",
            "name": "r-rcppeigen"
        },
        {
            "description": "Rcpp Machine Learning Library Fast machine learning algorithms including\nmatrix factorization and divisive clustering for large sparse and dense\nmatrices.",
            "name": "r-rcppml"
        },
        {
            "description": "Preprocessing Tools to Create Design Matrices. An extensible framework\nto create and preprocess design matrices. Recipes consist of one or more\ndata manipulation and analysis \"steps\". Statistical parameters for the\nsteps can be estimated from an initial data set and then applied to\nother data sets. The resulting design matrices can then be used as\ninputs into statistical or machine learning models.",
            "name": "r-recipes"
        },
        {
            "description": "Interface to 'Python'. Interface to 'Python' modules, classes, and\nfunctions. When calling into 'Python', R data types are automatically\nconverted to their equivalent 'Python' types. When values are returned\nfrom 'Python' to R they are converted back to R types. Compatible with\nall versions of 'Python' >= 2.7.",
            "name": "r-reticulate"
        },
        {
            "description": "Linear Model Evaluation with Randomized Residuals in a Permutation\nProcedure. Linear model calculations are made for many random versions\nof data. Using residual randomization in a permutation procedure, sums\nof squares are calculated over many permutations to generate empirical\nprobability distributions for evaluating model effects. This packaged is\ndescribed by Collyer & Adams (2018) <doi:10.1111/2041-210X.13029>.\nAdditionally, coefficients, statistics, fitted values, and residuals\ngenerated over many permutations can be used for various procedures\nincluding pairwise tests, prediction, classification, and model\ncomparison. This package should provide most tools one could need for\nthe analysis of high-dimensional data, especially in ecology and\nevolutionary biology, but certainly other fields, as well.",
            "name": "r-rrpp"
        },
        {
            "description": "Solvers for Large-Scale Eigenvalue and SVD Problems. R interface to the\n'Spectra' library <https://spectralib.org/> for large-scale eigenvalue\nand SVD problems. It is typically used to compute a few\neigenvalues/vectors of an n by n matrix, e.g., the k largest\neigenvalues, which is usually more efficient than eigen() if k << n.\nThis package provides the 'eigs()' function that does the similar job as\nin 'Matlab', 'Octave', 'Python SciPy' and 'Julia'. It also provides the\n'svds()' function to calculate the largest k singular values and\ncorresponding singular vectors of a real matrix. The matrix to be\ncomputed on can be dense, sparse, or in the form of an operator defined\nby the user.",
            "name": "r-rspectra"
        },
        {
            "description": "Mapping, quantification and variant analysis of sequencing data",
            "name": "r-rsubread"
        },
        {
            "description": "Randomized Singular Value Decomposition. Low-rank matrix decompositions\nare fundamental tools and widely used for data analysis, dimension\nreduction, and data compression. Classically, highly accurate\ndeterministic matrix algorithms are used for this task. However, the\nemergence of large-scale data has severely challenged our computational\nability to analyze big data. The concept of randomness has been\ndemonstrated as an effective strategy to quickly produce approximate\nanswers to familiar problems such as the singular value decomposition\n(SVD). The rsvd package provides several randomized matrix algorithms\nsuch as the randomized singular value decomposition (rsvd), randomized\nprincipal component analysis (rpca), randomized robust principal\ncomponent analysis (rrpca), randomized interpolative decomposition\n(rid), and the randomized CUR decomposition (rcur). In addition several\nplot functions are provided. The methods are discussed in detail by\nErichson et al. (2016) <arXiv:1608.02148>.",
            "name": "r-rsvd"
        },
        {
            "description": "Creating a DelayedMatrix of Scaled and Centered Values. Provides delayed\ncomputation of a matrix of scaled and centered values. The result is\nequivalent to using the scale() function but avoids explicit realization\nof a dense matrix during block processing. This permits greater\nefficiency in common operations, most notably matrix multiplication.",
            "name": "r-scaledmatrix"
        },
        {
            "description": "Single-Cell Analysis Toolkit for Gene Expression Data in R. A collection\nof tools for doing various analyses of single-cell RNA-seq gene\nexpression data, with a focus on quality control and visualization.",
            "name": "r-scater"
        },
        {
            "description": "The scDblFinder package gathers various methods for the detection and\nhandling of doublets/multiplets in single-cell sequencing data (i.e.\nmultiple cells captured within the same droplet or reaction volume). It\nincludes methods formerly found in the scran package, the new fast and\ncomprehensive scDblFinder method, and a reimplementation of the Amulet\ndetection method for single-cell ATAC-seq.",
            "name": "r-scdblfinder"
        },
        {
            "description": "Methods for Single-Cell RNA-Seq Data Analysis. Implements miscellaneous\nfunctions for interpretation of single-cell RNA-seq data. Methods are\nprovided for assignment of cell cycle phase, detection of highly\nvariable and significantly correlated genes, identification of marker\ngenes, and other common tasks in routine single-cell analysis workflows.",
            "name": "r-scran"
        },
        {
            "description": "Variance Stabilizing Transformations for Single Cell UMI Data. A\nnormalization method for single-cell UMI count data using a variance\nstabilizing transformation. The transformation is based on a negative\nbinomial regression model with regularized parameters. As part of the\nsame regression framework, this package also provides functions for\nbatch correction, and data correction. See Hafemeister and Satija 2019\n<doi:10.1101/576827> for more details.",
            "name": "r-sctransform"
        },
        {
            "description": "Single-Cell RNA-Seq Analysis Utilities. Provides basic utility functions\nfor performing single-cell analyses, focusing on simple normalization,\nquality control and data transformations. Also provides some helper\nfunctions to assist development of other packages.",
            "name": "r-scuttle"
        },
        {
            "description": "Tools for Single Cell Genomics. A toolkit for quality control, analysis,\nand exploration of single cell RNA sequencing data. 'Seurat' aims to\nenable users to identify and interpret sources of heterogeneity from\nsingle cell transcriptomic measurements, and to integrate diverse types\nof single cell data. See Satija R, Farrell J, Gennert D, et al (2015)\n<doi:10.1038/nbt.3192>, Macosko E, Basu A, Satija R, et al (2015)\n<doi:10.1016/j.cell.2015.05.002>, and Stuart T, Butler A, et al (2019)\n<doi:10.1016/j.cell.2019.05.031> for more details.",
            "name": "r-seurat"
        },
        {
            "description": "Data Structures for Single Cell Data. Defines S4 classes for single-cell\ngenomic data and associated information, such as dimensionality\nreduction embeddings, nearest-neighbor graphs, and spatially-resolved\ncoordinates. Provides data access methods and R-native hooks to ensure\nthe Seurat object is familiar to other R users. See Satija R, Farrell J,\nGennert D, et al (2015) <doi:10.1038/nbt.3192>, Macosko E, Basu A,\nSatija R, et al (2015) <doi:10.1016/j.cell.2015.05.002>, and Stuart T,\nButler A, et al (2019) <doi:10.1016/j.cell.2019.05.031> for more\ndetails.",
            "name": "r-seuratobject"
        },
        {
            "description": "Analysis of Single-Cell Chromatin Data. A framework for the analysis and\nexploration of single-cell chromatin data. The 'Signac' package contains\nfunctions for quantifying single-cell chromatin data, computing per-cell\nquality control metrics, dimension reduction and normalization,\nvisualization, and DNA sequence motif analysis. Reference: Stuart et al.\n(2021) <doi:10.1038/s41592-021-01282-5>.",
            "name": "r-signac"
        },
        {
            "description": "SnpMatrix and XSnpMatrix classes and methods. Classes and statistical\nmethods for large SNP association studies. This extends the earlier\nsnpMatrix package, allowing for uncertainty in genotypes.",
            "name": "r-snpstats"
        },
        {
            "description": "Summary Statistics for Rows and Columns of Sparse Matrices. High\nperformance functions for row and column operations on sparse matrices.\nFor example: col / rowMeans2, col / rowMedians, col / rowVars etc.\nCurrently, the optimizations are limited to data in the column sparse\nformat. This package is inspired by the matrixStats package by Henrik\nBengtsson.",
            "name": "r-sparsematrixstats"
        },
        {
            "description": "Spatial Regression Analysis. A collection of all the estimation\nfunctions for spatial cross-sectional models (on lattice/areal data\nusing spatial weights matrices) contained up to now in 'spdep', 'sphet'\nand 'spse'. These model fitting functions include maximum likelihood\nmethods for cross-sectional models proposed by 'Cliff' and 'Ord' (1973,\nISBN:0850860369) and (1981, ISBN:0850860814), fitting methods initially\ndescribed by 'Ord' (1975) <doi:10.1080/01621459.1975.10480272>. The\nmodels are further described by 'Anselin' (1988)\n<doi:10.1007/978-94-015-7799-1>. Spatial two stage least squares and\nspatial general method of moment models initially proposed by 'Kelejian'\nand 'Prucha' (1998) <doi:10.1023/A:1007707430416> and (1999)\n<doi:10.1111/1468-2354.00027> are provided. Impact methods and MCMC\nfitting methods proposed by 'LeSage' and 'Pace' (2009)\n<doi:10.1201/9781420064254> are implemented for the family of cross-\nsectional spatial regression models. Methods for fitting the log\ndeterminant term in maximum likelihood and MCMC fitting are compared by\n'Bivand et al.' (2013) <doi:10.1111/gean.12008>, and model fitting\nmethods by 'Bivand' and 'Piras' (2015) <doi:10.18637/jss.v063.i18>; both\nof these articles include extensive lists of references. 'spatialreg' >=\n1.1-* correspond to 'spdep' >= 1.1-1, in which the model fitting\nfunctions are deprecated and pass through to 'spatialreg', but will mask\nthose in 'spatialreg'. From versions 1.2-*, the functions will be made\ndefunct in 'spdep'.",
            "name": "r-spatialreg"
        },
        {
            "description": "Spatial Point Pattern Analysis, Model-Fitting, Simulation, Tests.\nComprehensive open-source toolbox for analysing Spatial Point Patterns.\nFocused mainly on two-dimensional point patterns, including\nmultitype/marked points, in any spatial region. Also supports three-\ndimensional point patterns, space-time point patterns in any number of\ndimensions, point patterns on a linear network, and patterns of other\ngeometrical objects. Supports spatial covariate data such as pixel\nimages. Contains over 2000 functions for plotting spatial data,\nexploratory data analysis, model-fitting, simulation, spatial sampling,\nmodel diagnostics, and formal inference. Data types include point\npatterns, line segment patterns, spatial windows, pixel images,\ntessellations, and linear networks. Exploratory methods include quadrat\ncounts, K-functions and their simulation envelopes, nearest neighbour\ndistance and empty space statistics, Fry plots, pair correlation\nfunction, kernel smoothed intensity, relative risk estimation with\ncross-validated bandwidth selection, mark correlation functions,\nsegregation indices, mark dependence diagnostics, and kernel estimates\nof covariate effects. Formal hypothesis tests of random pattern (chi-\nsquared, Kolmogorov-Smirnov, Monte Carlo, Diggle-Cressie-Loosmore-Ford,\nDao-Genton, two-stage Monte Carlo) and tests for covariate effects (Cox-\nBerman-Waller-Lawson, Kolmogorov-Smirnov, ANOVA) are also supported.\nParametric models can be fitted to point pattern data using the\nfunctions ppm(), kppm(), slrm(), dppm() similar to glm(). Types of\nmodels include Poisson, Gibbs and Cox point processes, Neyman-Scott\ncluster processes, and determinantal point processes. Models may involve\ndependence on covariates, inter-point interaction, cluster formation and\ndependence on marks. Models are fitted by maximum likelihood, logistic\nregression, minimum contrast, and composite likelihood methods. A model\ncan be fitted to a list of point patterns (replicated point pattern\ndata) using the function mppm(). The model can include random effects\nand fixed effects depending on the experimental design, in addition to\nall the features listed above. Fitted point process models can be\nsimulated, automatically. Formal hypothesis tests of a fitted model are\nsupported (likelihood ratio test, analysis of deviance, Monte Carlo\ntests) along with basic tools for model selection (stepwise(), AIC())\nand variable selection (sdr). Tools for validating the fitted model\ninclude simulation envelopes, residuals, residual plots and Q-Q plots,\nleverage and influence diagnostics, partial residuals, and added\nvariable plots.",
            "name": "r-spatstat"
        },
        {
            "description": "Core Functionality of the 'spatstat' Family. Functionality for data\nanalysis and modelling of spatial data, mainly spatial point patterns,\nin the 'spatstat' family of packages. (Excludes analysis of spatial data\non a linear network, which is covered by the separate package\n'spatstat.linnet'.) Exploratory methods include quadrat counts,\nK-functions and their simulation envelopes, nearest neighbour distance\nand empty space statistics, Fry plots, pair correlation function, kernel\nsmoothed intensity, relative risk estimation with cross-validated\nbandwidth selection, mark correlation functions, segregation indices,\nmark dependence diagnostics, and kernel estimates of covariate effects.\nFormal hypothesis tests of random pattern (chi-squared, Kolmogorov-\nSmirnov, Monte Carlo, Diggle-Cressie-Loosmore-Ford, Dao-Genton, two-\nstage Monte Carlo) and tests for covariate effects (Cox-Berman-Waller-\nLawson, Kolmogorov-Smirnov, ANOVA) are also supported. Parametric models\ncan be fitted to point pattern data using the functions ppm(), kppm(),\nslrm(), dppm() similar to glm(). Types of models include Poisson, Gibbs\nand Cox point processes, Neyman-Scott cluster processes, and\ndeterminantal point processes. Models may involve dependence on\ncovariates, inter-point interaction, cluster formation and dependence on\nmarks. Models are fitted by maximum likelihood, logistic regression,\nminimum contrast, and composite likelihood methods. A model can be\nfitted to a list of point patterns (replicated point pattern data) using\nthe function mppm(). The model can include random effects and fixed\neffects depending on the experimental design, in addition to all the\nfeatures listed above. Fitted point process models can be simulated,\nautomatically. Formal hypothesis tests of a fitted model are supported\n(likelihood ratio test, analysis of deviance, Monte Carlo tests) along\nwith basic tools for model selection (stepwise(), AIC()) and variable\nselection (sdr). Tools for validating the fitted model include\nsimulation envelopes, residuals, residual plots and Q-Q plots, leverage\nand influence diagnostics, partial residuals, and added variable plots.",
            "name": "r-spatstat-core"
        },
        {
            "description": "Datasets for 'spatstat' Family. Contains all the datasets for the\n'spatstat' family of packages.",
            "name": "r-spatstat-data"
        },
        {
            "description": "Exploratory Data Analysis for the 'spatstat' Family. Functionality for\nexploratory data analysis and nonparametric analysis of spatial data,\nmainly spatial point patterns, in the 'spatstat' family of packages.\n(Excludes analysis of spatial data on a linear network, which is covered\nby the separate package 'spatstat.linnet'.) Methods include quadrat\ncounts, K-functions and their simulation envelopes, nearest neighbour\ndistance and empty space statistics, Fry plots, pair correlation\nfunction, kernel smoothed intensity, relative risk estimation with\ncross-validated bandwidth selection, mark correlation functions,\nsegregation indices, mark dependence diagnostics, and kernel estimates\nof covariate effects. Formal hypothesis tests of random pattern (chi-\nsquared, Kolmogorov-Smirnov, Monte Carlo, Diggle-Cressie-Loosmore-Ford,\nDao-Genton, two-stage Monte Carlo) and tests for covariate effects (Cox-\nBerman-Waller-Lawson, Kolmogorov-Smirnov, ANOVA) are also supported.",
            "name": "r-spatstat-explore"
        },
        {
            "description": "Linear Networks Functionality of the 'spatstat' Family. Defines types of\nspatial data on a linear network and provides functionality for\ngeometrical operations, data analysis and modelling of data on a linear\nnetwork, in the 'spatstat' family of packages. Contains definitions and\nsupport for linear networks, including creation of networks, geometrical\nmeasurements, topological connectivity, geometrical operations such as\ninserting and deleting vertices, intersecting a network with another\nobject, and interactive editing of networks. Data types defined on a\nnetwork include point patterns, pixel images, functions, and\ntessellations. Exploratory methods include kernel estimation of\nintensity on a network, K-functions and pair correlation functions on a\nnetwork, simulation envelopes, nearest neighbour distance and empty\nspace distance, relative risk estimation with cross-validated bandwidth\nselection. Formal hypothesis tests of random pattern (chi-squared,\nKolmogorov-Smirnov, Monte Carlo, Diggle-Cressie-Loosmore-Ford, Dao-\nGenton, two-stage Monte Carlo) and tests for covariate effects (Cox-\nBerman-Waller-Lawson, Kolmogorov-Smirnov, ANOVA) are also supported.\nParametric models can be fitted to point pattern data using the function\nlppm() similar to glm(). Only Poisson models are implemented so far.\nModels may involve dependence on covariates and dependence on marks.\nModels are fitted by maximum likelihood. Fitted point process models can\nbe simulated, automatically. Formal hypothesis tests of a fitted model\nare supported (likelihood ratio test, analysis of deviance, Monte Carlo\ntests) along with basic tools for model selection (stepwise(), AIC())\nand variable selection (sdr). Tools for validating the fitted model\ninclude simulation envelopes, residuals, residual plots and Q-Q plots,\nleverage and influence diagnostics, partial residuals, and added\nvariable plots. Random point patterns on a network can be generated\nusing a variety of models.",
            "name": "r-spatstat-linnet"
        },
        {
            "description": "Parametric Statistical Modelling and Inference for the 'spatstat'\nFamily. Functionality for parametric statistical modelling and inference\nfor spatial data, mainly spatial point patterns, in the 'spatstat'\nfamily of packages. (Excludes analysis of spatial data on a linear\nnetwork, which is covered by the separate package 'spatstat.linnet'.)\nSupports parametric modelling, formal statistical inference, and model\nvalidation. Parametric models include Poisson point processes, Cox point\nprocesses, Neyman-Scott cluster processes, Gibbs point processes and\ndeterminantal point processes. Models can be fitted to data using\nmaximum likelihood, maximum pseudolikelihood, maximum composite\nlikelihood and the method of minimum contrast. Fitted models can be\nsimulated and predicted. Formal inference includes hypothesis tests\n(quadrat counting tests, Cressie-Read tests, Clark-Evans test, Berman\ntest, Diggle-Cressie-Loosmore-Ford test, scan test, studentised\npermutation test, segregation test, ANOVA tests of fitted models,\nadjusted composite likelihood ratio test, envelope tests, Dao-Genton\ntest, balanced independent two-stage test), confidence intervals for\nparameters, and prediction intervals for point counts. Model validation\ntechniques include leverage, influence, partial residuals, added\nvariable plots, diagnostic plots, pseudoscore residual plots, model\ncompensators and Q-Q plots.",
            "name": "r-spatstat-model"
        },
        {
            "description": "Sparse Three-Dimensional Arrays and Linear Algebra Utilities. Defines\nsparse three-dimensional arrays and supports standard operations on\nthem. The package also includes utility functions for matrix\ncalculations that are common in statistics, such as quadratic forms.",
            "name": "r-spatstat-sparse"
        },
        {
            "description": "Spatial Dependence: Weighting Schemes, Statistics. A collection of\nfunctions to create spatial weights matrix objects from polygon\n'contiguities', from point patterns by distance and tessellations, for\nsummarizing these objects, and for permitting their use in spatial data\nanalysis, including regional aggregation by minimum spanning tree; a\ncollection of tests for spatial 'autocorrelation', including global\n'Morans I' and 'Gearys C' proposed by 'Cliff' and 'Ord' (1973, ISBN:\n0850860369) and (1981, ISBN: 0850860814), 'Hubert/Mantel' general cross\nproduct statistic, Empirical Bayes estimates and 'Assuncao/Reis' (1999)\n<doi:10.1002/(SICI)1097-0258(19990830)18:16%3C2147::AID-SIM179%3E3.0.CO",
            "name": "r-spdep"
        },
        {
            "description": "Fitting Linear and Generalized Linear Models to Large Data Sets. Fitting\nlinear models and generalized linear models to large data sets by\nupdating algorithms.",
            "name": "r-speedglm"
        },
        {
            "description": "SummarizedExperiment container. The SummarizedExperiment container\ncontains one or more assays, each represented by a matrix-like object of\nnumeric or other mode. The rows typically represent genomic ranges of\ninterest and the columns represent samples.",
            "name": "r-summarizedexperiment"
        },
        {
            "description": "Analysis of Complex Survey Samples. Summary statistics, two-sample\ntests, rank tests, generalised linear models, cumulative link models,\nCox models, loglinear models, and general maximum pseudolikelihood\nestimation for multistage stratified, cluster-sampled, unequally\nweighted survey samples. Variances by Taylor series linearisation or\nreplicate weights. Post-stratification, calibration, and raking. Two-\nphase subsampling designs. Graphics. PPS sampling without replacement.\nPrincipal components, factor analysis.",
            "name": "r-survey"
        },
        {
            "description": "Survival Analysis. Contains the core survival analysis routines,\nincluding definition of Surv objects, Kaplan-Meier and Aalen-Johansen\n(multi-state) curves, Cox models, and parametric accelerated failure\ntime models.",
            "name": "r-survival"
        },
        {
            "description": "Optimal Thresholding Fisher's P-Value Combination Method. We provide the\ncumulative distribution function (CDF), quantile, and statistical power\ncalculator for a collection of thresholding Fisher's p-value combination\nmethods, including Fisher's p-value combination method, truncated\nproduct method and, in particular, soft-thresholding Fisher's p-value\ncombination method which is proven to be optimal in some context of\nsignal detection. The p-value calculator for the omnibus version of\nthese tests are also included. For reference, please see Hong Zhang and\nZheyang Wu. \"TFisher Tests: Optimal and Adaptive Thresholding for\nCombining p-Values\", submitted.",
            "name": "r-tfisher"
        },
        {
            "description": "Interactive 3D Scatter Plots, Networks and Globes. Create interactive 3D\nscatter plots, network plots, and globes using the 'three.js'\nvisualization library (\"https://threejs.org/\").",
            "name": "r-threejs"
        },
        {
            "description": "Transcript Quantification Import with Automatic Metadata Transcript\nquantification import from Salmon and alevin with automatic attachment\nof transcript ranges and release information, and other associated\nmetadata. De novo transcriptomes can be linked to the appropriate\nsources with linkedTxomes and shared for computational reproducibility.",
            "name": "r-tximeta"
        },
        {
            "description": "The Uniform Manifold Approximation and Projection (UMAP) Method for\nDimensionality Reduction. An implementation of the Uniform Manifold\nApproximation and Projection dimensionality reduction by McInnes et al.\n(2018) <arXiv:1802.03426>. It also provides means to transform new data\nand to carry out supervised dimensionality reduction. An implementation\nof the related LargeVis method of Tang et al. (2016) <arXiv:1602.00370>\nis also provided. This is a complete re-implementation in R (and C++,\nvia the 'Rcpp' package): no Python installation is required. See the\nuwot website (<https://github.com/jlmelville/uwot>) for more\ndocumentation and examples.",
            "name": "r-uwot"
        },
        {
            "description": "Extreme Gradient Boosting. Extreme Gradient Boosting, which is an\nefficient implementation of gradient boosting framework. This package is\nits R interface. The package includes efficient linear model solver and\ntree learning algorithms. The package can automatically do parallel\ncomputation on a single machine which could be more than 10 times faster\nthan existing gradient boosting packages. It supports various objective\nfunctions, including regression, classification and ranking. The package\nis made to be extensible, so that users are also allowed to define their\nown objectives easily.",
            "name": "r-xgboost"
        }
    ],
    "description": "Sparse and Dense Matrix Classes and Methods. A rich hierarchy of matrix\nclasses, including triangular, symmetric, and diagonal matrices, both\ndense and sparse and with pattern, logical and numeric entries. Numerous\nmethods for and operations on these matrices, using 'LAPACK' and\n'SuiteSparse' libraries.\n",
    "homepage": "https://cloud.r-project.org/package=Matrix",
    "latest_version": "1.7-0",
    "maintainers": [],
    "name": "r-matrix",
    "patches": [],
    "resources": [],
    "variants": [
        {
            "default": "generic",
            "description": "Build systems supported by the package",
            "name": "build_system"
        }
    ],
    "versions": [
        {
            "name": "1.7-0",
            "sha256": "fb97bba0df370222eb4f7e2da2e94dd01053b5e054b1c51829ff9a6efc08ad37"
        },
        {
            "name": "1.5-4",
            "sha256": "15ceb61993d61b442068104abb46e6d91b5a1179c01eeb64563b853abab66f06"
        },
        {
            "name": "1.5-1",
            "sha256": "557dba0358172d67dc63eb5db90841915bb5ce1528f941a8005ae808d635575d"
        },
        {
            "name": "1.4-1",
            "sha256": "42b24f1d1e94482b0ff0ef1292e2df29f69694bdbee47b3d6bfeec46fafb2f7e"
        },
        {
            "name": "1.4-0",
            "sha256": "c2b463702e4051b621f5e2b091a33f883f1caa97703d65f7a52b78caf81206f6"
        },
        {
            "name": "1.3-4",
            "sha256": "ab42179d44545e99bbdf44bb6d04cab051dd2aba552b1f6edd51ed71b55f6c39"
        },
        {
            "name": "1.3-3",
            "sha256": "f77ec8de43ae7bfa19dfdc7e76bfefbb21b3223dbc174423fcde70b44cf36a3b"
        },
        {
            "name": "1.3-2",
            "sha256": "950ba5d91018e711fd2743b3486a50dc47ae9c271389fce587792f0a9aab9531"
        },
        {
            "name": "1.2-17",
            "sha256": "db43e6f0196fd5dfd05a7e88cac193877352c60d771d4ec8772763e645723fcc"
        },
        {
            "name": "1.2-14",
            "sha256": "49a6403547b66675cb44c1afb04bb87130c054510cb2b94971435a826ab41396"
        },
        {
            "name": "1.2-11",
            "sha256": "ba8cd6565612552fe397e909721817b6cc0604a91299d56d118208006888dc0b"
        },
        {
            "name": "1.2-8",
            "sha256": "3cd2a187c45fc18a0766dc148b7f83dbf6f2163c256e887c41cbaa7c9a20dbb7"
        },
        {
            "name": "1.2-6",
            "sha256": "4b49b639b7bf612fa3d1c1b1c68125ec7859c8cdadae0c13f499f24099fd5f20"
        }
    ],
    "versions_deprecated": []
}