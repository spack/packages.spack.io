{
    "aliases": [],
    "build_system": "RPackage",
    "conflicts": [],
    "dependencies": [
        {
            "description": "R is 'GNU S', a freely available language and environment for\nstatistical computing and graphics which provides a wide variety of\nstatistical and graphical techniques: linear and nonlinear modelling,\nstatistical tests, time series analysis, classification, clustering,\netc. Please consult the R project homepage for further information.",
            "name": "r"
        }
    ],
    "dependent_to": [
        {
            "description": "The R Package Ada for Stochastic Boosting. Performs discrete, real, and\ngentle boost under both exponential and logistic loss on a given data\nset. The package ada provides a straightforward, well-documented, and\nbroad boosting routine for classification, ideally suited for small to\nmoderate-sized data sets.",
            "name": "r-ada"
        },
        {
            "description": "Applies Multiclass AdaBoost.M1, SAMME and Bagging. It implements Freund\nand Schapire's Adaboost.M1 algorithm and Breiman's Bagging algorithm\nusing classification trees as individual classifiers. Once these\nclassifiers have been trained, they can be used to predict on new data.\nAlso, cross validation estimation of the error can be done. Since\nversion 2.0 the function margins() is available to calculate the margins\nfor these classifiers. Also a higher flexibility is achieved giving\naccess to the rpart.control() argument of 'rpart'. Four important new\nfeatures were introduced on version 3.0, AdaBoost-SAMME (Zhu et al.,\n2009) is implemented and a new function errorevol() shows the error of\nthe ensembles as a function of the number of iterations. In addition,\nthe ensembles can be pruned using the option 'newmfinal' in the\npredict.bagging() and predict.boosting() functions and the posterior\nprobability of each class for observations can be obtained. Version 3.1\nmodifies the relative importance measure to take into account the gain\nof the Gini index given by a variable in each tree and the weights of\nthese trees. Version 4.0 includes the margin-based ordered aggregation\nfor Bagging pruning (Guo and Boukir, 2013) and a function to auto prune\nthe 'rpart' tree. Moreover, three new plots are also available\nimportanceplot(), plot.errorevol() and plot.margins(). Version 4.1\nallows to predict on unlabeled data. Version 4.2 includes the parallel\ncomputation option for some of the functions.",
            "name": "r-adabag"
        },
        {
            "description": "Multivariate Statistical Analysis in Chemometrics. R companion to the\nbook \"Introduction to Multivariate Statistical Analysis in Chemometrics\"\nwritten by K. Varmuza and P. Filzmoser (2009).",
            "name": "r-chemometrics"
        },
        {
            "description": "Harrell Miscellaneous. Contains many functions useful for data analysis,\nhigh-level graphics, utility operations, functions for computing sample\nsize and power, importing and annotating datasets, imputing missing\nvalues, advanced table making, variable clustering, character string\nmanipulation, conversion of R objects to LaTeX and html code, and\nrecoding variables.",
            "name": "r-hmisc"
        },
        {
            "description": "Improved Predictors. Improved predictive models by indirect\nclassification and bagging for classification, regression and survival\nproblems as well as resampling based estimators of prediction error.",
            "name": "r-ipred"
        },
        {
            "description": "Multivariate Imputation by Chained Equations. Multiple imputation using\nFully Conditional Specification (FCS) implemented by the MICE algorithm\nas described in Van Buuren and Groothuis-Oudshoorn (2011)\n<doi:10.18637/jss.v045.i03>. Each variable has its own imputation model.\nBuilt-in imputation models are provided for continuous data (predictive\nmean matching, normal), binary data (logistic regression), unordered\ncategorical data (polytomous logistic regression) and ordered\ncategorical data (proportional odds). MICE can also impute continuous\ntwo-level data (normal model, pan, second-level variables). Passive\nimputation can be used to maintain consistency between variables.\nVarious diagnostic plots are available to inspect the quality of the\nimputations.",
            "name": "r-mice"
        },
        {
            "description": "Uniform interfaces to R machine learning procedures for data in\nBioconductor containers. This package provides uniform interfaces to\nmachine learning code for data in R and Bioconductor containers.",
            "name": "r-mlinterfaces"
        },
        {
            "description": "A Toolkit for Recursive Partytioning. A toolkit with infrastructure for\nrepresenting, summarizing, and visualizing tree-structured regression\nand classification models. This unified infrastructure can be used for\nreading/coercing tree models from different sources ('rpart', 'RWeka',\n'PMML') yielding objects that share functionality for\nprint()/plot()/predict() methods. Furthermore, new and improved\nreimplementations of conditional inference trees (ctree()) and model-\nbased recursive partitioning (mob()) from the 'party' package are\nprovided based on the new infrastructure. A description of this package\nwas published by Hothorn and Zeileis (2015)\n<https://jmlr.org/papers/v16/hothorn15a.html>.",
            "name": "r-partykit"
        },
        {
            "description": "Data Mining Classification and Regression Methods. Facilitates the use\nof data mining algorithms in classification and regression (including\ntime series forecasting) tasks by presenting a short and coherent set of\nfunctions. Versions: 1.4.6 / 1.4.5 / 1.4.4 new automated machine\nlearning (AutoML) and ensembles, via improved fit(), mining() and\nmparheuristic() functions, and new categorical preprocessing, via\nimproved delevels() function; 1.4.3 new metrics (e.g., macro precision,\nexplained variance), new \"lssvm\" model and improved mparheuristic()\nfunction; 1.4.2 new \"NMAE\" metric, \"xgboost\" and \"cv.glmnet\" models (16\nclassification and 18 regression models); 1.4.1 new tutorial and more\nrobust version; 1.4 - new classification and regression models, with a\ntotal of 14 classification and 15 regression methods, including:\nDecision Trees, Neural Networks, Support Vector Machines, Random\nForests, Bagging and Boosting; 1.3 and 1.3.1 - new classification and\nregression metrics; 1.2 - new input importance methods via improved\nImportance() function; 1.0 - first version.",
            "name": "r-rminer"
        },
        {
            "description": "Regression Modeling Strategies. Regression modeling, testing,\nestimation, validation, graphics, prediction, and typesetting by storing\nenhanced model design attributes in the fit. 'rms' is a collection of\nfunctions that assist with and streamline modeling. It also contains\nfunctions for binary and ordinal logistic regression models, ordinal\nmodels for continuous Y with a variety of distribution families, and the\nBuckley-James multiple regression model for right-censored responses,\nand implements penalized maximum likelihood estimation for logistic and\nordinary linear models. 'rms' works with almost any regression model,\nbut it was especially written to work with binary or ordinal regression\nmodels, Cox regression, accelerated failure time models, ordinary linear\nmodels, the Buckley-James model, generalized least squares for serially\nor spatially correlated observations, generalized linear models, and\nquantile regression.",
            "name": "r-rms"
        },
        {
            "description": "Plot 'rpart' Models: An Enhanced Version of 'plot.rpart'. Plot 'rpart'\nmodels. Extends plot.rpart() and text.rpart() in the 'rpart' package.",
            "name": "r-rpart-plot"
        },
        {
            "description": "Spatial Point Pattern Analysis, Model-Fitting, Simulation, Tests.\nComprehensive open-source toolbox for analysing Spatial Point Patterns.\nFocused mainly on two-dimensional point patterns, including\nmultitype/marked points, in any spatial region. Also supports three-\ndimensional point patterns, space-time point patterns in any number of\ndimensions, point patterns on a linear network, and patterns of other\ngeometrical objects. Supports spatial covariate data such as pixel\nimages. Contains over 2000 functions for plotting spatial data,\nexploratory data analysis, model-fitting, simulation, spatial sampling,\nmodel diagnostics, and formal inference. Data types include point\npatterns, line segment patterns, spatial windows, pixel images,\ntessellations, and linear networks. Exploratory methods include quadrat\ncounts, K-functions and their simulation envelopes, nearest neighbour\ndistance and empty space statistics, Fry plots, pair correlation\nfunction, kernel smoothed intensity, relative risk estimation with\ncross-validated bandwidth selection, mark correlation functions,\nsegregation indices, mark dependence diagnostics, and kernel estimates\nof covariate effects. Formal hypothesis tests of random pattern (chi-\nsquared, Kolmogorov-Smirnov, Monte Carlo, Diggle-Cressie-Loosmore-Ford,\nDao-Genton, two-stage Monte Carlo) and tests for covariate effects (Cox-\nBerman-Waller-Lawson, Kolmogorov-Smirnov, ANOVA) are also supported.\nParametric models can be fitted to point pattern data using the\nfunctions ppm(), kppm(), slrm(), dppm() similar to glm(). Types of\nmodels include Poisson, Gibbs and Cox point processes, Neyman-Scott\ncluster processes, and determinantal point processes. Models may involve\ndependence on covariates, inter-point interaction, cluster formation and\ndependence on marks. Models are fitted by maximum likelihood, logistic\nregression, minimum contrast, and composite likelihood methods. A model\ncan be fitted to a list of point patterns (replicated point pattern\ndata) using the function mppm(). The model can include random effects\nand fixed effects depending on the experimental design, in addition to\nall the features listed above. Fitted point process models can be\nsimulated, automatically. Formal hypothesis tests of a fitted model are\nsupported (likelihood ratio test, analysis of deviance, Monte Carlo\ntests) along with basic tools for model selection (stepwise(), AIC())\nand variable selection (sdr). Tools for validating the fitted model\ninclude simulation envelopes, residuals, residual plots and Q-Q plots,\nleverage and influence diagnostics, partial residuals, and added\nvariable plots.",
            "name": "r-spatstat"
        },
        {
            "description": "Core Functionality of the 'spatstat' Family. Functionality for data\nanalysis and modelling of spatial data, mainly spatial point patterns,\nin the 'spatstat' family of packages. (Excludes analysis of spatial data\non a linear network, which is covered by the separate package\n'spatstat.linnet'.) Exploratory methods include quadrat counts,\nK-functions and their simulation envelopes, nearest neighbour distance\nand empty space statistics, Fry plots, pair correlation function, kernel\nsmoothed intensity, relative risk estimation with cross-validated\nbandwidth selection, mark correlation functions, segregation indices,\nmark dependence diagnostics, and kernel estimates of covariate effects.\nFormal hypothesis tests of random pattern (chi-squared, Kolmogorov-\nSmirnov, Monte Carlo, Diggle-Cressie-Loosmore-Ford, Dao-Genton, two-\nstage Monte Carlo) and tests for covariate effects (Cox-Berman-Waller-\nLawson, Kolmogorov-Smirnov, ANOVA) are also supported. Parametric models\ncan be fitted to point pattern data using the functions ppm(), kppm(),\nslrm(), dppm() similar to glm(). Types of models include Poisson, Gibbs\nand Cox point processes, Neyman-Scott cluster processes, and\ndeterminantal point processes. Models may involve dependence on\ncovariates, inter-point interaction, cluster formation and dependence on\nmarks. Models are fitted by maximum likelihood, logistic regression,\nminimum contrast, and composite likelihood methods. A model can be\nfitted to a list of point patterns (replicated point pattern data) using\nthe function mppm(). The model can include random effects and fixed\neffects depending on the experimental design, in addition to all the\nfeatures listed above. Fitted point process models can be simulated,\nautomatically. Formal hypothesis tests of a fitted model are supported\n(likelihood ratio test, analysis of deviance, Monte Carlo tests) along\nwith basic tools for model selection (stepwise(), AIC()) and variable\nselection (sdr). Tools for validating the fitted model include\nsimulation envelopes, residuals, residual plots and Q-Q plots, leverage\nand influence diagnostics, partial residuals, and added variable plots.",
            "name": "r-spatstat-core"
        },
        {
            "description": "Parametric Statistical Modelling and Inference for the 'spatstat'\nFamily. Functionality for parametric statistical modelling and inference\nfor spatial data, mainly spatial point patterns, in the 'spatstat'\nfamily of packages. (Excludes analysis of spatial data on a linear\nnetwork, which is covered by the separate package 'spatstat.linnet'.)\nSupports parametric modelling, formal statistical inference, and model\nvalidation. Parametric models include Poisson point processes, Cox point\nprocesses, Neyman-Scott cluster processes, Gibbs point processes and\ndeterminantal point processes. Models can be fitted to data using\nmaximum likelihood, maximum pseudolikelihood, maximum composite\nlikelihood and the method of minimum contrast. Fitted models can be\nsimulated and predicted. Formal inference includes hypothesis tests\n(quadrat counting tests, Cressie-Read tests, Clark-Evans test, Berman\ntest, Diggle-Cressie-Loosmore-Ford test, scan test, studentised\npermutation test, segregation test, ANOVA tests of fitted models,\nadjusted composite likelihood ratio test, envelope tests, Dao-Genton\ntest, balanced independent two-stage test), confidence intervals for\nparameters, and prediction intervals for point counts. Model validation\ntechniques include leverage, influence, partial residuals, added\nvariable plots, diagnostic plots, pseudoscore residual plots, model\ncompensators and Q-Q plots.",
            "name": "r-spatstat-model"
        }
    ],
    "description": "Recursive Partitioning and Regression Trees. Recursive partitioning for\nclassification, regression and survival trees. An implementation of most\nof the functionality of the 1984 book by Breiman, Friedman, Olshen and\nStone.\n",
    "homepage": "https://cloud.r-project.org/package=rpart",
    "latest_version": "4.1.23",
    "maintainers": [],
    "name": "r-rpart",
    "patches": [],
    "resources": [],
    "variants": [
        {
            "default": "generic",
            "description": "Build systems supported by the package",
            "name": "build_system"
        }
    ],
    "versions": [
        {
            "name": "4.1.23",
            "sha256": "f9b89aed6aa6cea656a2dcb271574e969ce2b1c98beb07bd91e17339f6daabaf"
        },
        {
            "name": "4.1.19",
            "sha256": "fe723ed0b5583fae8b40e6fecc29b357229cb11f2339b02a4e4f812926249565"
        },
        {
            "name": "4.1.16",
            "sha256": "27ec75258a5a3459ad999f5f36760ead974930744249605bf8465f234f31425c"
        },
        {
            "name": "4.1-15",
            "sha256": "2b8ebe0e9e11592debff893f93f5a44a6765abd0bd956b0eb1f70e9394cfae5c"
        },
        {
            "name": "4.1-13",
            "sha256": "8e11a6552224e0fbe23a85aba95acd21a0889a3fe48277f3d345de3147c7494c"
        },
        {
            "name": "4.1-11",
            "sha256": "38ab80959f59bcdd2c4c72860e8dd0deab0307668cbbf24f96014d7a2496ad98"
        },
        {
            "name": "4.1-10",
            "sha256": "c5ddaed288d38118876a94c7aa5000dce0070b8d736dba12de64a9cb04dc2d85"
        }
    ],
    "versions_deprecated": []
}