{
    "aliases": [],
    "build_system": "RPackage",
    "conflicts": [],
    "dependencies": [
        {
            "description": "The NVIDIA HPC SDK is a comprehensive suite of compilers, libraries and\ntools essential to maximizing developer productivity and the performance\nand portability of HPC applications. The NVIDIA HPC SDK C, C++, and\nFortran compilers support GPU acceleration of HPC modeling and\nsimulation applications with standard C++ and Fortran, OpenACC\ndirectives, and CUDA. GPU-accelerated math libraries maximize\nperformance on common HPC algorithms, and optimized communications\nlibraries enable standards-based multi-GPU and scalable systems\nprogramming. Performance profiling and debugging tools simplify porting\nand optimization of HPC applications.",
            "name": "c"
        },
        {
            "description": "The NVIDIA HPC SDK is a comprehensive suite of compilers, libraries and\ntools essential to maximizing developer productivity and the performance\nand portability of HPC applications. The NVIDIA HPC SDK C, C++, and\nFortran compilers support GPU acceleration of HPC modeling and\nsimulation applications with standard C++ and Fortran, OpenACC\ndirectives, and CUDA. GPU-accelerated math libraries maximize\nperformance on common HPC algorithms, and optimized communications\nlibraries enable standards-based multi-GPU and scalable systems\nprogramming. Performance profiling and debugging tools simplify porting\nand optimization of HPC applications.",
            "name": "cxx"
        },
        {
            "description": "R is 'GNU S', a freely available language and environment for\nstatistical computing and graphics which provides a wide variety of\nstatistical and graphical techniques: linear and nonlinear modelling,\nstatistical tests, time series analysis, classification, clustering,\netc. Please consult the R project homepage for further information.",
            "name": "r"
        }
    ],
    "dependent_to": [
        {
            "description": "Analysis of Ecological Data : Exploratory and Euclidean Methods in\nEnvironmental Sciences. Tools for multivariate data analysis. Several\nmethods are provided for the analysis (i.e., ordination) of one-table\n(e.g., principal component analysis, correspondence analysis), two-table\n(e.g., coinertia analysis, redundancy analysis), three-table (e.g., RLQ\nanalysis) and K-table (e.g., STATIS, multiple coinertia analysis). The\nphilosophy of the package is described in Dray and Dufour (2007)\n<doi:10.18637/jss.v022.i04>.",
            "name": "r-ade4"
        },
        {
            "description": "Exploratory Analysis of Genetic and Genomic Data. Toolset for the\nexploration of genetic and genomic data. Adegenet provides formal (S4)\nclasses for storing and handling various genetic data, including genetic\nmarkers with varying ploidy and hierarchical population structure\n('genind' class), alleles counts by populations ('genpop'), and genome-\nwide SNP data ('genlight'). It also implements original multivariate\nmethods (DAPC, sPCA), graphics, statistical tests, simulation tools,\ndistance and similarity measures, and several spatial methods. A range\nof both empirical and simulated datasets is also provided to illustrate\nvarious methods.",
            "name": "r-adegenet"
        },
        {
            "description": "Multivariate Multiscale Spatial Analysis. Tools for the multiscale\nspatial analysis of multivariate data. Several methods are based on the\nuse of a spatial weighting matrix and its eigenvector decomposition\n(Moran's Eigenvectors Maps, MEM). Several approaches are described in\nthe review Dray et al (2012) <doi:10.1890/11-1183.1>.",
            "name": "r-adespatial"
        },
        {
            "description": "Functions to accompany A. Gelman and J. Hill, Data Analysis Using\nRegression and Multilevel/Hierarchical Models, Cambridge University\nPress, 2007.",
            "name": "r-arm"
        },
        {
            "description": "Bayesian Generalized Linear Regression.",
            "name": "r-bglr"
        },
        {
            "description": "Companion to Applied Regression. Functions and Datasets to Accompany J.\nFox and S. Weisberg, An R Companion to Applied Regression, Second\nEdition, Sage, 2011.",
            "name": "r-car"
        },
        {
            "description": "Multivariate Statistical Analysis in Chemometrics. R companion to the\nbook \"Introduction to Multivariate Statistical Analysis in Chemometrics\"\nwritten by K. Varmuza and P. Filzmoser (2009).",
            "name": "r-chemometrics"
        },
        {
            "description": "Circular Statistics, from \"Topics in Circular Statistics\" (2001).\nCircular Statistics, from \"Topics in Circular Statistics\" (2001) S. Rao\nJammalamadaka and A. SenGupta, World Scientific.",
            "name": "r-circstats"
        },
        {
            "description": "Functions for Classification. Various functions for classification,\nincluding k-nearest neighbour, Learning Vector Quantization and Self-\nOrganizing Maps.",
            "name": "r-class"
        },
        {
            "description": "Random Cluster Generation (with Specified Degree of Separation). We\ndeveloped the clusterGeneration package to provide functions for\ngenerating random clusters, generating random covariance/correlation\nmatrices, calculating a separation index (data and population version)\nfor pairs of clusters or cluster distributions, and 1-D and 2-D\nprojection plots to visualize clusters. The package also contains a\nfunction to generate random clusters based on factorial designs with\nfactors such as degree of separation, number of clusters, number of\nvariables, number of noisy variables.",
            "name": "r-clustergeneration"
        },
        {
            "description": "Compositional Data Analysis. Provides functions for the consistent\nanalysis of compositional data (e.g. portions of substances) and\npositive numbers (e.g. concentrations) in the way proposed by J.\nAitchison and V. Pawlowsky-Glahn.",
            "name": "r-compositions"
        },
        {
            "description": "Analysis of Convergent Evolution. Quantifies and assesses the\nsignificance of convergent evolution using two different methods (and 5\ndifferent measures) as described in Stayton (2015)\n<doi:10.1111/evo.12729>. Also displays results in a phylomorphospace\nframework.",
            "name": "r-convevol"
        },
        {
            "description": "Hidden Markov Models of Character Evolution. Fits hidden Markov models\nof discrete character evolution which allow different transition rate\nclasses on different portions of a phylogeny. Beaulieu et al (2013)\n<doi:10.1093/sysbio/syt034>.",
            "name": "r-corhmm"
        },
        {
            "description": "Differential gene expression analysis based on the negative binomial\ndistribution. Estimate variance-mean dependence in count data from high-\nthroughput sequencing assays and test for differential expression based\non a model using the negative binomial distribution",
            "name": "r-deseq"
        },
        {
            "description": "Groupwise Statistics, LSmeans, Linear Estimates, Utilities. Utility\npackage containing: 1) Facilities for working with grouped data: 'do'\nsomething to data stratified 'by' some variables. 2) LSmeans (least-\nsquares means), general linear estimates. 3) Restrict functions to a\nsmaller domain. 4) Miscellaneous other utilities.",
            "name": "r-doby"
        },
        {
            "description": "Package for Environmental Statistics, Including US EPA Guidance.\nGraphical and statistical analyses of environmental data, with focus on\nanalyzing chemical concentrations and physical parameters, usually in\nthe context of mandated environmental monitoring. Major environmental\nstatistical methods found in the literature and regulatory guidance\ndocuments, with extensive help that explains what these methods do, how\nto use them, and where to find them in the literature. Numerous built-in\ndata sets from regulatory guidance documents and environmental\nstatistics literature. Includes scripts reproducing analyses presented\nin the book \"EnvStats: An R Package for Environmental Statistics\"\n(Millard, 2013, Springer, ISBN 978-1-4614-8455-4,\n<https://www.springer.com/book/9781461484554>).",
            "name": "r-envstats"
        },
        {
            "description": "Fit, Simulate and Diagnose Exponential-Family Models for Networks. An\nintegrated set of tools to analyze and simulate networks based on\nexponential-family random graph models (ERGMs). 'ergm' is a part of the\nStatnet suite of packages for network analysis. See Hunter, Handcock,\nButts, Goodreau, and Morris (2008) <doi:10.18637/jss.v024.i03> and\nKrivitsky, Hunter, Morris, and Klumb (2021) <arXiv:2106.04997>.",
            "name": "r-ergm"
        },
        {
            "description": "Multivariate Exploratory Data Analysis and Data Mining. Exploratory data\nanalysis methods to summarize, visualize and describe datasets. The main\nprincipal component methods are available, those with the largest\npotential in terms of applications: principal component analysis (PCA)\nwhen variables are quantitative, correspondence analysis (CA) and\nmultiple correspondence analysis (MCA) when variables are categorical,\nMultiple Factor Analysis when variables are structured in groups, etc.\nand hierarchical cluster analysis. F. Husson, S. Le and J. Pages (2017).",
            "name": "r-factominer"
        },
        {
            "description": "Help to Fit of a Parametric Distribution to Non-Censored or Censored\nData. Extends the fitdistr() function (of the MASS package) with several\nfunctions to help the fit of a parametric distribution to non-censored\nor censored data. Censored data may contain left censored, right\ncensored and interval censored values, with several lower and upper\nbounds. In addition to maximum likelihood estimation (MLE), the package\nprovides moment matching (MME), quantile matching (QME) and maximum\ngoodness-of-fit estimation (MGE) methods (available only for non-\ncensored data). Weighted versions of MLE, MME and QME are available. See\ne.g. Casella & Berger (2002). Statistical inference. Pacific Grove.",
            "name": "r-fitdistrplus"
        },
        {
            "description": "Flexible Procedures for Clustering. Various methods for clustering and\ncluster validation. Fixed point clustering. Linear regression\nclustering. Clustering by merging Gaussian mixture components. Symmetric\nand asymmetric discriminant projections for visualisation of the\nseparation of groupings. Cluster validation statistics for distance\nbased clustering including corrected Rand index. Standardisation of\ncluster validation statistics by random clusterings and comparison\nbetween many clustering methods and numbers of clusters based on this.\nCluster-wise cluster stability assessment. Methods for estimation of the\nnumber of clusters: Calinski-Harabasz, Tibshirani and Walther's\nprediction strength, Fang and Wang's bootstrap stability.\nGaussian/multinomial mixture fitting for mixed continuous/categorical\nvariables. Variable-wise statistics for cluster interpretation. DBSCAN\nclustering. Interface functions for many clustering methods implemented\nin R, including estimating the number of clusters with kmeans, pam and\nclara. Modality diagnosis for Gaussian mixtures. For an overview see\npackage?fpc.",
            "name": "r-fpc"
        },
        {
            "description": "Generalised Additive Models for Location Scale and Shape. Functions for\nfitting the Generalized Additive Models for Location Scale and Shape\nintroduced by Rigby and Stasinopoulos (2005),\n<doi:10.1111/j.1467-9876.2005.00510.x>. The models use a distributional\nregression approach where all the parameters of the conditional\ndistribution of the response variable are modelled using explanatory\nvariables.",
            "name": "r-gamlss"
        },
        {
            "description": "Distributions for Generalized Additive Models for Location Scale and\nShape. A set of distributions which can be used for modelling the\nresponse variables in Generalized Additive Models for Location Scale and\nShape, Rigby and Stasinopoulos (2005),\n<doi:10.1111/j.1467-9876.2005.00510.x>. The distributions can be\ncontinuous, discrete or mixed distributions. Extra distributions can be\ncreated, by transforming, any continuous distribution defined on the\nreal line, to a distribution defined on ranges 0 to infinity or 0 to 1,\nby using a ''log'' or a ''logit' transformation respectively.",
            "name": "r-gamlss-dist"
        },
        {
            "description": "Analysis of Evolutionary Diversification. Methods for fitting\nmacroevolutionary models to phylogenetic trees Pennell (2014)\n<doi:10.1093/bioinformatics/btu181>.",
            "name": "r-geiger"
        },
        {
            "description": "Population Genetics. Classes and methods for handling genetic data.\nIncludes classes to represent genotypes and haplotypes at single markers\nup to multiple markers on multiple chromosomes. Function include allele\nfrequencies, flagging homo/heterozygotes, flagging carriers of certain\nalleles, estimating and testing for Hardy-Weinberg disequilibrium,\nestimating and testing for linkage disequilibrium, ...",
            "name": "r-genetics"
        },
        {
            "description": "Analysis of Geostatistical Data. Geostatistical analysis including\nvariogram-based, likelihood-based and Bayesian methods. Software\ncompanion for Diggle and Ribeiro (2007) <doi:10.1007/978-0-387-48536-2>.",
            "name": "r-geor"
        },
        {
            "description": "Create Dendrograms and Tree Diagrams Using 'ggplot2'. This is a set of\ntools for dendrograms and tree plots using 'ggplot2'. The 'ggplot2'\nphilosophy is to clearly separate data from the presentation.\nUnfortunately the plot method for dendrograms plots directly to a plot\ndevice without exposing the data. The 'ggdendro' package resolves this\nby making available functions that extract the dendrogram plot data. The\npackage provides implementations for tree, rpart, as well as diana and\nagnes cluster diagrams.",
            "name": "r-ggdendro"
        },
        {
            "description": "Accelerating 'ggplot2'. The aim of 'ggplot2' is to aid in visual data\ninvestigations. This focus has led to a lack of facilities for composing\nspecialised plots. 'ggforce' aims to be a collection of mainly new stats\nand geoms that fills this gap. All additional functionality is aimed to\ncome through the official extension system so using 'ggforce' should be\na stable experience.",
            "name": "r-ggforce"
        },
        {
            "description": "Create Elegant Data Visualisations Using the Grammar of Graphics. A\nsystem for 'declaratively' creating graphics, based on \"The Grammar of\nGraphics\". You provide the data, tell 'ggplot2' how to map variables to\naesthetics, what graphical primitives to use, and it takes care of the\ndetails.",
            "name": "r-ggplot2"
        },
        {
            "description": "An Implementation of Grammar of Graphics for Graphs and Networks. The\ngrammar of graphics as implemented in ggplot2 is a poor fit for graph\nand network visualizations due to its reliance on tabular data input.\nggraph is an extension of the ggplot2 API tailored to graph\nvisualizations and provides the same flexible approach to building up\nplots layer by layer.",
            "name": "r-ggraph"
        },
        {
            "description": "Various R programming tools for model fitting.",
            "name": "r-gmodels"
        },
        {
            "description": "Improved Predictors. Improved predictive models by indirect\nclassification and bagging for classification, regression and survival\nproblems as well as resampling based estimators of prediction error.",
            "name": "r-ipred"
        },
        {
            "description": "Multilevel Joint Modelling Multiple Imputation. Similarly to Schafer's\npackage 'pan', 'jomo' is a package for multilevel joint modelling\nmultiple imputation (Carpenter and Kenward, 2013)\n<doi:10.1002/9781119942283>. Novel aspects of 'jomo' are the possibility\nof handling binary and categorical data through latent normal variables,\nthe option to use cluster-specific covariance matrices and to impute\ncompatibly with the substantive model.",
            "name": "r-jomo"
        },
        {
            "description": "Classification and Visualization. Miscellaneous functions for\nclassification and visualization, e.g. regularized discriminant\nanalysis, sknn() kernel-density naive Bayes, an interface to 'svmlight'\nand stepclass() wrapper variable selection for supervised\nclassification, partimat() visualization of classification rules and\nshardsplot() of cluster results as well as kmodes() clustering for\ncategorical data, corclust() variable clustering, variable extraction\nfrom different variable clustering models and weight of evidence\npreprocessing.",
            "name": "r-klar"
        },
        {
            "description": "Extra Graphical Utilities Based on Lattice. Building on the\ninfrastructure provided by the lattice package, this package provides\nseveral new high-level functions and methods, as well as additional\nutilities such as panel and axis annotation functions.",
            "name": "r-latticeextra"
        },
        {
            "description": "Latent Variable Analysis. Fit a variety of latent variable models,\nincluding confirmatory factor analysis, structural equation modeling and\nlatent growth curve models.",
            "name": "r-lavaan"
        },
        {
            "description": "Solving Linear Inverse Models. Functions that (1) find the\nminimum/maximum of a linear or quadratic function: min or max (f(x)),\nwhere f(x) = ||Ax-b||^2 or f(x) = sum(a_i*x_i) subject to equality\nconstraints Ex=f and/or inequality constraints Gx>=h, (2) sample an\nunderdetermined- or overdetermined system Ex=f subject to Gx>=h, and if\napplicable Ax~=b, (3) solve a linear system Ax=B for the unknown x. It\nincludes banded and tridiagonal linear systems.",
            "name": "r-limsolve"
        },
        {
            "description": "Allows researchers to conduct multivariate statistical analyses of\nsurvey data with list experiments.",
            "name": "r-list"
        },
        {
            "description": "Linear Mixed-Effects Models using 'Eigen' and S4. Fit linear and\ngeneralized linear mixed-effects models. The models and their components\nare represented using S4 classes and methods. The core computational\nalgorithms are implemented using the 'Eigen' C++ library for numerical\nlinear algebra and 'RcppEigen' \"glue\".",
            "name": "r-lme4"
        },
        {
            "description": "Tests in Linear Mixed Effects Models. Provides p-values in type I, II or\nIII anova and summary tables for lmer model fits (cf. lme4) via\nSatterthwaite's degrees of freedom method. A Kenward-Roger method is\nalso available via the pbkrtest package. Model selection methods include\nstep, drop1 and anova-like tables for random effects (ranova). Methods\nfor Least-Square means (LS-means) and tests of linear contrasts of fixed\neffects are also available.",
            "name": "r-lmertest"
        },
        {
            "description": "BeadArray Specific Methods for Illumina Methylation and Expression\nMicroarrays. The lumi package provides an integrated solution for the\nIllumina microarray data analysis. It includes functions of Illumina\nBeadStudio (GenomeStudio) data input, quality control, BeadArray-\nspecific variance stabilization, normalization and gene annotation at\nthe probe level. It also includes the functions of processing Illumina\nmethylation microarrays, especially Illumina Infinium methylation\nmicroarrays.",
            "name": "r-lumi"
        },
        {
            "description": "Markov Chain Monte Carlo (MCMC) Package. Contains functions to perform\nBayesian inference using posterior simulation for a number of\nstatistical models. Most simulation is done in compiled C++ written in\nthe Scythe Statistical Library Version 1.0.3. All models return 'coda'\nmcmc objects that can then be summarized using the 'coda' package. Some\nuseful utility functions such as density functions, pseudo-random number\ngenerators for statistical distributions, a general purpose Metropolis\nsampling algorithm, and tools for visualization are provided.",
            "name": "r-mcmcpack"
        },
        {
            "description": "Management of Survey Data and Presentation of Analysis Results. An\ninfrastructure for the management of survey data including value labels,\ndefinable missing values, recoding of variables, production of code\nbooks, and import of (subsets of) 'SPSS' and 'Stata' files is provided.\nFurther, the package allows to produce tables and data frames of\narbitrary descriptive statistics and (almost) publication-ready tables\nof regression model estimates, which can be exported to 'LaTeX' and\nHTML.",
            "name": "r-memisc"
        },
        {
            "description": "Merge Maid. The functions in this R extension are intended for cross-\nstudy comparison of gene expression array data. Required from the user\nis gene expression matrices, their corresponding gene-id vectors and\nother useful information, and they could be 'list','matrix', or\n'ExpressionSet'. The main function is 'mergeExprs' which transforms the\ninput objects into data in the merged format, such that common genes in\ndifferent datasets can be easily found. And the function 'intcor'\ncalculate the correlation coefficients. Other functions use the output\nfrom 'modelOutcome' to graphically display the results and cross-\nvalidate associations of gene expression data with survival.",
            "name": "r-mergemaid"
        },
        {
            "description": "Multivariate Imputation by Chained Equations. Multiple imputation using\nFully Conditional Specification (FCS) implemented by the MICE algorithm\nas described in Van Buuren and Groothuis-Oudshoorn (2011)\n<doi:10.18637/jss.v045.i03>. Each variable has its own imputation model.\nBuilt-in imputation models are provided for continuous data (predictive\nmean matching, normal), binary data (logistic regression), unordered\ncategorical data (polytomous logistic regression) and ordered\ncategorical data (proportional odds). MICE can also impute continuous\ntwo-level data (normal model, pan, second-level variables). Passive\nimputation can be used to maintain consistency between variables.\nVarious diagnostic plots are available to inspect the quality of the\nimputations.",
            "name": "r-mice"
        },
        {
            "description": "Analyze Illumina Infinium DNA methylation arrays. Tools to analyze &\nvisualize Illumina Infinium methylation arrays.",
            "name": "r-minfi"
        },
        {
            "description": "Tools for Analyzing Finite Mixture Models. Analyzes finite mixture\nmodels for various parametric and semiparametric settings. This includes\nmixtures of parametric distributions (normal, multivariate normal,\nmultinomial, gamma), various Reliability Mixture Models (RMMs),\nmixtures-of-regressions settings (linear regression, logistic\nregression, Poisson regression, linear regression with changepoints,\npredictor-dependent mixing proportions, random effects regressions,\nhierarchical mixtures-of-experts), and tools for selecting the number of\ncomponents (bootstrapping the likelihood ratio test statistic,\nmixturegrams, and model selection criteria). Bayesian estimation of\nmixtures-of-linear-regressions models is available as well as a novel\ndata depth method for obtaining credible bands. This package is based\nupon work supported by the National Science Foundation under Grant No.\nSES-0518772.",
            "name": "r-mixtools"
        },
        {
            "description": "Uniform interfaces to R machine learning procedures for data in\nBioconductor containers. This package provides uniform interfaces to\nmachine learning code for data in R and Bioconductor containers.",
            "name": "r-mlinterfaces"
        },
        {
            "description": "Multivariate Projection Methods. Exploratory graphical analysis of\nmultivariate data, specifically gene expression data with different\nprojection methods: principal component analysis, correspondence\nanalysis, spectral map analysis.",
            "name": "r-mpm"
        },
        {
            "description": "Core Utils for Mass Spectrometry Data. MsCoreUtils defines low-level\nfunctions for mass spectrometry data and is independent of any high-\nlevel data structures. These functions include mass spectra processing\nfunctions (noise estimation, smoothing, binning), quantitative\naggregation functions (median polish, robust summarisation, ...),\nmissing data imputation, data normalisation (quantiles, vsn, ...) as\nwell as misc helper functions, that are used across high-level data\nstructure within the R for Mass Spectrometry packages.",
            "name": "r-mscoreutils"
        },
        {
            "description": "Base Functions and Classes for Mass Spectrometry and Proteomics. MSnbase\nprovides infrastructure for manipulation, processing and visualisation\nof mass spectrometry and proteomics data, ranging from raw to\nquantitative and annotated data.",
            "name": "r-msnbase"
        },
        {
            "description": "Resampling-based multiple hypothesis testing. Non-parametric bootstrap\nand permutation resampling-based multiple testing procedures (including\nempirical Bayes methods) for controlling the family-wise error rate\n(FWER), generalized family-wise error rate (gFWER), tail probability of\nthe proportion of false positives (TPPFP), and false discovery rate\n(FDR). Several choices of bootstrap-based null distribution are\nimplemented (centered, centered and scaled, quantile- transformed).\nSingle-step and step-wise methods are available. Tests based on a\nvariety of t- and F-statistics (including t-statistics based on\nregression parameters from linear and survival models as well as those\nbased on correlation parameters) are included. When probing hypotheses\nwith t-statistics, users may also select a potentially faster null\ndistribution which is multivariate normal with mean zero and variance\ncovariance matrix derived from the vector influence function. Results\nare reported in terms of adjusted p-values, confidence regions and test\nstatistic cutoffs. The procedures are directly applicable to identifying\ndifferentially expressed genes in DNA microarray experiments.",
            "name": "r-multtest"
        },
        {
            "description": "Training of Neural Networks. Training of neural networks using\nbackpropagation, resilient backpropagation with (Riedmiller, 1994) or\nwithout weight backtracking (Riedmiller and Braun, 1993) or the modified\nglobally convergent version by Anastasiadis et al. (2005). The package\nallows flexible settings through custom-choice of error and activation\nfunction. Furthermore, the calculation of generalized weights (Intrator\nO & Intrator N, 1993) is implemented.",
            "name": "r-neuralnet"
        },
        {
            "description": "Parallel Analysis and Other Non Graphical Solutions to the Cattell Scree\nTest. Indices, heuristics and strategies to help determine the number of\nfactors/components to retain: 1. Acceleration factor (af with or without\nParallel Analysis); 2. Optimal Coordinates (noc with or without Parallel\nAnalysis); 3. Parallel analysis (components, factors and bootstrap); 4.\nlambda > mean(lambda) (Kaiser, CFA and related); 5. Cattell-Nelson-\nGorsuch (CNG); 6. Zoski and Jurs multiple regression (b, t and p); 7.\nZoski and Jurs standard error of the regression coeffcient (sescree); 8.\nNelson R2; 9. Bartlett khi-2; 10. Anderson khi-2; 11. Lawley khi-2 and\n12. Bentler-Yuan khi-2.",
            "name": "r-nfactors"
        },
        {
            "description": "Regression Models for Ordinal Data. Implementation of cumulative link\n(mixed) models also known as ordered regression models, proportional\nodds models, proportional hazards models for grouped survival times and\nordered logit/probit/... models. Estimation is via maximum likelihood\nand mixed models are fitted with the Laplace approximation and adaptive\nGauss-Hermite quadrature. Multiple random effect terms are allowed and\nthey may be nested, crossed or partially nested/crossed. Restrictions of\nsymmetry and equidistance can be imposed on the thresholds (cut-\npoints/intercepts). Standard model methods are available (summary,\nanova, drop-methods, step, confint, predict etc.) in addition to profile\nmethods and slice methods for visualizing the likelihood function and\nchecking convergence.",
            "name": "r-ordinal"
        },
        {
            "description": "Parametric Bootstrap, Kenward-Roger and Satterthwaite Based Methods for\nTest in Mixed Models. Test in mixed effects models. Attention is on\nmixed effects models as implemented in the 'lme4' package. For linear\nmixed models, this package implements (1) a parametric bootstrap test,\n(2) a Kenward-Roger-typ modification of F-tests for linear mixed effects\nmodels and (3) a Satterthwaite-type modification of F-tests for linear\nmixed effects models. The package also implements a parametric bootstrap\ntest for generalized linear mixed models. The facilities of the package\nare documented in the paper by Halehoh and Hojsgaard, (2012,\n<doi:10.18637/jss.v059.i09>). Please see 'citation(\"pbkrtest\")' for\ncitation details.",
            "name": "r-pbkrtest"
        },
        {
            "description": "A collection of PCA methods. Provides Bayesian PCA, Probabilistic PCA,\nNipals PCA, Inverse Non-Linear PCA and the conventional SVD PCA. A\ncluster based method for missing value estimation is included for\ncomparison. BPCA, PPCA and NipalsPCA may be used to perform PCA on\nincomplete data as well as for accurate missing value estimation. A set\nof methods for printing and plotting the results is also provided. All\nPCA methods make use of the same data structure (pcaRes) to provide a\ncommon interface to the PCA results. Initiated at the Max-Planck\nInstitute for Molecular Plant Physiology, Golm, Germany.",
            "name": "r-pcamethods"
        },
        {
            "description": "Phylogenetic Tools for Comparative Biology (and Other Things). A wide\nrange of functions for phylogenetic analysis. Functionality is\nconcentrated in phylogenetic comparative biology, but also includes\nnumerous methods for visualizing, manipulating, reading or writing, and\neven inferring phylogenetic trees and data. Included among the functions\nin phylogenetic comparative biology are various for ancestral state\nreconstruction, model-fitting, simulation of phylogenies and data, and\nmultivariate analysis. There are a broad range of plotting methods for\nphylogenies and comparative data which include, but are not restricted\nto, methods for mapping trait evolution on trees, for projecting trees\ninto phenotypic space or a geographic map, and for visualizing\ncorrelated speciation between trees. Finally, there are a number of\nfunctions for reading, writing, analyzing, inferring, simulating, and\nmanipulating phylogenetic trees and comparative data not covered by\nother packages. For instance, there are functions for randomly or non-\nrandomly attaching species or clades to a phylogeny, for estimating\nsupertrees or consensus phylogenies from a set, for simulating trees and\nphylogenetic data under a range of models, and for a wide variety of\nother manipulations and analyses that phylogenetic biologists might find\nuseful in their research.",
            "name": "r-phytools"
        },
        {
            "description": "Calculate Pairwise Multiple Comparisons of Mean Rank Sums Extended. For\none-way layout experiments the one-way ANOVA can be performed as an\nomnibus test. All-pairs multiple comparisons tests (Tukey-Kramer test,\nScheffe test, LSD-test) and many-to-one tests (Dunnett test) for\nnormally distributed residuals and equal within variance are available.\nFurthermore, all-pairs tests (Games-Howell test, Tamhane's T2 test,\nDunnett T3 test, Ury-Wiggins-Hochberg test) and many-to-one (Tamhane-\nDunnett Test) for normally distributed residuals and heterogeneous\nvariances are provided. Van der Waerden's normal scores test for\nomnibus, all-pairs and many-to-one tests is provided for non-normally\ndistributed residuals and homogeneous variances. The Kruskal-Wallis, BWS\nand Anderson-Darling omnibus test and all-pairs tests (Nemenyi test,\nDunn test, Conover test, Dwass-Steele-Critchlow- Fligner test) as well\nas many-to-one (Nemenyi test, Dunn test, U-test) are given for the\nanalysis of variance by ranks. Non-parametric trend tests (Jonckheere\ntest, Cuzick test, Johnson-Mehrotra test, Spearman test) are included.\nIn addition, a Friedman-test for one-way ANOVA with repeated measures on\nranks (CRBD) and Skillings-Mack test for unbalanced CRBD is provided\nwith consequent all-pairs tests (Nemenyi test, Siegel test, Miller test,\nConover test, Exact test) and many-to-one tests (Nemenyi test, Demsar\ntest, Exact test). A trend can be tested with Pages's test. Durbin's\ntest for a two-way balanced incomplete block design (BIBD) is given in\nthis package as well as Gore's test for CRBD with multiple observations\nper cell is given. Outlier tests, Mandel's k- and h statistic as well as\nfunctions for Type I error and Power analysis as well as generic\nsummary, print and plot methods are provided.",
            "name": "r-pmcmrplus"
        },
        {
            "description": "Functions for Clustering of Presence-Absence, Abundance and Multilocus\nGenetic Data. Distance-based parametric bootstrap tests for clustering\nwith spatial neighborhood information. Some distance measures,\nClustering of presence-absence, abundance and multilocus genetic data\nfor species delimitation, nearest neighbor based noise detection.\nGenetic distances between communities. Tests whether various distance-\nbased regressions are equal. Try package?prabclus for on overview.",
            "name": "r-prabclus"
        },
        {
            "description": "Projection Predictive Feature Selection. Performs projection predictive\nfeature selection for generalized linear models and generalized linear\nand additive multilevel models (see, Piironen, Paasiniemi and Vehtari,\n2020, <https://projecteuclid.org/euclid.ejs/1589335310>, Catalina,\nBurkner and Vehtari, 2020, <arXiv:2010.06994>). The package is\ncompatible with the 'rstanarm' and 'brms' packages, but other reference\nmodels can also be used. See the package vignette for more information\nand examples.",
            "name": "r-projpred"
        },
        {
            "description": "Creates Simultaneous Testing Bands for QQ-Plots. Provides functionality\nfor creating Quantile-Quantile (QQ) and Probability-Probability (PP)\nplots with simultaneous testing bands to asses significance of sample\ndeviation from a reference distribution.",
            "name": "r-qqconf"
        },
        {
            "description": "Quantile Regression. Estimation and inference methods for models of\nconditional quantiles: Linear and nonlinear parametric and non-\nparametric (total variation penalized) models for conditional quantiles\nof a univariate response and several methods for handling censored\nsurvival data. Portfolio selection methods based on expected shortfall\nrisk are also now included. See Koenker (2006)\n<doi:10.1017/CBO9780511754098> and Koenker et al. (2017)\n<doi:10.1201/9781315120256>.",
            "name": "r-quantreg"
        },
        {
            "description": "Bagplots, Boxplots and Rainbow Plots for Functional Data. Visualizing\nfunctional data and identifying functional outliers.",
            "name": "r-rainbow"
        },
        {
            "description": "Random General Linear Model Prediction. The package implements a bagging\npredictor based on general linear models.",
            "name": "r-randomglm"
        },
        {
            "description": "Data Mining Classification and Regression Methods. Facilitates the use\nof data mining algorithms in classification and regression (including\ntime series forecasting) tasks by presenting a short and coherent set of\nfunctions. Versions: 1.4.6 / 1.4.5 / 1.4.4 new automated machine\nlearning (AutoML) and ensembles, via improved fit(), mining() and\nmparheuristic() functions, and new categorical preprocessing, via\nimproved delevels() function; 1.4.3 new metrics (e.g., macro precision,\nexplained variance), new \"lssvm\" model and improved mparheuristic()\nfunction; 1.4.2 new \"NMAE\" metric, \"xgboost\" and \"cv.glmnet\" models (16\nclassification and 18 regression models); 1.4.1 new tutorial and more\nrobust version; 1.4 - new classification and regression models, with a\ntotal of 14 classification and 15 regression methods, including:\nDecision Trees, Neural Networks, Support Vector Machines, Random\nForests, Bagging and Boosting; 1.3 and 1.3.1 - new classification and\nregression metrics; 1.2 - new input importance methods via improved\nImportance() function; 1.0 - first version.",
            "name": "r-rminer"
        },
        {
            "description": "Regression Modeling Strategies. Regression modeling, testing,\nestimation, validation, graphics, prediction, and typesetting by storing\nenhanced model design attributes in the fit. 'rms' is a collection of\nfunctions that assist with and streamline modeling. It also contains\nfunctions for binary and ordinal logistic regression models, ordinal\nmodels for continuous Y with a variety of distribution families, and the\nBuckley-James multiple regression model for right-censored responses,\nand implements penalized maximum likelihood estimation for logistic and\nordinary linear models. 'rms' works with almost any regression model,\nbut it was especially written to work with binary or ordinal regression\nmodels, Cox regression, accelerated failure time models, ordinary linear\nmodels, the Buckley-James model, generalized least squares for serially\nor spatially correlated observations, generalized linear models, and\nquantile regression.",
            "name": "r-rms"
        },
        {
            "description": "Port of the S+ Robust Library. Methods for robust statistics, a state of\nthe art in the early 2000s, notably for robust regression and robust\nmultivariate analysis.",
            "name": "r-robust"
        },
        {
            "description": "The scDblFinder package gathers various methods for the detection and\nhandling of doublets/multiplets in single-cell sequencing data (i.e.\nmultiple cells captured within the same droplet or reaction volume). It\nincludes methods formerly found in the scran package, the new fast and\ncomprehensive scDblFinder method, and a reimplementation of the Amulet\ndetection method for single-cell ATAC-seq.",
            "name": "r-scdblfinder"
        },
        {
            "description": "Variance Stabilizing Transformations for Single Cell UMI Data. A\nnormalization method for single-cell UMI count data using a variance\nstabilizing transformation. The transformation is based on a negative\nbinomial regression model with regularized parameters. As part of the\nsame regression framework, this package also provides functions for\nbatch correction, and data correction. See Hafemeister and Satija 2019\n<doi:10.1101/576827> for more details.",
            "name": "r-sctransform"
        },
        {
            "description": "Regression Models with Break-Points / Change-Points Estimation. Given a\nregression model, segmented 'updates' it by adding one or more segmented\n(i.e., piece-wise linear) relationships. Several variables with multiple\nbreakpoints are allowed. The estimation method is discussed in Muggeo\n(2003, <doi:10.1002/sim.1545>) and illustrated in Muggeo (2008,\n<https://www.r-project.org/doc/Rnews/Rnews_2008-1.pdf>). An approach for\nhypothesis testing is presented in Muggeo (2016,\n<doi:10.1080/00949655.2016.1149855>), and interval estimation for the\nbreakpoint is discussed in Muggeo (2017, <doi:10.1111/anzs.12200>).",
            "name": "r-segmented"
        },
        {
            "description": "Tools for Single Cell Genomics. A toolkit for quality control, analysis,\nand exploration of single cell RNA sequencing data. 'Seurat' aims to\nenable users to identify and interpret sources of heterogeneity from\nsingle cell transcriptomic measurements, and to integrate diverse types\nof single cell data. See Satija R, Farrell J, Gennert D, et al (2015)\n<doi:10.1038/nbt.3192>, Macosko E, Basu A, Satija R, et al (2015)\n<doi:10.1016/j.cell.2015.05.002>, and Stuart T, Butler A, et al (2019)\n<doi:10.1016/j.cell.2019.05.031> for more details.",
            "name": "r-seurat"
        },
        {
            "description": "Functions for Kriging and Point Pattern Analysis. Functions for kriging\nand point pattern analysis.",
            "name": "r-spatial"
        },
        {
            "description": "Spatial Analysis and Modelling Utilities. Utilities to support spatial\ndata manipulation, query, sampling and modelling. Functions include\nmodels for species population density, download utilities for climate\nand global deforestation spatial products, spatial smoothing,\nmultivariate separability, point process model for creating pseudo-\nabsences and sub-sampling, polygon and point-distance landscape metrics,\nauto-logistic model, sampling models, cluster optimization, statistical\nexploratory tools and raster-based metrics.",
            "name": "r-spatialeco"
        },
        {
            "description": "Spatial Regression Analysis. A collection of all the estimation\nfunctions for spatial cross-sectional models (on lattice/areal data\nusing spatial weights matrices) contained up to now in 'spdep', 'sphet'\nand 'spse'. These model fitting functions include maximum likelihood\nmethods for cross-sectional models proposed by 'Cliff' and 'Ord' (1973,\nISBN:0850860369) and (1981, ISBN:0850860814), fitting methods initially\ndescribed by 'Ord' (1975) <doi:10.1080/01621459.1975.10480272>. The\nmodels are further described by 'Anselin' (1988)\n<doi:10.1007/978-94-015-7799-1>. Spatial two stage least squares and\nspatial general method of moment models initially proposed by 'Kelejian'\nand 'Prucha' (1998) <doi:10.1023/A:1007707430416> and (1999)\n<doi:10.1111/1468-2354.00027> are provided. Impact methods and MCMC\nfitting methods proposed by 'LeSage' and 'Pace' (2009)\n<doi:10.1201/9781420064254> are implemented for the family of cross-\nsectional spatial regression models. Methods for fitting the log\ndeterminant term in maximum likelihood and MCMC fitting are compared by\n'Bivand et al.' (2013) <doi:10.1111/gean.12008>, and model fitting\nmethods by 'Bivand' and 'Piras' (2015) <doi:10.18637/jss.v063.i18>; both\nof these articles include extensive lists of references. 'spatialreg' >=\n1.1-* correspond to 'spdep' >= 1.1-1, in which the model fitting\nfunctions are deprecated and pass through to 'spatialreg', but will mask\nthose in 'spatialreg'. From versions 1.2-*, the functions will be made\ndefunct in 'spdep'.",
            "name": "r-spatialreg"
        },
        {
            "description": "Spatial Dependence: Weighting Schemes, Statistics. A collection of\nfunctions to create spatial weights matrix objects from polygon\n'contiguities', from point patterns by distance and tessellations, for\nsummarizing these objects, and for permitting their use in spatial data\nanalysis, including regional aggregation by minimum spanning tree; a\ncollection of tests for spatial 'autocorrelation', including global\n'Morans I' and 'Gearys C' proposed by 'Cliff' and 'Ord' (1973, ISBN:\n0850860369) and (1981, ISBN: 0850860814), 'Hubert/Mantel' general cross\nproduct statistic, Empirical Bayes estimates and 'Assuncao/Reis' (1999)\n<doi:10.1002/(SICI)1097-0258(19990830)18:16%3C2147::AID-SIM179%3E3.0.CO",
            "name": "r-spdep"
        },
        {
            "description": "Fitting Linear and Generalized Linear Models to Large Data Sets. Fitting\nlinear models and generalized linear models to large data sets by\nupdating algorithms.",
            "name": "r-speedglm"
        },
        {
            "description": "Robust Trimmed Clustering. Provides functions for robust trimmed\nclustering. The methods are described in Garcia-Escudero (2008)\n<doi:10.1214/07-AOS515>, Fritz et al. (2012)\n<doi:10.18637/jss.v047.i12>, Garcia-Escudero et al. (2011)\n<doi:10.1007/s11222-010-9194-z> and others.",
            "name": "r-tclust"
        },
        {
            "description": "TH's Data Archive. Contains data sets used in other packages Torsten\nHothorn maintains.",
            "name": "r-th-data"
        },
        {
            "description": "Two Sample MR functions and interface to MR Base database. A package for\nperforming Mendelian randomization using GWAS summary data. It uses the\nIEU GWAS database to obtain data automatically, and a wide range of\nmethods to run the analysis. You can use the MR-Base web app to try out\na limited range of the functionality in this package, but for any\nserious work we strongly recommend using this R package.",
            "name": "r-twosamplemr"
        },
        {
            "description": "Visualizing Categorical Data. Visualization techniques, data sets,\nsummary and inference procedures aimed particularly at categorical data.\nSpecial emphasis is given to highly extensible grid graphics. The\npackage was package was originally inspired by the book \"Visualizing\nCategorical Data\" by Michael Friendly and is now the main support\npackage for a new book, \"Discrete Data Analysis with R\" by Michael\nFriendly and David Meyer (2015).",
            "name": "r-vcd"
        },
        {
            "description": "Community Ecology Package. Ordination methods, diversity analysis and\nother functions for community and vegetation ecologists.",
            "name": "r-vegan"
        },
        {
            "description": "Treatment of Zeros, Left-Censored and Missing Values in Compositional\nData Sets. Principled methods for the imputation of zeros, left-censored\nand missing data in compositional data sets (Palarea-Albaladejo and\nMartin-Fernandez (2015) <doi:10.1016/j.chemolab.2015.02.019>).",
            "name": "r-zcompositions"
        }
    ],
    "description": "Support Functions and Datasets for Venables and Ripley's MASS. Functions\nand datasets to support Venables and Ripley, \"Modern Applied Statistics\nwith S\" (4th edition, 2002).\n",
    "homepage": "https://cloud.r-project.org/package=MASS",
    "latest_version": "7.3-61",
    "maintainers": [],
    "name": "r-mass",
    "patches": [],
    "resources": [],
    "variants": [
        {
            "default": "generic",
            "description": "Build systems supported by the package",
            "name": "build_system"
        }
    ],
    "versions": [
        {
            "name": "7.3-61",
            "sha256": "3144c8bf579dd7b7c47c259728c27f53f53e294e7ed307da434dfd144e800a90"
        },
        {
            "name": "7.3-59",
            "sha256": "454200bec7a52835fbb7f9fe8e01a7aaa728b3ab87b068fc6d900e01c930da5a"
        },
        {
            "name": "7.3-58.1",
            "sha256": "f704e4e2fb131740d023ae1755c925c2e684886a3061b08e26397135f1231420"
        },
        {
            "name": "7.3-57",
            "sha256": "bd8b880105bc1aadb2db699086f74bd92a8611287979a24243187f9d80795a8d"
        },
        {
            "name": "7.3-55",
            "sha256": "65299cbc8f3fd5e09cb3535eabcb3faad2308e01d5ba9422145cc04d7d0c31a4"
        },
        {
            "name": "7.3-54",
            "sha256": "b800ccd5b5c2709b1559cf5eab126e4935c4f8826cf7891253432bb6a056e821"
        },
        {
            "name": "7.3-53",
            "sha256": "41824e70ada302a620226c0f17b1b2c880c6d1a3a100b53bd6df8e8c97e64b38"
        },
        {
            "name": "7.3-51.5",
            "sha256": "464c0615cef01820cde2bb8457e81575d6755ae9b3ac99f3bfaaac47d43d15cc"
        },
        {
            "name": "7.3-51.4",
            "sha256": "844270a2541eaed420871dfb61d681aa67ee57126645fb6b144b436c25698eeb"
        },
        {
            "name": "7.3-51.3",
            "sha256": "5b0e0e7704d43a94b08dcc4b3fe600b9723d1b3e446dd393e82d39ddf66608b6"
        },
        {
            "name": "7.3-47",
            "sha256": "ed44cdabe84fff3553122267ade61d5cc68071c435f7645d36c8f2e4e9f9c6bf"
        }
    ],
    "versions_deprecated": []
}