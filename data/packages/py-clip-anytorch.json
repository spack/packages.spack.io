{
    "aliases": [],
    "build_system": "PythonPackage",
    "conflicts": [],
    "dependencies": [
        {
            "description": "Fixes Unicode that's broken in various ways.",
            "name": "py-ftfy"
        },
        {
            "description": "The PyPA recommended tool for installing Python packages.",
            "name": "py-pip"
        },
        {
            "description": "Alternative regular expression module, to replace re.",
            "name": "py-regex"
        },
        {
            "description": "A Python utility that aids in the process of downloading, building,\nupgrading, installing, and uninstalling Python packages.",
            "name": "py-setuptools"
        },
        {
            "description": "Tensors and Dynamic neural networks in Python with strong GPU\nacceleration.",
            "name": "py-torch"
        },
        {
            "description": "Image and video datasets and models for torch deep learning.",
            "name": "py-torchvision"
        },
        {
            "description": "A Fast, Extensible Progress Meter",
            "name": "py-tqdm"
        },
        {
            "description": "A built-package format for Python.",
            "name": "py-wheel"
        },
        {
            "description": "The Python programming language.",
            "name": "python"
        },
        {
            "description": "A Spack managed Python virtual environment",
            "name": "python-venv"
        }
    ],
    "dependent_to": [],
    "description": "CLIP (Contrastive Language-Image Pre-Training) is a neural network\ntrained on a variety of (image, text) pairs. It can be instructed in\nnatural language to predict the most relevant text snippet, given an\nimage, without directly optimizing for the task, similarly to the zero-\nshot capabilities of GPT-2 and 3. We found CLIP matches the performance\nof the original ResNet50 on ImageNet \"zero-shot\" without using any of\nthe original 1.28M labeled examples, overcoming several major challenges\nin computer vision.\n",
    "homepage": "https://github.com/rom1504/CLIP",
    "latest_version": "2.6.0",
    "maintainers": [],
    "name": "py-clip-anytorch",
    "patches": [],
    "resources": [],
    "variants": [
        {
            "default": "python_pip",
            "description": "Build systems supported by the package",
            "name": "build_system"
        }
    ],
    "versions": [
        {
            "name": "2.6.0",
            "sha256": "1ac1f6ca47dfb5d4e55be8f45cc2f3bdf6415b91973a04b4529e812a8ae29bea"
        }
    ],
    "versions_deprecated": []
}