{
    "aliases": [],
    "build_system": "RPackage",
    "conflicts": [],
    "dependencies": [
        {
            "description": "The NVIDIA HPC SDK is a comprehensive suite of compilers, libraries and\ntools essential to maximizing developer productivity and the performance\nand portability of HPC applications. The NVIDIA HPC SDK C, C++, and\nFortran compilers support GPU acceleration of HPC modeling and\nsimulation applications with standard C++ and Fortran, OpenACC\ndirectives, and CUDA. GPU-accelerated math libraries maximize\nperformance on common HPC algorithms, and optimized communications\nlibraries enable standards-based multi-GPU and scalable systems\nprogramming. Performance profiling and debugging tools simplify porting\nand optimization of HPC applications.",
            "name": "c"
        },
        {
            "description": "The NVIDIA HPC SDK is a comprehensive suite of compilers, libraries and\ntools essential to maximizing developer productivity and the performance\nand portability of HPC applications. The NVIDIA HPC SDK C, C++, and\nFortran compilers support GPU acceleration of HPC modeling and\nsimulation applications with standard C++ and Fortran, OpenACC\ndirectives, and CUDA. GPU-accelerated math libraries maximize\nperformance on common HPC algorithms, and optimized communications\nlibraries enable standards-based multi-GPU and scalable systems\nprogramming. Performance profiling and debugging tools simplify porting\nand optimization of HPC applications.",
            "name": "cxx"
        },
        {
            "description": "The NVIDIA HPC SDK is a comprehensive suite of compilers, libraries and\ntools essential to maximizing developer productivity and the performance\nand portability of HPC applications. The NVIDIA HPC SDK C, C++, and\nFortran compilers support GPU acceleration of HPC modeling and\nsimulation applications with standard C++ and Fortran, OpenACC\ndirectives, and CUDA. GPU-accelerated math libraries maximize\nperformance on common HPC algorithms, and optimized communications\nlibraries enable standards-based multi-GPU and scalable systems\nprogramming. Performance profiling and debugging tools simplify porting\nand optimization of HPC applications.",
            "name": "fortran"
        },
        {
            "description": "GNU internationalization (i18n) and localization (l10n) library.",
            "name": "gettext"
        },
        {
            "description": "R is 'GNU S', a freely available language and environment for\nstatistical computing and graphics which provides a wide variety of\nstatistical and graphical techniques: linear and nonlinear modelling,\nstatistical tests, time series analysis, classification, clustering,\netc. Please consult the R project homepage for further information.",
            "name": "r"
        },
        {
            "description": "Trellis Graphics for R. A powerful and elegant high-level data\nvisualization system inspired by Trellis graphics, with an emphasis on\nmultivariate data. Lattice is sufficient for typical graphics needs, and\nis also flexible enough to handle most nonstandard requirements. See\n?Lattice for an introduction.",
            "name": "r-lattice"
        }
    ],
    "dependent_to": [
        {
            "description": "Investigates Allele Specific Expression. Provides a framework for\nallelic specific expression investigation using RNA-seq data.",
            "name": "r-allelicimbalance"
        },
        {
            "description": "Analyses of Phylogenetics and Evolution. Functions for reading, writing,\nplotting, and manipulating phylogenetic trees, analyses of comparative\ndata in a phylogenetic framework, ancestral character analyses, analyses\nof diversification and macroevolution, computing distances from DNA\nsequences, reading and writing nucleotide sequences as well as importing\nfrom BioConductor, and several tools such as Mantel's test, generalized\nskyline plots, graphical exploration of phylogenetic data (alex, trex,\nkronoviz), estimation of absolute evolutionary rates and clock-like\ntrees using mean path lengths and penalized likelihood, dating trees\nwith non-contemporaneous sequences, translating DNA into AA sequences,\nand assessing sequence alignments. Phylogeny estimation can be done with\nthe NJ, BIONJ, ME, MVR, SDM, and triangle methods, and several methods\nhandling incomplete distance matrices (NJ*, BIONJ*, MVR*, and the\ncorresponding triangle method). Some functions call external\napplications (PhyML, Clustal, T-Coffee, Muscle) whose results are\nreturned into R.",
            "name": "r-ape"
        },
        {
            "description": "Functions to accompany A. Gelman and J. Hill, Data Analysis Using\nRegression and Multilevel/Hierarchical Models, Cambridge University\nPress, 2007.",
            "name": "r-arm"
        },
        {
            "description": "Bayesian Regression Models using 'Stan'. Fit Bayesian generalized\n(non-)linear multivariate multilevel models using 'Stan' for full\nBayesian inference. A wide range of distributions and link functions are\nsupported, allowing users to fit - among others - linear, robust linear,\ncount data, survival, response times, ordinal, zero-inflated, hurdle,\nand even self-defined mixture models all in a multilevel context.\nFurther modeling options include non-linear and smooth terms, auto-\ncorrelation structures, censored data, meta-analytic standard errors,\nand quite a few more. In addition, all parameters of the response\ndistribution can be predicted in order to perform distributional\nregression. Prior specifications are flexible and explicitly encourage\nusers to apply prior distributions that actually reflect their beliefs.\nModel fit can easily be assessed and compared with posterior predictive\nchecks and leave-one-out cross-validation. References: Burkner (2017)\n<doi:10.18637/jss.v080.i01>; Burkner (2018) <doi:10.32614/RJ-2018-017>;\nCarpenter et al. (2017) <doi:10.18637/jss.v076.i01>.",
            "name": "r-brms"
        },
        {
            "description": "Convert Statistical Objects into Tidy Tibbles. Summarizes key\ninformation about statistical objects in tidy tibbles. This makes it\neasy to report results, create plots and consistently work with large\nnumbers of models at once. Broom provides three verbs that each provide\ndifferent types of information about a model. tidy() summarizes\ninformation about model components such as coefficients of a regression.\nglance() reports information about an entire model, such as goodness of\nfit measures like AIC and BIC. augment() adds information about\nindividual observations to a dataset, such as fitted values or influence\nmeasures.",
            "name": "r-broom"
        },
        {
            "description": "Companion to Applied Regression. Functions and Datasets to Accompany J.\nFox and S. Weisberg, An R Companion to Applied Regression, Second\nEdition, Sage, 2011.",
            "name": "r-car"
        },
        {
            "description": "Classification and Regression Training. Misc functions for training and\nplotting classification and regression models.",
            "name": "r-caret"
        },
        {
            "description": "Generalised Additive Models for Location Scale and Shape. Functions for\nfitting the Generalized Additive Models for Location Scale and Shape\nintroduced by Rigby and Stasinopoulos (2005),\n<doi:10.1111/j.1467-9876.2005.00510.x>. The models use a distributional\nregression approach where all the parameters of the conditional\ndistribution of the response variable are modelled using explanatory\nvariables.",
            "name": "r-gamlss"
        },
        {
            "description": "Linear Mixed-Effects Models using 'Eigen' and S4. Fit linear and\ngeneralized linear mixed-effects models. The models and their components\nare represented using S4 classes and methods. The core computational\nalgorithms are implemented using the 'Eigen' C++ library for numerical\nlinear algebra and 'RcppEigen' \"glue\".",
            "name": "r-lme4"
        },
        {
            "description": "Meta-Analysis Package for R. A comprehensive collection of functions for\nconducting meta-analyses in R. The package includes functions to\ncalculate various effect sizes or outcome measures, fit equal-, fixed-,\nrandom-, and mixed-effects models to such data, carry out moderator and\nmeta-regression analyses, and create various types of meta-analytical\nplots (e.g., forest, funnel, radial, L'Abbe, Baujat, bubble, and GOSH\nplots). For meta-analyses of binomial and person-time data, the package\nalso provides functions that implement specialized methods, including\nthe Mantel-Haenszel method, Peto's method, and a variety of suitable\ngeneralized linear (mixed-effects) models (i.e., mixed-effects logistic\nand Poisson regression models). Finally, the package provides\nfunctionality for fitting meta-analytic multivariate/multilevel models\nthat account for non-independent sampling errors and/or true effects\n(e.g., due to the inclusion of multiple treatment studies, multiple\nendpoints, or other forms of clustering). Network meta-analyses and\nmeta-analyses accounting for known correlation structures (e.g., due to\nphylogenetic relatedness) can also be conducted. An introduction to the\npackage can be found in Viechtbauer (2010) <doi:10.18637/jss.v036.i03>.",
            "name": "r-metafor"
        },
        {
            "description": "Mixed GAM Computation Vehicle with Automatic Smoothness Estimation.\nGeneralized additive (mixed) models, some of their extensions and other\ngeneralized ridge regression with multiple smoothing parameter\nestimation by (Restricted) Marginal Likelihood, Generalized Cross\nValidation and similar, or using iterated nested Laplace approximation\nfor fully Bayesian inference. See Wood (2017)\n<doi:10.1201/9781315370279> for an overview. Includes a gam() function,\na wide variety of smoothers, 'JAGS' support and distributions beyond the\nexponential family.",
            "name": "r-mgcv"
        },
        {
            "description": "Analyze Illumina Infinium DNA methylation arrays. Tools to analyze &\nvisualize Illumina Infinium methylation arrays.",
            "name": "r-minfi"
        },
        {
            "description": "Regression Models for Ordinal Data. Implementation of cumulative link\n(mixed) models also known as ordered regression models, proportional\nodds models, proportional hazards models for grouped survival times and\nordered logit/probit/... models. Estimation is via maximum likelihood\nand mixed models are fitted with the Laplace approximation and adaptive\nGauss-Hermite quadrature. Multiple random effect terms are allowed and\nthey may be nested, crossed or partially nested/crossed. Restrictions of\nsymmetry and equidistance can be imposed on the thresholds (cut-\npoints/intercepts). Standard model methods are available (summary,\nanova, drop-methods, step, confint, predict etc.) in addition to profile\nmethods and slice methods for visualizing the likelihood function and\nchecking convergence.",
            "name": "r-ordinal"
        },
        {
            "description": "Phylogenetic Tools for Comparative Biology (and Other Things). A wide\nrange of functions for phylogenetic analysis. Functionality is\nconcentrated in phylogenetic comparative biology, but also includes\nnumerous methods for visualizing, manipulating, reading or writing, and\neven inferring phylogenetic trees and data. Included among the functions\nin phylogenetic comparative biology are various for ancestral state\nreconstruction, model-fitting, simulation of phylogenies and data, and\nmultivariate analysis. There are a broad range of plotting methods for\nphylogenies and comparative data which include, but are not restricted\nto, methods for mapping trait evolution on trees, for projecting trees\ninto phenotypic space or a geographic map, and for visualizing\ncorrelated speciation between trees. Finally, there are a number of\nfunctions for reading, writing, analyzing, inferring, simulating, and\nmanipulating phylogenetic trees and comparative data not covered by\nother packages. For instance, there are functions for randomly or non-\nrandomly attaching species or clades to a phylogeny, for estimating\nsupertrees or consensus phylogenies from a set, for simulating trees and\nphylogenetic data under a range of models, and for a wide variety of\nother manipulations and analyses that phylogenetic biologists might find\nuseful in their research.",
            "name": "r-phytools"
        },
        {
            "description": "R tools for integrating phylogenies and ecology. Functions for phylocom\nintegration, community analyses, null-models, traits and evolution.\nImplements numerous ecophylogenetic approaches including measures of\ncommunity phylogenetic and trait diversity, phylogenetic signal,\nestimation of trait values for unobserved taxa, null models for\ncommunity and phylogeny randomizations, and utility functions for data\ninput/output and phylogeny plotting. A full description of package\nfunctionality and methods are provided by Kembel et al. (2010)\n<doi:10.1093/bioinformatics/btq166>.",
            "name": "r-picante"
        },
        {
            "description": "Procedures for Psychological, Psychometric, and Personality Research. A\ngeneral purpose toolbox for personality, psychometric theory and\nexperimental psychology. Functions are primarily for multivariate\nanalysis and scale construction using factor analysis, principal\ncomponent analysis, cluster analysis and reliability analysis, although\nothers provide basic descriptive statistics. Item Response Theory is\ndone using factor analysis of tetrachoric and polychoric correlations.\nFunctions for analyzing data at multiple levels include within and\nbetween group statistics, including correlations and factor analysis.\nFunctions for simulating and testing particular item and test structures\nare included. Several functions serve as a useful front end for\nstructural equation modeling. Graphical displays of path diagrams,\nfactor analysis and structural equation models are created using basic\ngraphics. Some of the functions are written to support a book on\npsychometric theory as well as publications in personality research. For\nmore information, see the <http://personality-project.org/r> web page.",
            "name": "r-psych"
        },
        {
            "description": "Regression Modeling Strategies. Regression modeling, testing,\nestimation, validation, graphics, prediction, and typesetting by storing\nenhanced model design attributes in the fit. 'rms' is a collection of\nfunctions that assist with and streamline modeling. It also contains\nfunctions for binary and ordinal logistic regression models, ordinal\nmodels for continuous Y with a variety of distribution families, and the\nBuckley-James multiple regression model for right-censored responses,\nand implements penalized maximum likelihood estimation for logistic and\nordinary linear models. 'rms' works with almost any regression model,\nbut it was especially written to work with binary or ordinal regression\nmodels, Cox regression, accelerated failure time models, ordinary linear\nmodels, the Buckley-James model, generalized least squares for serially\nor spatially correlated observations, generalized linear models, and\nquantile regression.",
            "name": "r-rms"
        },
        {
            "description": "Regression Models with Break-Points / Change-Points Estimation. Given a\nregression model, segmented 'updates' it by adding one or more segmented\n(i.e., piece-wise linear) relationships. Several variables with multiple\nbreakpoints are allowed. The estimation method is discussed in Muggeo\n(2003, <doi:10.1002/sim.1545>) and illustrated in Muggeo (2008,\n<https://www.r-project.org/doc/Rnews/Rnews_2008-1.pdf>). An approach for\nhypothesis testing is presented in Muggeo (2016,\n<doi:10.1080/00949655.2016.1149855>), and interval estimation for the\nbreakpoint is discussed in Muggeo (2017, <doi:10.1111/anzs.12200>).",
            "name": "r-segmented"
        },
        {
            "description": "Spatial Regression Analysis. A collection of all the estimation\nfunctions for spatial cross-sectional models (on lattice/areal data\nusing spatial weights matrices) contained up to now in 'spdep', 'sphet'\nand 'spse'. These model fitting functions include maximum likelihood\nmethods for cross-sectional models proposed by 'Cliff' and 'Ord' (1973,\nISBN:0850860369) and (1981, ISBN:0850860814), fitting methods initially\ndescribed by 'Ord' (1975) <doi:10.1080/01621459.1975.10480272>. The\nmodels are further described by 'Anselin' (1988)\n<doi:10.1007/978-94-015-7799-1>. Spatial two stage least squares and\nspatial general method of moment models initially proposed by 'Kelejian'\nand 'Prucha' (1998) <doi:10.1023/A:1007707430416> and (1999)\n<doi:10.1111/1468-2354.00027> are provided. Impact methods and MCMC\nfitting methods proposed by 'LeSage' and 'Pace' (2009)\n<doi:10.1201/9781420064254> are implemented for the family of cross-\nsectional spatial regression models. Methods for fitting the log\ndeterminant term in maximum likelihood and MCMC fitting are compared by\n'Bivand et al.' (2013) <doi:10.1111/gean.12008>, and model fitting\nmethods by 'Bivand' and 'Piras' (2015) <doi:10.18637/jss.v063.i18>; both\nof these articles include extensive lists of references. 'spatialreg' >=\n1.1-* correspond to 'spdep' >= 1.1-1, in which the model fitting\nfunctions are deprecated and pass through to 'spatialreg', but will mask\nthose in 'spatialreg'. From versions 1.2-*, the functions will be made\ndefunct in 'spdep'.",
            "name": "r-spatialreg"
        },
        {
            "description": "Spatial Point Pattern Analysis, Model-Fitting, Simulation, Tests.\nComprehensive open-source toolbox for analysing Spatial Point Patterns.\nFocused mainly on two-dimensional point patterns, including\nmultitype/marked points, in any spatial region. Also supports three-\ndimensional point patterns, space-time point patterns in any number of\ndimensions, point patterns on a linear network, and patterns of other\ngeometrical objects. Supports spatial covariate data such as pixel\nimages. Contains over 2000 functions for plotting spatial data,\nexploratory data analysis, model-fitting, simulation, spatial sampling,\nmodel diagnostics, and formal inference. Data types include point\npatterns, line segment patterns, spatial windows, pixel images,\ntessellations, and linear networks. Exploratory methods include quadrat\ncounts, K-functions and their simulation envelopes, nearest neighbour\ndistance and empty space statistics, Fry plots, pair correlation\nfunction, kernel smoothed intensity, relative risk estimation with\ncross-validated bandwidth selection, mark correlation functions,\nsegregation indices, mark dependence diagnostics, and kernel estimates\nof covariate effects. Formal hypothesis tests of random pattern (chi-\nsquared, Kolmogorov-Smirnov, Monte Carlo, Diggle-Cressie-Loosmore-Ford,\nDao-Genton, two-stage Monte Carlo) and tests for covariate effects (Cox-\nBerman-Waller-Lawson, Kolmogorov-Smirnov, ANOVA) are also supported.\nParametric models can be fitted to point pattern data using the\nfunctions ppm(), kppm(), slrm(), dppm() similar to glm(). Types of\nmodels include Poisson, Gibbs and Cox point processes, Neyman-Scott\ncluster processes, and determinantal point processes. Models may involve\ndependence on covariates, inter-point interaction, cluster formation and\ndependence on marks. Models are fitted by maximum likelihood, logistic\nregression, minimum contrast, and composite likelihood methods. A model\ncan be fitted to a list of point patterns (replicated point pattern\ndata) using the function mppm(). The model can include random effects\nand fixed effects depending on the experimental design, in addition to\nall the features listed above. Fitted point process models can be\nsimulated, automatically. Formal hypothesis tests of a fitted model are\nsupported (likelihood ratio test, analysis of deviance, Monte Carlo\ntests) along with basic tools for model selection (stepwise(), AIC())\nand variable selection (sdr). Tools for validating the fitted model\ninclude simulation envelopes, residuals, residual plots and Q-Q plots,\nleverage and influence diagnostics, partial residuals, and added\nvariable plots.",
            "name": "r-spatstat"
        },
        {
            "description": "Core Functionality of the 'spatstat' Family. Functionality for data\nanalysis and modelling of spatial data, mainly spatial point patterns,\nin the 'spatstat' family of packages. (Excludes analysis of spatial data\non a linear network, which is covered by the separate package\n'spatstat.linnet'.) Exploratory methods include quadrat counts,\nK-functions and their simulation envelopes, nearest neighbour distance\nand empty space statistics, Fry plots, pair correlation function, kernel\nsmoothed intensity, relative risk estimation with cross-validated\nbandwidth selection, mark correlation functions, segregation indices,\nmark dependence diagnostics, and kernel estimates of covariate effects.\nFormal hypothesis tests of random pattern (chi-squared, Kolmogorov-\nSmirnov, Monte Carlo, Diggle-Cressie-Loosmore-Ford, Dao-Genton, two-\nstage Monte Carlo) and tests for covariate effects (Cox-Berman-Waller-\nLawson, Kolmogorov-Smirnov, ANOVA) are also supported. Parametric models\ncan be fitted to point pattern data using the functions ppm(), kppm(),\nslrm(), dppm() similar to glm(). Types of models include Poisson, Gibbs\nand Cox point processes, Neyman-Scott cluster processes, and\ndeterminantal point processes. Models may involve dependence on\ncovariates, inter-point interaction, cluster formation and dependence on\nmarks. Models are fitted by maximum likelihood, logistic regression,\nminimum contrast, and composite likelihood methods. A model can be\nfitted to a list of point patterns (replicated point pattern data) using\nthe function mppm(). The model can include random effects and fixed\neffects depending on the experimental design, in addition to all the\nfeatures listed above. Fitted point process models can be simulated,\nautomatically. Formal hypothesis tests of a fitted model are supported\n(likelihood ratio test, analysis of deviance, Monte Carlo tests) along\nwith basic tools for model selection (stepwise(), AIC()) and variable\nselection (sdr). Tools for validating the fitted model include\nsimulation envelopes, residuals, residual plots and Q-Q plots, leverage\nand influence diagnostics, partial residuals, and added variable plots.",
            "name": "r-spatstat-core"
        },
        {
            "description": "Exploratory Data Analysis for the 'spatstat' Family. Functionality for\nexploratory data analysis and nonparametric analysis of spatial data,\nmainly spatial point patterns, in the 'spatstat' family of packages.\n(Excludes analysis of spatial data on a linear network, which is covered\nby the separate package 'spatstat.linnet'.) Methods include quadrat\ncounts, K-functions and their simulation envelopes, nearest neighbour\ndistance and empty space statistics, Fry plots, pair correlation\nfunction, kernel smoothed intensity, relative risk estimation with\ncross-validated bandwidth selection, mark correlation functions,\nsegregation indices, mark dependence diagnostics, and kernel estimates\nof covariate effects. Formal hypothesis tests of random pattern (chi-\nsquared, Kolmogorov-Smirnov, Monte Carlo, Diggle-Cressie-Loosmore-Ford,\nDao-Genton, two-stage Monte Carlo) and tests for covariate effects (Cox-\nBerman-Waller-Lawson, Kolmogorov-Smirnov, ANOVA) are also supported.",
            "name": "r-spatstat-explore"
        },
        {
            "description": "Parametric Statistical Modelling and Inference for the 'spatstat'\nFamily. Functionality for parametric statistical modelling and inference\nfor spatial data, mainly spatial point patterns, in the 'spatstat'\nfamily of packages. (Excludes analysis of spatial data on a linear\nnetwork, which is covered by the separate package 'spatstat.linnet'.)\nSupports parametric modelling, formal statistical inference, and model\nvalidation. Parametric models include Poisson point processes, Cox point\nprocesses, Neyman-Scott cluster processes, Gibbs point processes and\ndeterminantal point processes. Models can be fitted to data using\nmaximum likelihood, maximum pseudolikelihood, maximum composite\nlikelihood and the method of minimum contrast. Fitted models can be\nsimulated and predicted. Formal inference includes hypothesis tests\n(quadrat counting tests, Cressie-Read tests, Clark-Evans test, Berman\ntest, Diggle-Cressie-Loosmore-Ford test, scan test, studentised\npermutation test, segregation test, ANOVA tests of fitted models,\nadjusted composite likelihood ratio test, envelope tests, Dao-Genton\ntest, balanced independent two-stage test), confidence intervals for\nparameters, and prediction intervals for point counts. Model validation\ntechniques include leverage, influence, partial residuals, added\nvariable plots, diagnostic plots, pseudoscore residual plots, model\ncompensators and Q-Q plots.",
            "name": "r-spatstat-model"
        },
        {
            "description": "Spatial Dependence: Weighting Schemes, Statistics. A collection of\nfunctions to create spatial weights matrix objects from polygon\n'contiguities', from point patterns by distance and tessellations, for\nsummarizing these objects, and for permitting their use in spatial data\nanalysis, including regional aggregation by minimum spanning tree; a\ncollection of tests for spatial 'autocorrelation', including global\n'Morans I' and 'Gearys C' proposed by 'Cliff' and 'Ord' (1973, ISBN:\n0850860369) and (1981, ISBN: 0850860814), 'Hubert/Mantel' general cross\nproduct statistic, Empirical Bayes estimates and 'Assuncao/Reis' (1999)\n<doi:10.1002/(SICI)1097-0258(19990830)18:16%3C2147::AID-SIM179%3E3.0.CO",
            "name": "r-spdep"
        },
        {
            "description": "Unit Root and Cointegration Tests for Time Series Data. Unit root and\ncointegration tests encountered in applied econometric analysis are\nimplemented.",
            "name": "r-urca"
        }
    ],
    "description": "Linear and Nonlinear Mixed Effects Models. Fit and compare Gaussian\nlinear and nonlinear mixed-effects models.\n",
    "homepage": "https://cloud.r-project.org/package=nlme",
    "latest_version": "3.1-166",
    "maintainers": [],
    "name": "r-nlme",
    "patches": [],
    "resources": [],
    "variants": [
        {
            "default": "generic",
            "description": "Build systems supported by the package",
            "name": "build_system"
        }
    ],
    "versions": [
        {
            "name": "3.1-166",
            "sha256": "237a14ee8d78755b11a7efe234b95be40b46fbdd1b4aaf463f6d532be1909762"
        },
        {
            "name": "3.1-162",
            "sha256": "ba6da2575554afa2614c4cba9971f8a9f8a07622d201284cb78899f3d6a2dc67"
        },
        {
            "name": "3.1-160",
            "sha256": "d4454623194876b083774c662fd223bc3b9e8325824cb758b8adecd5dc0d8a08"
        },
        {
            "name": "3.1-159",
            "sha256": "9bb05f5c3146e2d75078e668821485a3e9ca246fd5d7db2ef1963d3735d919bf"
        },
        {
            "name": "3.1-157",
            "sha256": "ddf2a2729dcb6cbaaf579d8093cf62fc41736648b5e8b74afc3acc7a9ae1d96c"
        },
        {
            "name": "3.1-155",
            "sha256": "9f390f842852422921b5845130ea73c1f006d7bb5e988e82f728093a0cbdff4f"
        },
        {
            "name": "3.1-153",
            "sha256": "3d27a98edf1b16ee868949e823ac0babbf10c937a7220d648b7ef9480cd680e3"
        },
        {
            "name": "3.1-152",
            "sha256": "5b65d1b1f121caf29e60341acf6d85e267fd94ed517748cf42d36359f74e515e"
        },
        {
            "name": "3.1-151",
            "sha256": "a2c626bad68bf582663005170d1b9d844a10dca8efb13597f15ffb4b1fe886ca"
        },
        {
            "name": "3.1-141",
            "sha256": "910046260a03d8f776ac7b0766b5adee91556829d0d8a70165b2c695ce038056"
        },
        {
            "name": "3.1-139",
            "sha256": "0460fc69d85122177e7ef01bad665d56bcaf63d31bdbfdbdfdcba2c082085739"
        },
        {
            "name": "3.1-131",
            "sha256": "79daa167eb9bc7d8dba506da4b24b5250665b051d4e0a51dfccbb0087fdb564c"
        },
        {
            "name": "3.1-130",
            "sha256": "ec576bd906ef2e1c79b6a4382743d425846f63be2a43de1cce6aa397b40e290e"
        }
    ],
    "versions_deprecated": []
}