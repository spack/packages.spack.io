{
    "aliases": [],
    "build_system": "AutotoolsPackage",
    "conflicts": [
        {
            "description": null,
            "name": "arch=windows-None-None",
            "spec": "build_system=autotools"
        }
    ],
    "dependencies": [
        {
            "description": "Lightweight but flexible shim designed to rectify the incompatibilities\nbetween the Accelerate/vecLib BLAS and LAPACK libraries shipped with\nmacOS and FORTRAN code compiled with modern compilers such as GNU\nFortran.",
            "name": "blas"
        },
        {
            "description": "bzip2 is a freely available, patent free high-quality data compressor.\nIt typically compresses files to within 10% to 15% of the best available\ntechniques (the PPM family of statistical compressors), whilst being\naround twice as fast at compression and six times faster at\ndecompression.",
            "name": "bzip2"
        },
        {
            "description": "The NVIDIA HPC SDK is a comprehensive suite of compilers, libraries and\ntools essential to maximizing developer productivity and the performance\nand portability of HPC applications. The NVIDIA HPC SDK C, C++, and\nFortran compilers support GPU acceleration of HPC modeling and\nsimulation applications with standard C++ and Fortran, OpenACC\ndirectives, and CUDA. GPU-accelerated math libraries maximize\nperformance on common HPC algorithms, and optimized communications\nlibraries enable standards-based multi-GPU and scalable systems\nprogramming. Performance profiling and debugging tools simplify porting\nand optimization of HPC applications.",
            "name": "c"
        },
        {
            "description": "Cairo is a 2D graphics library with support for multiple output devices.",
            "name": "cairo"
        },
        {
            "description": "cURL is an open source command line tool and library for transferring\ndata with URL syntax",
            "name": "curl"
        },
        {
            "description": "The NVIDIA HPC SDK is a comprehensive suite of compilers, libraries and\ntools essential to maximizing developer productivity and the performance\nand portability of HPC applications. The NVIDIA HPC SDK C, C++, and\nFortran compilers support GPU acceleration of HPC modeling and\nsimulation applications with standard C++ and Fortran, OpenACC\ndirectives, and CUDA. GPU-accelerated math libraries maximize\nperformance on common HPC algorithms, and optimized communications\nlibraries enable standards-based multi-GPU and scalable systems\nprogramming. Performance profiling and debugging tools simplify porting\nand optimization of HPC applications.",
            "name": "cxx"
        },
        {
            "description": "The NVIDIA HPC SDK is a comprehensive suite of compilers, libraries and\ntools essential to maximizing developer productivity and the performance\nand portability of HPC applications. The NVIDIA HPC SDK C, C++, and\nFortran compilers support GPU acceleration of HPC modeling and\nsimulation applications with standard C++ and Fortran, OpenACC\ndirectives, and CUDA. GPU-accelerated math libraries maximize\nperformance on common HPC algorithms, and optimized communications\nlibraries enable standards-based multi-GPU and scalable systems\nprogramming. Performance profiling and debugging tools simplify porting\nand optimization of HPC applications.",
            "name": "fortran"
        },
        {
            "description": "GNU internationalization (i18n) and localization (l10n) library.",
            "name": "gettext"
        },
        {
            "description": "GNU Make is a tool which controls the generation of executables and\nother non-source files of a program from the program's source files.",
            "name": "gmake"
        },
        {
            "description": "The GNU config.guess and config.sub scripts versioned by timestamp.\nThis package can be used as a build dependency for autotools packages\nthat ship a tarball with outdated config.guess and config.sub files.",
            "name": "gnuconfig"
        },
        {
            "description": "The Harfbuzz package contains an OpenType text shaping engine.",
            "name": "harfbuzz"
        },
        {
            "description": "ICU is a mature, widely used set of C/C++ and Java libraries providing\nUnicode and Globalization support for software applications. ICU4C is\nthe C/C++ interface.",
            "name": "icu4c"
        },
        {
            "description": "The free and opensource java implementation",
            "name": "java"
        },
        {
            "description": "MozJPEG is a patched version of libjpeg-turbo which improves JPEG\ncompression efficiency achieving higher visual quality and smaller file\nsizes at the same time",
            "name": "jpeg"
        },
        {
            "description": "Lightweight but flexible shim designed to rectify the incompatibilities\nbetween the Accelerate/vecLib BLAS and LAPACK libraries shipped with\nmacOS and FORTRAN code compiled with modern compilers such as GNU\nFortran.",
            "name": "lapack"
        },
        {
            "description": "libpng is the official PNG reference library.",
            "name": "libpng"
        },
        {
            "description": "LibTIFF - Tag Image File Format (TIFF) Library and Utilities.",
            "name": "libtiff"
        },
        {
            "description": "Libtirpc is a port of Suns Transport-Independent RPC library to Linux.",
            "name": "libtirpc"
        },
        {
            "description": "libX11 - Core X11 protocol client library.",
            "name": "libx11"
        },
        {
            "description": "This library contains miscellaneous utilities and is not part of the\nXlib standard. It contains routines which only use public interfaces so\nthat it may be layered on top of any proprietary implementation of Xlib\nor Xt.",
            "name": "libxmu"
        },
        {
            "description": "libXt - X Toolkit Intrinsics library.",
            "name": "libxt"
        },
        {
            "description": "The ncurses (new curses) library is a free software emulation of curses\nin System V Release 4.0, and more. It uses terminfo format, supports\npads and color and multiple highlights and forms characters and\nfunction-key mapping, and has all the other SYSV-curses enhancements\nover BSD curses.",
            "name": "ncurses"
        },
        {
            "description": "Pango is a library for laying out and rendering of text, with an\nemphasis on internationalization. It can be used anywhere that text\nlayout is needed, though most of the work on Pango so far has been done\nin the context of the GTK+ widget toolkit.",
            "name": "pango"
        },
        {
            "description": "The PCRE package contains Perl Compatible Regular Expression libraries.\nThese are useful for implementing regular expression pattern matching\nusing the same syntax and semantics as Perl 5.",
            "name": "pcre"
        },
        {
            "description": "The PCRE2 package contains Perl Compatible Regular Expression libraries.\nThese are useful for implementing regular expression pattern matching\nusing the same syntax and semantics as Perl 5.",
            "name": "pcre2"
        },
        {
            "description": "The GNU Readline library provides a set of functions for use by\napplications that allow users to edit command lines as they are typed\nin. Both Emacs and vi editing modes are available. The Readline library\nincludes additional functions to maintain a list of previously-entered\ncommand lines, to recall and perhaps reedit those lines, and perform\ncsh-like history expansion on previous commands.",
            "name": "readline"
        },
        {
            "description": "Texinfo is the official documentation format of the GNU project. It was\ninvented by Richard Stallman and Bob Chassell many years ago, loosely\nbased on Brian Reid's Scribe and other formatting languages of the time.\nIt is used by many non-GNU projects as well.",
            "name": "texinfo"
        },
        {
            "description": "Tk is a graphical user interface toolkit that takes developing desktop\napplications to a higher level than conventional approaches. Tk is the\nstandard GUI not only for Tcl, but for many other dynamic languages, and\ncan produce rich, native applications that run unchanged across Windows,\nMac OS X, Linux and more.",
            "name": "tk"
        },
        {
            "description": "GNU which - is a utility that is used to find which executable (or alias\nor shell function) is executed when entered on the shell prompt.",
            "name": "which"
        },
        {
            "description": "XZ Utils is free general-purpose data compression software with high\ncompression ratio. XZ Utils were written for POSIX-like systems, but\nalso work on some not-so-POSIX systems. XZ Utils are the successor to\nLZMA Utils.",
            "name": "xz"
        },
        {
            "description": "A free, general-purpose, legally unencumbered lossless data-compression\nlibrary.",
            "name": "zlib"
        },
        {
            "description": "zlib replacement with optimizations for next generation systems.",
            "name": "zlib-api"
        },
        {
            "description": "Zstandard, or zstd as short version, is a fast lossless compression\nalgorithm, targeting real-time compression scenarios at zlib-level and\nbetter compression ratios.",
            "name": "zstd"
        }
    ],
    "dependent_to": [
        {
            "description": "Angsd is a program for analysing NGS data. The software can handle a\nnumber of different input types from mapped reads to imputed genotype\nprobabilities. Most methods take genotype uncertainty into account\ninstead of basing the analysis on called genotypes. This is especially\nuseful for low and medium depth data.",
            "name": "angsd"
        },
        {
            "description": "breseq is a computational pipeline for finding mutations relative to a\nreference sequence in short-read DNA re-sequencing data for haploid\nmicrobial-sized genomes.",
            "name": "breseq"
        },
        {
            "description": "CleaveLand4: Analysis of degradome data to find sliced miRNA and siRNA\ntargets",
            "name": "cleaveland4"
        },
        {
            "description": "CPAT is an alignment-free method to predict RNA coding potential using\nfour sequence features",
            "name": "cpat"
        },
        {
            "description": "DXT Explorer is an interactive web-based log analysis tool to visualize\nDarshan DXT logs and help understand the I/O behavior of applications.",
            "name": "dxt-explorer"
        },
        {
            "description": "EMEWS Queues for R (EQ/R) Installs EQ/R.",
            "name": "eq-r"
        },
        {
            "description": "Genome Analysis Toolkit Variant Discovery in High-Throughput Sequencing\nData",
            "name": "gatk"
        },
        {
            "description": "HiCUP: a bioinformatics pipeline for processing Hi-C data",
            "name": "hicup"
        },
        {
            "description": "KmerGenie estimates the best k-mer length for genome de novo assembly.",
            "name": "kmergenie"
        },
        {
            "description": "LibPressio metric that runs R code",
            "name": "libpressio-rmetric"
        },
        {
            "description": "METplus is a verification framework that spans a wide range of temporal\n(warn-on-forecast to climate) and spatial (storm to global) scales.",
            "name": "metplus"
        },
        {
            "description": "mlpack is an intuitive, fast, and flexible header-only C++ machine\nlearning library with bindings to other languages. It is meant to be a\nmachine learning analog to LAPACK, and aims to implement a wide array of\nmachine learning methods and functions as a \"swiss army knife\" for\nmachine learning researchers.",
            "name": "mlpack"
        },
        {
            "description": "OrthoFiller: Identifying missing annotations for evolutionarily\nconserved genes.",
            "name": "orthofiller"
        },
        {
            "description": "This package computes informative enrichment and quality measures for\nChIP-seq/DNase-seq/FAIRE-seq/MNase-seq data.",
            "name": "phantompeakqualtools"
        },
        {
            "description": "rpy2 is a redesign and rewrite of rpy. It is providing a low-level\ninterface to R from Python, a proposed high-level interface, including\nwrappers to graphical libraries, as well as R-like structures and\nfunctions.",
            "name": "py-rpy2"
        },
        {
            "description": "RSeQC package provides a number of useful modules that can\ncomprehensively evaluate high throughput sequence data especially RNA-\nseq data.",
            "name": "py-rseqc"
        },
        {
            "description": "The QoRTs software package is a fast, efficient, and portable\nmultifunction toolkit designed to assist in the analysis, quality\ncontrol, and data management of RNA-Seq and DNA-Seq datasets. Its\nprimary function is to aid in the detection and identification of\nerrors, biases, and artifacts produced by high-throughput sequencing\ntechnology.",
            "name": "qorts"
        },
        {
            "description": "A complete tool set for molecular QTL discovery and analysis.",
            "name": "qtltools"
        },
        {
            "description": "Automated Affymetrix Array Analysis Umbrella Package. Umbrella package\nis available for the entire Automated Affymetrix Array Analysis suite of\npackage.",
            "name": "r-a4"
        },
        {
            "description": "Automated Affymetrix Array Analysis Base Package. Base utility functions\nare available for the Automated Affymetrix Array Analysis set of\npackages.",
            "name": "r-a4base"
        },
        {
            "description": "Automated Affymetrix Array Analysis Classification Package.\nFunctionalities for classification of Affymetrix microarray data,\nintegrating within the Automated Affymetrix Array Analysis set of\npackages.",
            "name": "r-a4classif"
        },
        {
            "description": "Automated Affymetrix Array Analysis Core Package. Utility functions for\nthe Automated Affymetrix Array Analysis set of packages.",
            "name": "r-a4core"
        },
        {
            "description": "Automated Affymetrix Array Analysis Preprocessing Package. Utility\nfunctions to pre-process data for the Automated Affymetrix Array\nAnalysis set of packages.",
            "name": "r-a4preproc"
        },
        {
            "description": "Automated Affymetrix Array Analysis Reporting Package. Utility functions\nto facilitate the reporting of the Automated Affymetrix Array Analysis\nReporting set of packages.",
            "name": "r-a4reporting"
        },
        {
            "description": "Averaged gene expression in human brain regions from Allen Brain Atlas.\nProvides the data for the gene expression enrichment analysis conducted\nin the package 'ABAEnrichment'. The package includes three datasets\nwhich are derived from the Allen Brain Atlas: (1) Gene expression data\nfrom Human Brain (adults) averaged across donors, (2) Gene expression\ndata from the Developing Human Brain pooled into five age categories and\naveraged across donors and (3) a developmental effect score based on the\nDeveloping Human Brain expression data. All datasets are restricted to\nprotein coding genes.",
            "name": "r-abadata"
        },
        {
            "description": "Gene expression enrichment in human brain regions. The package\nABAEnrichment is designed to test for enrichment of user defined\ncandidate genes in the set of expressed genes in different human brain\nregions. The core function 'aba_enrich' integrates the expression of the\ncandidate gene set (averaged across donors) and the structural\ninformation of the brain using an ontology, both provided by the Allen\nBrain Atlas project. 'aba_enrich' interfaces the ontology enrichment\nsoftware FUNC to perform the statistical analyses. Additional functions\nprovided in this package like 'get_expression' and 'plot_expression'\nfacilitate exploring the expression data, and besides the standard\ncandidate vs. background gene set enrichment, also three additional\ntests are implemented, e.g. for cases when genes are ranked instead of\ndivided into candidate and background.",
            "name": "r-abaenrichment"
        },
        {
            "description": "Combine Multidimensional Arrays. Combine multidimensional arrays into a\nsingle array. This is a generalization of 'cbind' and 'rbind'. Works\nwith vectors, matrices, and higher-dimensional arrays. Also provides\nfunctions 'adrop', 'asub', and 'afill' for manipulating, extracting and\nreplacing data in arrays.",
            "name": "r-abind"
        },
        {
            "description": "ABSSeq: a new RNA-Seq analysis method based on modelling absolute\nexpression differences. Inferring differential expression genes by\nabsolute counts difference between two groups, utilizing Negative\nbinomial distribution and moderating fold-change according to\nheterogeneity of dispersion across expression level.",
            "name": "r-absseq"
        },
        {
            "description": "Artificial Components Detection of Differentially Expressed Genes. This\npackage provides a multivariate inferential analysis method for\ndetecting differentially expressed genes in gene expression data. It\nuses artificial components, close to the data's principal components but\nwith an exact interpretation in terms of differential genetic\nexpression, to identify differentially expressed genes while controlling\nthe false discovery rate (FDR). The methods on this package are\ndescribed in the vignette or in the article 'Multivariate Method for\nInferential Identification of Differentially Expressed Genes in Gene\nExpression Experiments' by J. P. Acosta, L. Lopez-Kleine and S. Restrepo\n(2015, pending publication).",
            "name": "r-acde"
        },
        {
            "description": "ACE and AVAS for Selecting Multiple Regression Transformations. Two\nnonparametric methods for multiple regression transform selection are\nprovided. The first, Alternative Conditional Expectations (ACE), is an\nalgorithm to find the fixed point of maximal correlation, i.e. it finds\na set of transformed response variables that maximizes R^2 using\nsmoothing functions [see Breiman, L., and J.H. Friedman. 1985.\n\"Estimating Optimal Transformations for Multiple Regression and\nCorrelation\". Journal of the American Statistical Association.\n80:580-598. <doi:10.1080/01621459.1985.10478157>]. Also included is the\nAdditivity Variance Stabilization (AVAS) method which works better than\nACE when correlation is low [see Tibshirani, R.. 1986. \"Estimating\nTransformations for Regression via Additivity and Variance\nStabilization\". Journal of the American Statistical Association.\n83:394-405. <doi:10.1080/01621459.1988.10478610>]. A good introduction\nto these two methods is in chapter 16 of Frank Harrel's \"Regression\nModeling Strategies\" in the Springer Series in Statistics.",
            "name": "r-acepack"
        },
        {
            "description": "Classes and functions for Array Comparative Genomic Hybridization data.\nFunctions for reading aCGH data from image analysis output files and\nclone information files, creation of aCGH S3 objects for storing these\ndata. Basic methods for accessing/replacing, subsetting, printing and\nplotting aCGH objects.",
            "name": "r-acgh"
        },
        {
            "description": "Algorithms for Calculating Microarray Enrichment (ACME). ACME\n(Algorithms for Calculating Microarray Enrichment) is a set of tools for\nanalysing tiling array ChIP/chip, DNAse hypersensitivity, or other\nexperiments that result in regions of the genome showing \"enrichment\".\nIt does not rely on a specific array technology (although the array\nshould be a \"tiling\" array), is very general (can be applied in\nexperiments resulting in regions of enrichment), and is very insensitive\nto array noise or normalization methods. It is also very fast and can be\napplied on whole-genome tiling array experiments quite easily with\nenough memory.",
            "name": "r-acme"
        },
        {
            "description": "The R Package Ada for Stochastic Boosting. Performs discrete, real, and\ngentle boost under both exponential and logistic loss on a given data\nset. The package ada provides a straightforward, well-documented, and\nbroad boosting routine for classification, ideally suited for small to\nmoderate-sized data sets.",
            "name": "r-ada"
        },
        {
            "description": "Applies Multiclass AdaBoost.M1, SAMME and Bagging. It implements Freund\nand Schapire's Adaboost.M1 algorithm and Breiman's Bagging algorithm\nusing classification trees as individual classifiers. Once these\nclassifiers have been trained, they can be used to predict on new data.\nAlso, cross validation estimation of the error can be done. Since\nversion 2.0 the function margins() is available to calculate the margins\nfor these classifiers. Also a higher flexibility is achieved giving\naccess to the rpart.control() argument of 'rpart'. Four important new\nfeatures were introduced on version 3.0, AdaBoost-SAMME (Zhu et al.,\n2009) is implemented and a new function errorevol() shows the error of\nthe ensembles as a function of the number of iterations. In addition,\nthe ensembles can be pruned using the option 'newmfinal' in the\npredict.bagging() and predict.boosting() functions and the posterior\nprobability of each class for observations can be obtained. Version 3.1\nmodifies the relative importance measure to take into account the gain\nof the Gini index given by a variable in each tree and the weights of\nthese trees. Version 4.0 includes the margin-based ordered aggregation\nfor Bagging pruning (Guo and Boukir, 2013) and a function to auto prune\nthe 'rpart' tree. Moreover, three new plots are also available\nimportanceplot(), plot.errorevol() and plot.margins(). Version 4.1\nallows to predict on unlabeled data. Version 4.2 includes the parallel\ncomputation option for some of the functions.",
            "name": "r-adabag"
        },
        {
            "description": "Analysis of Ecological Data : Exploratory and Euclidean Methods in\nEnvironmental Sciences. Tools for multivariate data analysis. Several\nmethods are provided for the analysis (i.e., ordination) of one-table\n(e.g., principal component analysis, correspondence analysis), two-table\n(e.g., coinertia analysis, redundancy analysis), three-table (e.g., RLQ\nanalysis) and K-table (e.g., STATIS, multiple coinertia analysis). The\nphilosophy of the package is described in Dray and Dufour (2007)\n<doi:10.18637/jss.v022.i04>.",
            "name": "r-ade4"
        },
        {
            "description": "Exploratory Analysis of Genetic and Genomic Data. Toolset for the\nexploration of genetic and genomic data. Adegenet provides formal (S4)\nclasses for storing and handling various genetic data, including genetic\nmarkers with varying ploidy and hierarchical population structure\n('genind' class), alleles counts by populations ('genpop'), and genome-\nwide SNP data ('genlight'). It also implements original multivariate\nmethods (DAPC, sPCA), graphics, statistical tests, simulation tools,\ndistance and similarity measures, and several spatial methods. A range\nof both empirical and simulated datasets is also provided to illustrate\nvarious methods.",
            "name": "r-adegenet"
        },
        {
            "description": "An S4 Lattice-Based Package for the Representation of Multivariate Data.\nGraphical functionalities for the representation of multivariate data.\nIt is a complete re-implementation of the functions available in the\n'ade4' package.",
            "name": "r-adegraphics"
        },
        {
            "description": "Exploratory Analyses for the Phylogenetic Comparative Method.\nMultivariate tools to analyze comparative data, i.e. a phylogeny and\nsome traits measured for each taxa.",
            "name": "r-adephylo"
        },
        {
            "description": "Multivariate Multiscale Spatial Analysis. Tools for the multiscale\nspatial analysis of multivariate data. Several methods are based on the\nuse of a spatial weighting matrix and its eigenvector decomposition\n(Moran's Eigenvectors Maps, MEM). Several approaches are described in\nthe review Dray et al (2012) <doi:10.1890/11-1183.1>.",
            "name": "r-adespatial"
        },
        {
            "description": "Anderson-Darling GoF test. Anderson-Darling GoF test with p-value\ncalculation based on Marsaglia's 2004 paper 'Evaluating the Anderson-\nDarling Distribution'.",
            "name": "r-adgoftest"
        },
        {
            "description": "Annotation-Driven Clustering. This package implements clustering of\nmicroarray gene expression profiles according to functional annotations.\nFor each term genes are annotated to, splits into two subclasses are\ncomputed and a significance of the supporting gene set is determined.",
            "name": "r-adsplit"
        },
        {
            "description": "Applied Econometrics with R. Functions, data sets, examples, demos, and\nvignettes for the book Christian Kleiber and Achim Zeileis (2008),\nApplied Econometrics with R, Springer-Verlag, New York. ISBN\n978-0-387-77316-2.",
            "name": "r-aer"
        },
        {
            "description": "Analysis of Factorial Experiments. Convenience functions for analyzing\nfactorial experiments using ANOVA or mixed models. aov_ez(), aov_car(),\nand aov_4() allow specification of between, within (i.e., repeated-\nmeasures), or mixed (i.e., split-plot) ANOVAs for data in long format\n(i.e., one observation per row), automatically aggregating multiple\nobservations per individual and cell of the design. mixed() fits mixed\nmodels using lme4::lmer() and computes p-values for all fixed effects\nusing either Kenward-Roger or Satterthwaite approximation for degrees of\nfreedom (LMM only), parametric bootstrap (LMMs and GLMMs), or likelihood\nratio tests (LMMs and GLMMs). afex_plot() provides a high-level\ninterface for interaction or one-way plots using ggplot2, combining raw\ndata and model estimates. afex uses type 3 sums of squares as default\n(imitating commercial statistical software).",
            "name": "r-afex"
        },
        {
            "description": "Affymetrix File Parsing SDK. Package for parsing Affymetrix files (CDF,\nCEL, CHP, BPMAP, BAR). It provides methods for fast and memory efficient\nparsing of Affymetrix files using the Affymetrix' Fusion SDK. Both\nASCII- and binary-based files are supported. Currently, there are\nmethods for reading chip definition file (CDF) and a cell intensity file\n(CEL). These files can be read either in full or in part. For example,\nprobe signals from a few probesets can be extracted very quickly from a\nset of CEL files into a convenient list structure.",
            "name": "r-affxparser"
        },
        {
            "description": "Methods for Affymetrix Oligonucleotide Arrays. The package contains\nfunctions for exploratory oligonucleotide array analysis. The dependence\non tkWidgets only concerns few convenience functions. 'affy' is fully\nfunctional without it.",
            "name": "r-affy"
        },
        {
            "description": "Graphics Toolbox for Assessment of Affymetrix Expression Measures. The\npackage contains functions that can be used to compare expression\nmeasures for Affymetrix Oligonucleotide Arrays.",
            "name": "r-affycomp"
        },
        {
            "description": "Affymetrix GeneChip software compatibility. This package provides an\ninterface to Affymetrix chip annotation and sample attribute files. The\npackage allows an easy way for users to download and manage local data\nbases of Affynmetrix NetAffx annotation files. The package also provides\naccess to GeneChip Operating System (GCOS) and GeneChip Command Console\n(AGCC)-compatible sample annotation files.",
            "name": "r-affycompatible"
        },
        {
            "description": "structured corruption of affymetrix cel file data. structured corruption\nof cel file data to demonstrate QA effectiveness",
            "name": "r-affycontam"
        },
        {
            "description": "Functions useful for those doing repetitive analyses with Affymetrix\nGeneChips. Various wrapper functions that have been written to\nstreamline the more common analyses that a core Biostatistician might\nsee.",
            "name": "r-affycoretools"
        },
        {
            "description": "Affymetrix Data for Demonstration Purpose. Example datasets of a\nslightly large size. They represent 'real world examples', unlike the\nartificial examples included in the package affy.",
            "name": "r-affydata"
        },
        {
            "description": "Affymetrix Quality Assessment and Analysis Tool. The purpose of this\npackage is to provide a comprehensive and easy-to- use tool for quality\nassessment and to identify differentially expressed genes in the\nAffymetrix gene expression data.",
            "name": "r-affyexpress"
        },
        {
            "description": "Linear Model of background subtraction and the Langmuir isotherm.\naffyILM is a preprocessing tool which estimates gene expression levels\nfor Affymetrix Gene Chips. Input from physical chemistry is employed to\nfirst background subtract intensities before calculating concentrations\non behalf of the Langmuir model.",
            "name": "r-affyilm"
        },
        {
            "description": "Tools for parsing Affymetrix data files. Routines for parsing Affymetrix\ndata files based upon file format information. Primary focus is on\naccessing the CEL and CDF file formats.",
            "name": "r-affyio"
        },
        {
            "description": "Probe Dependent Nearest Neighbours (PDNN) for the affy package. The\npackage contains functions to perform the PDNN method described by Li\nZhang et al.",
            "name": "r-affypdnn"
        },
        {
            "description": "Methods for fitting probe-level models. A package that extends and\nimproves the functionality of the base affy package. Routines that make\nheavy use of compiled code for speed. Central focus is on implementation\nof methods for fitting probe-level models and tools using these models.\nPLM based quality assessment tools.",
            "name": "r-affyplm"
        },
        {
            "description": "QC Report Generation for affyBatch objects. This package creates a QC\nreport for an AffyBatch object. The report is intended to allow the user\nto quickly assess the quality of a set of arrays in an AffyBatch object.",
            "name": "r-affyqcreport"
        },
        {
            "description": "Analyze and correct probe positional bias in microarray data due to RNA\ndegradation. The package helps with the assessment and correction of RNA\ndegradation effects in Affymetrix 3' expression arrays. The parameter d\ngives a robust and accurate measure of RNA integrity. The correction\nremoves the probe positional bias, and thus improves comparability of\nsamples that are affected by RNA degradation.",
            "name": "r-affyrnadegradation"
        },
        {
            "description": "Agreement of Differential Expression Analysis. A tool to evaluate\nagreement of differential expression for cross- species genomics",
            "name": "r-agdex"
        },
        {
            "description": "Agilent expression array processing package. More about what it does\n(maybe more than one line).",
            "name": "r-agilp"
        },
        {
            "description": "Processing and Differential Expression Analysis of Agilent microRNA\nchips. Processing and Analysis of Agilent microRNA data.",
            "name": "r-agimicrorna"
        },
        {
            "description": "Absolute Assignment of Breast Cancer Intrinsic Molecular Subtype. This\npackage contains the AIMS implementation. It contains necessary\nfunctions to assign the five intrinsic molecular subtypes (Luminal A,\nLuminal B, Her2-enriched, Basal-like, Normal-like). Assignments could be\ndone on individual samples as well as on dataset of gene expression\ndata.",
            "name": "r-aims"
        },
        {
            "description": "Analysis Of Differential Abundance Taking Sample Variation Into Account.\nA differential abundance analysis for the comparison of two or more\nconditions. Useful for analyzing data from standard RNA-seq or meta-RNA-\nseq assays as well as selected and unselected values from in-vitro\nsequence selections. Uses a Dirichlet-multinomial model to infer\nabundance from counts, optimized for three or more experimental\nreplicates. The method infers biological and sampling variation to\ncalculate the expected false discovery rate, given the variation, based\non a Wilcoxon Rank Sum test and Welch's t-test (via aldex.ttest), a\nKruskal-Wallis test (via aldex.kw), a generalized linear model (via\naldex.glm), or a correlation test (via aldex.corr). All tests report\np-values and Benjamini-Hochberg corrected p-values.",
            "name": "r-aldex2"
        },
        {
            "description": "Investigates Allele Specific Expression. Provides a framework for\nallelic specific expression investigation using RNA-seq data.",
            "name": "r-allelicimbalance"
        },
        {
            "description": "alpine. Fragment sequence bias modeling and correction for RNA-seq\ntranscript abundance estimation.",
            "name": "r-alpine"
        },
        {
            "description": "Multivariate Curve Resolution Alternating Least Squares (MCR-ALS).\nAlternating least squares is often used to resolve components\ncontributing to data with a bilinear structure; the basic technique may\nbe extended to alternating constrained least squares. Commonly applied\nconstraints include unimodality, non-negativity, and normalization of\ncomponents. Several data matrices may be decomposed simultaneously by\nassuming that one of the two matrices in the bilinear decomposition is\nshared between datasets.",
            "name": "r-als"
        },
        {
            "description": "ALS for the Automatic Chemical Exploration of mixtures. Alternating\nLeast Squares (or Multivariate Curve Resolution) for analytical chemical\ndata, in particular hyphenated data where the first direction is a\nretention time axis, and the second a spectral axis. Package builds on\nthe basic als function from the ALS package and adds functionality for\nhigh-throughput analysis, including definition of time windows,\nclustering of profiles, retention time correction, etcetera.",
            "name": "r-alsace"
        },
        {
            "description": "alternative CDF environments (aka probeset mappings). Convenience data\nstructures and functions to handle cdfenvs.",
            "name": "r-altcdfenvs"
        },
        {
            "description": "Another Multidimensional Analysis Package. Tools for Clustering and\nPrincipal Component Analysis (With robust methods, and parallelized\nfunctions).",
            "name": "r-amap"
        },
        {
            "description": "A Program for Missing Data. A tool that \"multiply imputes\" missing data\nin a single cross-section (such as a survey), from a time series (like\nvariables collected for each year in a country), or from a time-series-\ncross-sectional data set (such as collected by years for each of several\ncountries). Amelia II implements our bootstrapping-based algorithm that\ngives essentially the same answers as the standard IP or EMis\napproaches, is usually considerably faster than existing approaches and\ncan handle many more variables. Unlike Amelia I and other statistically\nrigorous imputation software, it virtually never crashes (but please let\nus know if you find to the contrary!). The program also generalizes\nexisting approaches by allowing for trends in time series across\nobservations within a cross-sectional unit, as well as priors that allow\nexperts to incorporate beliefs they have about the values of missing\ncells in their data. Amelia II also includes useful diagnostics of the\nfit of multiple imputation models. The program works from the R command\nline or via a graphical user interface that does not require users to\nknow R.",
            "name": "r-amelia"
        },
        {
            "description": "Analysis of amplicon enrichment panels. The package provides tools and\nreports for the analysis of amplicon sequencing panels, such as AmpliSeq",
            "name": "r-ampliqueso"
        },
        {
            "description": "A framework for sharing interactive data and plots from R through the\nweb. AnalysisPageServer is a modular system that enables sharing of\ncustomizable R analyses via the web.",
            "name": "r-analysispageserver"
        },
        {
            "description": "Statistical analysis of sequins. The project is intended to support the\nuse of sequins (synthetic sequencing spike-in controls) owned and made\navailable by the Garvan Institute of Medical Research. The goal is to\nprovide a standard open source library for quantitative analysis,\nmodelling and visualization of spike-in controls.",
            "name": "r-anaquin"
        },
        {
            "description": "Analysis of Copy Number Variation in Single-Cell-Sequencing Data.\nAneuFinder implements functions for copy-number detection, breakpoint\ndetection, and karyotype and heterogeneity analysis in single-cell whole\ngenome sequencing and strand-seq data.",
            "name": "r-aneufinder"
        },
        {
            "description": "WGSCS Data for Demonstration Purposes. Whole-genome single cell\nsequencing data for demonstration purposes in the AneuFinder package.",
            "name": "r-aneufinderdata"
        },
        {
            "description": "A Gallery of Animations in Statistics and Utilities to Create\nAnimations. Provides functions for animations in statistics, covering\ntopics in probability theory, mathematical statistics, multivariate\nstatistics, non-parametric statistics, sampling survey, linear models,\ntime series, computational statistics, data mining and machine learning.\nThese functions maybe helpful in teaching statistics and data analysis.",
            "name": "r-animation"
        },
        {
            "description": "Annotation tools for Affymetrix biological metadata. Functions for\nhandling data from Bioconductor Affymetrix annotation data packages.\nProduces compact HTML and text reports including experimental data and\nURL links to many online databases. Allows searching biological metadata\nusing various criteria.",
            "name": "r-annaffy"
        },
        {
            "description": "Annotation for microarrays. Using R enviroments for annotation.",
            "name": "r-annotate"
        },
        {
            "description": "Manipulation of SQLite-based annotations in Bioconductor. Implements a\nuser-friendly interface for querying SQLite-based annotation data\npackages.",
            "name": "r-annotationdbi"
        },
        {
            "description": "Facilities for Filtering Bioconductor Annotation Resources. This package\nprovides class and other infrastructure to implement filters for\nmanipulating Bioconductor annotation resources. The filters will be used\nby ensembldb, Organism.dplyr, and other packages.",
            "name": "r-annotationfilter"
        },
        {
            "description": "Tools for building SQLite-based annotation data packages. Provides code\nfor generating Annotation packages and their databases. Packages\nproduced are intended to be used with AnnotationDbi.",
            "name": "r-annotationforge"
        },
        {
            "description": "Client to access AnnotationHub resources. This package provides a client\nfor the Bioconductor AnnotationHub web resource. The AnnotationHub web\nresource provides a central location where genomic files (e.g., VCF,\nbed, wig) and other resources from standard locations (e.g., UCSC,\nEnsembl) can be discovered. The resource includes metadata about each\nresource, e.g., a textual description, tags, and date of modification.\nThe client creates and manages a local cache of files retrieved by the\nuser, helping with quick and reproducible access.",
            "name": "r-annotationhub"
        },
        {
            "description": "Anything to 'POSIXct' or 'Date' Converter. Convert input in any one of\ncharacter, integer, numeric, factor, or ordered type into 'POSIXct' (or\n'Date') objects, using one of a number of predefined formats, and\nrelying on Boost facilities for date and time parsing.",
            "name": "r-anytime"
        },
        {
            "description": "Analysis of Overdispersed Data. Provides a set of functions to analyse\noverdispersed counts or proportions. Most of the methods are already\navailable elsewhere but are scattered in different packages. The\nproposed functions should be considered as complements to more\nsophisticated methods such as generalized estimating equations (GEE) or\ngeneralized linear mixed effect models (GLMM).",
            "name": "r-aod"
        },
        {
            "description": "Analyses of Phylogenetics and Evolution. Functions for reading, writing,\nplotting, and manipulating phylogenetic trees, analyses of comparative\ndata in a phylogenetic framework, ancestral character analyses, analyses\nof diversification and macroevolution, computing distances from DNA\nsequences, reading and writing nucleotide sequences as well as importing\nfrom BioConductor, and several tools such as Mantel's test, generalized\nskyline plots, graphical exploration of phylogenetic data (alex, trex,\nkronoviz), estimation of absolute evolutionary rates and clock-like\ntrees using mean path lengths and penalized likelihood, dating trees\nwith non-contemporaneous sequences, translating DNA into AA sequences,\nand assessing sequence alignments. Phylogeny estimation can be done with\nthe NJ, BIONJ, ME, MVR, SDM, and triangle methods, and several methods\nhandling incomplete distance matrices (NJ*, BIONJ*, MVR*, and the\ncorresponding triangle method). Some functions call external\napplications (PhyML, Clustal, T-Coffee, Muscle) whose results are\nreturned into R.",
            "name": "r-ape"
        },
        {
            "description": "Decorate a 'ggplot' with Associated Information. For many times, we are\nnot just aligning plots as what 'cowplot' and 'patchwork' did. Users\nwould like to align associated information that requires axes to be\nexactly matched in subplots, e.g. hierarchical clustering with a\nheatmap. This package provides utilities to aligns associated subplots\nto a main plot at different sides (left, right, top and bottom) with\naxes exactly matched.",
            "name": "r-aplot"
        },
        {
            "description": "Command Line Optional and Positional Argument Parser. A command line\nparser to be used with Rscript to write \"#!\" shebang scripts that\ngracefully accept positional and optional arguments and automatically\ngenerate usage.",
            "name": "r-argparse"
        },
        {
            "description": "Functions to accompany A. Gelman and J. Hill, Data Analysis Using\nRegression and Multilevel/Hierarchical Models, Cambridge University\nPress, 2007.",
            "name": "r-arm"
        },
        {
            "description": "Light-Weight Methods for Normalization and Visualization of Microarray\nData using Only Basic R Data Types. Methods for microarray analysis that\ntake basic data types such as matrices and lists of vectors. These\nmethods can be used standalone, be utilized in other packages, or be\nwrapped up in higher-level classes.",
            "name": "r-aroma-light"
        },
        {
            "description": "Fast Generators and Iterators for Permutations, Combinations, Integer\nPartitions and Compositions. Fast generators and iterators for\npermutations, combinations, integer partitions and compositions. The\narrangements are in lexicographical order and generated iteratively in a\nmemory efficient manner. It has been demonstrated that 'arrangements'\noutperforms most existing packages of similar kind. Benchmarks could be\nfound at\n<https://randy3k.github.io/arrangements/articles/benchmark.html>.",
            "name": "r-arrangements"
        },
        {
            "description": "David Scott's ASH Routines. David Scott's ASH routines ported from\nS-PLUS to R.",
            "name": "r-ash"
        },
        {
            "description": "Safe Password Entry for R, Git, and SSH. Cross-platform utilities for\nprompting the user for credentials or a passphrase, for example to\nauthenticate with a server or read a protected key. Includes native\nprograms for MacOS and Windows, hence no 'tcltk' is required. Password\nentry can be invoked in two different ways: directly from R via the\naskpass() function, or indirectly as password-entry back-end for 'ssh-\nagent' or 'git-credential' via the SSH_ASKPASS and GIT_ASKPASS\nenvironment variables. Thereby the user can be prompted for credentials\nor a passphrase if needed when R calls out to git or ssh.",
            "name": "r-askpass"
        },
        {
            "description": "ASReml-R is a statistical package that fits linear mixed models using\nResidual Maximum Likelihood (REML) in the R environment.",
            "name": "r-asreml"
        },
        {
            "description": "Readable Check Functions to Ensure Code Integrity. Lots of predicates\n(is_* functions) to check the state of your variables, and assertions\n(assert_* functions) to throw errors if they aren't in the right form.",
            "name": "r-assertive"
        },
        {
            "description": "A Lightweight Core of the 'assertive' Package. A minimal set of\npredicates and assertions used by the assertive package. This is mainly\nfor use by other package developers who want to include run-time testing\nfeatures in their own packages. End-users will usually want to use\nassertive directly.",
            "name": "r-assertive-base"
        },
        {
            "description": "Assertions to Check Properties of Code. A set of predicates and\nassertions for checking the properties of code. This is mainly for use\nby other package developers who want to include run-time testing\nfeatures in their own packages. End-users will usually want to use\nassertive directly.",
            "name": "r-assertive-code"
        },
        {
            "description": "Assertions to Check Properties of Data. A set of predicates and\nassertions for checking the properties of (country independent) complex\ndata types. This is mainly for use by other package developers who want\nto include run-time testing features in their own packages. End-users\nwill usually want to use assertive directly.",
            "name": "r-assertive-data"
        },
        {
            "description": "Assertions to Check Properties of Strings. A set of predicates and\nassertions for checking the properties of UK-specific complex data\ntypes. This is mainly for use by other package developers who want to\ninclude run-time testing features in their own packages. End-users will\nusually want to use assertive directly.",
            "name": "r-assertive-data-uk"
        },
        {
            "description": "Assertions to Check Properties of Strings. A set of predicates and\nassertions for checking the properties of US-specific complex data\ntypes. This is mainly for use by other package developers who want to\ninclude run-time testing features in their own packages. End-users will\nusually want to use assertive directly.",
            "name": "r-assertive-data-us"
        },
        {
            "description": "Assertions to Check Properties of Dates and Times. A set of predicates\nand assertions for checking the properties of dates and times. This is\nmainly for use by other package developers who want to include run-time\ntesting features in their own packages. End-users will usually want to\nuse assertive directly.",
            "name": "r-assertive-datetimes"
        },
        {
            "description": "Assertions to Check Properties of Files. A set of predicates and\nassertions for checking the properties of files and connections. This is\nmainly for use by other package developers who want to include run-time\ntesting features in their own packages. End-users will usually want to\nuse assertive directly.",
            "name": "r-assertive-files"
        },
        {
            "description": "Assertions to Check Properties of Matrices. A set of predicates and\nassertions for checking the properties of matrices. This is mainly for\nuse by other package developers who want to include run-time testing\nfeatures in their own packages. End-users will usually want to use\nassertive directly.",
            "name": "r-assertive-matrices"
        },
        {
            "description": "Assertions to Check Properties of Models. A set of predicates and\nassertions for checking the properties of models. This is mainly for use\nby other package developers who want to include run-time testing\nfeatures in their own packages. End-users will usually want to use\nassertive directly.",
            "name": "r-assertive-models"
        },
        {
            "description": "Assertions to Check Properties of Numbers. A set of predicates and\nassertions for checking the properties of numbers. This is mainly for\nuse by other package developers who want to include run-time testing\nfeatures in their own packages. End-users will usually want to use\nassertive directly.",
            "name": "r-assertive-numbers"
        },
        {
            "description": "Assertions to Check Properties of Variables. A set of predicates and\nassertions for checking the properties of variables, such as length,\nnames and attributes. This is mainly for use by other package developers\nwho want to include run-time testing features in their own packages.\nEnd-users will usually want to use assertive directly.",
            "name": "r-assertive-properties"
        },
        {
            "description": "Assertions for Checking the State of R. A set of predicates and\nassertions for checking the state and capabilities of R, the operating\nsystem it is running on, and the IDE being used. This is mainly for use\nby other package developers who want to include run-time testing\nfeatures in their own packages. End-users will usually want to use\nassertive directly.",
            "name": "r-assertive-reflection"
        },
        {
            "description": "Assertions to Check Properties of Sets. A set of predicates and\nassertions for checking the properties of sets. This is mainly for use\nby other package developers who want to include run-time testing\nfeatures in their own packages. End-users will usually want to use\nassertive directly.",
            "name": "r-assertive-sets"
        },
        {
            "description": "Assertions to Check Properties of Strings. A set of predicates and\nassertions for checking the properties of strings. This is mainly for\nuse by other package developers who want to include run-time testing\nfeatures in their own packages. End-users will usually want to use\nassertive directly.",
            "name": "r-assertive-strings"
        },
        {
            "description": "Assertions to Check Types of Variables. A set of predicates and\nassertions for checking the types of variables. This is mainly for use\nby other package developers who want to include run-time testing\nfeatures in their own packages. End-users will usually want to use\nassertive directly.",
            "name": "r-assertive-types"
        },
        {
            "description": "Easy Pre and Post Assertions. An extension to stopifnot() that makes it\neasy to declare the pre and post conditions that you code should\nsatisfy, while also producing friendly error messages so that your users\nknow what's gone wrong.",
            "name": "r-assertthat"
        },
        {
            "description": "Automatic Interpolation Package. An automatic interpolation is done by\nautomatically estimating the variogram and then calling gstat. An\noverview is given by Hiemstra et al (2008)\n<doi:10.1016/j.cageo.2008.10.011>.",
            "name": "r-automap"
        },
        {
            "description": "Reimplementations of Functions Introduced Since R-3.0.0. Functions\nintroduced or changed since R v3.0.0 are re-implemented in this package.\nThe backports are conditionally exported in order to let R resolve the\nfunction name to either the implemented backport, or the respective base\nversion, if available. Package developers can make use of new functions\nor arguments by selectively importing specific backports to support\nolder installations.",
            "name": "r-backports"
        },
        {
            "description": "Extract read count signals from bam files. This package allows to\nefficiently obtain count vectors from indexed bam files. It counts the\nnumber of reads in given genomic ranges and it computes reads profiles\nand coverage profiles. It also handles paired- end data.",
            "name": "r-bamsignals"
        },
        {
            "description": "Base64 Encoder and Decoder. Compatibility wrapper to replace the\norphaned package by Romain Francois. New applications should use the\n'openssl' or 'base64enc' package instead.",
            "name": "r-base64"
        },
        {
            "description": "Tools for base64 encoding. This package provides tools for handling\nbase64 encoding. It is more flexible than the orphaned base64 package.",
            "name": "r-base64enc"
        },
        {
            "description": "Freezing Python Dependencies Inside Bioconductor Packages. Installs a\nself-contained conda instance that is managed by the R/Bioconductor\ninstallation machinery. This aims to provide a consistent Python\nenvironment that can be used reliably by Bioconductor packages.\nFunctions are also provided to enable smooth interoperability of\nmultiple Python environments in a single R session.",
            "name": "r-basilisk"
        },
        {
            "description": "Basilisk Installation Utilities. Implements utilities for installation\nof the basilisk package, primarily for creation of the underlying Conda\ninstance. This allows us to avoid re-writing the same R code in both the\nconfigure script (for centrally administered R installations) and in the\nlazy installation mechanism (for distributed package binaries). It is\nhighly unlikely that developers - or, heaven forbid, end-users! - will\nneed to interact with this package directly; they should be using the\nbasilisk package instead.",
            "name": "r-basilisk-utils"
        },
        {
            "description": "Bayesian Inference for Marketing/Micro-Econometrics. Covers many\nimportant models used in marketing and micro-econometrics applications.\nThe package includes: Bayes Regression (univariate or multivariate dep\nvar), Bayes Seemingly Unrelated Regression (SUR), Binary and Ordinal\nProbit, Multinomial Logit (MNL) and Multinomial Probit (MNP),\nMultivariate Probit, Negative Binomial (Poisson) Regression,\nMultivariate Mixtures of Normals (including clustering), Dirichlet\nProcess Prior Density Estimation with normal base, Hierarchical Linear\nModels with normal prior and covariates, Hierarchical Linear Models with\na mixture of normals prior and covariates, Hierarchical Multinomial\nLogits with a mixture of normals prior and covariates, Hierarchical\nMultinomial Logits with a Dirichlet Process prior and covariates,\nHierarchical Negative Binomial Regression Models, Bayesian analysis of\nchoice-based conjoint data, Bayesian treatment of linear instrumental\nvariables models, Analysis of Multivariate Ordinal survey data with\nscale usage heterogeneity (as in Rossi et al, JASA (01)), Bayesian\nAnalysis of Aggregate Random Coefficient Logit Models as in BLP (see\nJiang, Manchanda, Rossi 2009) For further reference, consult our book,\nBayesian Statistics and Marketing by Rossi, Allenby and McCulloch (Wiley\n2005) and Bayesian Non- and Semi-Parametric Methods and Applications\n(Princeton U Press 2014).",
            "name": "r-bayesm"
        },
        {
            "description": "Plotting for Bayesian Models. Plotting functions for posterior analysis,\nMCMC diagnostics, prior and posterior predictive checks, and other\nvisualizations to support the applied Bayesian workflow advocated in\nGabry, Simpson, Vehtari, Betancourt, and Gelman (2019)\n<doi:10.1111/rssa.12378>. The package is designed not only to provide\nconvenient functionality for users, but also a common set of functions\nthat can be easily used by developers working on a variety of R packages\nfor Bayesian modeling, particularly (but not exclusively) packages\ninterfacing with 'Stan'.",
            "name": "r-bayesplot"
        },
        {
            "description": "Miscellaneous Helper Functions for B. Bischl. Miscellaneous helper\nfunctions for and from B. Bischl and some other guys, mainly for package\ndevelopment.",
            "name": "r-bbmisc"
        },
        {
            "description": "Compiling Bioconductor to Handle Each Matrix Type. Provides a consistent\nC++ class interface for reading from and writing data to a variety of\ncommonly used matrix types. Ordinary matrices and several sparse/dense\nMatrix classes are directly supported, third-party S4 classes may be\nsupported by external linkage, while all other matrices are handled by\nDelayedArray block processing.",
            "name": "r-beachmat"
        },
        {
            "description": "Visualization via Beanplots (like Boxplot/Stripchart/Violin Plot). Plots\nunivariate comparison graphs, an alternative to\nboxplot/stripchart/violin plot.",
            "name": "r-beanplot"
        },
        {
            "description": "The Bee Swarm Plot, an Alternative to Stripchart. The bee swarm plot is\na one-dimensional scatter plot like \"stripchart\", but with closely-\npacked, non-overlapping points.",
            "name": "r-beeswarm"
        },
        {
            "description": "Breaks for Additive Season and Trend. Decomposition of time series into\ntrend, seasonal, and remainder components with methods for detecting and\ncharacterizing abrupt changes within the trend and seasonal components.\n'BFAST' can be used to analyze different types of satellite image time\nseries and can be applied to other disciplines dealing with seasonal or\nnon-seasonal time series, such as hydrology, climatology, and\neconometrics. The algorithm can be extended to label detected changes\nwith information on the parameters of the fitted piecewise linear\nmodels. 'BFAST' monitoring functionality is described in Verbesselt et\nal. (2010) <doi:10.1016/j.rse.2009.08.014>. 'BFAST monitor' provides\nfunctionality to detect disturbance in near real-time based on 'BFAST'-\ntype models, and is described in Verbesselt et al. (2012)\n<doi:10.1016/j.rse.2012.02.022>. 'BFAST Lite' approach is a flexible\napproach that handles missing data without interpolation, and will be\ndescribed in an upcoming paper. Furthermore, different models can now be\nused to fit the time series data and detect structural changes (breaks).",
            "name": "r-bfast"
        },
        {
            "description": "Pre-process gridded time-series data in order for them to be analyzed\nwith change detection algorithms such as bfast. Uses classes from the\nraster package and includes utilities to run the algorithms and post-\nprocess the results.",
            "name": "r-bfastspatial"
        },
        {
            "description": "Bayesian Generalized Linear Regression.",
            "name": "r-bglr"
        },
        {
            "description": "Boost C++ Header Files. Boost provides free peer-reviewed portable C++\nsource libraries. A large part of Boost is provided as C++ template code\nwhich is resolved entirely at compile-time without linking. This package\naims to provide the most useful subset of Boost libraries for template\nuse among CRAN package. By placing these libraries in this package, we\noffer a more efficient distribution system for CRAN as replication of\nthis code in the sources of other packages is avoided. As of release\n1.60.0-2, the following Boost libraries are included: 'algorithm' 'any'\n'bimap' 'bind' 'circular_buffer' 'concept' 'config' 'container'\n'date'_'time' 'detail' 'dynamic_bitset' 'exception' 'filesystem'\n'flyweight' 'foreach' 'functional' 'fusion' 'geometry' 'graph' 'heap'\n'icl' 'integer' 'interprocess' 'intrusive' 'io' 'iostreams' 'iterator'\n'math' 'move' 'mpl' 'multiprcecision' 'numeric' 'pending' 'phoenix'\n'preprocessor' 'random' 'range' 'smart_ptr' 'spirit' 'tuple'\n'type_trains' 'typeof' 'unordered' 'utility' 'uuid'.",
            "name": "r-bh"
        },
        {
            "description": "Biased Urn Model Distributions. Statistical models of biased sampling in\nthe form of univariate and multivariate noncentral hypergeometric\ndistributions, including Wallenius' noncentral hypergeometric\ndistribution and Fisher's noncentral hypergeometric distribution (also\ncalled extended hypergeometric distribution). See vignette(\"UrnTheory\")\nfor explanation of these distributions.",
            "name": "r-biasedurn"
        },
        {
            "description": "Bibtex Parser. Utility to parse a bibtex file.",
            "name": "r-bibtex"
        },
        {
            "description": "'BLAS' and 'LAPACK' Routines for Native R Matrices and 'big.matrix'\nObjects. Provides arithmetic functions for R matrix and 'big.matrix'\nobjects as well as functions for QR factorization, Cholesky\nfactorization, General eigenvalue, and Singular value decomposition\n(SVD). A method matrix multiplication and an arithmetic method -for\nmatrix addition, matrix difference- allows for mixed type operation -a\nmatrix class object and a big.matrix class object- and pure type\noperation for two big.matrix class objects.",
            "name": "r-bigalgebra"
        },
        {
            "description": "Regression for data too large to fit in memory.",
            "name": "r-biglm"
        },
        {
            "description": "Manage Massive Matrices with Shared Memory and Memory-Mapped. Files\nCreate, store, access, and manipulate massive matrices. Matrices are\nallocated to shared memory and may use memory-mapped files. Packages\n'biganalytics', 'bigtabulate', 'synchronicity', and 'bigalgebra' provide\nadvanced functionality.",
            "name": "r-bigmemory"
        },
        {
            "description": "A shared resource interface for Bigmemory Project packages. This package\nprovides a shared resource interface for the bigmemory and synchronicity\npackages.",
            "name": "r-bigmemory-sri"
        },
        {
            "description": "Parametrized Active Bindings. Provides a simple interface for creating\nactive bindings where the bound function accepts additional arguments.",
            "name": "r-bindr"
        },
        {
            "description": "An 'Rcpp' Interface to Active Bindings. Provides an easy way to fill an\nenvironment with active bindings that call a C++ function.",
            "name": "r-bindrcpp"
        },
        {
            "description": "Biological Structure Analysis. Utilities to process, organize and\nexplore protein structure, sequence and dynamics data. Features include\nthe ability to read and write structure, sequence and dynamic trajectory\ndata, perform sequence and structure database searches, data summaries,\natom selection, alignment, superposition, rigid core identification,\nclustering, torsion analysis, distance matrix analysis, structure and\nsequence conservation analysis, normal mode analysis, principal\ncomponent analysis of heterogeneous structure data, and correlation\nnetwork analysis from normal mode and molecular dynamics data. In\naddition, various utility functions are provided to enable the\nstatistical and graphical power of the R environment to work with\nbiological sequence and structural data. Please refer to the URLs below\nfor more information.",
            "name": "r-bio3d"
        },
        {
            "description": "Biobase: Base functions for Bioconductor. Functions that are needed by\nmany other packages or which replace R functions.",
            "name": "r-biobase"
        },
        {
            "description": "Manage Files Across Sessions. This package creates a persistent on-disk\ncache of files that the user can add, update, and retrieve. It is useful\nfor managing resources (such as custom Txdb objects) that are costly or\ndifficult to create, web resources, and data files used across sessions.",
            "name": "r-biocfilecache"
        },
        {
            "description": "S4 generic functions used in Bioconductor. The package defines S4\ngeneric functions used in Bioconductor.",
            "name": "r-biocgenerics"
        },
        {
            "description": "Install/Update Bioconductor, CRAN, and github Packages. This package is\nused to install and update Bioconductor, CRAN, and (some) github\npackages.",
            "name": "r-biocinstaller"
        },
        {
            "description": "Standard Input and Output for Bioconductor Packages. Implements\n`import()` and `export()` standard generics for importing and exporting\nbiological data formats. `import()` supports whole-file as well as\nchunk-wise iterative import. The `import()` interface optionally\nprovides a standard mechanism for 'lazy' access via `filter()` (on row\nor element-like components of the file resource), `select()` (on column-\nlike components of the file resource) and `collect()`. The `import()`\ninterface optionally provides transparent access to remote (e.g. via\nhttps) as well as local access. Developers can register a file\nextension, e.g., `.loom` for dispatch from character-based URIs to\nspecific `import()` / `export()` methods based on classes representing\nfile types, e.g., `LoomFile()`.",
            "name": "r-biocio"
        },
        {
            "description": "Access the Bioconductor Project Package Repository. A convenient tool to\ninstall and update Bioconductor packages.",
            "name": "r-biocmanager"
        },
        {
            "description": "Nearest Neighbor Detection for Bioconductor Packages. Implements exact\nand approximate methods for nearest neighbor detection, in a framework\nthat allows them to be easily switched within Bioconductor packages or\nworkflows. Exact searches can be performed using the k-means for\nk-nearest neighbors algorithm or with vantage point trees. Approximate\nsearches can be performed using the Annoy or HNSW libraries. Searching\non either Euclidean or Manhattan distances is supported. Parallelization\nis achieved for all methods by using BiocParallel. Functions are also\nprovided to search for all neighbors within a given distance.",
            "name": "r-biocneighbors"
        },
        {
            "description": "Bioconductor facilities for parallel evaluation. This package provides\nmodified versions and novel implementation of functions for parallel\nevaluation, tailored to use with Bioconductor objects.",
            "name": "r-biocparallel"
        },
        {
            "description": "Singular Value Decomposition for Bioconductor Packages. Implements exact\nand approximate methods for singular value decomposition and principal\ncomponents analysis, in a framework that allows them to be easily\nswitched within Bioconductor packages or workflows. Where possible,\nparallelization is achieved using the BiocParallel framework.",
            "name": "r-biocsingular"
        },
        {
            "description": "Standard styles for vignettes and other Bioconductor documents. Provides\nstandard formatting styles for Bioconductor PDF and HTML documents.\nPackage vignettes illustrate use and functionality.",
            "name": "r-biocstyle"
        },
        {
            "description": "Set the appropriate version of Bioconductor packages. This package\nprovides repository information for the appropriate version of\nBioconductor.",
            "name": "r-biocversion"
        },
        {
            "description": "Utilities for the BIOM (Biological Observation Matrix) Format. Provides\nutilities to facilitate import, export and computation with the BIOM\n(Biological Observation Matrix) format (https://biom-format.org/).",
            "name": "r-biom-utils"
        },
        {
            "description": "Interface to BioMart databases (i.e. Ensembl). In recent years a wealth\nof biological data has become available in public data repositories.\nEasy access to these valuable data resources and firm integration with\ndata analysis is needed for comprehensive bioinformatics data analysis.\nbiomaRt provides an interface to a growing collection of databases\nimplementing the BioMart software suite (<http://www.biomart.org>). The\npackage enables retrieval of large amounts of data in a uniform way\nwithout the need to know the underlying database schemas or write\ncomplex SQL queries. The most prominent examples of BioMart databases\nare maintain by Ensembl, which provides biomaRt users direct access to a\ndiverse set of data and enables a wide range of powerful online queries\nfrom gene annotation to database mining.",
            "name": "r-biomart"
        },
        {
            "description": "Genomic Data Retrieval. Perform large scale genomic data retrieval and\nfunctional annotation retrieval. This package aims to provide users with\na standardized way to automate genome, proteome, 'RNA', coding sequence\n('CDS'), 'GFF', and metagenome retrieval from 'NCBI RefSeq', 'NCBI\nGenbank', 'ENSEMBL', 'ENSEMBLGENOMES', and 'UniProt' databases.\nFurthermore, an interface to the 'BioMart' database (Smedley et al.\n(2009) <doi:10.1186/1471-2164-10-22>) allows users to retrieve\nfunctional annotation for genomic loci. In addition, users can download\nentire databases such as 'NCBI RefSeq' (Pruitt et al. (2007)\n<doi:10.1093/nar/gkl842>), 'NCBI nr', 'NCBI nt', 'NCBI Genbank' (Benson\net al. (2013) <doi:10.1093/nar/gks1195>), etc. as well as 'ENSEMBL' and\n'ENSEMBLGENOMES' with only one command.",
            "name": "r-biomartr"
        },
        {
            "description": "An interface package for the BIOM file format. This is an R package for\ninterfacing with the BIOM format. This package includes basic tools for\nreading biom-format files, accessing and subsetting data tables from a\nbiom object (which is more complex than a single table), as well as\nlimited support for writing a biom-object back to a biom-format file.\nThe design of this API is intended to match the python API and other\ntools included with the biom-format project, but with a decidedly \"R\nflavor\" that should be familiar to R users. This includes S4 classes and\nmethods, as well as extensions of common core functions/methods.",
            "name": "r-biomformat"
        },
        {
            "description": "Efficient manipulation of biological strings. Memory efficient string\ncontainers, string matching algorithms, and other utilities, for fast\nmanipulation of large biological sequences or sets of sequences.",
            "name": "r-biostrings"
        },
        {
            "description": "Basic graphic utilities for visualization of genomic data. The\nbiovizBase package is designed to provide a set of utilities, color\nschemes and conventions for genomic data. It serves as the base for\nvarious high-level packages for biological data visualization. This\nsaves development effort and encourages consistency.",
            "name": "r-biovizbase"
        },
        {
            "description": "Classes and Methods for Fast Memory-Efficient Boolean Selections.\nProvided are classes for boolean and skewed boolean vectors, fast\nboolean methods, fast unique and non-unique integer sorting, fast set\noperations on sorted and unsorted sets of integers, and foundations for\nff (range index, compression, chunked processing).",
            "name": "r-bit"
        },
        {
            "description": "A S3 Class for Vectors of 64bit Integers. Package 'bit64' provides\nserializable S3 atomic 64bit (signed) integers. These are useful for\nhandling database keys and exact counting in +-2^63. WARNING: do not use\nthem as replacement for 32bit integers, integer64 are not supported for\nsubscripting by R-core and they have different semantics when combined\nwith double, e.g. integer64 + double => integer64. Class integer64 can\nbe used in vectors, matrices, arrays and data.frames. Methods are\navailable for coercion from and to logicals, integers, doubles,\ncharacters and factors as well as many elementwise and summary\nfunctions. Many fast algorithmic operations such as 'match' and 'order'\nsupport inter- active data exploration and manipulation and optionally\nleverage caching.",
            "name": "r-bit64"
        },
        {
            "description": "Bitwise Operations. Functions for bitwise operations on integer vectors.",
            "name": "r-bitops"
        },
        {
            "description": "Bayesian Latent Variable Analysis. Fit a variety of Bayesian latent\nvariable models, including confirmatory factor analysis, structural\nequation models, and latent growth curve models. References: Merkle &\nRosseel (2018) <doi:10.18637/jss.v085.i04>; Merkle et al. (2021)\n<doi:10.18637/jss.v100.i06>.",
            "name": "r-blavaan"
        },
        {
            "description": "A Simple S3 Class for Representing Vectors of Binary Data ('BLOBS'). R's\nraw vector is useful for storing a single binary object. What if you\nwant to put a vector of them in a data frame? The blob package provides\nthe blob object, a list of raw vectors, suitable for use as a column in\ndata frame.",
            "name": "r-blob"
        },
        {
            "description": "Generalized and Classical Blockmodeling of Valued Networks. This is\nprimarily meant as an implementation of generalized blockmodeling for\nvalued networks.",
            "name": "r-blockmodeling"
        },
        {
            "description": "Clustering Algorithms for Bioconductor. Wraps common clustering\nalgorithms in an easily extended S4 framework. Backends are implemented\nfor hierarchical, k-means and graph-based clustering. Several utilities\nare also provided to compare and evaluate clustering results.",
            "name": "r-bluster"
        },
        {
            "description": "Read Windows Bitmap (BMP) Images. Reads Windows BMP format images.\nCurrently limited to 8 bit greyscale images and 24,32 bit (A)RGB images.\nPure R implementation without external dependencies.",
            "name": "r-bmp"
        },
        {
            "description": "Authoring Books and Technical Documents with R Markdown. Output formats\nand utilities for authoring books and technical documents with R\nMarkdown.",
            "name": "r-bookdown"
        },
        {
            "description": "Bootstrap Functions (Originally by Angelo Canty for S). Functions and\ndatasets for bootstrapping from the book \"Bootstrap Methods and Their\nApplication\" by A. C. Davison and D. V. Hinkley (1997, CUP), originally\nwritten by Angelo Canty for S.",
            "name": "r-boot"
        },
        {
            "description": "Wrapper Algorithm for All Relevant Feature Selection. An all relevant\nfeature selection wrapper algorithm. It finds relevant features by\ncomparing original attributes' importance with importance achievable at\nrandom, estimated using their permuted copies (shadows).",
            "name": "r-boruta"
        },
        {
            "description": "Templating Framework for Report Generation. Brew implements a templating\nframework for mixing text and R code for report generation. brew\ntemplate syntax is similar to PHP, Ruby's erb module, Java Server Pages,\nand Python's psp module.",
            "name": "r-brew"
        },
        {
            "description": "Bridge Sampling for Marginal Likelihoods and Bayes Factors. Provides\nfunctions for estimating marginal likelihoods, Bayes factors, posterior\nmodel probabilities, and normalizing constants in general, via different\nversions of bridge sampling (Meng & Wong, 1996,\n<http://www3.stat.sinica.edu.tw/statistica/j6n4/j6n43/j6n43.htm>).\nGronau, Singmann, & Wagenmakers (2020) <doi:10.18637/jss.v092.i10>.",
            "name": "r-bridgesampling"
        },
        {
            "description": "Basic R Input Output. Functions to handle basic input output, these\nfunctions always read and write UTF-8 (8-bit Unicode Transformation\nFormat) files and provide more explicit control over line endings.",
            "name": "r-brio"
        },
        {
            "description": "Bayesian Regression Models using 'Stan'. Fit Bayesian generalized\n(non-)linear multivariate multilevel models using 'Stan' for full\nBayesian inference. A wide range of distributions and link functions are\nsupported, allowing users to fit - among others - linear, robust linear,\ncount data, survival, response times, ordinal, zero-inflated, hurdle,\nand even self-defined mixture models all in a multilevel context.\nFurther modeling options include non-linear and smooth terms, auto-\ncorrelation structures, censored data, meta-analytic standard errors,\nand quite a few more. In addition, all parameters of the response\ndistribution can be predicted in order to perform distributional\nregression. Prior specifications are flexible and explicitly encourage\nusers to apply prior distributions that actually reflect their beliefs.\nModel fit can easily be assessed and compared with posterior predictive\nchecks and leave-one-out cross-validation. References: Burkner (2017)\n<doi:10.18637/jss.v080.i01>; Burkner (2018) <doi:10.32614/RJ-2018-017>;\nCarpenter et al. (2017) <doi:10.18637/jss.v076.i01>.",
            "name": "r-brms"
        },
        {
            "description": "Very Large Numbers in R. Handles very large numbers in R. Real numbers\nare held using their natural logarithms, plus a logical flag indicating\nsign. The package includes a vignette that gives a step-by-step\nintroduction to using S4 methods.",
            "name": "r-brobdingnag"
        },
        {
            "description": "Convert Statistical Objects into Tidy Tibbles. Summarizes key\ninformation about statistical objects in tidy tibbles. This makes it\neasy to report results, create plots and consistently work with large\nnumbers of models at once. Broom provides three verbs that each provide\ndifferent types of information about a model. tidy() summarizes\ninformation about model components such as coefficients of a regression.\nglance() reports information about an entire model, such as goodness of\nfit measures like AIC and BIC. augment() adds information about\nindividual observations to a dataset, such as fitted values or influence\nmeasures.",
            "name": "r-broom"
        },
        {
            "description": "Provides suite of functions to work with regression model\n'broom::tidy()' tibbles. The suite includes functions to group\nregression model terms by variable, insert reference and header rows for\ncategorical variables, add variable labels, and more.",
            "name": "r-broom-helpers"
        },
        {
            "description": "Software infrastructure for efficient representation of full genomes and\ntheir SNPs. Infrastructure shared by all the Biostrings-based genome\ndata packages.",
            "name": "r-bsgenome"
        },
        {
            "description": "Full genome sequences for Homo sapiens (UCSC version hg19, based on\nGRCh37.p13). Full genome sequences for Homo sapiens (Human) as provided\nby UCSC (hg19, Feb. 2009) and stored in Biostrings objects.",
            "name": "r-bsgenome-hsapiens-ucsc-hg19"
        },
        {
            "description": "Custom 'Bootstrap' 'Sass' Themes for 'shiny' and 'rmarkdown'. Simplifies\ncustom 'CSS' styling of both 'shiny' and 'rmarkdown' via 'Bootstrap'\n'Sass'. Supports both 'Bootstrap' 3 and 4 as well as their various\n'Bootswatch' themes. An interactive widget is also provided for\npreviewing themes in real time.",
            "name": "r-bslib"
        },
        {
            "description": "Analyze, manage and store bisulfite sequencing data. A collection of\ntools for analyzing and visualizing bisulfite sequencing data.",
            "name": "r-bsseq"
        },
        {
            "description": "Bump Hunter. Tools for finding bumps in genomic data",
            "name": "r-bumphunter"
        },
        {
            "description": "Baumgartner Weiss Schindler Test of Equal Distributions. Performs the\n'Baumgartner-Weiss-Schindler' two-sample test of equal probability\ndistributions, <doi:10.2307/2533862>. Also performs similar rank-based\ntests for equal probability distributions due to Neuhauser\n<doi:10.1080/10485250108832874> and Murakami\n<doi:10.1080/00949655.2010.551516>.",
            "name": "r-bwstest"
        },
        {
            "description": "C5.0 Decision Trees and Rule-Based Models. C5.0 decision trees and rule-\nbased models for pattern recognition that extend the work of Quinlan\n(1993, ISBN:1-55860-238-0).",
            "name": "r-c50"
        },
        {
            "description": "Simple, Multiple and Joint Correspondence Analysis. Computation and\nvisualization of simple, multiple and joint correspondence analysis.",
            "name": "r-ca"
        },
        {
            "description": "Cache R Objects with Automatic Pruning. Key-value stores with automatic\npruning. Caches can limit either their total size or the age of the\noldest object (or both), automatically pruning objects to maintain the\nconstraints.",
            "name": "r-cachem"
        },
        {
            "description": "R graphics device using cairo graphics library for creating high-quality\nbitmap (PNG, JPEG, TIFF), vector (PDF, SVG, PostScript) and display (X11\nand Win32) output. R graphics device using cairographics library that\ncan be used to create high-quality vector (PDF, PostScript and SVG) and\nbitmap output (PNG,JPEG,TIFF), and high-quality rendering in displays\n(X11 and Win32). Since it uses the same back-end for all output, copying\nacross formats is WYSIWYG. Files are created without the dependence on\nX11 or other external programs. This device supports alpha channel\n(semi-transparent drawing) and resulting images can contain transparent\nand semi-transparent regions. It is ideal for use in server environments\n(file output) and as a replacement for other devices that don't have\nCairo's capabilities such as alpha support or anti-aliasing. Backends\nare modular such that any subset of backends is supported.",
            "name": "r-cairo"
        },
        {
            "description": "Call R from R. It is sometimes useful to perform a computation in a\nseparate R process, without affecting the current R process at all. This\npackages does exactly that.",
            "name": "r-callr"
        },
        {
            "description": "Companion to Applied Regression. Functions and Datasets to Accompany J.\nFox and S. Weisberg, An R Companion to Applied Regression, Second\nEdition, Sage, 2011.",
            "name": "r-car"
        },
        {
            "description": "Computer Algebra. Computer algebra via the 'SymPy' library\n(<https://www.sympy.org/>). This makes it possible to solve equations\nsymbolically, find symbolic integrals, symbolic sums and other important\nquantities.",
            "name": "r-caracas"
        },
        {
            "description": "Companion to Applied Regression Data Sets. Datasets to Accompany J. Fox\nand S. Weisberg, An R Companion to Applied Regression, Third Edition,\nSage (2019).",
            "name": "r-cardata"
        },
        {
            "description": "Classification and Regression Training. Misc functions for training and\nplotting classification and regression models.",
            "name": "r-caret"
        },
        {
            "description": "Ensembles of Caret Models. Functions for creating ensembles of caret\nmodels: caretList() and caretStack(). caretList() is a convenience\nfunction for fitting multiple caret::train() models to the same dataset.\ncaretStack() will make linear or non-linear combinations of these\nmodels, using a caret::train() model as a meta-model, and\ncaretEnsemble() will make a robust linear combination of models using a\nGLM.",
            "name": "r-caretensemble"
        },
        {
            "description": "A Collection of Database, Data Structure, Visualization, andUtility\nFunctions for R. The caroline R library contains dozens of functions\nuseful for: database migration (dbWriteTable2), database style joins &\naggregation (nerge, groupBy & bestBy), data structure conversion (nv,\ntab2df), legend table making (sstable & leghead), plot annotation\n(labsegs & mvlabs), data visualization (violins, pies & raPlot),\ncharacter string manipulation (m & pad), file I/O (write.delim), batch\nscripting and more. The package's greatest contributions lie in the\ndatabase style merge, aggregation and interface functions as well as in\nit's extensive use and propagation of row, column and vector names in\nmost functions.",
            "name": "r-caroline"
        },
        {
            "description": "Category Analysis. A collection of tools for performing category (gene\nset enrichment) analysis.",
            "name": "r-category"
        },
        {
            "description": "Moving Window Statistics, GIF, Base64, ROC AUC, etc. Contains several\nbasic utility functions including: moving (rolling, running) window\nstatistic functions, read/write for GIF and ENVI binary files, fast\ncalculation of AUC, LogitBoost classifier, base64 encoder/decoder,\nround-off-error-free sum and cumsum, etc.",
            "name": "r-catools"
        },
        {
            "description": "Canonical Correlation Analysis. Provides a set of functions that extend\nthe 'cancor' function with new numerical and graphical outputs. It also\ninclude a regularized extension of the canonical correlation analysis to\ndeal with datasets with more variables than observations.",
            "name": "r-cca"
        },
        {
            "description": "Significance Tests for Canonical Correlation Analysis (CCA).\nSignificance tests for canonical correlation analysis, including\nasymptotic tests and a Monte Carlo method",
            "name": "r-ccp"
        },
        {
            "description": "Retrieve Flu Season Data from the United States Centers for Disease\nControl and Prevention ('CDC') 'FluView' Portal. The 'U.S.' Centers for\nDisease Control ('CDC') maintains a portal\n<https://gis.cdc.gov/grasp/fluview/fluportaldashboard.html> for\naccessing state, regional and national influenza statistics as well as\nMortality Surveillance Data. The web interface makes it difficult and\ntime-consuming to select and retrieve influenza data. Tools are provided\nto access the data provided by the portal's underlying 'API'.",
            "name": "r-cdcfluview"
        },
        {
            "description": "Translate Spreadsheet Cell Ranges to Rows and Columns. Helper functions\nto work with spreadsheets and the \"A1:D10\" style of cell range\nspecification.",
            "name": "r-cellranger"
        },
        {
            "description": "Chip Analysis Methylation Pipeline for Illumina HumanMethylation450 and\nEPIC. The package includes quality control metrics, a selection of\nnormalization methods and novel methods to identify differentially\nmethylated regions and to highlight copy number alterations.",
            "name": "r-champ"
        },
        {
            "description": "Packages for ChAMP package. Provides datasets needed for ChAMP including\na test dataset and blood controls for CNA analysis.",
            "name": "r-champdata"
        },
        {
            "description": "Fast and Versatile Argument Checks. Tests and assertions to perform\nfrequent argument checks. A substantial part of the package was written\nin C to minimize any worries about execution time overhead.",
            "name": "r-checkmate"
        },
        {
            "description": "Install Packages from Snapshots on the Checkpoint Server for\nReproducibility. The goal of checkpoint is to solve the problem of\npackage reproducibility in R. Specifically, checkpoint allows you to\ninstall packages as they existed on CRAN on a specific snapshot date as\nif you had a CRAN time machine. To achieve reproducibility, the\ncheckpoint() function installs the packages required or called by your\nproject and scripts to a local library exactly as they existed at the\nspecified point in time. Only those packages are available to your\nproject, thereby avoiding any package updates that came later and may\nhave altered your results. In this way, anyone using checkpoint's\ncheckpoint() can ensure the reproducibility of your scripts or projects\nat any time. To create the snapshot archives, once a day (at midnight\nUTC) Microsoft refreshes the Austria CRAN mirror on the \"Microsoft R\nArchived Network\" server (<https://mran.microsoft.com/>). Immediately\nafter completion of the rsync mirror process, the process takes a\nsnapshot, thus creating the archive. Snapshot archives exist starting\nfrom 2014-09-17.",
            "name": "r-checkpoint"
        },
        {
            "description": "Multivariate Statistical Analysis in Chemometrics. R companion to the\nbook \"Introduction to Multivariate Statistical Analysis in Chemometrics\"\nwritten by K. Varmuza and P. Filzmoser (2009).",
            "name": "r-chemometrics"
        },
        {
            "description": "A package for analyzing chipseq data, Tools for helping process short\nread data for chipseq experiments",
            "name": "r-chipseq"
        },
        {
            "description": "Chronological objects which can handle dates and times. Provides\nchronological objects which can handle dates and times.",
            "name": "r-chron"
        },
        {
            "description": "Circular Visualization. Circular layout is an efficient way for the\nvisualization of huge amounts of information. Here this package provides\nan implementation of circular layout generation in R as well as an\nenhancement of available software. The flexibility of the package is\nbased on the usage of low-level graphics functions such that self-\ndefined high-level graphics can be easily implemented by users for\nspecific purposes. Together with the seamless connection between the\npowerful computational and visual environment in R, it gives users more\nconvenience and freedom to design figures for better understanding\ncomplex patterns behind multiple dimensional data. The package is\ndescribed in Gu et al. 2014 <doi:10.1093/bioinformatics/btu393>.",
            "name": "r-circlize"
        },
        {
            "description": "Circular Statistics, from \"Topics in Circular Statistics\" (2001).\nCircular Statistics, from \"Topics in Circular Statistics\" (2001) S. Rao\nJammalamadaka and A. SenGupta, World Scientific.",
            "name": "r-circstats"
        },
        {
            "description": "A versatile interior point solver that solves linear programs (LPs),\nquadratic programs (QPs), second-order cone programs (SOCPs),\nsemidefinite programs (SDPs), and problems with exponential and power\ncone constraints (<https://clarabel.org/stable/>). For quadratic\nobjectives, unlike interior point solvers based on the standard\nhomogeneous self-dual embedding (HSDE) model, 'Clarabel' handles\nquadratic objective without requiring any epigraphical reformulation of\nits objective function. It can therefore be significantly faster than\nother HSDE-based solvers for problems with quadratic objective\nfunctions. Infeasible problems are detected using using a homogeneous\nembedding technique.",
            "name": "r-clarabel"
        },
        {
            "description": "Functions for Classification. Various functions for classification,\nincluding k-nearest neighbour, Learning Vector Quantization and Self-\nOrganizing Maps.",
            "name": "r-class"
        },
        {
            "description": "Choose Univariate Class Intervals. Selected commonly used methods for\nchoosing univariate class intervals for mapping or other graphics\npurposes.",
            "name": "r-classint"
        },
        {
            "description": "Helpers for Developing Command Line Interfaces. A suite of tools to\nbuild attractive command line interfaces ('CLIs'), from semantic\nelements: headings, lists, alerts, paragraphs, etc. Supports custom\nthemes via a 'CSS'-like language. It also contains a number of lower\nlevel 'CLI' elements: rules, boxes, trees, and 'Unicode' symbols with\n'ASCII' alternatives. It integrates with the 'crayon' package to support\n'ANSI' terminal colors.",
            "name": "r-cli"
        },
        {
            "description": "Read and Write from the System Clipboard. Simple utility functions to\nread from and write to the Windows, OS X, and X11 clipboards.",
            "name": "r-clipr"
        },
        {
            "description": "Unicode Symbols at the R Prompt. A small subset of Unicode symbols, that\nare useful when building command line applications. They fall back to\nalternatives on terminals that do not support Unicode. Many symbols were\ntaken from the 'figures' 'npm' package (see\n<https://github.com/sindresorhus/figures>).",
            "name": "r-clisymbols"
        },
        {
            "description": "Date-Time Types and Tools. Provides a comprehensive library for date-\ntime manipulations using a new family of orthogonal date-time classes\n(durations, time points, zoned-times, and calendars) that partition\nresponsibilities so that the complexities of time zones are only\nconsidered when they are really needed. Capabilities include: date-time\nparsing, formatting, arithmetic, extraction and updating of components,\nand rounding.",
            "name": "r-clock"
        },
        {
            "description": "Cluster Ensembles.",
            "name": "r-clue"
        },
        {
            "description": "\"Finding Groups in Data\": Cluster Analysis Extended Rousseeuw et al.\nMethods for Cluster analysis. Much extended the original from Peter\nRousseeuw, Anja Struyf and Mia Hubert, based on Kaufman and Rousseeuw\n(1990) \"Finding Groups in Data\".",
            "name": "r-cluster"
        },
        {
            "description": "Random Cluster Generation (with Specified Degree of Separation). We\ndeveloped the clusterGeneration package to provide functions for\ngenerating random clusters, generating random covariance/correlation\nmatrices, calculating a separation index (data and population version)\nfor pairs of clusters or cluster distributions, and 1-D and 2-D\nprojection plots to visualize clusters. The package also contains a\nfunction to generate random clusters based on factorial designs with\nfactors such as degree of separation, number of clusters, number of\nvariables, number of noisy variables.",
            "name": "r-clustergeneration"
        },
        {
            "description": "statistical analysis and visualization of functional profiles for genes\nand gene clusters. This package implements methods to analyze and\nvisualize functional profiles (GO and KEGG) of gene and gene clusters.",
            "name": "r-clusterprofiler"
        },
        {
            "description": "R Interface to 'CmdStan'. A lightweight interface to 'Stan' <https://mc-\nstan.org>. The 'CmdStanR' interface is an alternative to 'RStan' that\ncalls the command line interface for compilation and running algorithms\ninstead of interfacing with C++ via 'Rcpp'. This has many benefits\nincluding always being compatible with the latest version of Stan, fewer\ninstallation errors, fewer unexpected crashes in RStudio, and a more\npermissive license.",
            "name": "r-cmdstanr"
        },
        {
            "description": "CNE Detection and Visualization. Large-scale identification and advanced\nvisualization of sets of conserved noncoding elements.",
            "name": "r-cner"
        },
        {
            "description": "Output Analysis and Diagnostics for MCMC. Provides functions for\nsummarizing and plotting the output from Markov Chain Monte Carlo (MCMC)\nsimulations, as well as diagnostic tests of convergence to the\nequilibrium distribution of the Markov chain.",
            "name": "r-coda"
        },
        {
            "description": "Code analysis tools for R.",
            "name": "r-codetools"
        },
        {
            "description": "A Normalization and Copy Number Variation Detection Method for Whole\nExome Sequencing. A normalization and copy number variation calling\nprocedure for whole exome DNA sequencing data. CODEX relies on the\navailability of multiple samples processed using the same sequencing\npipeline for normalization, and does not require matched controls. The\nnormalization model in CODEX includes terms that specifically remove\nbiases due to GC content, exon length and targeting and amplification\nefficiency, and latent systemic artifacts. CODEX also includes a Poisson\nlikelihood-based recursive segmentation procedure that explicitly models\nthe count-based exome sequencing data.",
            "name": "r-codex"
        },
        {
            "description": "Conditional Inference Procedures in a Permutation Test Framework.\nConditional inference procedures for the general independence problem\nincluding two-sample, K-sample (non-parametric ANOVA), correlation,\ncensored, ordered and multivariate problems.",
            "name": "r-coin"
        },
        {
            "description": "A Toolbox for Manipulating and Assessing Colors and Palettes. Carries\nout mapping between assorted color spaces including RGB, HSV, HLS,\nCIEXYZ, CIELUV, HCL (polar CIELUV), CIELAB, and polar CIELAB.\nQualitative, sequential, and diverging color palettes based on HCL\ncolors are provided along with corresponding ggplot2 color scales. Color\npalette choice is aided by an interactive app (with either a Tcl/Tk or a\nshiny graphical user interface) and shiny apps with an HCL color picker\nand a color vision deficiency emulator. Plotting functions for\ndisplaying and assessing palettes include color swatches, visualizations\nof the HCL space, and trajectories in HCL and/or RGB spectrum. Color\nmanipulation functions include: desaturation, lightening/darkening,\nmixing, and simulation of color vision deficiencies (deutanomaly,\nprotanomaly, tritanomaly). Details can be found on the project web page\nat <https://colorspace.R-Forge.R-project.org/> and in the accompanying\nscientific paper: Zeileis et al. (2020, Journal of Statistical Software,\n<doi:10.18637/jss.v096.i01>).",
            "name": "r-colorspace"
        },
        {
            "description": "A Colour Picker Tool for Shiny and for Selecting Colours in Plots. A\ncolour picker that can be used as an input in 'Shiny' apps or Rmarkdown\ndocuments. The colour picker supports alpha opacity, custom colour\npalettes, and many more options. A Plot Colour Helper tool is available\nas an 'RStudio' Addin, which helps you pick colours to use in your\nplots. A more generic Colour Picker 'RStudio' Addin is also provided to\nlet you select colours to use in your R code.",
            "name": "r-colourpicker"
        },
        {
            "description": "combinatorics utilities. routines for combinatorics.",
            "name": "r-combinat"
        },
        {
            "description": "High Performance CommonMark and Github Markdown Rendering in R. The\nCommonMark specification defines a rationalized version of markdown\nsyntax. This package uses the 'cmark' reference implementation for\nconverting markdown text into various formats including html, latex and\ngroff man. In addition it exposes the markdown parse tree in xml format.\nAlso includes opt-in support for GFM extensions including tables,\nautolinks, and strikethrough text.",
            "name": "r-commonmark"
        },
        {
            "description": "Make Complex Heatmaps. Complex heatmaps are efficient to visualize\nassociations between different sources of data sets and reveal potential\npatterns. Here the ComplexHeatmap package provides a highly flexible way\nto arrange multiple heatmaps and supports various annotation graphics.",
            "name": "r-complexheatmap"
        },
        {
            "description": "Compositional Data Analysis. Provides functions for the consistent\nanalysis of compositional data (e.g. portions of substances) and\npositive numbers (e.g. concentrations) in the way proposed by J.\nAitchison and V. Pawlowsky-Glahn.",
            "name": "r-compositions"
        },
        {
            "description": "Distribution Function of Quadratic Forms in Normal Variables. Computes\nthe distribution function of quadratic forms in normal variables using\nImhof's method, Davies's algorithm, Farebrother's algorithm or Liu et\nal.'s algorithm.",
            "name": "r-compquadform"
        },
        {
            "description": "Condition-Dependent Operon Predictions. An implementation of the\ncomputational strategy for the comprehensive analysis of condition-\ndependent operon maps in prokaryotes proposed by Fortino et al. (2014)\n<doi:10.1186/1471-2105-15-145>. It uses RNA-seq transcriptome profiles\nto improve prokaryotic operon map inference.",
            "name": "r-condop"
        },
        {
            "description": "An Alternative Conflict Resolution Strategy. R's default conflict\nmanagement system gives the most recently loaded package precedence.\nThis can make it hard to detect conflicts, particularly when they arise\nbecause a package update creates ambiguity that did not previously\nexist. 'conflicted' takes a different approach, making every conflict an\nerror and forcing you to choose which function to use.",
            "name": "r-conflicted"
        },
        {
            "description": "Convolution-Type Smoothed Quantile Regression. Fast and accurate\nconvolution-type smoothed quantile regression. Implemented using\nBarzilai-Borwein gradient descent with a Huber regression warm start.\nConstruct confidence intervals for regression coefficients using\nmultiplier bootstrap.",
            "name": "r-conquer"
        },
        {
            "description": "Compute the median ranking according to the Kemeny's axiomatic approach.",
            "name": "r-consrank"
        },
        {
            "description": "Models Spatially Continuous and Discrete Population GeneticStructure. A\nmethod for modeling genetic data as a combination of discrete layers,\nwithin each of which relatedness may decay continuously with geographic\ndistance. This package contains code for running analyses (which are\nimplemented in the modeling language 'rstan') and visualizing and\ninterpreting output. See the paper for more details on the model and its\nutility.",
            "name": "r-construct"
        },
        {
            "description": "Analysis of Convergent Evolution. Quantifies and assesses the\nsignificance of convergent evolution using two different methods (and 5\ndifferent measures) as described in Stayton (2015)\n<doi:10.1111/evo.12729>. Also displays results in a phylomorphospace\nframework.",
            "name": "r-convevol"
        },
        {
            "description": "Multivariate Dependence with Copulas. Classes (S4) of commonly used\nelliptical, Archimedean, extreme-value and other copula families, as\nwell as their rotations, mixtures and asymmetrizations. Nested\nArchimedean copulas, related tools and special functions. Methods for\ndensity, distribution, random number generation, bivariate dependence\nmeasures, Rosenblatt transform, Kendall distribution function,\nperspective and contour plots. Fitting of copula models with potentially\npartly fixed parameters, including standard errors. Serial independence\ntests, copula specification tests (independence, exchangeability, radial\nsymmetry, extreme-value dependence, goodness-of-fit) and model selection\nbased on cross-validation. Empirical copula, smoothed versions, and non-\nparametric estimators of the Pickands dependence function.",
            "name": "r-copula"
        },
        {
            "description": "Hidden Markov Models of Character Evolution. Fits hidden Markov models\nof discrete character evolution which allow different transition rate\nclasses on different portions of a phylogeny. Beaulieu et al (2013)\n<doi:10.1093/sysbio/syt034>.",
            "name": "r-corhmm"
        },
        {
            "description": "Efficient Estimation of Covariance and (Partial) Correlation. Implements\na James-Stein-type shrinkage estimator for the covariance matrix, with\nseparate shrinkage for variances and correlations. The details of the\nmethod are explained in Schafer and Strimmer (2005)\n<DOI:10.2202/1544-6115.1175> and Opgen-Rhein and Strimmer (2007)\n<DOI:10.2202/1544-6115.1252>. The approach is both computationally as\nwell as statistically very efficient, it is applicable to \"small n,\nlarge p\" data, and always returns a positive definite and well-\nconditioned covariance matrix. In addition to inferring the covariance\nmatrix the package also provides shrinkage estimators for partial\ncorrelations and partial variances. The inverse of the covariance and\ncorrelation matrix can be efficiently computed, as well as any arbitrary\npower of the shrinkage correlation matrix. Furthermore, functions are\navailable for fast singular value decomposition, for computing the\npseudoinverse, and for checking the rank and positive definiteness of a\nmatrix.",
            "name": "r-corpcor"
        },
        {
            "description": "Visualization of a Correlation Matrix. Provides a visual exploratory\ntool on correlation matrix that supports automatic variable reordering\nto help detect hidden patterns among variables.",
            "name": "r-corrplot"
        },
        {
            "description": "Convert Country Names and Country Codes. Countrycode standardizes\ncountry names, converts them into ~40 different coding schemes, and\nassigns region descriptors.",
            "name": "r-countrycode"
        },
        {
            "description": "Test Coverage for Packages. Track and report code coverage for your\npackage and (optionally) upload the results to a coverage service like\n'Codecov' <http://codecov.io> or 'Coveralls' <https://coveralls.io/>.\nCode coverage is a measure of the amount of code being exercised by a\nset of tests. It is an indirect measure of test quality and\ncompleteness. This package is compatible with any testing methodology or\nframework and tracks coverage of both R code and compiled C/C++/FORTRAN\ncode.",
            "name": "r-covr"
        },
        {
            "description": "Streamlined Plot Theme and Plot Annotations for 'ggplot2'. Provides\nvarious features that help with creating publication-quality figures\nwith 'ggplot2', such as a set of themes, functions to align plots and\narrange them into complex compound figures, and functions that make it\neasy to annotate plots and or mix plots with images. The package was\noriginally written for internal use in the Wilke lab, hence the name\n(Claus O. Wilke's plot package). It has also been used extensively in\nthe book Fundamentals of Data Visualization.",
            "name": "r-cowplot"
        },
        {
            "description": "A C++11 Interface for R's C Interface. Provides a header only, C++11\ninterface to R's C interface. Compared to other approaches 'cpp11'\nstrives to be safe against long jumps from the C API as well as C++\nexceptions, conform to normal R function semantics and supports\ninteraction with 'ALTREP' vectors.",
            "name": "r-cpp11"
        },
        {
            "description": "Colored Terminal Output. Colored terminal output on terminals that\nsupport 'ANSI' color and highlight codes. It also works in 'Emacs'\n'ESS'. 'ANSI' color support is automatically detected. Colors and\nhighlighting can be combined and nested. New styles can also be created\neasily. This package was inspired by the 'chalk' 'JavaScript' project.",
            "name": "r-crayon"
        },
        {
            "description": "Tools for Managing SSH and Git Credentials. Setup and retrieve HTTPS and\nSSH credentials for use with 'git' and other services. For HTTPS remotes\nthe package interfaces the 'git-credential' utility which 'git' uses to\nstore HTTP usernames and passwords. For SSH remotes we provide\nconvenient functions to find or generate appropriate SSH keys. The\npackage both helps the user to setup a local git installation, and also\nprovides a back-end for git/ssh client libraries to authenticate with\nexisting user credentials.",
            "name": "r-credentials"
        },
        {
            "description": "Inter-Widget Interactivity for HTML Widgets. Provides building blocks\nfor allowing HTML widgets to communicate with each other, with Shiny or\nwithout (i.e. static .html files). Currently supports linked brushing\nand filtering.",
            "name": "r-crosstalk"
        },
        {
            "description": "HTTP Client. A simple HTTP client, with tools for making HTTP requests,\nand mocking HTTP requests. The package is built on R6, and takes\ninspiration from Ruby's 'faraday' gem\n(<https://rubygems.org/gems/faraday>). The package name is a play on\ncurl, the widely used command line tool for HTTP, and this package is\nbuilt on top of the R package 'curl', an interface to 'libcurl'\n(<https://curl.haxx.se/libcurl>).",
            "name": "r-crul"
        },
        {
            "description": "Cluster and Tree Conversion. Tools for export and import classification\ntrees and clusters to other programs",
            "name": "r-ctc"
        },
        {
            "description": "Adaptive multivariate integration over hypercubes. R wrappers around the\ncubature C library of Steven G. Johnson for adaptive multivariate\nintegration over hypercubes and the Cuba C library of Thomas Hahn for\ndeterministic and Monte Carlo integration. Scalar and vector interfaces\nfor cubature and Cuba routines are provided; the vector interfaces are\nhighly recommended as demonstrated in the package vignette.",
            "name": "r-cubature"
        },
        {
            "description": "Rule- And Instance-Based Regression Modeling. Regression modeling using\nrules with added instance-based corrections.",
            "name": "r-cubist"
        },
        {
            "description": "A Modern and Flexible Web Client for R. The curl() and curl_download()\nfunctions provide highly configurable drop-in replacements for base\nurl() and download.file() with better performance, support for\nencryption (https, ftps), gzip compression, authentication, and other\nlibcurl goodies. The core of the package implements a framework for\nperforming fully customized requests where data can be processed either\nin memory, on disk, or streaming via the callback or connection\ninterfaces. Some knowledge of libcurl is recommended; for a more-user-\nfriendly web client see the 'httr' package which builds on this package\nwith http specific tools and logic.",
            "name": "r-curl"
        },
        {
            "description": "Disciplined Convex Optimization. An object-oriented modeling language\nfor disciplined convex programming (DCP) as described in Fu, Narasimhan,\nand Boyd (2020, <doi:10.18637/jss.v094.i14>). It allows the user to\nformulate convex optimization problems in a natural way following\nmathematical convention and DCP rules. The system analyzes the problem,\nverifies its convexity, converts it into a canonical form, and hands it\noff to an appropriate solver to obtain the solution. Interfaces to\nsolvers on CRAN and elsewhere are provided, both commercial and open\nsource.",
            "name": "r-cvxr"
        },
        {
            "description": "Accurate sample inference from amplicon data with single nucleotide\nresolution",
            "name": "r-dada2"
        },
        {
            "description": "Extension of `data.frame`. Fast aggregation of large data (e.g. 100GB in\nRAM), fast ordered joins, fast add/modify/delete of columns by group\nusing no copies at all, list columns and a fast file reader (fread).\nOffers a natural and flexible syntax, for faster development.",
            "name": "r-data-table"
        },
        {
            "description": "R Database Interface. A database interface definition for communication\nbetween R and relational database management systems. All classes in\nthis package are virtual and need to be extended by the various R/DBMS\nimplementations.",
            "name": "r-dbi"
        },
        {
            "description": "A 'dplyr' Back End for Databases. A 'dplyr' back end for databases that\nallows you to work with remote database tables as if they are in-memory\ndata frames. Basic features works with any database that has a 'DBI'\nback end; more advanced features require 'SQL' translation to be\nprovided by the package author.",
            "name": "r-dbplyr"
        },
        {
            "description": "Debug R Packages. Specify debug messages as special string constants,\nand control debugging of packages via environment variables.",
            "name": "r-debugme"
        },
        {
            "description": "Tools for curating, analyzing, and manipulating biological sequences. A\ntoolset for deciphering and managing biological sequences.",
            "name": "r-decipher"
        },
        {
            "description": "A unified framework for working transparently with on-disk and in-memory\narray-like datasets. Wrapping an array-like object (typically an on-disk\nobject) in a DelayedArray object allows one to perform common array\noperations on it without loading the object in memory. In order to\nreduce memory usage and optimize performance, operations on the object\nare either delayed or executed using a block processing mechanism. Note\nthat this also works on in-memory array-like objects like DataFrame\nobjects (typically with Rle columns), Matrix objects, and ordinary\narrays and data frames.",
            "name": "r-delayedarray"
        },
        {
            "description": "Functions that Apply to Rows and Columns of 'DelayedMatrix' Objects. A\nport of the 'matrixStats' API for use with DelayedMatrix objects from\nthe 'DelayedArray' package. High-performing functions operating on rows\nand columns of DelayedMatrix objects, e.g. col / rowMedians(), col /\nrowRanks(), and col / rowSds(). Functions optimized per data type and\nfor subsetted calculations such that both memory usage and processing\ntime is minimized.",
            "name": "r-delayedmatrixstats"
        },
        {
            "description": "Delaunay Triangulation and Dirichlet (Voronoi) Tessellation. Calculates\nthe Delaunay triangulation and the Dirichlet or Voronoi tessellation\n(with respect to the entire plane) of a planar point set. Plots\ntriangulations and tessellations in various ways. Clips tessellations to\nsub-windows. Calculates perimeters of tessellations. Summarises\ninformation about the tiles of the tessellation.",
            "name": "r-deldir"
        },
        {
            "description": "Extending 'Dendrogram' Functionality in R. Offers a set of functions for\nextending 'dendrogram' objects in R, letting you visualize and compare\ntrees of 'hierarchical clusterings'. You can (1) Adjust a tree's\ngraphical parameters - the color, size, type, etc of its branches, nodes\nand labels. (2) Visually and statistically compare different\n'dendrograms' to one another.",
            "name": "r-dendextend"
        },
        {
            "description": "Density-Preserving Data Visualization via Non-Linear Dimensionality\nReduction. Implements the density-preserving modification to t-SNE and\nUMAP described by Narayan et al. (2020) . The non-linear dimensionality\nreduction techniques t-SNE and UMAP enable users to summarise complex\nhigh-dimensional sequencing data such as single cell RNAseq using lower\ndimensional representations. These lower dimensional representations\nenable the visualisation of discrete transcriptional states, as well as\ncontinuous trajectory (for example, in early development). However,\nthese methods focus on the local neighbourhood structure of the data. In\nsome cases, this results in misleading visualisations, where the density\nof cells in the low-dimensional embedding does not represent the\ntranscriptional heterogeneity of data in the original high-dimensional\nspace. den-SNE and densMAP aim to enable more accurate visual\ninterpretation of high-dimensional datasets by producing lower-\ndimensional embeddings that accurately represent the heterogeneity of\nthe original high-dimensional space, enabling the identification of\nhomogeneous and heterogeneous cell states. This accuracy is accomplished\nby including in the optimisation process a term which considers the\nlocal density of points in the original high-dimensional space. This can\nhelp to create visualisations that are more representative of\nheterogeneity in the original high-dimensional space.",
            "name": "r-densvis"
        },
        {
            "description": "Global Optimization by Differential Evolution. Implements the\ndifferential evolution algorithm for global optimization of a real-\nvalued function of a real-valued parameter vector.",
            "name": "r-deoptim"
        },
        {
            "description": "Differential Evolution Optimization in Pure R. Differential Evolution\n(DE) stochastic algorithms for global optimization of problems with and\nwithout constraints. The aim is to curate a collection of its state-of-\nthe-art variants that (1) do not sacrifice simplicity of design, (2) are\nessentially tuning-free, and (3) can be efficiently implemented directly\nin the R language. Currently, it only provides an implementation of the\n'jDE' algorithm by Brest et al. (2006) <doi:10.1109/TEVC.2006.872133>.",
            "name": "r-deoptimr"
        },
        {
            "description": "Symbolic Differentiation. R-based solution for symbolic differentiation.\nIt admits user-defined function as well as function substitution in\narguments of functions to be differentiated. Some symbolic\nsimplification is part of the work.",
            "name": "r-deriv"
        },
        {
            "description": "Manipulate DESCRIPTION Files. Tools to read, write, create, and\nmanipulate DESCRIPTION files. It is intended for packages that create or\nmanipulate other packages.",
            "name": "r-desc"
        },
        {
            "description": "Differential gene expression analysis based on the negative binomial\ndistribution. Estimate variance-mean dependence in count data from high-\nthroughput sequencing assays and test for differential expression based\non a model using the negative binomial distribution",
            "name": "r-deseq"
        },
        {
            "description": "Differential gene expression analysis based on the negative binomial\ndistribution. Estimate variance-mean dependence in count data from high-\nthroughput sequencing assays and test for differential expression based\non a model using the negative binomial distribution.",
            "name": "r-deseq2"
        },
        {
            "description": "Solvers for Initial Value Problems of Differential Equations ('ODE',\n'DAE', 'DDE'). Functions that solve initial value problems of a system\nof first-order ordinary differential equations ('ODE'), of partial\ndifferential equations ('PDE'), of differential algebraic equations\n('DAE'), and of delay differential equations. The functions provide an\ninterface to the FORTRAN functions 'lsoda', 'lsodar', 'lsode', 'lsodes'\nof the 'ODEPACK' collection, to the FORTRAN functions 'dvode', 'zvode'\nand 'daspk' and a C-implementation of solvers of the 'Runge-Kutta'\nfamily with fixed or variable time steps. The package contains routines\ndesigned for solving 'ODEs' resulting from 1-D, 2-D and 3-D partial\ndifferential equations ('PDE') that have been converted to 'ODEs' by\nnumerical differencing.",
            "name": "r-desolve"
        },
        {
            "description": "Tools to Make Developing R Packages Easier. Collection of package\ndevelopment tools.",
            "name": "r-devtools"
        },
        {
            "description": "Inference of differential exon usage in RNA-Seq. The package is focused\non finding differential exon usage using RNA-seq exon counts between\nsamples with different experimental designs. It provides functions that\nallows the user to make the necessary statistical tests based on a model\nthat uses the negative binomial distribution to estimate the variance\nbetween biological replicates and generalized linear models for testing.\nThe package also provides functions for the visualization and\nexploration of the results.",
            "name": "r-dexseq"
        },
        {
            "description": "Functions for Visualising Simple Graphs (Networks), Plotting Flow\nDiagrams. Visualises simple graphs (networks) based on a transition\nmatrix, utilities to plot flow diagrams, visualising webs, electrical\nnetworks, etc. Support for the book \"A practical guide to ecological\nmodelling - using R as a simulation platform\" by Karline Soetaert and\nPeter M.J. Herman (2009), Springer. and the book \"Solving Differential\nEquations in R\" by Karline Soetaert, Jeff Cash and Francesca Mazzia\n(2012), Springer. Includes demo(flowchart), demo(plotmat),\ndemo(plotweb).",
            "name": "r-diagram"
        },
        {
            "description": "Graph/Network Visualization. Build graph/network structures using\nfunctions for stepwise addition and deletion of nodes and edges. Work\nwith data available in tables for bulk addition of nodes, edges, and\nassociated metadata. Use graph selections and traversals to apply\nchanges to specific nodes or edges. A wide selection of graph algorithms\nallow for the analysis of graphs. Visualize the graphs and take\nadvantage of any aesthetic properties assigned to nodes and edges.",
            "name": "r-diagrammer"
        },
        {
            "description": "Kriging Methods for Computer Experiments. Estimation, validation and\nprediction of kriging models. Important functions: km, print.km,\nplot.km, predict.km.",
            "name": "r-dicekriging"
        },
        {
            "description": "Color Schemes for Dichromats. Collapse red-green or green-blue\ndistinctions to simulate the effects of different types of color-\nblindness.",
            "name": "r-dichromat"
        },
        {
            "description": "Diffs for R Objects. Generate a colorized diff of two R objects for an\nintuitive visualization of their differences.",
            "name": "r-diffobj"
        },
        {
            "description": "Diffusion Map. Implements diffusion map method of data parametrization,\nincluding creation and visualization of diffusion map, clustering with\ndiffusion K-means and regression using adaptive regression model.\nRichards (2009) <doi:10.1088/0004-637X/691/1/32>.",
            "name": "r-diffusionmap"
        },
        {
            "description": "Create Compact Hash Digests of R Objects. Implementation of a function\n'digest()' for the creation of hash digests of arbitrary R objects\n(using the md5, sha-1, sha-256, crc32, xxhash and murmurhash algorithms)\npermitting easy comparison of R language objects, as well as a function\n'hmac()' to create hash-based message authentication code. The md5\nalgorithm by Ron Rivest is specified in RFC 1321, the sha-1 and sha-256\nalgorithms are specified in FIPS-180-1 and FIPS-180-2, and the crc32\nalgorithm is described in\nftp://ftp.rocksoft.com/cliens/rocksoft/papers/crc_v3.txt. For md5,\nsha-1, sha-256 and aes, this package uses small standalone\nimplementations that were provided by Christophe Devine. For crc32, code\nfrom the zlib library is used. For sha-512, an implementation by Aaron\nD. Gifford is used. For xxhash, the implementation by Yann Collet is\nused. For murmurhash, an implementation by Shane Day is used. Please\nnote that this package is not meant to be deployed for cryptographic\npurposes for which more comprehensive (and widely tested) libraries such\nas OpenSSL should be used.",
            "name": "r-digest"
        },
        {
            "description": "Hartigan's Dip Test Statistic for Unimodality - Corrected. Compute\nHartigan's dip test statistic for unimodality /; multimodality and\nprovide a test with simulation based p-values, where; the original\npublic code has been corrected.",
            "name": "r-diptest"
        },
        {
            "description": "Managing Expiration for Cache Directories. Implements an expiration\nsystem for access to versioned directories. Directories that have not\nbeen accessed by a registered function within a certain time frame are\ndeleted. This aims to reduce disk usage by eliminating obsolete caches\ngenerated by old versions of packages.",
            "name": "r-dir-expiry"
        },
        {
            "description": "Dirichlet-Multinomial Mixture Model Machine Learning for Microbiome\nData. Dirichlet-multinomial mixture models can be used to describe\nvariability in microbial metagenomic data. This package is an interface\nto code originally made available by Holmes, Harris, and Quince, 2012,\nPLoS ONE 7(2): 1-15, as discussed further in the man page for this\npackage, ?DirichletMultinomial.",
            "name": "r-dirichletmultinomial"
        },
        {
            "description": "Species Distribution Modeling. Methods for species distribution\nmodeling, that is, predicting the environmental similarity of any site\nto that of the locations of known occurrences of a species.",
            "name": "r-dismo"
        },
        {
            "description": "Functions for Base Types and Core R and 'Tidyverse' Features. Vectorised\ndistribution objects with tools for manipulating, visualising, and using\nprobability distributions. Designed to allow model prediction outputs to\nreturn distributions rather than their parameters, allowing users to\ndirectly interact with predictive distributions in a data-oriented\nworkflow. In addition to providing generic replacements for p/d/q/r\nfunctions, other useful statistics can be computed including means,\nvariances, intervals, and highest density regions.",
            "name": "r-distributional"
        },
        {
            "description": "Comparative 'Phylogenetic' Analyses of Diversification. Mostly focusing\non analysing diversification and character evolution. Contains\nimplementations of 'BiSSE' (Binary State 'Speciation' and Extinction)\nand its unresolved tree extensions, 'MuSSE' (Multiple State 'Speciation'\nand Extinction), 'QuaSSE', 'GeoSSE', and 'BiSSE-ness' Other included\nmethods include Markov models of discrete and continuous trait evolution\nand constant rate 'speciation' and extinction.",
            "name": "r-diversitree"
        },
        {
            "description": "Methylation array and sequencing spatial analysis methods. De novo\nidentification and extraction of differentially methylated regions\n(DMRs) from the human genome using Whole Genome Bisulfite Sequencing\n(WGBS) and Illumina Infinium Array (450K and EPIC) data. Provides\nfunctionality for filtering probes possibly confounded by SNPs and\ncross-hybridisation. Includes GRanges generation and plotting functions.",
            "name": "r-dmrcate"
        },
        {
            "description": "DNA copy number data analysis. Implements the circular binary\nsegmentation (CBS) algorithm to segment DNA copy number data and\nidentify genomic regions with abnormal copy number.",
            "name": "r-dnacopy"
        },
        {
            "description": "A set of annotation maps describing the entire Disease Ontology. A set\nof annotation maps describing the entire Disease Ontology assembled\nusing data from DO.",
            "name": "r-do-db"
        },
        {
            "description": "Groupwise Statistics, LSmeans, Linear Estimates, Utilities. Utility\npackage containing: 1) Facilities for working with grouped data: 'do'\nsomething to data stratified 'by' some variables. 2) LSmeans (least-\nsquares means), general linear estimates. 3) Restrict functions to a\nsmaller domain. 4) Miscellaneous other utilities.",
            "name": "r-doby"
        },
        {
            "description": "Foreach Parallel Adaptor for 'parallel'. Provides a parallel backend for\nthe %dopar% function using the multicore functionality of the parallel\npackage.",
            "name": "r-domc"
        },
        {
            "description": "Foreach Parallel Adaptor for the 'parallel' Package. Provides a parallel\nbackend for the %dopar% function using the parallel package.",
            "name": "r-doparallel"
        },
        {
            "description": "Generic Reproducible Parallel Backend for 'foreach' Loops. Provides\nfunctions to perform reproducible parallel foreach loops, using\nindependent random streams as generated by L'Ecuyer's combined multiple-\nrecursive generator (L'Ecuyer (1999), <doi:10.1287/opre.47.1.159>). It\nenables to easily convert standard %dopar% loops into fully reproducible\nloops, independently of the number of workers, the task scheduling\nstrategy, or the chosen parallel environment and associated foreach\nbackend.",
            "name": "r-dorng"
        },
        {
            "description": "Disease Ontology Semantic and Enrichment analysis. This package\nimplements five methods proposed by Resnik, Schlicker, Jiang, Lin and\nWang respectively for measuring semantic similarities among DO terms and\ngene products. Enrichment analyses including hypergeometric model and\ngene set enrichment analysis are also implemented for discovering\ndisease associations of high-throughput biological data.",
            "name": "r-dose"
        },
        {
            "description": "Foreach Parallel Adaptor for the 'snow' Package. Provides a parallel\nbackend for the %dopar% function using the snow package of Tierney,\nRossini, Li, and Sevcikova.",
            "name": "r-dosnow"
        },
        {
            "description": "Enhanced Foreign Function Interface Supporting Long Vectors. Provides\n.C64(), which is an enhanced version of .C() and .Fortran() from the\nforeign function interface. .C64() supports long vectors, arguments of\ntype 64-bit integer, and provides a mechanism to avoid unnecessary\ncopies of read-only and write-only arguments. This makes it a convenient\nand fast interface to C/C++ and Fortran code.",
            "name": "r-dotcall64"
        },
        {
            "description": "Syntax Highlighting and Automatic Linking. Syntax highlighting of R\ncode, specifically designed for the needs of 'RMarkdown' packages like\n'pkgdown', 'hugodown', and 'bookdown'. It includes linking of function\ncalls to their documentation on the web, and automatic translation of\nANSI escapes in output to the equivalent HTML.",
            "name": "r-downlit"
        },
        {
            "description": "Download Files over HTTP and HTTPS. Provides a wrapper for the\ndownload.file function, making it possible to download files over HTTPS\non Windows, Mac OS X, and other Unix-like platforms. The 'RCurl' package\nprovides this functionality (and much more) but can be difficult to\ninstall because it must be compiled with external dependencies. This\npackage has no external dependencies, so it is much easier to install.",
            "name": "r-downloader"
        },
        {
            "description": "A Grammar of Data Manipulation. A fast, consistent tool for working with\ndata frame like objects, both in memory and out of memory.",
            "name": "r-dplyr"
        },
        {
            "description": "Fast Pseudo Random Number Generators. Several fast random number\ngenerators are provided as C++ header only libraries: The PCG family by\nO'Neill (2014 <https://www.cs.hmc.edu/tr/hmc-cs-2014-0905.pdf>) as well\nas Xoroshiro128+ and Xoshiro256+ by Blackman and Vigna (2018\n<arXiv:1805.01407>). In addition fast functions for generating random\nnumbers according to a uniform, normal and exponential distribution are\nincluded. The latter two use the Ziggurat algorithm originally proposed\nby Marsaglia and Tsang (2000, <doi:10.18637/jss.v005.i08>). These\nfunctions are exported to R and as a C++ interface and are enabled for\nuse with the default 64 bit generator from the PCG family, Xoroshiro128+\nand Xoshiro256+ as well as the 64 bit version of the 20 rounds Threefry\nengine (Salmon et al., 2011 <doi:10.1145/2063384.2063405>) as provided\nby the package 'sitmo'.",
            "name": "r-dqrng"
        },
        {
            "description": "Dispersion shrinkage for sequencing data. DSS is an R library performing\ndifferntial analysis for count-based sequencing data. It detectes\ndifferentially expressed genes (DEGs) from RNA-seq, and differentially\nmethylated loci or regions (DML/DMRs) from bisulfite sequencing (BS-\nseq). The core of DSS is a new dispersion shrinkage method for\nestimating the dispersion parameter from Gamma-Poisson or Beta-Binomial\ndistributions.",
            "name": "r-dss"
        },
        {
            "description": "A Wrapper of the JavaScript Library 'DataTables'. Data objects in R can\nbe rendered as HTML tables using the JavaScript library 'DataTables'\n(typically via R Markdown or Shiny). The 'DataTables' library has been\nincluded in this R package. The package name 'DT' is an abbreviation of\n'DataTables'.",
            "name": "r-dt"
        },
        {
            "description": "Data Table Back-End for 'dplyr'. Provides a data.table backend for\n'dplyr'. The goal of 'dtplyr' is to allow you to write 'dplyr' code that\nis automatically translated to the equivalent, but usually much faster,\ndata.table code.",
            "name": "r-dtplyr"
        },
        {
            "description": "Dynamic Time Warping Algorithms. A comprehensive implementation of\ndynamic time warping (DTW) algorithms in R. DTW computes the optimal\n(least cumulative distance) alignment between points of two time series.\nCommon DTW variants covered include local (slope) and global (window)\nconstraints, subsequence matches, arbitrary distance definitions,\nnormalizations, minimum variance matching, and so on. Provides\ncumulative distances, alignments, specialized plot styles, etc., as\ndescribed in Giorgino (2009) <doi:10.18637/jss.v031.i07>.",
            "name": "r-dtw"
        },
        {
            "description": "Assessment of duplication rates in RNA-Seq datasets",
            "name": "r-dupradar"
        },
        {
            "description": "Interface to 'Dygraphs' Interactive Time Series Charting Library. An R\ninterface to the 'dygraphs' JavaScript charting library (a copy of which\nis included in the package). Provides rich facilities for charting time-\nseries data in R, including highly configurable series- and axis-display\nand interactive features like zoom/pan and series/point highlighting.",
            "name": "r-dygraphs"
        },
        {
            "description": "Methods for Detection of Clusters in Hierarchical Clustering Dendrograms\nContains methods for detection of clusters in hierarchical clustering\ndendrograms.",
            "name": "r-dynamictreecut"
        },
        {
            "description": "Misc Functions of the Department of Statistics, Probability Theory Group\n(Formerly: E1071), TU Wien. Functions for latent class analysis, short\ntime Fourier transform, fuzzy clustering, support vector machines,\nshortest path computation, bagged clustering, naive Bayes classifier,\ngeneralized k-nearest neighbour ...",
            "name": "r-e1071"
        },
        {
            "description": "Multivariate Adaptive Regression Splines. Build regression models using\nthe techniques in Friedman's papers \"Fast MARS\" and \"Multivariate\nAdaptive Regression Splines\" <doi:10.1214/aos/1176347963>.",
            "name": "r-earth"
        },
        {
            "description": "An R package for gene and isoform differential expression analysis of\nRNA-seq data. R/EBSeq is an R package for identifying genes and isoforms\ndifferentially expressed (DE) across two or more biological conditions\nin an RNA-seq experiment. Details can be found in Leng et al., 2013. It\nprovides the syntax required for identifying DE genes and isoforms in a\ntwo-group RNA-seq experiment as well for identifying DE genes across\nmore than two conditions (the commands for identifying DE isoforms\nacross more than two conditions are the same as those required for gene-\nlevel analysis).",
            "name": "r-ebseq"
        },
        {
            "description": "Embedded Conic Solver in R. R interface to the Embedded COnic Solver\n(ECOS), an efficient and robust C library for convex problems. Conic and\nequality constraints can be specified in addition to integer and boolean\nvariable constraints for mixed-integer problems. This R interface is\ninspired by the python interface and has similar calling conventions.",
            "name": "r-ecosolver"
        },
        {
            "description": "Non-Parametric Multiple Change-Point Analysis of MultivariateData.\nImplements various procedures for finding multiple change-points from\nMatteson D. et al (2013) <doi:10.1080/01621459.2013.849605>, Zhang W. et\nal (2017) <doi:10.1109/ICDMW.2017.44>, Arlot S. et al (2019). Two\nmethods make use of dynamic programming and pruning, with no\ndistributional assumptions other than the existence of certain absolute\nmoments in one method. Hierarchical and exact search methods are\nincluded. All methods return the set of estimated change-points as well\nas other summary information.",
            "name": "r-ecp"
        },
        {
            "description": "Empirical Analysis of Digital Gene Expression Data in R. Differential\nexpression analysis of RNA-seq expression profiles with biological\nreplication. Implements a range of statistical methodology based on the\nnegative binomial distributions, including empirical Bayes estimation,\nexact tests, generalized linear models and quasi-likelihood tests. As\nwell as RNA-seq, it be applied to differential signal analysis of other\ntypes of genomic data that produce counts, including ChIP-seq,\nBisulfite-seq, SAGE and CAGE.",
            "name": "r-edger"
        },
        {
            "description": "Effect Displays for Linear, Generalized Linear, and Other Models.\nGraphical and tabular effect displays, e.g., of interactions, for\nvarious statistical models with linear predictors.",
            "name": "r-effects"
        },
        {
            "description": "Data Sets, Functions and Examples from the Book: \"The Elements of\nStatistical Learning, Data Mining, Inference, and Prediction\" by Trevor\nHastie, Robert Tibshirani and Jerome Friedman",
            "name": "r-elemstatlearn"
        },
        {
            "description": "Functions for Drawing Ellipses and Ellipse-Like Confidence Regions.\nContains various routines for drawing ellipses and ellipse-like\nconfidence regions, implementing the plots described in Murdoch and Chow\n(1996), A graphical display of large correlation matrices, The American\nStatistician 50, 178-180. There are also routines implementing the\nprofile plots described in Bates and Watts (1988), Nonlinear Regression\nAnalysis and its Applications.",
            "name": "r-ellipse"
        },
        {
            "description": "Tools for Working with ... The ellipsis is a powerful tool for extending\nfunctions. Unfortunately this power comes at a cost: misspelled\narguments will be silently ignored. The ellipsis package provides a\ncollection of functions to catch problems and alert the user.",
            "name": "r-ellipsis"
        },
        {
            "description": "Estimated Marginal Means, aka Least-Squares Means. Obtain estimated\nmarginal means (EMMs) for many linear, generalized linear, and mixed\nmodels. Compute contrasts or linear functions of EMMs, trends, and\ncomparisons of slopes. Plots and other displays. Least-squares means are\ndiscussed, and the term \"estimated marginal means\" is suggested, in\nSearle, Speed, and Milliken (1980) Population marginal means in the\nlinear model: An alternative to least squares means, The American\nStatistician 34(4), 216-221 <doi:10.1080/00031305.1980.10483031>.",
            "name": "r-emmeans"
        },
        {
            "description": "A Maximum Likelihood Approach to the Analysis of Modularity. Fit models\nof modularity to morphological landmarks. Perform model selection on\nresults. Fit models with a single within-module correlation or with\nseparate within-module correlations fitted to each module.",
            "name": "r-emmli"
        },
        {
            "description": "E-Statistics: Multivariate Inference via the Energy of Data.\nE-statistics (energy) tests and statistics for multivariate and\nunivariate inference, including distance correlation, one-sample, two-\nsample, and multi-sample tests for comparing multivariate distributions,\nare implemented. Measuring and testing multivariate independence based\non distance correlation, partial distance correlation, multivariate\ngoodness-of-fit tests, k-groups and hierarchical clustering based on\nenergy distance, testing for multivariate normality, distance components\n(disco) for non-parametric analysis of structured data, and other energy\nstatistics/methods are implemented.",
            "name": "r-energy"
        },
        {
            "description": "Visualization of Functional Enrichment Result. The 'enrichplot' package\nimplements several visualization methods for interpreting functional\nenrichment results obtained from ORA or GSEA analysis. All the\nvisualization methods are developed based on 'ggplot2' graphics.",
            "name": "r-enrichplot"
        },
        {
            "description": "Utilities to create and use Ensembl-based annotation databases. The\npackage provides functions to create and use transcript centric\nannotation databases/packages. The annotation for the databases are\ndirectly fetched from Ensembl using their Perl API. The functionality\nand data is similar to that of the TxDb packages from the\nGenomicFeatures package, but, in addition to retrieve all\ngene/transcript models and annotations from the database, ensembldb\nprovides a filter framework allowing to retrieve annotations for\nspecific entries like genes encoded on a chromosome region or transcript\nmodels of lincRNA genes. EnsDb databases built with ensembldb contain\nalso protein annotations and mappings between proteins and their\nencoding transcripts. Finally, ensembldb provides functions to map\nbetween genomic, transcript and protein coordinates.",
            "name": "r-ensembldb"
        },
        {
            "description": "Package for Environmental Statistics, Including US EPA Guidance.\nGraphical and statistical analyses of environmental data, with focus on\nanalyzing chemical concentrations and physical parameters, usually in\nthe context of mandated environmental monitoring. Major environmental\nstatistical methods found in the literature and regulatory guidance\ndocuments, with extensive help that explains what these methods do, how\nto use them, and where to find them in the literature. Numerous built-in\ndata sets from regulatory guidance documents and environmental\nstatistics literature. Includes scripts reproducing analyses presented\nin the book \"EnvStats: An R Package for Environmental Statistics\"\n(Millard, 2013, Springer, ISBN 978-1-4614-8455-4,\n<https://www.springer.com/book/9781461484554>).",
            "name": "r-envstats"
        },
        {
            "description": "Fit, Simulate and Diagnose Exponential-Family Models for Networks. An\nintegrated set of tools to analyze and simulate networks based on\nexponential-family random graph models (ERGMs). 'ergm' is a part of the\nStatnet suite of packages for network analysis. See Hunter, Handcock,\nButts, Goodreau, and Morris (2008) <doi:10.18637/jss.v024.i03> and\nKrivitsky, Hunter, Morris, and Klumb (2021) <arXiv:2106.04997>.",
            "name": "r-ergm"
        },
        {
            "description": "Tools for Assessing Estimability of Linear Predictions. Provides tools\nfor determining estimability of linear functions of regression\ncoefficients, and 'epredict' methods that handle non-estimable cases\ncorrectly. Estimability theory is discussed in many linear-models\ntextbooks including Chapter 3 of Monahan, JF (2008), \"A Primer on Linear\nModels\", Chapman and Hall (ISBN 978-1-4200-6201-4).",
            "name": "r-estimability"
        },
        {
            "description": "R Interface to the Europe PubMed Central RESTful Web Service. An R\nClient for the Europe PubMed Central RESTful Web Service (see\n<https://europepmc.org/RestfulWebService> for more information). It\ngives access to both metadata on life science literature and open access\nfull texts. Europe PMC indexes all PubMed content and other literature\nsources including Agricola, a bibliographic database of citations to the\nagricultural literature, or Biological Patents. In addition to\nbibliographic metadata, the client allows users to fetch citations and\nreference lists. Links between life-science literature and other EBI\ndatabases, including ENA, PDB or ChEMBL are also accessible. No\nregistration or API key is required. See the vignettes for usage\nexamples.",
            "name": "r-europepmc"
        },
        {
            "description": "Parsing and Evaluation Tools that Provide More Details than the Default.\nParsing and evaluation tools that make it easy to recreate the command\nline behaviour of R.",
            "name": "r-evaluate"
        },
        {
            "description": "Functions for Extreme Value Distributions. Extends simulation,\ndistribution, quantile and density functions to univariate and\nmultivariate parametric extreme value distributions, and provides\nfitting functions which calculate maximum likelihood estimates for\nunivariate and bivariate maxima models, and for univariate and bivariate\nthreshold models.",
            "name": "r-evd"
        },
        {
            "description": "Fast Extraction from Raster Datasets using Polygons. Provides a\nreplacement for the 'extract' function from the 'raster' package that is\nsuitable for extracting raster values using 'sf' polygons.",
            "name": "r-exactextractr"
        },
        {
            "description": "Copy number variant detection from exome sequencing read depth.\nDetection of copy number variants (CNV) from exome sequencing samples,\nincluding unpaired samples. The package implements a hidden Markov model\nwhich uses positional covariates, such as background read depth and GC-\ncontent, to simultaneously normalize and segment the samples into\nregions of constant copy count.",
            "name": "r-exomecopy"
        },
        {
            "description": "Calls Copy Number Variants from Targeted Sequence Data. Calls copy\nnumber variants (CNVs) from targeted sequence data, typically exome\nsequencing experiments designed to identify the genetic basis of\nMendelian disorders.",
            "name": "r-exomedepth"
        },
        {
            "description": "Client to access ExperimentHub resources. This package provides a client\nfor the Bioconductor ExperimentHub web resource. ExperimentHub provides\na central location where curated data from experiments, publications or\ntraining courses can be accessed. Each resource has associated metadata,\ntags and date of modification. The client creates and manages a local\ncache of files retrieved enabling quick and reproducible access.",
            "name": "r-experimenthub"
        },
        {
            "description": "Exponential Integral and Incomplete Gamma Function. The exponential\nintegrals E_1(x), E_2(x), E_n(x) and Ei(x), and the incomplete gamma\nfunction G(a, x) defined for negative values of its first argument. The\npackage also gives easy access to the underlying C routines through an\nAPI; see the package vignette for details. A test package included in\nsub-directory example_API provides an implementation. C routines derived\nfrom the GNU Scientific Library <https://www.gnu.org/software/gsl/>.",
            "name": "r-expint"
        },
        {
            "description": "Matrix Exponential, Log, 'etc'. Computation of the matrix exponential,\nlogarithm, sqrt, and related quantities.",
            "name": "r-expm"
        },
        {
            "description": "Extract and Visualize the Results of Multivariate Data Analyses.\nProvides some easy-to-use functions to extract and visualize the output\nof multivariate data analyses, including 'PCA' (Principal Component\nAnalysis), 'CA' (Correspondence Analysis), 'MCA' (Multiple\nCorrespondence Analysis), 'FAMD' (Factor Analysis of Mixed Data), 'MFA'\n(Multiple Factor Analysis) and 'HMFA' (Hierarchical Multiple Factor\nAnalysis) functions from different R packages. It contains also\nfunctions for simplifying some clustering analysis steps and provides\n'ggplot2' - based elegant data visualization.",
            "name": "r-factoextra"
        },
        {
            "description": "Multivariate Exploratory Data Analysis and Data Mining. Exploratory data\nanalysis methods to summarize, visualize and describe datasets. The main\nprincipal component methods are available, those with the largest\npotential in terms of applications: principal component analysis (PCA)\nwhen variables are quantitative, correspondence analysis (CA) and\nmultiple correspondence analysis (MCA) when variables are categorical,\nMultiple Factor Analysis when variables are structured in groups, etc.\nand hierarchical cluster analysis. F. Husson, S. Le and J. Pages (2017).",
            "name": "r-factominer"
        },
        {
            "description": "ANSI Control Sequence Aware String Functions. Counterparts to R string\nmanipulation functions that account for the effects of ANSI text\nformatting control sequences.",
            "name": "r-fansi"
        },
        {
            "description": "High Performance Colour Space Manipulation. The encoding of colour can\nbe handled in many different ways, using different colour spaces. As\ndifferent colour spaces have different uses, efficient conversion\nbetween these representations are important. The 'farver' package\nprovides a set of functions that gives access to very fast colour space\nconversion and comparisons implemented in C++, and offers speed\nimprovements over the 'convertColor' function in the 'grDevices'\npackage.",
            "name": "r-farver"
        },
        {
            "description": "Fast Hierarchical Clustering Routines for R and 'Python'. This is a two-\nin-one package which provides interfaces to both R and 'Python'. It\nimplements fast hierarchical, agglomerative clustering routines. Part of\nthe functionality is designed as drop-in replacement for existing\nroutines: linkage() in the 'SciPy' package 'scipy.cluster.hierarchy',\nhclust() in R's 'stats' package, and the 'flashClust' package. It\nprovides the same functionality with the benefit of a much faster\nimplementation. Moreover, there are memory-saving routines for\nclustering of vector data, which go beyond what the existing packages\nprovide. For information on how to install the 'Python' files, see the\nfile INSTALL in the source distribution.",
            "name": "r-fastcluster"
        },
        {
            "description": "Fast, Low Memory-Footprint Digests of R Objects. Provides an R interface\nto Bob Jenkin's streaming, non-cryptographic 'SpookyHash' hash algorithm\nfor use in digest-based comparisons of R objects. 'fastdigest' plugs\ndirectly into R's internal serialization machinery, allowing digests of\nall R objects the serialize() function supports, including reference-\nstyle objects via custom hooks. Speed is high and scales linearly by\nobject size; memory usage is constant and negligible.",
            "name": "r-fastdigest"
        },
        {
            "description": "Fast Creation of Dummy (Binary) Columns and Rows from Categorical\nVariables.",
            "name": "r-fastdummies"
        },
        {
            "description": "FastICA Algorithms to Perform ICA and Projection Pursuit. Implementation\nof FastICA algorithm to perform Independent Component Analysis (ICA) and\nProjection Pursuit.",
            "name": "r-fastica"
        },
        {
            "description": "Fast Implementation of a Key-Value Store. Fast implementation of a key-\nvalue store. Environments are commonly used as key-value stores, but\nevery time a new key is used, it is added to R's global symbol table,\ncausing a small amount of memory leakage. This can be problematic in\ncases where many different keys are used. Fastmap avoids this memory\nleak issue by implementing the map using data structures in C++.",
            "name": "r-fastmap"
        },
        {
            "description": "Fast 'match()' Function. Package providing a fast match() replacement\nfor cases that require repeated look-ups. It is slightly faster that R's\nbuilt-in match() function on first match against a table, but extremely\nfast on any subsequent lookup as it keeps the hash table in memory.",
            "name": "r-fastmatch"
        },
        {
            "description": "Fast Computation of some Matrices Useful in Statistics. Small set of\nfunctions to fast computation of some matrices and operations useful in\nstatistics and econometrics. Currently, there are functions for\nefficient computation of duplication, commutation and symmetrizer\nmatrices with minimal storage requirements. Some commonly used matrix\ndecompositions (LU and LDL), basic matrix operations (for instance,\nHadamard, Kronecker products and the Sherman-Morrison formula) and\niterative solvers for linear systems are also available. In addition,\nthe package includes a number of common statistical procedures such as\nthe sweep operator, weighted mean and covariance matrix using an online\nalgorithm, linear regression (using Cholesky, QR, SVD, sweep operator\nand conjugate gradients methods), ridge regression (with optimal\nselection of the ridge parameter considering the GCV procedure),\nfunctions to compute the multivariate skewness, kurtosis, Mahalanobis\ndistance (checking the positive defineteness) and the Wilson-Hilferty\ntransformation of chi squared variables. Furthermore, the package\nprovides interfaces to C code callable by another C code from other R\npackages.",
            "name": "r-fastmatrix"
        },
        {
            "description": "Functional Data Analysis. These functions were developed to support\nfunctional data analysis as described in Ramsay, J. O. and Silverman, B.\nW. (2005) Functional Data Analysis. New York: Springer and in Ramsay, J.\nO., Hooker, Giles, and Graves, Spencer (2009).",
            "name": "r-fda"
        },
        {
            "description": "Annotation package for Illumina Infinium DNA methylation probes.\nCompiled HumanMethylation27 and HumanMethylation450 annotations",
            "name": "r-fdb-infiniummethylation-hg18"
        },
        {
            "description": "Annotation package for Illumina Infinium DNA methylation probes.\nCompiled HumanMethylation27 and HumanMethylation450 annotations.",
            "name": "r-fdb-infiniummethylation-hg19"
        },
        {
            "description": "Functional data sets.",
            "name": "r-fds"
        },
        {
            "description": "Memory-Efficient Storage of Large Data on Disk and Fast Access\nFunctions. The ff package provides data structures that are stored on\ndisk but behave (almost) as if they were in RAM by transparently mapping\nonly a section (pagesize) in main memory - the effective virtual memory\nconsumption per ff object. ff supports R's standard atomic data types\n'double', 'logical', 'raw' and 'integer' and non-standard atomic types\nboolean (1 bit), quad (2 bit unsigned), nibble (4 bit unsigned), byte (1\nbyte signed with NAs), ubyte (1 byte unsigned), short (2 byte signed\nwith NAs), ushort (2 byte unsigned), single (4 byte float with NAs). For\nexample 'quad' allows efficient storage of genomic data as an\n'A','T','G','C' factor. The unsigned types support 'circular'\narithmetic. There is also support for close-to-atomic types 'factor',\n'ordered', 'POSIXct', 'Date' and custom close-to-atomic types. ff not\nonly has native C-support for vectors, matrices and arrays with flexible\ndimorder (major column-order, major row-order and generalizations for\narrays). There is also a ffdf class not unlike data.frames and\nimport/export filters for csv files. ff objects store raw data in binary\nflat files in native encoding, and complement this with metadata stored\nin R as physical and virtual attributes. ff objects have well-defined\nhybrid copying semantics, which gives rise to certain performance\nimprovements through virtualization. ff objects can be stored and\nreopened across R sessions. ff files can be shared by multiple ff R\nobjects (using different data en/de-coding schemes) in the same process\nor from multiple R processes to exploit parallelism. A wide choice of\nfinalizer options allows to work with 'permanent' files as well as\ncreating/removing 'temporary' ff files completely transparent to the\nuser. On certain OS/Filesystem combinations, creating the ff files works\nwithout notable delay thanks to using sparse file allocation. Several\naccess optimization techniques such as Hybrid Index Preprocessing and\nVirtualization are implemented to achieve good performance even with\nlarge datasets, for example virtual matrix transpose without touching a\nsingle byte on disk. Further, to reduce disk I/O, 'logicals' and non-\nstandard data types get stored native and compact on binary flat files\ni.e. logicals take up exactly 2 bits to represent TRUE, FALSE and NA.\nBeyond basic access functions, the ff package also provides\ncompatibility functions that facilitate writing code for ff and ram\nobjects and support for batch processing on ff objects (e.g. as.ram,\nas.ff, ffapply). ff interfaces closely with functionality from package\n'bit': chunked looping, fast bit operations and coercions between\ndifferent objects that can store subscript information ('bit',\n'bitwhich', ff 'boolean', ri range index, hi hybrid index). This allows\nto work interactively with selections of large datasets and quickly\nmodify selection criteria. Further high-performance enhancements can be\nmade available upon request.x",
            "name": "r-ff"
        },
        {
            "description": "Wrapper for 'FFTW3' Includes: One-Dimensional Univariate, One-\nDimensional Multivariate, and Two-Dimensional Transform. Provides a\nwrapper for several 'FFTW' functions. This package provides access to\nthe two-dimensional 'FFT', the multivariate 'FFT', and the one-\ndimensional real to complex 'FFT' using the 'FFTW3' library. The package\nincludes the functions fftw() and mvfftw() which are designed to mimic\nthe functionality of the R functions fft() and mvfft(). The 'FFT'\nfunctions have a parameter that allows them to not return the redundant\ncomplex conjugate when the input is real data.",
            "name": "r-fftwtools"
        },
        {
            "description": "Fast Gene Set Enrichment Analysis. The package implements an algorithm\nfor fast gene set enrichment analysis. Using the fast algorithm allows\nto make more permutations and get more fine grained p-values, which\nallows to use accurate stantard approaches to multiple hypothesis\ncorrection.",
            "name": "r-fgsea"
        },
        {
            "description": "Tools for Spatial Data. For curve, surface and function fitting with an\nemphasis; on splines, spatial data, geostatistics, and spatial\nstatistics. The major methods; include cubic, and thin plate splines,\nKriging, and compactly supported; covariance functions for large data\nsets. The splines and Kriging methods are; supported by functions that\ncan determine the smoothing parameter; (nugget and sill variance) and\nother covariance function parameters by cross; validation and also by\nrestricted maximum likelihood. For Kriging; there is an easy to use\nfunction that also estimates the correlation; scale (range parameter). A\nmajor feature is that any covariance function; implemented in R and\nfollowing a simple format can be used for; spatial prediction. There are\nalso many useful functions for plotting; and working with spatial data\nas images. This package also contains; an implementation of sparse\nmatrix methods for large spatial data; sets and currently requires the\nsparse matrix (spam) package. Use; help(fields) to get started and for\nan overview. The fields source; code is deliberately commented and\nprovides useful explanations of; numerical details as a companion to the\nmanual pages. The commented; source code can be viewed by expanding the\nsource code version; and looking in the R subdirectory. The reference\nfor fields can be generated; by the citation function in R and has DOI\n<doi:10.5065/D6W957CT>. Development; of this package was supported in\npart by the National Science Foundation Grant; 1417857, the National\nCenter for Atmospheric Research, and Colorado School of Mines.; See the\nFields URL; for a vignette on using this package and some background on\nspatial statistics.",
            "name": "r-fields"
        },
        {
            "description": "Simple Key-Value Database. Implements a simple key-value style database\nwhere character string keys are associated with data values that are\nstored on the disk. A simple interface is provided for inserting,\nretrieving, and deleting data from the database. Utilities are provided\nthat allow 'filehash' databases to be treated much like environments and\nlists are already used in R. These utilities are provided to encourage\ninteractive and exploratory analysis on large datasets. Three different\nfile formats for representing the database are currently available and\nnew formats can easily be incorporated by third parties for use in the\n'filehash' framework.",
            "name": "r-filehash"
        },
        {
            "description": "Portable File Locking. Place an exclusive or shared lock on a file. It\nuses 'LockFile' on Windows and 'fcntl' locks on Unix-like systems.",
            "name": "r-filelock"
        },
        {
            "description": "Package designed to find an acceptable python binary.",
            "name": "r-findpython"
        },
        {
            "description": "Compare Fitted Models. The fit.models function and its associated\nmethods (coefficients, print, summary, plot, etc.) were originally\nprovided in the robust package to compare robustly and classically\nfitted model objects. See chapters 2, 3, and 5 in Insightful (2002)\n'Robust Library User's Guide'\n<https://robust.r-forge.r-project.org/Robust.pdf>). The aim of the\nfit.models package is to separate this fitted model object comparison\nfunctionality from the robust package and to extend it to support\nfitting methods (e.g., classical, robust, Bayesian, regularized, etc.)\nmore generally.",
            "name": "r-fit-models"
        },
        {
            "description": "Help to Fit of a Parametric Distribution to Non-Censored or Censored\nData. Extends the fitdistr() function (of the MASS package) with several\nfunctions to help the fit of a parametric distribution to non-censored\nor censored data. Censored data may contain left censored, right\ncensored and interval censored values, with several lower and upper\nbounds. In addition to maximum likelihood estimation (MLE), the package\nprovides moment matching (MME), quantile matching (QME) and maximum\ngoodness-of-fit estimation (MGE) methods (available only for non-\ncensored data). Weighted versions of MLE, MME and QME are available. See\ne.g. Casella & Berger (2002). Statistical inference. Pacific Grove.",
            "name": "r-fitdistrplus"
        },
        {
            "description": "Implementation of optimal hierarchical clustering.",
            "name": "r-flashclust"
        },
        {
            "description": "Flexible Cluster Algorithms. The main function kcca implements a general\nframework for k-centroids cluster analysis supporting arbitrary distance\nmeasures and centroid computation. Further cluster methods include hard\ncompetitive learning, neural gas, and QT clustering. There are numerous\nvisualization methods for cluster results (neighborhood graphs, convex\ncluster hulls, barcharts of centroids, ...), and bootstrap methods for\nthe analysis of cluster stability.",
            "name": "r-flexclust"
        },
        {
            "description": "Flexible Mixture Modeling. A general framework for finite mixtures of\nregression models using the EM algorithm is implemented. The E-step and\nall data handling are provided, while the M-step can be supplied by the\nuser to easily define new models. Existing drivers implement mixtures of\nstandard linear models, generalized linear models and model-based\nclustering.",
            "name": "r-flexmix"
        },
        {
            "description": "Fast Nearest Neighbor Search Algorithms and Applications. Cover-tree and\nkd-tree fast k-nearest neighbor search algorithms and related\napplications including KNN classification, regression and information\nmeasures are implemented.",
            "name": "r-fnn"
        },
        {
            "description": "Easily Work with 'Font Awesome' Icons. Easily and flexibly insert 'Font\nAwesome' icons into 'R Markdown' documents and 'Shiny' apps. These icons\ncan be inserted into HTML content through inline 'SVG' tags or 'i' tags.\nThere is also a utility function for exporting 'Font Awesome' icons as\n'PNG' images for those situations where raster graphics are needed.",
            "name": "r-fontawesome"
        },
        {
            "description": "Tools for Working with Categorical Variables (Factors). Helpers for\nreordering factor levels (including moving specified levels to front,\nordering by first appearance, reversing, and randomly shuffling), and\ntools for modifying factor levels (including collapsing rare levels into\nother, 'anonymising', and manually 'recoding').",
            "name": "r-forcats"
        },
        {
            "description": "Provides Foreach Looping Construct. Support for the foreach looping\nconstruct. Foreach is an idiom that allows for iterating over elements\nin a collection, without the use of an explicit loop counter. This\npackage in particular is intended to be used for its return value,\nrather than for its side effects. In that sense, it is similar to the\nstandard lapply function, but doesn't require the evaluation of a\nfunction. Using foreach without side effects also facilitates executing\nthe loop in parallel.",
            "name": "r-foreach"
        },
        {
            "description": "Forecasting Functions for Time Series and Linear Models. Methods and\ntools for displaying and analysing univariate time series forecasts\nincluding exponential smoothing via state space models and automatic\nARIMA modelling.",
            "name": "r-forecast"
        },
        {
            "description": "Read Data Stored by 'Minitab', 'S', 'SAS', 'SPSS', 'Stata', 'Systat',\n'Weka', 'dBase', ... Reading and writing data stored by some versions of\n'Epi Info', 'Minitab', 'S', 'SAS', 'SPSS', 'Stata', 'Systat', 'Weka',\nand for reading and writing some 'dBase' files.",
            "name": "r-foreign"
        },
        {
            "description": "Format R Code Automatically. Provides a function tidy_source() to format\nR source code. Spaces and indent will be added to the code\nautomatically, and comments will be preserved under certain conditions,\nso that R code will be more human-readable and tidy. There is also a\nShiny app as a user interface in this package.",
            "name": "r-formatr"
        },
        {
            "description": "Extended Model Formulas. Infrastructure for extended formulas with\nmultiple parts on the right-hand side and/or multiple responses on the\nleft-hand side (see <doi:10.18637/jss.v034.i01>).",
            "name": "r-formula"
        },
        {
            "description": "Flexible Procedures for Clustering. Various methods for clustering and\ncluster validation. Fixed point clustering. Linear regression\nclustering. Clustering by merging Gaussian mixture components. Symmetric\nand asymmetric discriminant projections for visualisation of the\nseparation of groupings. Cluster validation statistics for distance\nbased clustering including corrected Rand index. Standardisation of\ncluster validation statistics by random clusterings and comparison\nbetween many clustering methods and numbers of clusters based on this.\nCluster-wise cluster stability assessment. Methods for estimation of the\nnumber of clusters: Calinski-Harabasz, Tibshirani and Walther's\nprediction strength, Fang and Wang's bootstrap stability.\nGaussian/multinomial mixture fitting for mixed continuous/categorical\nvariables. Variable-wise statistics for cluster interpretation. DBSCAN\nclustering. Interface functions for many clustering methods implemented\nin R, including estimating the number of clusters with kmeans, pam and\nclara. Modality diagnosis for Gaussian mixtures. For an overview see\npackage?fpc.",
            "name": "r-fpc"
        },
        {
            "description": "Reliable Comparison of Floating Point Numbers. Comparisons of floating\npoint numbers are problematic due to errors associated with the binary\nrepresentation of decimal numbers. Despite being aware of these\nproblems, people still use numerical methods that fail to account for\nthese and other rounding errors (this pitfall is the first to be\nhighlighted in Circle 1 of Burns (2012) 'The R Inferno'\n<https://www.burns-stat.com/pages/Tutor/R_inferno.pdf>). This package\nprovides new relational operators useful for performing floating point\nnumber comparisons with a set tolerance.",
            "name": "r-fpcompare"
        },
        {
            "description": "Fractionally Differenced ARIMA aka ARFIMA(P,d,q) Models. Maximum\nlikelihood estimation of the parameters of a fractionally differenced\nARIMA(p,d,q) model (Haslett and Raftery, Appl.Statistics, 1989);\nincluding inference and basic methods. Some alternative algorithms to\nestimate \"H\".",
            "name": "r-fracdiff"
        },
        {
            "description": "Cross-Platform File System Operations Based on 'libuv'. A cross-platform\ninterface to file system operations, built on top of the 'libuv' C\nlibrary.",
            "name": "r-fs"
        },
        {
            "description": "Curry, Compose, and other higher-order functions Curry, Compose, and\nother higher-order functions",
            "name": "r-functional"
        },
        {
            "description": "Apply Mapping Functions in Parallel using Futures Implementations of the\nfamily of map() functions from 'purrr' that can be resolved using any\n'future'-supported backend, e.g. parallel on the local machine or\ndistributed on a compute cluster.",
            "name": "r-furrr"
        },
        {
            "description": "A Logging Utility for R. Provides a simple yet powerful logging utility.\nBased loosely on log4j, futile.logger takes advantage of R idioms to\nmake logging a convenient and easy to use replacement for cat and print\nstatements.",
            "name": "r-futile-logger"
        },
        {
            "description": "Futile Options Management. A scoped options management framework.",
            "name": "r-futile-options"
        },
        {
            "description": "Unified Parallel and Distributed Processing in R for Everyone. The\npurpose of this package is to provide a lightweight and unified Future\nAPI for sequential and parallel processing of R expression via futures.\nThe simplest way to evaluate an expression in parallel is to use 'x %<-%\n{ expression }' with 'plan(multiprocess)'. This package implements\nsequential, multicore, multisession, and cluster futures. With these, R\nexpressions can be evaluated on the local machine, in parallel a set of\nlocal machines, or distributed on a mix of local and remote machines.\nExtensions to this package implement additional backends for processing\nfutures via compute cluster schedulers etc. Because of its unified API,\nthere is no need to modify any code in order switch from sequential on\nthe local machine to, say, distributed processing on a remote compute\ncluster. Another strength of this package is that global variables and\nfunctions are automatically identified and exported as needed, making it\nstraightforward to tweak existing code to make use of futures.",
            "name": "r-future"
        },
        {
            "description": "Apply Function to Elements in Parallel using Futures. Implementations of\napply(), by(), eapply(), lapply(), Map(), mapply(), replicate(),\nsapply(), tapply(), and vapply() that can be resolved using any future-\nsupported backend, e.g. parallel on the local machine or distributed on\na compute cluster. These future_*apply() functions come with the same\npros and cons as the corresponding base-R *apply() functions but with\nthe additional feature of being able to be processed via the future\nframework.",
            "name": "r-future-apply"
        },
        {
            "description": "Generalised Additive Models for Location Scale and Shape. Functions for\nfitting the Generalized Additive Models for Location Scale and Shape\nintroduced by Rigby and Stasinopoulos (2005),\n<doi:10.1111/j.1467-9876.2005.00510.x>. The models use a distributional\nregression approach where all the parameters of the conditional\ndistribution of the response variable are modelled using explanatory\nvariables.",
            "name": "r-gamlss"
        },
        {
            "description": "GAMLSS Data. Data used as examples in the current two books on\nGeneralised Additive Models for Location Scale and Shape introduced by\nRigby and Stasinopoulos (2005), <doi:10.1111/j.1467-9876.2005.00510.x>.",
            "name": "r-gamlss-data"
        },
        {
            "description": "Distributions for Generalized Additive Models for Location Scale and\nShape. A set of distributions which can be used for modelling the\nresponse variables in Generalized Additive Models for Location Scale and\nShape, Rigby and Stasinopoulos (2005),\n<doi:10.1111/j.1467-9876.2005.00510.x>. The distributions can be\ncontinuous, discrete or mixed distributions. Extra distributions can be\ncreated, by transforming, any continuous distribution defined on the\nreal line, to a distribution defined on ranges 0 to infinity or 0 to 1,\nby using a ''log'' or a ''logit' transformation respectively.",
            "name": "r-gamlss-dist"
        },
        {
            "description": "Generalized Additive Mixed Models using 'mgcv' and 'lme4'. Estimate\ngeneralized additive mixed models via a version of function gamm() from\n'mgcv', using 'lme4' for estimation.",
            "name": "r-gamm4"
        },
        {
            "description": "Utilities for Working with Google APIs. Provides utilities for working\nwith Google APIs <https://developers.google.com/apis-explorer>. This\nincludes functions and classes for handling common credential types and\nfor preparing, executing, and processing HTTP requests.",
            "name": "r-gargle"
        },
        {
            "description": "Generalized Boosted Regression Models. An implementation of extensions\nto Freund and Schapire's AdaBoost algorithm and Friedman's gradient\nboosting machine. Includes regression methods for least squares,\nabsolute loss, t-distribution loss, quantile regression, logistic,\nmultinomial logistic, Poisson, Cox proportional hazards partial\nlikelihood, AdaBoost exponential loss, Huberized hinge loss, and\nLearning to Rank measures (LambdaMart). Originally developed by Greg\nRidgeway.",
            "name": "r-gbm"
        },
        {
            "description": "Utilities for processing Rd objects and files. Provides utilities for\nprocessing Rd objects and files. Extract argument descriptions and other\nparts of the help pages of functions.",
            "name": "r-gbrd"
        },
        {
            "description": "Background Adjustment Using Sequence Information. Background adjustment\nusing sequence information.",
            "name": "r-gcrma"
        },
        {
            "description": "Wrappers for 'GDAL' Utilities Executables. R's 'sf' package ships with\nself-contained 'GDAL' executables, including a bare bones interface to\nseveral 'GDAL'-related utility programs collectively known as the 'GDAL\nutilities'. For each of those utilities, this package provides an R\nwrapper whose formal arguments closely mirror those of the 'GDAL'\ncommand line interface. The utilities operate on data stored in files\nand typically write their output to other files. Therefore, to process\ndata stored in any of R's more common spatial formats (i.e. those\nsupported by the 'sp', 'sf', and 'raster' packages), first write them to\ndisk, then process them with the package's wrapper functions before\nreading the outputted results back into R. GDAL function arguments\nintroduced in GDAL version 3.2.1 or earlier are supported.",
            "name": "r-gdalutilities"
        },
        {
            "description": "Wrappers for the Geospatial Data Abstraction Library (GDAL) Utilities.",
            "name": "r-gdalutils"
        },
        {
            "description": "Various R Programming Tools for Data Manipulation. Various R programming\ntools for data manipulation, including: [1] medical unit conversions\n('ConvertMedUnits', 'MedUnits'), [2] combining objects ('bindData',\n'cbindX', 'combine', 'interleave'), [3] character vector operations\n('centerText', 'startsWith', 'trim'), [4] factor manipulation ('levels',\n'reorder.factor', 'mapLevels'), [5] obtaining information about R\nobjects ('object.size', 'elem', 'env', 'humanReadable', 'is.what', 'll',\n'keep', 'ls.funs', 'Args','nPairs', 'nobs'), [6] manipulating MS-Excel\nformatted files ('read.xls', 'installXLSXsupport', 'sheetCount',\n'xlsFormats'), [7] generating fixed-width format files ('write.fwf'),\n[8] extricating components of date & time objects ('getYear',\n'getMonth', 'getDay', 'getHour', 'getMin', 'getSec'), [9] operations on\ncolumns of data frames ('matchcols', 'rename.vars'), [10] matrix\noperations ('unmatrix', 'upperTriangle', 'lowerTriangle'), [11]\noperations on vectors ('case', 'unknownToNA', 'duplicated2', 'trimSum'),\n[12] operations on data frames ('frameApply', 'wideByFactor'), [13]\nvalue of last evaluated expression ('ans'), and [14] wrapper for\n'sample' that ensures consistent behavior for both scalar and vector\narguments ('resample').",
            "name": "r-gdata"
        },
        {
            "description": "R Interface to CoreArray Genomic Data Structure (GDS) Files. This\npackage provides a high-level R interface to CoreArray Genomic Data\nStructure (GDS) data files, which are portable across platforms with\nhierarchical structure to store multiple scalable array-oriented data\nsets with metadata information. It is suited for large-scale datasets,\nespecially for data which are much larger than the available random-\naccess memory. The gdsfmt package offers the efficient operations\nspecifically designed for integers of less than 8 bits, since a diploid\ngenotype, like single-nucleotide polymorphism (SNP), usually occupies\nfewer bits than a byte. Data compression and decompression are available\nwith relatively efficient random access. It is also allowed to read a\nGDS file in parallel with multiple R processes supported by the package\nparallel.",
            "name": "r-gdsfmt"
        },
        {
            "description": "Analysis of Evolutionary Diversification. Methods for fitting\nmacroevolutionary models to phylogenetic trees Pennell (2014)\n<doi:10.1093/bioinformatics/btu181>.",
            "name": "r-geiger"
        },
        {
            "description": "Methods for filtering genes from high-throughput experiments. Some basic\nfunctions for filtering genes.",
            "name": "r-genefilter"
        },
        {
            "description": "Lengths of mRNA transcripts for a number of genomes. Length of mRNA\ntranscripts for a number of genomes and gene ID formats, largely based\non UCSC table browser",
            "name": "r-genelendatabase"
        },
        {
            "description": "MetaAnalysis for High Throughput Experiments. A collection of meta-\nanalysis tools for analysing high throughput experimental data",
            "name": "r-genemeta"
        },
        {
            "description": "Graphics related functions for Bioconductor. Functions for plotting\ngenomic data.",
            "name": "r-geneplotter"
        },
        {
            "description": "Common S3 Generics not Provided by Base R Methods Related to Model\nFitting. In order to reduce potential package dependencies and\nconflicts, generics provides a number of commonly used S3 generics.",
            "name": "r-generics"
        },
        {
            "description": "Population Genetics. Classes and methods for handling genetic data.\nIncludes classes to represent genotypes and haplotypes at single markers\nup to multiple markers on multiple chromosomes. Function include allele\nfrequencies, flagging homo/heterozygotes, flagging carriers of certain\nalleles, estimating and testing for Hardy-Weinberg disequilibrium,\nestimating and testing for linkage disequilibrium, ...",
            "name": "r-genetics"
        },
        {
            "description": "GEne Network Inference with Ensemble of trees. This package implements\nthe GENIE3 algorithm for inferring gene regulatory networks from\nexpression data.",
            "name": "r-genie3"
        },
        {
            "description": "Utilities for manipulating chromosome names, including modifying them to\nfollow a particular naming style. Contains data and functions that\ndefine and allow translation between different chromosome sequence\nnaming conventions (e.g., \"chr1\" versus \"1\"), including a function that\nattempts to place sequence names in their natural, rather than\nlexicographic, order.",
            "name": "r-genomeinfodb"
        },
        {
            "description": "for mapping between NCBI taxonomy ID and species. Used by functions in\nthe GenomeInfoDb package.",
            "name": "r-genomeinfodbdata"
        },
        {
            "description": "Representation and manipulation of short genomic alignments. Provides\nefficient containers for storing and manipulating short genomic\nalignments (typically obtained by aligning short reads to a reference\ngenome). This includes read counting, computing the coverage, junction\ndetection, and working with the nucleotide content of the alignments.",
            "name": "r-genomicalignments"
        },
        {
            "description": "Conveniently import and query gene models. A set of tools and methods\nfor making and manipulating transcript centric annotations. With these\ntools the user can easily download the genomic locations of the\ntranscripts, exons and cds of a given organism, from either the UCSC\nGenome Browser or a BioMart database (more sources will be supported in\nthe future). This information is then stored in a local database that\nkeeps track of the relationship between transcripts, exons, cds and\ngenes. Flexible methods are provided for extracting the desired features\nin a convenient format.",
            "name": "r-genomicfeatures"
        },
        {
            "description": "Representation and manipulation of genomic intervals. The ability to\nefficiently represent and manipulate genomic annotations and alignments\nis playing a central role when it comes to analyzing high-throughput\nsequencing data (a.k.a. NGS data). The GenomicRanges package defines\ngeneral purpose containers for storing and manipulating genomic\nintervals and variables defined along a genome. More specialized\ncontainers for representing and manipulating short alignments against a\nreference genome, or a matrix-like summarization of an experiment, are\ndefined in the GenomicAlignments and SummarizedExperiment packages,\nrespectively. Both packages build on top of the GenomicRanges\ninfrastructure.",
            "name": "r-genomicranges"
        },
        {
            "description": "Generalized Simulated Annealing. Performs search for global minimum of a\nvery complex non-linear objective function with a very large number of\noptima.",
            "name": "r-gensa"
        },
        {
            "description": "GeoJSON to Simple Feature Converter. Converts Between GeoJSON and simple\nfeature objects.",
            "name": "r-geojsonsf"
        },
        {
            "description": "Convert Between R Objects and Geometric Structures. Geometry shapes in\n'R' are typically represented by matrices (points, lines), with more\ncomplex shapes being lists of matrices (polygons). 'Geometries' will\nconvert various 'R' objects into these shapes. Conversion functions are\navailable at both the 'R' level, and through 'Rcpp'.",
            "name": "r-geometries"
        },
        {
            "description": "Mesh Generation and Surface Tessellation. Makes the 'Qhull' library\n<http://www.qhull.org> available in R, in a similar manner as in Octave\nand MATLAB. Qhull computes convex hulls, Delaunay triangulations,\nhalfspace intersections about a point, Voronoi diagrams, furthest-site\nDelaunay triangulations, and furthest-site Voronoi diagrams. It runs in\n2D, 3D, 4D, and higher dimensions. It implements the Quickhull algorithm\nfor computing the convex hull. Qhull does not support constrained\nDelaunay triangulations, or mesh generation of non-convex objects, but\nthe package does include some R functions that allow for this.",
            "name": "r-geometry"
        },
        {
            "description": "Geometric Morphometric Analyses of 2D/3D Landmark Data. Read,\nmanipulate, and digitize landmark data, generate shape variables via\nProcrustes analysis for points, curves and surfaces, perform shape\nanalyses, and provide graphical depictions of shapes and patterns of\nshape variation.",
            "name": "r-geomorph"
        },
        {
            "description": "Interface to the \"Geonames\" Spatial Query Web Service. The web service\nat <https://www.geonames.org/> provides a number of spatial data\nqueries, including administrative area hierarchies, city locations and\nsome country postal code queries. A (free) username is required and rate\nlimits exist.",
            "name": "r-geonames"
        },
        {
            "description": "Get data from NCBI Gene Expression Omnibus (GEO). The NCBI Gene\nExpression Omnibus (GEO) is a public repository of microarray data.\nGiven the rich and varied nature of this resource, it is only natural to\nwant to apply BioConductor tools to these data. GEOquery is the bridge\nbetween GEO and BioConductor.",
            "name": "r-geoquery"
        },
        {
            "description": "Analysis of Geostatistical Data. Geostatistical analysis including\nvariogram-based, likelihood-based and Bayesian methods. Software\ncompanion for Diggle and Ribeiro (2007) <doi:10.1007/978-0-387-48536-2>.",
            "name": "r-geor"
        },
        {
            "description": "Spherical Trigonometry. Spherical trigonometry for geographic\napplications. That is, compute distances and related measures for\nangular (longitude/latitude) locations.",
            "name": "r-geosphere"
        },
        {
            "description": "Simple Git Client for R. Simple git client for R based on 'libgit2' with\nsupport for SSH and HTTPS remotes. All functions in 'gert' use basic R\ndata types (such as vectors and data-frames) for their arguments and\nreturn values. User credentials are shared with command line 'git'\nthrough the git-credential store and ssh keys stored on disk or ssh-\nagent.",
            "name": "r-gert"
        },
        {
            "description": "C-Like 'getopt' Behavior. Package designed to be used with Rscript to\nwrite \"#!\" shebang scripts that accept short and long flags/options.\nMany users will prefer using instead the packages optparse or argparse\nwhich add extra features like automatically generated help option and\nusage, support for default values, positional argument support, etc.",
            "name": "r-getopt"
        },
        {
            "description": "Parsing Command-Line Arguments and Simple Variable Interpolation. This\nis yet another command-line argument parser which wraps the powerful\nPerl module Getopt::Long and with some adaptation for easier use in R.\nIt also provides a simple way for variable interpolation in R.",
            "name": "r-getoptlong"
        },
        {
            "description": "Extension to 'ggplot2'. The R package 'ggplot2' is a plotting system\nbased on the grammar of graphics. 'GGally' extends 'ggplot2' by adding\nseveral functions to reduce the complexity of combining geometric\nobjects with transformed data. Some of these functions include a\npairwise plot matrix, a two group pairwise plot matrix, a parallel\ncoordinates plot, a survival plot, and several functions to plot\nnetworks.",
            "name": "r-ggally"
        },
        {
            "description": "Categorical Scatter (Violin Point) Plots. Provides two methods of\nplotting categorical scatter plots such that the arrangement of points\nwithin a category reflects the density of data at that region, and\navoids over-plotting.",
            "name": "r-ggbeeswarm"
        },
        {
            "description": "Visualization tools for genomic data. The ggbio package extends and\nspecializes the grammar of graphics for biological data. The graphics\nare designed to answer common scientific questions, in particular those\noften asked of high throughput genomics data. All core Bioconductor data\nstructures are supported, where appropriate. The package supports\ndetailed views of particular genomic regions, as well as genome-wide\noverviews. Supported overviews include ideograms and grand linear views.\nHigh-level plots include sequence fragment length, edge-linked interval\nto data view, mismatch pileup, and several splicing summaries.",
            "name": "r-ggbio"
        },
        {
            "description": "Create Dendrograms and Tree Diagrams Using 'ggplot2'. This is a set of\ntools for dendrograms and tree plots using 'ggplot2'. The 'ggplot2'\nphilosophy is to clearly separate data from the presentation.\nUnfortunately the plot method for dendrograms plots directly to a plot\ndevice without exposing the data. The 'ggdendro' package resolves this\nby making available functions that extract the dendrogram plot data. The\npackage provides implementations for tree, rpart, as well as diana and\nagnes cluster diagrams.",
            "name": "r-ggdendro"
        },
        {
            "description": "Accelerating 'ggplot2'. The aim of 'ggplot2' is to aid in visual data\ninvestigations. This focus has led to a lack of facilities for composing\nspecialised plots. 'ggforce' aims to be a collection of mainly new stats\nand geoms that fills this gap. All additional functionality is aimed to\ncome through the official extension system so using 'ggforce' should be\na stable experience.",
            "name": "r-ggforce"
        },
        {
            "description": "Miscellaneous Functions for 'ggplot2'. Useful functions to edit 'ggplot'\nobject (e.g., setting fonts for theme and layers, adding rounded\nrectangle as background for each of the legends).",
            "name": "r-ggfun"
        },
        {
            "description": "Joyplots in 'ggplot2'. Joyplots provide a convenient way of visualizing\nchanges in distributions over time or space.",
            "name": "r-ggjoy"
        },
        {
            "description": "Spatial Visualization with ggplot2. A collection of functions to\nvisualize spatial data and models on top of static maps from various\nonline sources (e.g Google Maps and Stamen Maps). It includes tools\ncommon to those tasks, including functions for geolocation and routing.",
            "name": "r-ggmap"
        },
        {
            "description": "Multiple Fill and Colour Scales in 'ggplot2'. Use multiple fill and\ncolour scales in 'ggplot2'.",
            "name": "r-ggnewscale"
        },
        {
            "description": "Create Elegant Data Visualisations Using the Grammar of Graphics. A\nsystem for 'declaratively' creating graphics, based on \"The Grammar of\nGraphics\". You provide the data, tell 'ggplot2' how to map variables to\naesthetics, what graphical primitives to use, and it takes care of the\ndetails.",
            "name": "r-ggplot2"
        },
        {
            "description": "Convert Plot to 'grob' or 'ggplot' Object. Convert plot function call\n(using expression or formula) to 'grob' or 'ggplot' object that\ncompatible to the 'grid' and 'ggplot2' ecosystem. With this package, we\nare able to e.g. using 'cowplot' to align plots produced by 'base'\ngraphics, 'ComplexHeatmap', 'eulerr', 'grid', 'lattice', 'magick',\n'pheatmap', 'vcd' etc. by converting them to 'ggplot' objects.",
            "name": "r-ggplotify"
        },
        {
            "description": "'ggplot2' Based Publication Ready Plots. The 'ggplot2' package is\nexcellent and flexible for elegant data visualization in R. However the\ndefault generated plots requires some formatting before we can send them\nfor publication. Furthermore, to customize a 'ggplot', the syntax is\nopaque and this raises the level of difficulty for researchers with no\nadvanced R programming skills. 'ggpubr' provides some easy-to-use\nfunctions for creating and customizing 'ggplot2'- based publication\nready plots.",
            "name": "r-ggpubr"
        },
        {
            "description": "An Implementation of Grammar of Graphics for Graphs and Networks. The\ngrammar of graphics as implemented in ggplot2 is a poor fit for graph\nand network visualizations due to its reliance on tabular data input.\nggraph is an extension of the ggplot2 API tailored to graph\nvisualizations and provides the same flexible approach to building up\nplots layer by layer.",
            "name": "r-ggraph"
        },
        {
            "description": "Rasterize Layers for 'ggplot2'. Rasterize only specific layers of a\n'ggplot2' plot while simultaneously keeping all labels and text in\nvector format. This allows users to keep plots within the reasonable\nsize limit without loosing vector properties of the scale-sensitive\ninformation.",
            "name": "r-ggrastr"
        },
        {
            "description": "Repulsive Text and Label Geoms for 'ggplot2'. Provides text and label\ngeoms for 'ggplot2' that help to avoid overlapping text labels. Labels\nrepel away from each other and away from the data points.",
            "name": "r-ggrepel"
        },
        {
            "description": "Ridgeline Plots in 'ggplot2'. Ridgeline plots provide a convenient way\nof visualizing changes in distributions over time or space. This package\nenables the creation of such plots in 'ggplot2'.",
            "name": "r-ggridges"
        },
        {
            "description": "Scientific Journal and Sci-Fi Themed Color Palettes for 'ggplot2'.\ncollection of 'ggplot2' color palettes inspired by plots in scientific\njournals, data visualization libraries, science fiction movies, and TV\nshows.",
            "name": "r-ggsci"
        },
        {
            "description": "Significance Brackets for 'ggplot2'. Enrich your 'ggplots' with group-\nwise comparisons. This package provides an easy way to indicate if two\ngroups are significantly different. Commonly this is shown by a bracket\non top connecting the groups of interest which itself is annotated with\nthe level of significance (NS, *, **, ***). The package provides a\nsingle layer (geom_signif()) that takes the groups for comparison and\nthe test (t.test(), wilcox.text() etc.) as arguments and adds the\nannotation to the plot.",
            "name": "r-ggsignif"
        },
        {
            "description": "Provides new statistics, new geometries and new positions for 'ggplot2'\nand a suite of functions to facilitate the creation of statistical\nplots.",
            "name": "r-ggstats"
        },
        {
            "description": "Extra Themes, Scales and Geoms for 'ggplot2'. Some extra themes, geoms,\nand scales for 'ggplot2'. Provides 'ggplot2' themes and scales that\nreplicate the look of plots by Edward Tufte, Stephen Few,\n'Fivethirtyeight', 'The Economist', 'Stata', 'Excel', and 'The Wall\nStreet Journal', among others. Provides 'geoms' for Tufte's box plot and\nrange frame.",
            "name": "r-ggthemes"
        },
        {
            "description": "an R package for visualization of tree and annotation data. 'ggtree'\nextends the 'ggplot2' plotting system which implemented the grammar of\ngraphics. 'ggtree' is designed for visualization and annotation of\nphylogenetic trees and other tree-like structures with their annotation\ndata.",
            "name": "r-ggtree"
        },
        {
            "description": "Interactive Grammar of Graphics. An implementation of an interactive\ngrammar of graphics, taking the best parts of 'ggplot2', combining them\nwith the reactive framework from 'shiny' and web graphics from 'vega'.",
            "name": "r-ggvis"
        },
        {
            "description": "'GitHub' 'API'. Minimal client to access the 'GitHub' 'API'.",
            "name": "r-gh"
        },
        {
            "description": "Work with 'GitHub' 'Gists'. Work with 'GitHub' 'gists' from 'R' (e.g.,\n<https://en.wikipedia.org/wiki/GitHub#Gist>,\n<https://docs.github.com/en/github/writing-on-github/creating-gists/>).\nA 'gist' is simply one or more files with code/text/images/etc. This\npackage allows the user to create new 'gists', update 'gists' with new\nfiles, rename files, delete files, get and delete 'gists', star and 'un-\nstar' 'gists', fork 'gists', open a 'gist' in your default browser, get\nembed code for a 'gist', list 'gist' 'commits', and get rate limit\ninformation when 'authenticated'. Some requests require authentication\nand some do not. 'Gists' website: <https://gist.github.com/>.",
            "name": "r-gistr"
        },
        {
            "description": "Provides Access to Git Repositories. Interface to the 'libgit2' library,\nwhich is a pure C implementation of the 'Git' core methods. Provides\naccess to 'Git' repositories to extract data and running some basic\n'Git' commands.",
            "name": "r-git2r"
        },
        {
            "description": "Query 'git' Credentials from 'R'. Query, set, delete credentials from\nthe 'git' credential store. Manage 'GitHub' tokens and other 'git'\ncredentials. This package is to be used by other packages that need to\nauthenticate to 'GitHub' and/or other 'git' repositories.",
            "name": "r-gitcreds"
        },
        {
            "description": "Interactive HTML graphics. This package generates interactive\nvisualisations for analysis of RNA- sequencing data using output from\nlimma, edgeR or DESeq2 packages in an HTML page. The interactions are\nbuilt on top of the popular static representations of analysis results\nin order to provide additional information.",
            "name": "r-glimma"
        },
        {
            "description": "Fit a Gamma-Poisson Generalized Linear Model. Fit linear models to\noverdispersed count data. The package can estimate the overdispersion\nand fit repeated models for matrix input. It is designed to handle large\ninput datasets as they typically occur in single cell RNA-seq\nexperiments.",
            "name": "r-glmgampoi"
        },
        {
            "description": "Lasso and Elastic-Net Regularized Generalized Linear Models. Extremely\nefficient procedures for fitting the entire lasso or elastic-net\nregularization path for linear regression, logistic and multinomial\nregression models, Poisson regression and the Cox model. Two recent\nadditions are the multiple-response Gaussian, and the grouped\nmultinomial. The algorithm uses cyclical coordinate descent in a path-\nwise fashion, as described in the paper linked to via the URL below.",
            "name": "r-glmnet"
        },
        {
            "description": "Generate Functions to Get or Set Global Options. It provides more\ncontrols on the option values such as validation and filtering on the\nvalues, making options invisible or private.",
            "name": "r-globaloptions"
        },
        {
            "description": "Identify Global Objects in R Expressions. Identifies global (\"unknown\"\nor \"free\") objects in R expressions by code inspection using various\nstrategies, e.g. conservative or liberal. The objective of this package\nis to make it as simple as possible to identify global objects for the\npurpose of exporting them in distributed compute environments.",
            "name": "r-globals"
        },
        {
            "description": "Testing Groups of Covariates/Features for Association with a Response\nVariable, with Applications to Gene Set Testing. The global test tests\ngroups of covariates (or features) for association with a response\nvariable. This package implements the test with diagnostic plots and\nmultiple testing utilities, along with several functions to facilitate\nthe use of this test for gene set testing of GO and KEGG terms.",
            "name": "r-globaltest"
        },
        {
            "description": "Interpreted String Literals. An implementation of interpreted string\nliterals, inspired by Python's Literal String Interpolation\n<https://www.python.org/dev/peps/pep-0498/> and Docstrings\n<https://www.python.org/dev/peps/pep-0257/> and Julia's Triple-Quoted\nString Literals <https://docs.julialang.org/en/stable/\nmanual/strings/#triple-quoted-string-literals>.",
            "name": "r-glue"
        },
        {
            "description": "Various R programming tools for model fitting.",
            "name": "r-gmodels"
        },
        {
            "description": "Multiple Precision Arithmetic. Multiple Precision Arithmetic (big\nintegers and rationals, prime number tests, matrix computation),\n\"arithmetic without limitations\" using the C library GMP (GNU Multiple\nPrecision Arithmetic).",
            "name": "r-gmp"
        },
        {
            "description": "A set of annotation maps describing the entire Gene Ontology. A set of\nannotation maps describing the entire Gene Ontology assembled using data\nfrom GO.",
            "name": "r-go-db"
        },
        {
            "description": "Classical Goodness-of-Fit Tests for Univariate Distributions. Cramer-Von\nMises and Anderson-Darling tests of goodness-of-fit for continuous\nunivariate distributions, using efficient algorithms.",
            "name": "r-goftest"
        },
        {
            "description": "Gene ontology enrichment using FUNC. GOfuncR performs a gene ontology\nenrichment analysis based on the ontology enrichment software FUNC. GO-\nannotations are obtained from OrganismDb or OrgDb packages\n('Homo.sapiens' by default); the GO-graph is included in the package and\nupdated regularly (27-Mar-2019). GOfuncR provides the standard candidate\nvs. background enrichment analysis using the hypergeometric test, as\nwell as three additional tests: (i) the Wilcoxon rank-sum test that is\nused when genes are ranked, (ii) a binomial test that is used when genes\nare associated with two counts and (iii) a Chi-square or Fisher's exact\ntest that is used in cases when genes are associated with four counts.\nTo correct for multiple testing and interdependency of the tests,\nfamily-wise error rates are computed based on random permutations of the\ngene-associated variables. GOfuncR also provides tools for exploring the\nontology graph and the annotations, and options to take gene-length or\nspatial clustering of genes into account. It is also possible to provide\ncustom gene coordinates, annotations and ontologies.",
            "name": "r-gofuncr"
        },
        {
            "description": "Authenticate and Create Google APIs. Create R functions that interact\nwith OAuth2 Google APIs <https://developers.google.com/apis-explorer/>\neasily, with auto-refresh and Shiny compatibility.",
            "name": "r-googleauthr"
        },
        {
            "description": "An Interface to Google Drive. Manage Google Drive files from R.",
            "name": "r-googledrive"
        },
        {
            "description": "Access Google Sheets using the Sheets API V4. Interact with Google\nSheets through the Sheets API v4\n<https://developers.google.com/sheets/api>. \"API\" is an acronym for\n\"application programming interface\"; the Sheets API allows users to\ninteract with Google Sheets programmatically, instead of via a web\nbrowser. The \"v4\" refers to the fact that the Sheets API is currently at\nversion 4. This package can read and write both the metadata and the\ncell data in a Sheet.",
            "name": "r-googlesheets4"
        },
        {
            "description": "R Interface to Google Charts. R interface to Google Charts API, allowing\nusers to create interactive charts based on data frames. Charts are\ndisplayed locally via the R HTTP help server. A modern browser with an\nInternet connection is required and for some charts a Flash player. The\ndata remains local and is not uploaded to Google.",
            "name": "r-googlevis"
        },
        {
            "description": "Visualization of Functional Analysis Data. Implementation of\nmultilayered visualizations for enhanced graphical representation of\nfunctional analysis data. It combines and integrates omics data derived\nfrom expression and functional annotation enrichment analyses. Its\nplotting functions have been developed with an hierarchical structure in\nmind: starting from a general overview to identify the most enriched\ncategories (modified bar plot, bubble plot) to a more detailed one\ndisplaying different types of relevant information for the molecules in\na given set of categories (circle plot, chord plot, cluster plot, Venn\ndiagram, heatmap).",
            "name": "r-goplot"
        },
        {
            "description": "GO-terms Semantic Similarity Measures. The semantic comparisons of Gene\nOntology (GO) annotations provide quantitative ways to compute\nsimilarities between genes and gene groups, and have became important\nbasis for many bioinformatics analysis approaches. GOSemSim is an R\npackage for semantic similarity computation among GO terms, sets of GO\nterms, gene products and gene clusters. GOSemSim implemented five\nmethods proposed by Resnik, Schlicker, Jiang, Lin and Wang respectively.",
            "name": "r-gosemsim"
        },
        {
            "description": "Gene Ontology analyser for RNA-seq and other length biased data. Detects\nGene Ontology and/or other user defined categories which are over/under\nrepresented in RNA-seq data",
            "name": "r-goseq"
        },
        {
            "description": "Tools for manipulating GO and microarrays. A set of tools for\ninteracting with GO and microarray data. A variety of basic manipulation\ntools for graphs, hypothesis testing and other simple calculations.",
            "name": "r-gostats"
        },
        {
            "description": "Gower's Distance. Compute Gower's distance (or similarity) coefficient\nbetween records. Compute the top-n matches between records. Core\nalgorithms are executed in parallel on systems supporting OpenMP.",
            "name": "r-gower"
        },
        {
            "description": "GPA Factor Rotation. Gradient Projection Algorithm Rotation for Factor\nAnalysis. See GPArotation.Intro for more details.",
            "name": "r-gparotation"
        },
        {
            "description": "Various R Programming Tools for Plotting Data. Various R programming\ntools for plotting data, including: [1] calculating and plotting locally\nsmoothed summary function as ('bandplot', 'wapply'), [2] enhanced\nversions of standard plots ('barplot2', 'boxplot2', 'heatmap.2',\n'smartlegend'), [3] manipulating colors ('col2hex', 'colorpanel',\n'redgreen', 'greenred', 'bluered', 'redblue', 'rich.colors'), [4]\ncalculating and plotting two-dimensional data summaries ('ci2d',\n'hist2d'), [5] enhanced regression diagnostic plots ('lmplot2',\n'residplot'), [6] formula-enabled interface to 'stats::lowess' function\n('lowess'), [7] displaying textual data in plots ('textplot',\n'sinkplot'), [8] plotting a matrix where each cell contains a dot whose\nsize reflects the relative magnitude of the elements ('balloonplot'),\n[9] plotting \"Venn\" diagrams ('venn'), [10] displaying Open-Office style\nplots ('ooplot'), [11] plotting multiple data on same region, with\nseparate axes ('overplot'), [12] plotting means and confidence intervals\n('plotCI', 'plotmeans'), [13] spacing points in an x-y plot so they\ndon't overlap ('space').",
            "name": "r-gplots"
        },
        {
            "description": "A package to handle graph data structures. A package that implements\nsome simple graph handling capabilities.",
            "name": "r-graph"
        },
        {
            "description": "Additional Layout Algorithms for Network Visualizations. Several new\nlayout algorithms to visualize networks are provided which are not part\nof 'igraph'. Most are based on the concept of stress majorization by\nGansner et al. (2004) <doi:10.1007/978-3-540-31843-9_25>. Some more\nspecific algorithms allow to emphasize hidden group structures in\nnetworks or focus on specific nodes.",
            "name": "r-graphlayouts"
        },
        {
            "description": "A Package for Graphical Modelling in R. The 'gRbase' package provides\ngraphical modelling features used by e.g. the packages 'gRain', 'gRim'\nand 'gRc'. 'gRbase' implements graph algorithms including (i) maximum\ncardinality search (for marked and unmarked graphs). (ii) moralization,\n(iii) triangulation, (iv) creation of junction tree. 'gRbase'\nfacilitates array operations, 'gRbase' implements functions for testing\nfor conditional independence. 'gRbase' illustrates how hierarchical log-\nlinear models may be implemented and describes concept of graphical meta\ndata. The facilities of the package are documented in the book by\nHojsgaard, Edwards and Lauritzen (2012, <doi:10.1007/978-1-4614-2299-0>)\nand in the paper by Dethlefsen and Hojsgaard, (2005,\n<doi:10.18637/jss.v014.i17>). Please see 'citation(\"gRbase\")' for\ncitation details. NOTICE 'gRbase' requires that the packages graph,\n'Rgraphviz' and 'RBGL' are installed from 'bioconductor'; for\ninstallation instructions please refer to the web page given below.",
            "name": "r-grbase"
        },
        {
            "description": "Integration of base and grid graphics.",
            "name": "r-gridbase"
        },
        {
            "description": "Miscellaneous Functions for \"Grid\" Graphics. Provides a number of user-\nlevel functions to work with \"grid\" graphics, notably to arrange\nmultiple grid-based plots on a page, and draw tables.",
            "name": "r-gridextra"
        },
        {
            "description": "Redraw Base Graphics Using 'grid' Graphics. Functions to convert a page\nof plots drawn with the 'graphics' package into identical output drawn\nwith the 'grid' package. The result looks like the original\n'graphics'-based plot, but consists of 'grid' grobs and viewports that\ncan then be manipulated with 'grid' functions (e.g., edit grobs and\nrevisit viewports).",
            "name": "r-gridgraphics"
        },
        {
            "description": "Gene Set Analysis.",
            "name": "r-gsa"
        },
        {
            "description": "Utility Functions For GATK. This package contains utility functions used\nby the Genome Analysis Toolkit (GATK) to load tables and plot data. The\nGATK is a toolkit for variant discovery in high-throughput sequencing\ndata.",
            "name": "r-gsalib"
        },
        {
            "description": "Gene set enrichment data structures and methods. This package provides\nclasses and methods to support Gene Set Enrichment Analysis (GSEA).",
            "name": "r-gseabase"
        },
        {
            "description": "Wrapper for the Gnu Scientific Library. An R wrapper for some of the\nfunctionality of the Gnu Scientific Library.",
            "name": "r-gsl"
        },
        {
            "description": "A Global Surface Summary of the Day (GSOD) Weather Data Client for R.\nProvides automated downloading, parsing, cleaning, unit conversion and\nformatting of Global Surface Summary of the Day ('GSOD') weather data\nfrom the from the USA National Centers for Environmental Information\n('NCEI'). Units are converted from from United States Customary System\n('USCS') units to International System of Units ('SI'). Stations may be\nindividually checked for number of missing days defined by the user,\nwhere stations with too many missing observations are omitted. Only\nstations with valid reported latitude and longitude values are permitted\nin the final data. Additional useful elements, saturation vapour\npressure ('es'), actual vapour pressure ('ea') and relative humidity\n('RH') are calculated from the original data using the improved August-\nRoche-Magnus approximation (Alduchov & Eskridge 1996) and included in\nthe final data set. The resulting metadata include station\nidentification information, country, state, latitude, longitude,\nelevation, weather observations and associated flags. For information on\nthe 'GSOD' data from 'NCEI', please see the 'GSOD' 'readme.txt' file\navailable from, <https://www1.ncdc.noaa.gov/pub/data/gsod/readme.txt>.",
            "name": "r-gsodr"
        },
        {
            "description": "Base Class and Methods for 'gson' Format. Proposes a new file format\n('gson') for storing gene set and related information, and provides\nread, write and other utilities to process this file format.",
            "name": "r-gson"
        },
        {
            "description": "General Smoothing Splines. A comprehensive package for structural\nmultivariate function estimation using smoothing splines.",
            "name": "r-gss"
        },
        {
            "description": "Spatial and Spatio-Temporal Geostatistical Modelling, Predictionand\nSimulation. Variogram modelling; simple, ordinary and universal point or\nblock (co)kriging; spatio-temporal kriging; sequential Gaussian or\nindicator (co)simulation; variogram and variogram map plotting utility\nfunctions; supports sf and stars.",
            "name": "r-gstat"
        },
        {
            "description": "Utilities for Strings and Function Arguments. gsubfn is like gsub but\ncan take a replacement function or certain other objects instead of the\nreplacement string. Matches and back references are input to the\nreplacement function and replaced by the function output. gsubfn can be\nused to split strings based on content rather than delimiters and for\nquasi-perl-style string interpolation. The package also has facilities\nfor translating formulas to functions and allowing such formulas in\nfunction calls instead of functions. This can be used with R functions\nsuch as apply, sapply, lapply, optim, integrate, xyplot, Filter and any\nother function that expects another function as an input argument or\nfunctions like cat or sql calls that may involve strings where\nsubstitution is desirable.",
            "name": "r-gsubfn"
        },
        {
            "description": "Arrange 'Grobs' in Tables. Tools to make it easier to work with \"tables\"\nof 'grobs'. The 'gtable' package defines a 'gtable' grob class that\nspecifies a grid along with a list of grobs and their placement in the\ngrid. Further the package makes it easy to manipulate and combine\n'gtable' objects so that complex compositions can be build up\nsequentially.",
            "name": "r-gtable"
        },
        {
            "description": "Various R Programming Tools. Functions to assist in R programming.\nIncluding: [1] assist in developing, updating, and maintaining R and R\npackages ('ask', 'checkRVersion', 'getDependencies', 'keywords',\n'scat'); [2] calculate the logit and inverse logit transformations\n('logit', 'inv.logit'); [3] test if a value is missing, empty or\ncontains only NA and NULL values ('invalid'); [4] manipulate R's .Last\nfunction ('addLast'); [5] define macros ('defmacro'); [6] detect odd and\neven integers ('odd', 'even'); [7] convert strings containing non-ASCII\ncharacters (like single quotes) to plain ASCII ('ASCIIfy'); [8] perform\na binary search ('binsearch'); [9] sort strings containing both numeric\nand character components ('mixedsort'); [10] create a factor variable\nfrom the quantiles of a continuous variable ('quantcut'); [11] enumerate\npermutations and combinations ('combinations', 'permutation'); [12]\ncalculate and convert between fold-change and log-ratio ('foldchange',\n'logratio2foldchange', 'foldchange2logratio'); [13] calculate\nprobabilities and generate random numbers from Dirichlet distributions\n('rdirichlet', 'ddirichlet'); [14] apply a function over adjacent\nsubsets of a vector ('running'); [15] modify the TCP_NODELAY ('de-\nNagle') flag for socket objects; [16] efficient 'rbind' of data frames,\neven if the column names don't match ('smartbind'); [17] generate\nsignificance stars from p-values ('stars.pval'); [18] convert characters\nto/from ASCII codes;",
            "name": "r-gtools"
        },
        {
            "description": "Genome Level Trellis Layout. Genome level Trellis graph visualizes\ngenomic data conditioned by genomic categories (e.g. chromosomes). For\neach genomic category, multiple dimensional data which are represented\nas tracks describe different features from different aspects. This\npackage provides high flexibility to arrange genomic categories and to\nadd self-defined graphics in the plot.",
            "name": "r-gtrellis"
        },
        {
            "description": "Plotting data and annotation information along genomic coordinates.\nGenomic data analyses requires integrated visualization of known genomic\ninformation and new experimental data. Gviz uses the biomaRt and the\nrtracklayer packages to perform live annotation queries to Ensembl and\nUCSC and translates this to e.g. gene/transcript structures in viewports\nof the grid graphics package. This results in genomic information\nplotted together with your data.",
            "name": "r-gviz"
        },
        {
            "description": "Geographically-Weighted Models. Techniques from a particular branch of\nspatial statistics,termed geographically-weighted (GW) models. GW models\nsuit situations when data are not described well by some global model,\nbut where there are spatial regions where a suitably localised\ncalibration provides a better description. 'GWmodel' includes functions\nto calibrate: GW summary statistics (Brunsdon et al., 2002)\n<doi:10.1016/s0198-9715(01)00009-6>, GW principal components analysis\n(Harris et al., 2011) <doi:10.1080/13658816.2011.554838>, GW\ndiscriminant analysis (Brunsdon et al., 2007)\n<doi:10.1111/j.1538-4632.2007.00709.x> and various forms of GW\nregression (Brunsdon et al., 1996)\n<doi:10.1111/j.1538-4632.1996.tb00936.x>; some of which are provided in\nbasic and robust (outlier resistant) forms.",
            "name": "r-gwmodel"
        },
        {
            "description": "Construct Modeling Packages. Building modeling packages is hard. A large\namount of effort generally goes into providing an implementation for a\nnew method that is efficient, fast, and correct, but often less emphasis\nis put on the user interface. A good interface requires specialized\nknowledge about S3 methods and formulas, which the average package\ndeveloper might not have. The goal of 'hardhat' is to reduce the burden\naround building new modeling packages by providing functionality for\npreprocessing, predicting, and validating input.",
            "name": "r-hardhat"
        },
        {
            "description": "Import and Export 'SPSS', 'Stata' and 'SAS' Files. Import foreign\nstatistical formats into R via the embedded 'ReadStat' C library,\n<https://github.com/WizardMac/ReadStat>.",
            "name": "r-haven"
        },
        {
            "description": "HDF5 backend for DelayedArray objects. Implements the HDF5Array and\nTENxMatrix classes, 2 convenient and memory-efficient array-like\ncontainers for on-disk representation of HDF5 datasets. HDF5Array is for\ndatasets that use the conventional (i.e. dense) HDF5 representation.\nTENxMatrix is for datasets that use the HDF5-based sparse matrix\nrepresentation from 10x Genomics (e.g. the 1.3 Million Brain Cell\nDataset). Both containers being DelayedArray extensions, they support\nall operations supported by DelayedArray objects. These operations can\nbe either delayed or block-processed.",
            "name": "r-hdf5array"
        },
        {
            "description": "Interface to the 'HDF5' Binary Data Format. 'HDF5' is a data model,\nlibrary and file format for storing and managing large amounts of data.\nThis package provides a nearly feature complete, object oriented wrapper\nfor the 'HDF5' API\n<https://support.hdfgroup.org/HDF5/doc/RM/RM_H5Front.html> using R6\nclasses. Additionally, functionality is added so that 'HDF5' objects\nbehave very similar to their corresponding R counterparts.",
            "name": "r-hdf5r"
        },
        {
            "description": "A set of annotation maps describing the entire Human Disease Ontology. A\nset of annotation maps describing the entire Human Disease Ontology\nassembled using data from DO. Its annotation data comes from https://git\nhub.com/DiseaseOntology/HumanDiseaseOntology/tree/main/src/ontology.",
            "name": "r-hdo-db"
        },
        {
            "description": "Highest Density Regions and Conditional Density Estimation. Computation\nof highest density regions in one and two dimensions, kernel estimation\nof univariate density functions conditional on one covariate,and\nmultimodal regression.",
            "name": "r-hdrcde"
        },
        {
            "description": "A Simpler Way to Find Your Files. Constructs paths to your project's\nfiles. Declare the relative path of a file within your project with\n'i_am()'. Use the 'here()' function as a drop-in replacement for\n'file.path()', it will always locate the files relative to your project\nroot.",
            "name": "r-here"
        },
        {
            "description": "Hexagonal Binning Routines. Binning and plotting functions for hexagonal\nbins. Now uses and relies on grid graphics and formal (S4) classes and\nmethods.",
            "name": "r-hexbin"
        },
        {
            "description": "Statistical Analysis and Data Display: Heiberger and Holland. Support\nsoftware for Statistical Analysis and Data Display (Second Edition,\nSpringer, ISBN 978-1-4939-2121-8, 2015) and (First Edition, Springer,\nISBN 0-387-40270-5, 2004) by Richard M. Heiberger and Burt Holland. This\ncontemporary presentation of statistical methods features extensive use\nof graphical displays for exploring data and for displaying the\nanalysis. The second edition includes redesigned graphics and additional\nchapters. The authors emphasize how to construct and interpret graphs,\ndiscuss principles of graphical design, and show how accompanying\ntraditional tabular results are used to confirm the visual impressions\nderived directly from the graphs. Many of the graphical formats are\nnovel and appear here for the first time in print. All chapters have\nexercises. All functions introduced in the book are in the package. R\ncode for all examples, both graphs and tables, in the book is included\nin the scripts directory of the package.",
            "name": "r-hh"
        },
        {
            "description": "Syntax Highlighting for R Source Code. Provides syntax highlighting for\nR source code. Currently it supports LaTeX and HTML output. Source code\nof other languages is supported via Andre Simon's highlight package.",
            "name": "r-highr"
        },
        {
            "description": "Harrell Miscellaneous. Contains many functions useful for data analysis,\nhigh-level graphics, utility operations, functions for computing sample\nsize and power, importing and annotating datasets, imputing missing\nvalues, advanced table making, variable clustering, character string\nmanipulation, conversion of R objects to LaTeX and html code, and\nrecoding variables.",
            "name": "r-hmisc"
        },
        {
            "description": "Pretty Time of Day. Implements an S3 class for storing and formatting\ntime-of-day values, based on the 'difftime' class.",
            "name": "r-hms"
        },
        {
            "description": "Manage Cached Files. Suite of tools for managing cached files, targeting\nuse in other R packages. Uses 'rappdirs' for cross-platform paths.\nProvides utilities to manage cache directories, including targeting\nfiles by path or by key; cached directories can be compressed and\nuncompressed easily to save disk space.",
            "name": "r-hoardr"
        },
        {
            "description": "Advanced Tables for Markdown/HTML. Tables with state-of-the-art layout\nelements such as row spanners, column spanners, table spanners, zebra\nstriping, and more. While allowing advanced layout, the underlying css-\nstructure is simple in order to maximize compatibility with word\nprocessors such as 'MS Word' or 'LibreOffice'. The package also contains\na few text formatting functions that help outputting text compatible\nwith HTML/'LaTeX'.",
            "name": "r-htmltable"
        },
        {
            "description": "Tools for HTML. Tools for HTML generation and output.",
            "name": "r-htmltools"
        },
        {
            "description": "HTML Widgets for R. A framework for creating HTML widgets that render in\nvarious contexts including the R console, 'R Markdown' documents, and\n'Shiny' web applications.",
            "name": "r-htmlwidgets"
        },
        {
            "description": "'HTTP' Status Code Helper. Find and explain the meaning of 'HTTP' status\ncodes. Functions included for searching for codes by full or partial\nnumber, by message, and get appropriate dog and cat images for many\nstatus codes.",
            "name": "r-httpcode"
        },
        {
            "description": "HTTP and WebSocket Server Library. Provides low-level socket and\nprotocol support for handling HTTP and WebSocket requests directly from\nwithin R. It is primarily intended as a building block for other\npackages, rather than making it particularly easy to create complete web\napplications using httpuv alone. httpuv is built on top of the libuv and\nhttp-parser C libraries, both of which were developed by Joyent, Inc.\n(See LICENSE file for libuv and http-parser license information.)",
            "name": "r-httpuv"
        },
        {
            "description": "Tools for Working with URLs and HTTP. Useful tools for working with HTTP\norganised by HTTP verbs (GET(), POST(), etc). Configuration functions\nmake it easy to control additional request components (authenticate(),\nadd_headers() and so on).",
            "name": "r-httr"
        },
        {
            "description": "Perform HTTP Requests and Process the Responses. Tools for creating and\nmodifying HTTP requests, then performing them and processing the\nresults. 'httr2' is a modern re-imagining of 'httr' that uses a pipe-\nbased interface and solves more of the problems that API wrapping\npackages face.",
            "name": "r-httr2"
        },
        {
            "description": "A Parser for Human Names Human names are complicated and nonstandard\nthings. Humaniformat, which is based on Anthony Ettinger's 'humanparser'\nproject (https://github.com/chovy/humanparser) provides functions for\nparsing human names, making a best- guess attempt to distinguish sub-\ncomponents such as prefixes, suffixes, middle names and salutations.",
            "name": "r-humaniformat"
        },
        {
            "description": "HTML Writer - Outputs R objects in HTML format. Easy-to-use and\nversatile functions to output R objects in HTML format.",
            "name": "r-hwriter"
        },
        {
            "description": "Goodness-of-Fit Functions for Comparison of Simulated and Observed\nHydrological Time Series. S3 functions implementing both statistical and\ngraphical goodness-of-fit measures between observed and simulated\nvalues, mainly oriented to be used during the calibration, validation,\nand application of hydrological models. Missing values in observed\nand/or simulated values can be removed before computations. Comments /\nquestions / collaboration of any kind are very welcomed.",
            "name": "r-hydrogof"
        },
        {
            "description": "Time Series Management, Analysis and Interpolation for Hydrological\nModelling. S3 functions for management, analysis, interpolation and\nplotting of time series used in hydrology and related environmental\nsciences. In particular, this package is highly oriented to hydrological\nmodelling tasks. The focus of this package has been put in providing a\ncollection of tools useful for the daily work of hydrologists (although\nan effort was made to optimise each function as much as possible,\nfunctionality has had priority over speed). Bugs / comments / questions\n/ collaboration of any kind are very welcomed, and in particular,\ndatasets that can be included in this package for academic purposes.",
            "name": "r-hydrotsm"
        },
        {
            "description": "A package providing hypergraph data structures. A package that\nimplements some simple capabilities for representing and manipulating\nhypergraphs.",
            "name": "r-hypergraph"
        },
        {
            "description": "Independent Component Analysis. Independent Component Analysis (ICA)\nusing various algorithms: FastICA, Information-Maximization (Infomax),\nand Joint Approximate Diagonalization of Eigenmatrices (JADE).",
            "name": "r-ica"
        },
        {
            "description": "Generate Random Identifiers. Generate random or human readable and\npronounceable identifiers.",
            "name": "r-ids"
        },
        {
            "description": "R Interface to the OpenGWAS Database API. R interface to the OpenGWAS\ndatabase API. Includes a wrapper to make generic calls to the API, plus\nconvenience functions for specific queries.",
            "name": "r-ieugwasr"
        },
        {
            "description": "Network Analysis and Visualization. Routines for simple graphs and\nnetwork analysis. It can handle large graphs very well and provides\nfunctions for generating random and regular graphs, graph visualization,\ncentrality methods and much more.",
            "name": "r-igraph"
        },
        {
            "description": "Annotation Package combining variant data from 1000 Genomes Project for\nIllumina HumanMethylation450 Bead Chip probes. Includes details on\nvariants for each probe on the 450k bead chip for each of the four\npopulations (Asian, American, African and European).",
            "name": "r-illumina450probevariants-db"
        },
        {
            "description": "Annotation for Illumina's 450k methylation arrays. Manifests and\nannotation for Illumina's 450k array data.",
            "name": "r-illuminahumanmethylation450kanno-ilmn12-hg19"
        },
        {
            "description": "Annotation for Illumina's 450k methylation arrays.",
            "name": "r-illuminahumanmethylation450kmanifest"
        },
        {
            "description": "Annotation for Illumina's EPIC methylation arrays.",
            "name": "r-illuminahumanmethylationepicanno-ilm10b4-hg19"
        },
        {
            "description": "Manifest for Illumina's EPIC methylation arrays.",
            "name": "r-illuminahumanmethylationepicmanifest"
        },
        {
            "description": "Parsing Illumina Microarray Output Files. Tools for parsing Illumina's\nmicroarray output files, including IDAT.",
            "name": "r-illuminaio"
        },
        {
            "description": "Image Processing Library Based on 'CImg'. Fast image processing for\nimages in up to 4 dimensions (two spatial dimensions, one time/depth\ndimension, one colour dimension). Provides most traditional image\nprocessing tools (filtering, morphology, transformations, etc.) as well\nas various functions for easily analysing image data using R. The\npackage wraps 'CImg', <https://cimg.eu/>, a simple, modern C++ library\nfor image processing.",
            "name": "r-imager"
        },
        {
            "description": "impute: Imputation for microarray data. Imputation for microarray data\n(currently KNN only)",
            "name": "r-impute"
        },
        {
            "description": "Software Tools to Quantify Structural Importance of Nodes in a Network.\nProvides functionality to compute various node centrality measures on\nnetworks. Included are functions to compute betweenness centrality (by\nutilizing Madduri and Bader's SNAP library), implementations of Burt's\nconstraint and effective network size (ENS) metrics, Borgatti's\nalgorithm to identify key players, and Valente's bridging metric. On\nUnix systems, the betweenness, Key Players, and bridging implementations\nare parallelized with OpenMP, which may run faster on systems which have\nOpenMP configured.",
            "name": "r-influencer"
        },
        {
            "description": "Read and Write '.ini' Files. Parse simple '.ini' configuration files to\nan structured list. Users can manipulate this resulting list with\nlapply() functions. This same structured list can be used to write back\nto file after modifications.",
            "name": "r-ini"
        },
        {
            "description": "Functions to Inline C, C++, Fortran Function Calls from R. Functionality\nto dynamically define R functions and S4 methods with inlined C, C++ or\nFortran code supporting .C and .Call calling conventions.",
            "name": "r-inline"
        },
        {
            "description": "Easy Access to Model Information for Various Model Objects. A tool to\nprovide an easy, intuitive and consistent access to information\ncontained in various R models, like model formulas, model terms,\ninformation about random effects, data that was used to fit the model or\ndata from response variables. 'insight' mainly revolves around two types\nof functions: Functions that find (the names of) information, starting\nwith 'find_', and functions that get the underlying data, starting with\n'get_'. The package has a consistent syntax and works with many\ndifferent model objects, where otherwise functions to access these\ninformation are missing.",
            "name": "r-insight"
        },
        {
            "description": "Base package for enabling powerful shiny web displays of Bioconductor\nobjects. The interactiveDisplayBase package contains the the basic\nmethods needed to generate interactive Shiny based display methods for\nBioconductor objects.",
            "name": "r-interactivedisplaybase"
        },
        {
            "description": "Interpolation Methods. Bivariate data interpolation on regular and\nirregular grids, either linear or using splines are the main part of\nthis package. It is intended to provide FOSS replacement functions for\nthe ACM licensed akima::interp and tripack::tri.mesh functions. Linear\ninterpolation is implemented in interp::interp(..., method=\"linear\"),\nthis corresponds to the call akima::interp(..., linear=TRUE) which is\nthe default setting and covers most of akima::interp use cases in\ndepending packages. A re-implementation of Akimas irregular grid spline\ninterpolation (akima::interp(..., linear=FALSE)) is now also available\nvia interp::interp(..., method=\"akima\"). Estimators for partial\nderivatives are now also available in interp::locpoly(), these are a\nprerequisite for the spline interpolation. The basic part is a GPLed\ntriangulation algorithm (sweep hull algorithm by David Sinclair)\nproviding the starting point for the irregular grid interpolator. As\nside effect this algorithm is also used to provide replacements for\nalmost all functions of the tripack package which also suffers from the\nsame ACM license restrictions. All functions are designed to be backward\ncompatible with their akima / tripack counterparts.",
            "name": "r-interp"
        },
        {
            "description": "Tools for working with and comparing sets of points and intervals.",
            "name": "r-intervals"
        },
        {
            "description": "Interval and Enum-Type Representation of Vectors. Enum-type\nrepresentation of vectors and representation of intervals, including a\nmethod of coercing variables in data frames.",
            "name": "r-inum"
        },
        {
            "description": "Improved Predictors. Improved predictive models by indirect\nclassification and bagging for classification, regression and survival\nproblems as well as resampling based estimators of prediction error.",
            "name": "r-ipred"
        },
        {
            "description": "Foundation of integer range manipulation in Bioconductor. Provides\nefficient low-level and highly reusable S4 classes for storing,\nmanipulating and aggregating over annotated ranges of integers.\nImplements an algebra of range operations, including efficient\nalgorithms for finding overlaps and nearest neighbors. Defines efficient\nlist-like classes for storing, transforming and aggregating large\ngrouped data, i.e., collections of atomic vectors and DataFrames.",
            "name": "r-iranges"
        },
        {
            "description": "'Jupyter' Display Machinery. An interface to the rich display\ncapabilities of 'Jupyter' front-ends (e.g. 'Jupyter Notebook')\n<https://jupyter.org>. Designed to be used from a running 'IRkernel'\nsession <https://irkernel.github.io>.",
            "name": "r-irdisplay"
        },
        {
            "description": "Native R Kernel for the 'Jupyter Notebook'. The R kernel for the\n'Jupyter' environment executes R code which the front-end ('Jupyter\nNotebook' or other front-ends) submits to the kernel via the network.",
            "name": "r-irkernel"
        },
        {
            "description": "Fast Truncated Singular Value Decomposition and Principal Components\nAnalysis for Large Dense and Sparse Matrices. Fast and memory efficient\nmethods for truncated singular value decomposition and principal\ncomponents analysis of large sparse and dense matrices.",
            "name": "r-irlba"
        },
        {
            "description": "Parse 'NOAA' Integrated Surface Data Files. Tools for parsing 'NOAA'\nIntegrated Surface Data ('ISD') files, described at\n<https://www.ncdc.noaa.gov/isd>. Data includes for example, wind speed\nand direction, temperature, cloud data, sea level pressure, and more.\nIncludes data from approximately 35,000 stations worldwide, though best\ncoverage is in North America/Europe/Australia. Data is stored as\nvariable length ASCII character strings, with most fields optional.\nIncluded are tools for parsing entire files, or individual lines of\ndata.",
            "name": "r-isdparser"
        },
        {
            "description": "Data for an Introduction to Statistical Learning with Applications in R.\nWe provide the collection of data-sets used in the book 'An Introduction\nto Statistical Learning with Applications in R'.",
            "name": "r-islr"
        },
        {
            "description": "Functions to Perform Isotonic Regression. Linear order and unimodal\norder (univariate) isotonic regression; bivariate isotonic regression\nwith linear order on both variables.",
            "name": "r-iso"
        },
        {
            "description": "Generate Isolines and Isobands from Regularly Spaced Elevation Grids. A\nfast C++ implementation to generate contour lines (isolines) and contour\npolygons (isobands) from regularly spaced grids containing elevation\ndata.",
            "name": "r-isoband"
        },
        {
            "description": "Independent Surrogate Variable Analysis. Independent Surrogate Variable\nAnalysis is an algorithm for feature selection in the presence of\npotential confounding factors (see Teschendorff AE et al 2011,\n<doi:10.1093/bioinformatics/btr171>).",
            "name": "r-isva"
        },
        {
            "description": "Provides Iterator Construct. Support for iterators, which allow a\nprogrammer to traverse through all the elements of a vector, list, or\nother collection of data.",
            "name": "r-iterators"
        },
        {
            "description": "Efficient Iterator for Permutations and Combinations. Iterator for\ngenerating permutations and combinations. They can be either drawn with\nor without replacement, or with distinct/ non-distinct items (multiset).\nThe generated sequences are in lexicographical order (dictionary order).\nThe algorithms to generate permutations and combinations are memory\nefficient. These iterative algorithms enable users to process all\nsequences without putting all results in the memory at the same time.\nThe algorithms are written in C/C++ for faster performance. Note:\n'iterpc' is no longer being maintained. Users are recommended to switch\nto 'arrangements'.",
            "name": "r-iterpc"
        },
        {
            "description": "Blind Source Separation Methods Based on Joint Diagonalization and Some\nBSS Performance Criteria. Cardoso's JADE algorithm as well as his\nfunctions for joint diagonalization are ported to R. Also several other\nblind source separation (BSS) methods, like AMUSE and SOBI, and some\ncriteria for performance evaluation of BSS algorithms, are given. The\npackage is described in Miettinen, Nordhausen and Taskinen (2017)\n<doi:10.18637/jss.v076.i02>.",
            "name": "r-jade"
        },
        {
            "description": "Simple Tools for Examining and Cleaning Dirty Data. The main janitor\nfunctions can: perfectly format data.frame column names; provide quick\none- and two-variable tabulations (i.e., frequency tables and\ncrosstabs); and isolate duplicate records. Other janitor functions\nnicely format the tabulation results. These tabulate-and-report\nfunctions approximate popular features of SPSS and Microsoft Excel. This\npackage follows the principles of the \"tidyverse\" and works well with\nthe pipe function %>%. janitor was built with beginning-to-intermediate\nR users in mind and is optimized for user-friendliness. Advanced R users\ncan already do everything covered here, but with janitor they can do it\nfaster and save their thinking for the fun stuff.",
            "name": "r-janitor"
        },
        {
            "description": "Data package for JASPAR 2018. Data package for JASPAR 2018. To search\nthis databases, please use the package TFBSTools (>= 1.15.6).",
            "name": "r-jaspar2018"
        },
        {
            "description": "Multilevel Joint Modelling Multiple Imputation. Similarly to Schafer's\npackage 'pan', 'jomo' is a package for multilevel joint modelling\nmultiple imputation (Carpenter and Kenward, 2013)\n<doi:10.1002/9781119942283>. Novel aspects of 'jomo' are the possibility\nof handling binary and categorical data through latent normal variables,\nthe option to use cluster-specific covariance matrices and to impute\ncompatibly with the substantive model.",
            "name": "r-jomo"
        },
        {
            "description": "Read and write JPEG images. This package provides an easy and simple way\nto read, write and display bitmap images stored in the JPEG format. It\ncan read and write both files and in-memory raw vectors.",
            "name": "r-jpeg"
        },
        {
            "description": "Obtain 'jQuery' as an HTML Dependency Object. Obtain any major version\nof 'jQuery' (<https://code.jquery.com/>) and use it in any webpage\ngenerated by 'htmltools' (e.g. 'shiny', 'htmlwidgets', and 'rmarkdown').\nMost R users don't need to use this package directly, but other R\npackages (e.g. 'shiny', 'rmarkdown', etc.) depend on this package to\navoid bundling redundant copies of 'jQuery'.",
            "name": "r-jquerylib"
        },
        {
            "description": "Convert Between 'R' Objects and Javascript Object Notation (JSON).\nConversions between 'R' objects and Javascript Object Notation (JSON)\nusing the 'rapidjsonr' library\n<https://CRAN.R-project.org/package=rapidjsonr>.",
            "name": "r-jsonify"
        },
        {
            "description": "A Simple and Robust JSON Parser and Generator for R. A fast JSON parser\nand generator optimized for statistical data and the web. Started out as\na fork of 'RJSONIO', but has been completely rewritten in recent\nversions. The package offers flexible, robust, high performance tools\nfor working with JSON in R and is particularly powerful for building\npipelines and interacting with a web API. The implementation is based on\nthe mapping described in the vignette (Ooms, 2014). In addition to\nconverting JSON data from/to R objects, 'jsonlite' contains functions to\nstream, validate, and prettify JSON data. The unit tests included with\nthe package verify that all edge cases are encoded and decoded\nconsistently for use with dynamic data in systems and applications.",
            "name": "r-jsonlite"
        },
        {
            "description": "Construct Complex Table with 'kable' and Pipe Syntax. Build complex HTML\nor 'LaTeX' tables using 'kable()' from 'knitr' and the piping syntax\nfrom 'magrittr'. Function 'kable()' is a light weight table generator\ncoming from 'knitr'. This package simplifies the way to manipulate the\nHTML or 'LaTeX' codes generated by 'kable()' and allows users to\nconstruct complex tables and customize styles using a readable syntax.",
            "name": "r-kableextra"
        },
        {
            "description": "A set of annotation maps for KEGG. A set of annotation maps for KEGG\nassembled using data from KEGG.",
            "name": "r-kegg-db"
        },
        {
            "description": "KEGGgraph: A graph approach to KEGG PATHWAY in R and Bioconductor.\nKEGGGraph is an interface between KEGG pathway and graph object as well\nas a collection of tools to analyze, dissect and visualize these graphs.\nIt parses the regularly updated KGML (KEGG XML) files into graph models\nmaintaining all essential pathway attributes. The package offers\nfunctionalities including parsing, graph operation, visualization and\netc.",
            "name": "r-kegggraph"
        },
        {
            "description": "Client-side REST access to KEGG. A package that provides a client\ninterface to the KEGG REST server. Based on KEGGSOAP by J. Zhang, R.\nGentleman, and Marc Carlson, and KEGG (python package) by Aurelien\nMazurie.",
            "name": "r-keggrest"
        },
        {
            "description": "Kernel-Based Machine Learning Lab. Kernel-based machine learning methods\nfor classification, regression, clustering, novelty detection, quantile\nregression and dimensionality reduction. Among other methods 'kernlab'\nincludes Support Vector Machines, Spectral Clustering, Kernel PCA,\nGaussian Processes and a QP solver.",
            "name": "r-kernlab"
        },
        {
            "description": "Functions for Kernel Smoothing Supporting Wand & Jones (1995). Functions\nfor kernel smoothing (and density estimation) corresponding to the book:\nWand, M.P. and Jones, M.C. (1995) \"Kernel Smoothing\".",
            "name": "r-kernsmooth"
        },
        {
            "description": "Weighted k-Nearest Neighbors. Weighted k-Nearest Neighbors for\nClassification, Regression and Clustering.",
            "name": "r-kknn"
        },
        {
            "description": "Classification and Visualization. Miscellaneous functions for\nclassification and visualization, e.g. regularized discriminant\nanalysis, sknn() kernel-density naive Bayes, an interface to 'svmlight'\nand stepclass() wrapper variable selection for supervised\nclassification, partimat() visualization of classification rules and\nshardsplot() of cluster results as well as kmodes() clustering for\ncategorical data, corclust() variable clustering, variable extraction\nfrom different variable clustering models and weight of evidence\npreprocessing.",
            "name": "r-klar"
        },
        {
            "description": "A General-Purpose Package for Dynamic Report Generation in R. Provides a\ngeneral-purpose tool for dynamic report generation in R using Literate\nProgramming techniques.",
            "name": "r-knitr"
        },
        {
            "description": "Known Population Median Test. Functions that implement the known\npopulation median test.",
            "name": "r-kpmt"
        },
        {
            "description": "Kernel Smoothing. Kernel smoothers for univariate and multivariate data,\nincluding densities, density derivatives, cumulative distributions,\nclustering, classification, density ridges, significant modal regions,\nand two-sample hypothesis tests. Chacon & Duong (2018)\n<doi:10.1201/9780429485572>.",
            "name": "r-ks"
        },
        {
            "description": "K-Sample Rank Tests and their Combinations. Compares k samples using the\nAnderson-Darling test, Kruskal-Wallis type tests with different rank\nscore criteria, Steel's multiple comparison test, and the Jonckheere-\nTerpstra (JT) test. It computes asymptotic, simulated or (limited) exact\nP-values, all valid under randomization, with or without ties, or\nconditionally under random sampling from populations, given the observed\ntie pattern. Except for Steel's test and the JT test it also combines\nthese tests across several blocks of samples. Also analyzed are 2 x t\ncontingency tables and their blocked combinations using the Kruskal-\nWallis criterion. Steel's test is inverted to provide simultaneous\nconfidence bounds for shift parameters. A plotting function compares\ntail probabilities obtained under asymptotic approximation with those\nobtained via simulation or exact calculations.",
            "name": "r-ksamples"
        },
        {
            "description": "Axis Labeling. Provides a range of axis labeling algorithms.",
            "name": "r-labeling"
        },
        {
            "description": "Manipulating Labelled Data. Work with labelled data imported from 'SPSS'\nor 'Stata' with 'haven' or 'foreign'. This package provides useful\nfunctions to deal with \"haven_labelled\" and \"haven_labelled_spss\"\nclasses introduced by 'haven' package.",
            "name": "r-labelled"
        },
        {
            "description": "Modeling Data with Functional Programming. A language extension to\nefficiently write functional programs in R. Syntax extensions include\nmulti-part function definitions, pattern matching, guard statements,\nbuilt-in (optional) type safety.",
            "name": "r-lambda-r"
        },
        {
            "description": "Complete Environment for Bayesian Inference. Provides a complete\nenvironment for Bayesian inference using a variety of different samplers\n(see ?LaplacesDemon for an overview). The README describes the history\nof the package development process.",
            "name": "r-laplacesdemon"
        },
        {
            "description": "Least Angle Regression, Lasso and Forward Stagewise. Efficient\nprocedures for fitting an entire lasso sequence with the cost of a\nsingle least squares fit.",
            "name": "r-lars"
        },
        {
            "description": "Utilities for Scheduling Functions to Execute Later with Event Loops.\nExecutes arbitrary R or C functions some time after the current time,\nafter the R execution stack has emptied.",
            "name": "r-later"
        },
        {
            "description": "Trellis Graphics for R. A powerful and elegant high-level data\nvisualization system inspired by Trellis graphics, with an emphasis on\nmultivariate data. Lattice is sufficient for typical graphics needs, and\nis also flexible enough to handle most nonstandard requirements. See\n?Lattice for an introduction.",
            "name": "r-lattice"
        },
        {
            "description": "Extra Graphical Utilities Based on Lattice. Building on the\ninfrastructure provided by the lattice package, this package provides\nseveral new high-level functions and methods, as well as additional\nutilities such as panel and axis annotation functions.",
            "name": "r-latticeextra"
        },
        {
            "description": "Latent Variable Models. A general implementation of Structural Equation\nModels with latent variables (MLE, 2SLS, and composite likelihood\nestimators) with both continuous, censored, and ordinal outcomes (Holst\nand Budtz-Joergensen (2013) <doi:10.1007/s00180-012-0344-y>). Mixture\nlatent variable models and non-linear latent variable models (Holst and\nBudtz-Joergensen (2019) <doi:10.1093/biostatistics/kxy082>). The package\nalso provides methods for graph exploration (d-separation, back-door\ncriterion), simulation of general non-linear latent variable models, and\nestimation of influence functions for a broad range of statistical\nmodels.",
            "name": "r-lava"
        },
        {
            "description": "Latent Variable Analysis. Fit a variety of latent variable models,\nincluding confirmatory factor analysis, structural equation modeling and\nlatent growth curve models.",
            "name": "r-lavaan"
        },
        {
            "description": "Lazy (Non-Standard) Evaluation. An alternative approach to non-standard\nevaluation using formulas. Provides a full implementation of LISP style\n'quasiquotation', making it easier to generate code with other code.",
            "name": "r-lazyeval"
        },
        {
            "description": "Graphical Display of Pairwise Linkage Disequilibria Between SNPs.\nProduces a graphical display, as a heat map, of measures of pairwise\nlinkage disequilibria between single nucleotide polymorphisms (SNPs).\nUsers may optionally include the physical locations or genetic map\ndistances of each SNP on the plot. The methods are described in Shin et\nal. (2006) <doi:10.18637/jss.v016.c03>. Users should note that the\nimported package 'snpStats' and the suggested packages 'rtracklayer',\n'GenomicRanges', 'GenomInfoDb' and 'IRanges' are all BioConductor\npackages <https://bioconductor.org>.",
            "name": "r-ldheatmap"
        },
        {
            "description": "'leaflet' Extensions for 'mapview'. Provides extensions for packages\n'leaflet' & 'mapdeck', many of which are used by package 'mapview'.\nFocus is on functionality readily available in Geographic Information\nSystems such as 'Quantum GIS'. Includes functions to display coordinates\nof mouse pointer position, query image values via mouse pointer and\nzoom-to-layer buttons. Additionally, provides a feature type agnostic\nfunction to add points, lines, polygons to a map.",
            "name": "r-leafem"
        },
        {
            "description": "Create Interactive Web Maps with the JavaScript 'Leaflet' Library.\nCreate and customize interactive maps using the 'Leaflet' JavaScript\nlibrary and the 'htmlwidgets' package. These maps can be used directly\nfrom the R console, from 'RStudio', in Shiny apps and R Markdown\ndocuments.",
            "name": "r-leaflet"
        },
        {
            "description": "Leaflet Providers. Contains third-party map tile provider information\nfrom 'Leaflet.js', <https://github.com/leaflet-extras/leaflet-\nproviders>, to be used with the 'leaflet' R package. Additionally,\n'leaflet.providers' enables users to retrieve up-to-date provider\ninformation between package updates.",
            "name": "r-leaflet-providers"
        },
        {
            "description": "Include Tables, Images and Graphs in Leaflet Pop-Ups. Creates 'HTML'\nstrings to embed tables, images or graphs in pop-ups of interactive maps\ncreated with packages like 'leaflet' or 'mapview'. Handles local images\nlocated on the file system or via remote URL. Handles graphs created\nwith 'lattice' or 'ggplot2' as well as interactive plots created with\n'htmlwidgets'.",
            "name": "r-leafpop"
        },
        {
            "description": "Regression Subset Selection. Regression subset selection, including\nexhaustive search.",
            "name": "r-leaps"
        },
        {
            "description": "Functions for Learning Bayesian Inference. LearnBayes contains a\ncollection of functions helpful in learning the basic tenets of Bayesian\nstatistical inference. It contains functions for summarizing basic one\nand two parameter posterior distributions and predictive distributions.\nIt contains MCMC algorithms for summarizing posterior distributions\ndefined by the user. It also contains functions for regression models,\nhierarchical models, Bayesian tests, and illustrations of Gibbs\nsampling.",
            "name": "r-learnbayes"
        },
        {
            "description": "R Implementation of Leiden Clustering Algorithm. Implements the 'Python\nleidenalg' module to be called in R. Enables clustering using the leiden\nalgorithm for partition a graph into communities. See the 'Python'\nrepository for more details: <https://github.com/vtraag/leidenalg> Traag\net al (2018) From Louvain to Leiden: guaranteeing well-connected\ncommunities. <arXiv:1810.08473>.",
            "name": "r-leiden"
        },
        {
            "description": "Linear Group Fixed Effects. Transforms away factors with many levels\nprior to doing an OLS. Useful for estimating linear models with multiple\ngroup fixed effects, and for estimating linear models which uses factors\nwith many levels as pure control variables. See Gaure (2013)\n<doi:10.1016/j.csda.2013.03.024> Includes support for instrumental\nvariables, conditional F statistics for weak instruments, robust and\nmulti-way clustered standard errors, as well as limited mobility bias\ncorrection (Gaure 2014 <doi:10.1002/sta4.68>). WARNING: This package is\nNOT under active development anymore, no further improvements are to be\nexpected, and the package is at risk of being removed from CRAN.",
            "name": "r-lfe"
        },
        {
            "description": "Latin Hypercube Samples. Provides a number of methods for creating and\naugmenting Latin Hypercube Samples.",
            "name": "r-lhs"
        },
        {
            "description": "Linear Test Statistics for Permutation Inference. Basic infrastructure\nfor linear test statistics and permutation inference in the framework of\nStrasser and Weber (1999) <https://epub.wu.ac.at/102/>. This package\nmust not be used by end-users. CRAN package 'coin' implements all user\ninterfaces and is ready to be used by anyone.",
            "name": "r-libcoin"
        },
        {
            "description": "R package for libpressio",
            "name": "r-libpressio"
        },
        {
            "description": "Airborne LiDAR data manipulation and visualisation for forestry\napplication",
            "name": "r-lidr"
        },
        {
            "description": "Manage the Life Cycle of your Package Functions. Manage the life cycle\nof your exported functions with shared conventions, documentation\nbadges, and non-invasive deprecation warnings. The 'lifecycle' package\ndefines four development stages (experimental, maturing, stable, and\nquestioning) and three deprecation stages (soft-deprecated, deprecated,\nand defunct). It makes it easy to insert badges corresponding to these\nstages in your documentation. Usage of deprecated functions are\nsignalled with increasing levels of non-invasive verbosity.",
            "name": "r-lifecycle"
        },
        {
            "description": "Linear Models for Microarray Data. Data analysis, linear models and\ndifferential expression for microarray data.",
            "name": "r-limma"
        },
        {
            "description": "Solving Linear Inverse Models. Functions that (1) find the\nminimum/maximum of a linear or quadratic function: min or max (f(x)),\nwhere f(x) = ||Ax-b||^2 or f(x) = sum(a_i*x_i) subject to equality\nconstraints Ex=f and/or inequality constraints Gx>=h, (2) sample an\nunderdetermined- or overdetermined system Ex=f subject to Gx>=h, and if\napplicable Ax~=b, (3) solve a linear system Ax=B for the unknown x. It\nincludes banded and tridiagonal linear systems.",
            "name": "r-limsolve"
        },
        {
            "description": "Linear Programming / Optimization. Can be used to solve Linear\nProgramming / Linear Optimization problems by using the simplex\nalgorithm.",
            "name": "r-linprog"
        },
        {
            "description": "Allows researchers to conduct multivariate statistical analyses of\nsurvey data with list experiments.",
            "name": "r-list"
        },
        {
            "description": "Environments Behaving (Almost) as Lists. List environments are\nenvironments that have list-like properties. For instance, the elements\nof a list environment are ordered and can be accessed and iterated over\nusing index subsetting.",
            "name": "r-listenv"
        },
        {
            "description": "Linear Mixed-Effects Models using 'Eigen' and S4. Fit linear and\ngeneralized linear mixed-effects models. The models and their components\nare represented using S4 classes and methods. The core computational\nalgorithms are implemented using the 'Eigen' C++ library for numerical\nlinear algebra and 'RcppEigen' \"glue\".",
            "name": "r-lme4"
        },
        {
            "description": "Tests in Linear Mixed Effects Models. Provides p-values in type I, II or\nIII anova and summary tables for lmer model fits (cf. lme4) via\nSatterthwaite's degrees of freedom method. A Kenward-Roger method is\nalso available via the pbkrtest package. Model selection methods include\nstep, drop1 and anova-like tables for random effects (ranova). Methods\nfor Least-Square means (LS-means) and tests of linear contrasts of fixed\neffects are also available.",
            "name": "r-lmertest"
        },
        {
            "description": "Testing Linear Regression Models. A collection of tests, data sets, and\nexamples for diagnostic checking in linear regression models.\nFurthermore, some generic tools for inference in parametric models are\nprovided.",
            "name": "r-lmtest"
        },
        {
            "description": "Visualize R Data Structures with Trees. A set of tools for inspecting\nand understanding R data structures inspired by str(). Includes ast()\nfor visualizing abstract syntax trees, ref() for showing shared\nreferences, cst() for showing call stack trees, and obj_size() for\ncomputing object sizes.",
            "name": "r-lobstr"
        },
        {
            "description": "Local regression, likelihood and density estimation. Local regression,\nlikelihood and density estimation methods as described in the 1999 book\nby Loader.",
            "name": "r-locfit"
        },
        {
            "description": "A Fast and Lightweight Logging System for R, Based on 'log4j'. logr4\nprovides an object-oriented logging system that uses an API roughly\nequivalent to log4j and its related variants.",
            "name": "r-log4r"
        },
        {
            "description": "Efficient Leave-One-Out Cross-Validation and WAIC for BayesianModels.\nEfficient approximate leave-one-out cross-validation (LOO) for Bayesian\nmodels fit using Markov chain Monte Carlo, as described in Vehtari,\nGelman, and Gabry (2017) <doi:10.1007/s11222-016-9696-4>. The\napproximation uses Pareto smoothed importance sampling (PSIS), a new\nprocedure for regularizing importance weights. As a byproduct of the\ncalculations, we also obtain approximate standard errors for estimated\npredictive errors and for the comparison of predictive errors between\nmodels. The package also provides methods for using stacking and other\nmodel weighting techniques to average Bayesian predictive distributions.",
            "name": "r-loo"
        },
        {
            "description": "Interface to 'Lp_solve' v. 5.5 to Solve Linear/Integer Programs.\nLp_solve is freely available (under LGPL 2) software for solving linear,\ninteger and mixed integer programs. In this implementation we supply a\n\"wrapper\" function in C and some R functions that solve general\nlinear/integer problems, assignment problems, and transportation\nproblems. This version calls lp_solve",
            "name": "r-lpsolve"
        },
        {
            "description": "R Interface to 'lp_solve' Version 5.5.2.0. The lpSolveAPI package\nprovides an R interface to 'lp_solve', a Mixed Integer Linear\nProgramming (MILP) solver with support for pure linear, (mixed)\ninteger/binary, semi-continuous and special ordered sets (SOS) models.",
            "name": "r-lpsolveapi"
        },
        {
            "description": "Solving Least Squares or Quadratic Programming Problems under\nEquality/Inequality Constraints. It contains functions that solve least\nsquares linear regression problems under linear equality/inequality\nconstraints. Functions for solving quadratic programming problems are\nalso available, which transform such problems into least squares ones\nfirst. It is developed based on the 'Fortran' program of Lawson and\nHanson (1974, 1995), which is public domain and available at\n<http://www.netlib.org/lawson-hanson>.",
            "name": "r-lsei"
        },
        {
            "description": "Make Dealing with Dates a Little Easier. Functions to work with date-\ntimes and timespans: fast and user friendly parsing of date-time data,\nextraction and updating of components of a date-time (years, months,\ndays, hours, minutes, and seconds), algebraic manipulation on date-time\nand timespan objects. The 'lubridate' package has a consistent and\nmemorable syntax that makes working with dates easy and fun.",
            "name": "r-lubridate"
        },
        {
            "description": "BeadArray Specific Methods for Illumina Methylation and Expression\nMicroarrays. The lumi package provides an integrated solution for the\nIllumina microarray data analysis. It includes functions of Illumina\nBeadStudio (GenomeStudio) data input, quality control, BeadArray-\nspecific variance stabilization, normalization and gene annotation at\nthe probe level. It also includes the functions of processing Illumina\nmethylation microarrays, especially Illumina Infinium methylation\nmicroarrays.",
            "name": "r-lumi"
        },
        {
            "description": "Bindings to Selected 'liblwgeom' Functions for Simple Features. Access\nto selected functions found in 'liblwgeom'\n<https://github.com/postgis/postgis/tree/master/liblwgeom>, the light-\nweight geometry library used by 'PostGIS' <https://postgis.net/>.",
            "name": "r-lwgeom"
        },
        {
            "description": "Create and Investigate Magic Squares. A collection of efficient,\nvectorized algorithms for the creation and investigation of magic\nsquares and hypercubes, including a variety of functions for the\nmanipulation and analysis of arbitrarily dimensioned arrays. The package\nincludes methods for creating normal magic squares of any order greater\nthan 2. The ultimate intention is for the package to be a computerized\nembodiment all magic square knowledge, including direct numerical\nverification of properties of magic squares (such as recent results on\nthe determinant of odd-ordered semimagic squares). Some antimagic\nfunctionality is included. The package also serves as a rebuttal to the\noften-heard comment \"I thought R was just for statistics\".",
            "name": "r-magic"
        },
        {
            "description": "Advanced Graphics and Image-Processing in R. Bindings to 'ImageMagick':\nthe most comprehensive open-source image processing library available.\nSupports many common formats (png, jpeg, tiff, pdf, etc) and\nmanipulations (rotate, scale, crop, trim, flip, blur, etc). All\noperations are vectorized via the Magick++ STL meaning they operate\neither on a single frame or a series of frames for working with layers,\ncollages, or animation. In RStudio images are automatically previewed\nwhen printed to the console, resulting in an interactive editing\nenvironment. The latest version of the package includes a native\ngraphics device for creating in-memory graphics or drawing onto images\nusing pixel coordinates.",
            "name": "r-magick"
        },
        {
            "description": "A Forward-Pipe Operator for R. Provides a mechanism for chaining\ncommands with a new forward-pipe operator, %>%. This operator will\nforward a value, or the result of an expression, into the next function\ncall/expression. There is flexible support for the type of right-hand\nside expressions. For more information, see package vignette.",
            "name": "r-magrittr"
        },
        {
            "description": "CDF Environment Maker. This package has two functions. One reads a\nAffymetrix chip description file (CDF) and creates a hash table\nenvironment containing the location/probe set membership mapping. The\nother creates a package that automatically loads that environment.",
            "name": "r-makecdfenv"
        },
        {
            "description": "Quantitative Analysis of Mass Spectrometry Data. A complete analysis\npipeline for matrix-assisted laser desorption/ionization-time-of-flight\n(MALDI-TOF) and other two-dimensional mass spectrometry data. In\naddition to commonly used plotting and processing methods it includes\ndistinctive features, namely baseline subtraction methods such as\nmorphological filters (TopHat) or the statistics-sensitive non-linear\niterative peak-clipping algorithm (SNIP), peak alignment using warping\nfunctions, handling of replicated measurements as well as allowing\nspectra with different resolutions.",
            "name": "r-maldiquant"
        },
        {
            "description": "Add Even More Interactivity to Interactive Charts. Like package\n'manipulate' does for static graphics, this package helps to easily add\ncontrols like sliders, pickers, checkboxes, etc. that can be used to\nmodify the input data or the parameters of an interactive chart created\nwith package 'htmlwidgets'.",
            "name": "r-manipulatewidget"
        },
        {
            "description": "Data Visualisation on Maps. Create simple maps; add sub-plots like pie\nplots to a map or any other plot; format, plot and export gridded data.\nThe package was developed for displaying fisheries data but most\nfunctions can be used for more generic data visualisation.",
            "name": "r-mapplots"
        },
        {
            "description": "Map Projections. Converts latitude/longitude into projected coordinates.",
            "name": "r-mapproj"
        },
        {
            "description": "Draw Geographical Maps. Display of maps. Projection code and larger maps\nare in separate packages ('mapproj' and 'mapdata').",
            "name": "r-maps"
        },
        {
            "description": "Tools for Handling Spatial Objects. Set of tools for manipulating and\nreading geographic data, in particular ESRI shapefiles; C code used from\nshapelib. It includes binary access to GSHHG shoreline files. The\npackage also provides interface wrappers for exchanging spatial objects\nwith packages such as PBSmapping, spatstat, maps, RArcInfo, Stata tmap,\nWinBUGS, Mondrian, and others.",
            "name": "r-maptools"
        },
        {
            "description": "Interactive Viewing of Spatial Data in R. Quickly and conveniently\ncreate interactive visualisations of spatial data with or without\nbackground maps. Attributes of displayed features are fully queryable\nvia pop-up windows. Additional functionality includes methods to\nvisualise true- and false-color raster images and bounding boxes.",
            "name": "r-mapview"
        },
        {
            "description": "Render Markdown with the C Library 'Sundown'. Provides R bindings to the\n'Sundown' 'Markdown' rendering library (https://github.com/vmg/sundown).\n'Markdown' is a plain-text formatting syntax that can be converted to\n'XHTML' or other formats. See https://en.wikipedia.org/wiki/Markdown for\nmore information about 'Markdown'.",
            "name": "r-markdown"
        },
        {
            "description": "Exploratory analysis for two-color spotted microarray data. Class\ndefinitions for two-color spotted microarray data. Fuctions for data\ninput, diagnostic plots, normalization and quality checking.",
            "name": "r-marray"
        },
        {
            "description": "Support Functions and Datasets for Venables and Ripley's MASS. Functions\nand datasets to support Venables and Ripley, \"Modern Applied Statistics\nwith S\" (4th edition, 2002).",
            "name": "r-mass"
        },
        {
            "description": "Using 'Mathjax' in Rd Files. Provides 'MathJax' and macros to enable its\nuse within Rd files for rendering equations in the HTML help files.",
            "name": "r-mathjaxr"
        },
        {
            "description": "MATLAB emulation package. Emulate MATLAB code using R.",
            "name": "r-matlab"
        },
        {
            "description": "Metagenomics Analysis Tools. Package matR (Metagenomics Analysis Tools\nfor R) is an analysis client for the MG-RAST metagenome annotation\nengine, part of the US Department of Energy (DOE) Systems Biology\nKnowledge Base (KBase). Customized analysis and visualization tools\nsecurely access remote data and metadata within the popular open source\nR language and environment for statistical computing.",
            "name": "r-matr"
        },
        {
            "description": "Sparse and Dense Matrix Classes and Methods. A rich hierarchy of matrix\nclasses, including triangular, symmetric, and diagonal matrices, both\ndense and sparse and with pattern, logical and numeric entries. Numerous\nmethods for and operations on these matrices, using 'LAPACK' and\n'SuiteSparse' libraries.",
            "name": "r-matrix"
        },
        {
            "description": "S4 Generic Summary Statistic Functions that Operate on Matrix-Like\nObjects. S4 generic functions modeled after the 'matrixStats' API for\nalternative matrix implementations. Packages with alternative matrix\nimplementation can depend on this package and implement the generic\nfunctions that are defined here for a useful set of row and column\nsummary statistics. Other package developers can import this package and\nhandle a different matrix implementations without worrying about\nincompatibilities.",
            "name": "r-matrixgenerics"
        },
        {
            "description": "Modelling with Sparse and Dense Matrices. Modelling with sparse and\ndense 'Matrix' matrices, using modular prediction and response module\nclasses.",
            "name": "r-matrixmodels"
        },
        {
            "description": "Functions that Apply to Rows and Columns of Matrices (and to Vectors).\nHigh-performing functions operating on rows and columns of matrices,\ne.g. col / rowMedians(), col / rowRanks(), and col / rowSds(). Functions\noptimized per data type and for subsetted calculations such that both\nmemory usage and processing time is minimized. There are also optimized\nvector-based methods, e.g. binMeans(), madDiff() and weightedMedian().",
            "name": "r-matrixstats"
        },
        {
            "description": "Multinomial Logit Models, with or without Random Effects or\nOverdispersion. Provides estimators for multinomial logit models in\ntheir conditional logit and baseline logit variants, with or without\nrandom effects, with or without overdispersion. Random effects models\nare estimated using the PQL technique (based on a Laplace approximation)\nor the MQL technique (based on a Solomon-Cox approximation). Estimates\nshould be treated with caution if the group sizes are small.",
            "name": "r-mclogit"
        },
        {
            "description": "Gaussian Mixture Modelling for Model-Based Clustering, Classification,\nand Density Estimation. Gaussian finite mixture models fitted via EM\nalgorithm for model-based clustering, classification, and density\nestimation, including Bayesian regularization, dimension reduction for\nvisualisation, and resampling-based inference.",
            "name": "r-mclust"
        },
        {
            "description": "Markov Chain Monte Carlo. Simulates continuous distributions of random\nvectors using Markov chain Monte Carlo (MCMC). Users specify the\ndistribution by an R function that evaluates the log unnormalized\ndensity. Algorithms are random walk Metropolis algorithm (function\nmetrop), simulated tempering (function temper), and morphometric random\nwalk Metropolis (Johnson and Geyer, 2012, <doi:10.1214/12-AOS1048>,\nfunction morph.metrop), which achieves geometric ergodicity by change of\nvariable.",
            "name": "r-mcmc"
        },
        {
            "description": "MCMC Generalised Linear Mixed Models. Fits Multivariate Generalised\nLinear Mixed Models (and related models) using Markov chain Monte Carlo\ntechniques (Hadfield 2010 J. Stat. Soft.).",
            "name": "r-mcmcglmm"
        },
        {
            "description": "Markov Chain Monte Carlo (MCMC) Package. Contains functions to perform\nBayesian inference using posterior simulation for a number of\nstatistical models. Most simulation is done in compiled C++ written in\nthe Scythe Statistical Library Version 1.0.3. All models return 'coda'\nmcmc objects that can then be summarized using the 'coda' package. Some\nuseful utility functions such as density functions, pseudo-random number\ngenerators for statistical distributions, a general purpose Metropolis\nsampling algorithm, and tools for visualization are provided.",
            "name": "r-mcmcpack"
        },
        {
            "description": "Multiple Criteria Optimization Algorithms and Related Functions. A\ncollection of function to solve multiple criteria optimization problems\nusing genetic algorithms (NSGA-II). Also included is a collection of\ntest functions.",
            "name": "r-mco"
        },
        {
            "description": "Mixture and Flexible Discriminant Analysis. Mixture and flexible\ndiscriminant analysis, multivariate adaptive regression splines (MARS),\nBRUTO.",
            "name": "r-mda"
        },
        {
            "description": "Management of Survey Data and Presentation of Analysis Results. An\ninfrastructure for the management of survey data including value labels,\ndefinable missing values, recoding of variables, production of code\nbooks, and import of (subsets of) 'SPSS' and 'Stata' files is provided.\nFurther, the package allows to produce tables and data frames of\narbitrary descriptive statistics and (almost) publication-ready tables\nof regression model estimates, which can be exported to 'LaTeX' and\nHTML.",
            "name": "r-memisc"
        },
        {
            "description": "'Memoisation' of Functions. Cache the results of a function so that when\nyou call it again with the same arguments it returns the pre-computed\nvalue.",
            "name": "r-memoise"
        },
        {
            "description": "Memory Estimation Utilities. How much ram do you need to store a 100,000\nby 100,000 matrix? How much ram is your current R session using? How\nmuch ram do you even have? Learn the scintillating answer to these and\nmany more such questions with the 'memuse' package.",
            "name": "r-memuse"
        },
        {
            "description": "Mendelian Randomization Package. Encodes several methods for performing\nMendelian randomization analyses with summarized data. Summarized data\non genetic associations with the exposure and with the outcome can be\nobtained from large consortia. These data can be used for obtaining\ncausal estimates using instrumental variable methods.",
            "name": "r-mendelianrandomization"
        },
        {
            "description": "Merge Maid. The functions in this R extension are intended for cross-\nstudy comparison of gene expression array data. Required from the user\nis gene expression matrices, their corresponding gene-id vectors and\nother useful information, and they could be 'list','matrix', or\n'ExpressionSet'. The main function is 'mergeExprs' which transforms the\ninput objects into data in the merged format, such that common genes in\ndifferent datasets can be easily found. And the function 'intcor'\ncalculate the correlation coefficients. Other functions use the output\nfrom 'modelOutcome' to graphically display the results and cross-\nvalidate associations of gene expression data with survival.",
            "name": "r-mergemaid"
        },
        {
            "description": "General Package for Meta-Analysis. User-friendly general package\nproviding standard methods for meta-analysis and supporting Schwarzer,\nCarpenter, and R\u00fccker <doi:10.1007/978-3-319-21416-0>, \"Meta-Analysis\nwith R\" (2015): - common effect and random effects meta-analysis; -\nseveral plots (forest, funnel, Galbraith / radial, L'Abbe, Baujat,\nbubble); - three-level meta-analysis model; - generalised linear mixed\nmodel; - Hartung-Knapp method for random effects model; - Kenward-Roger\nmethod for random effects model; - prediction interval; - statistical\ntests for funnel plot asymmetry; - trim-and-fill method to evaluate bias\nin meta-analysis; - meta-regression; - cumulative meta-analysis and\nleave-one-out meta-analysis; - import data from 'RevMan 5'; - produce\nforest plot summarising several (subgroup) meta-analyses.",
            "name": "r-meta"
        },
        {
            "description": "Meta-Analysis Datasets. A collection of meta-analysis datasets for\nteaching purposes, illustrating/testing meta-analytic methods, and\nvalidating published analyses.",
            "name": "r-metadat"
        },
        {
            "description": "Meta-Analysis Package for R. A comprehensive collection of functions for\nconducting meta-analyses in R. The package includes functions to\ncalculate various effect sizes or outcome measures, fit equal-, fixed-,\nrandom-, and mixed-effects models to such data, carry out moderator and\nmeta-regression analyses, and create various types of meta-analytical\nplots (e.g., forest, funnel, radial, L'Abbe, Baujat, bubble, and GOSH\nplots). For meta-analyses of binomial and person-time data, the package\nalso provides functions that implement specialized methods, including\nthe Mantel-Haenszel method, Peto's method, and a variety of suitable\ngeneralized linear (mixed-effects) models (i.e., mixed-effects logistic\nand Poisson regression models). Finally, the package provides\nfunctionality for fitting meta-analytic multivariate/multilevel models\nthat account for non-independent sampling errors and/or true effects\n(e.g., due to the inclusion of multiple treatment studies, multiple\nendpoints, or other forms of clustering). Network meta-analyses and\nmeta-analyses accounting for known correlation structures (e.g., due to\nphylogenetic relatedness) can also be conducted. An introduction to the\npackage can be found in Viechtbauer (2010) <doi:10.18637/jss.v036.i03>.",
            "name": "r-metafor"
        },
        {
            "description": "Meta-Analysis of Significance Values. The canonical way to perform meta-\nanalysis involves using effect sizes. When they are not available this\npackage provides a number of methods for meta-analysis of significance\nvalues including the methods of Edgington, Fisher, Lancaster, Stouffer,\nTippett, and Wilkinson; a number of data-sets to replicate published\nresults; and a routine for graphical display.",
            "name": "r-metap"
        },
        {
            "description": "Meta-Analyses on P-Values of Differential Analyses. Implements a variety\nof methods for combining p-values in differential analyses of genome-\nscale datasets. Functions can combine p-values across different tests in\nthe same analysis (e.g., genomic windows in ChIP-seq, exons in RNA-seq)\nor for corresponding tests across separate analyses (e.g., replicated\ncomparisons, effect of different treatment conditions). Support is\nprovided for handling log-transformed input p-values, missing values and\nweighting where appropriate.",
            "name": "r-metapod"
        },
        {
            "description": "Handle Illumina methylation data. This package provides classes for\nholding and manipulating Illumina methylation data. Based on eSet, it\ncan contain MIAME information, sample information, feature information,\nand multiple matrices of data. An \"intelligent\" import function,\nmethylumiR can read the Illumina text files and create a MethyLumiSet.\nmethylumIDAT can directly read raw IDAT files from HumanMethylation27\nand HumanMethylation450 microarrays. Normalization, background\ncorrection, and quality control features for GoldenGate, Infinium, and\nInfinium HD arrays are also included.",
            "name": "r-methylumi"
        },
        {
            "description": "Mixed GAM Computation Vehicle with Automatic Smoothness Estimation.\nGeneralized additive (mixed) models, some of their extensions and other\ngeneralized ridge regression with multiple smoothing parameter\nestimation by (Restricted) Marginal Likelihood, Generalized Cross\nValidation and similar, or using iterated nested Laplace approximation\nfor fully Bayesian inference. See Wood (2017)\n<doi:10.1201/9781315370279> for an overview. Includes a gam() function,\na wide variety of smoothers, 'JAGS' support and distributions beyond the\nexponential family.",
            "name": "r-mgcv"
        },
        {
            "description": "API Client for the MG-RAST Server of the US DOE KBase. Convenience\nFunctions for R Language Access to the v.1 API of the MG-RAST Metagenome\nAnnotation Server, part of the US Department of Energy (DOE) Systems\nBiology Knowledge Base (KBase).",
            "name": "r-mgraster"
        },
        {
            "description": "Multivariate Imputation by Chained Equations. Multiple imputation using\nFully Conditional Specification (FCS) implemented by the MICE algorithm\nas described in Van Buuren and Groothuis-Oudshoorn (2011)\n<doi:10.18637/jss.v045.i03>. Each variable has its own imputation model.\nBuilt-in imputation models are provided for continuous data (predictive\nmean matching, normal), binary data (logistic regression), unordered\ncategorical data (polytomous logistic regression) and ordered\ncategorical data (proportional odds). MICE can also impute continuous\ntwo-level data (normal model, pan, second-level variables). Passive\nimputation can be used to maintain consistency between variables.\nVarious diagnostic plots are available to inspect the quality of the\nimputations.",
            "name": "r-mice"
        },
        {
            "description": "Accurate Timing Functions. Provides infrastructure to accurately measure\nand compare the execution time of R expressions.",
            "name": "r-microbenchmark"
        },
        {
            "description": "Map Filenames to MIME Types. Guesses the MIME type from a filename\nextension using the data derived from /etc/mime.types in UNIX-type\nsystems.",
            "name": "r-mime"
        },
        {
            "description": "Analyze Illumina Infinium DNA methylation arrays. Tools to analyze &\nvisualize Illumina Infinium methylation arrays.",
            "name": "r-minfi"
        },
        {
            "description": "Shiny UI Widgets for Small Screens. Provides UI widget and layout\nfunctions for writing Shiny apps that work well on small screens.",
            "name": "r-miniui"
        },
        {
            "description": "Derivative-free optimization algorithms by quadratic approximation.\nDerivative-free optimization by quadratic approximation based on an\ninterface to Fortran implementations by M. J. D. Powell.",
            "name": "r-minqa"
        },
        {
            "description": "Miscellaneous 3D Plots. A collection of miscellaneous 3d plots,\nincluding isosurfaces.",
            "name": "r-misc3d"
        },
        {
            "description": "Analysing Illumina HumanMethylation BeadChip Data. Normalisation,\ntesting for differential variability and differential methylation and\ngene set testing for data from Illumina's Infinium HumanMethylation\narrays. The normalisation procedure is subset-quantile within-array\nnormalisation (SWAN), which allows Infinium I and II type probes on a\nsingle array to be normalised together. The test for differential\nvariability is based on an empirical Bayes version of Levene's test.\nDifferential methylation testing is performed using RUV, which can\nadjust for systematic errors of unknown origin in high-dimensional data\nby using negative control probes. Gene ontology analysis is performed by\ntaking into account the number of probes per gene on the array, as well\nas taking into account multi-gene associated probes.",
            "name": "r-missmethyl"
        },
        {
            "description": "Tools for Multiple Imputation in Multilevel Modeling. Provides tools for\nmultiple imputation of missing data in multilevel modeling. Includes a\nuser-friendly interface to the packages 'pan' and 'jomo', and several\nfunctions for visualization, data management and the analysis of\nmultiply imputed data sets.",
            "name": "r-mitml"
        },
        {
            "description": "Tools for Multiple Imputation of Missing Data. Tools to perform analyses\nand combine results from multiple-imputation datasets.",
            "name": "r-mitools"
        },
        {
            "description": "Tools for Analyzing Finite Mixture Models. Analyzes finite mixture\nmodels for various parametric and semiparametric settings. This includes\nmixtures of parametric distributions (normal, multivariate normal,\nmultinomial, gamma), various Reliability Mixture Models (RMMs),\nmixtures-of-regressions settings (linear regression, logistic\nregression, Poisson regression, linear regression with changepoints,\npredictor-dependent mixing proportions, random effects regressions,\nhierarchical mixtures-of-experts), and tools for selecting the number of\ncomponents (bootstrapping the likelihood ratio test statistic,\nmixturegrams, and model selection criteria). Bayesian estimation of\nmixtures-of-linear-regressions models is available as well as a novel\ndata depth method for obtaining credible bands. This package is based\nupon work supported by the National Science Foundation under Grant No.\nSES-0518772.",
            "name": "r-mixtools"
        },
        {
            "description": "Machine Learning Benchmark Problems. A collection of artificial and\nreal-world machine learning benchmark problems, including, e.g., several\ndata sets from the UCI repository.",
            "name": "r-mlbench"
        },
        {
            "description": "Uniform interfaces to R machine learning procedures for data in\nBioconductor containers. This package provides uniform interfaces to\nmachine learning code for data in R and Bioconductor containers.",
            "name": "r-mlinterfaces"
        },
        {
            "description": "Machine Learning in R. Interface to a large number of classification and\nregression techniques, including machine-readable parameter\ndescriptions. There is also an experimental extension for survival\nanalysis, clustering and general, example-specific cost-sensitive\nlearning. Generic resampling, including cross-validation, bootstrapping\nand subsampling. Hyperparameter tuning with modern optimization\ntechniques, for single- and multi-objective problems. Filter and wrapper\nmethods for feature selection. Extension of basic learners with\nadditional operations common in machine learning, also allowing for easy\nnested resampling. Most operations can be parallelized.",
            "name": "r-mlr"
        },
        {
            "description": "Bayesian Optimization and Model-Based Optimization of Expensive Black-\nBox Functions. Flexible and comprehensive R toolbox for model-based\noptimization ('MBO'), also known as Bayesian optimization. It is\ndesigned for both single- and multi-objective optimization with mixed\ncontinuous, categorical and conditional parameters. The machine learning\ntoolbox 'mlr' provide dozens of regression learners to model the\nperformance of the target algorithm with respect to the parameter\nsettings. It provides many different infill criteria to guide the search\nprocess. Additional features include multi-point batch proposal,\nparallel execution as well as visualization and sophisticated logging\nmechanisms, which is especially useful for teaching and understanding of\nalgorithm behavior. 'mlrMBO' is implemented in a modular fashion, such\nthat single components can be easily replaced or adapted by the user for\nspecific use cases.",
            "name": "r-mlrmbo"
        },
        {
            "description": "Convert Dates to MMWR Day, Week, and Year. The first day of any MMWR\nweek is Sunday. MMWR week numbering is sequential beginning with 1 and\nincrementing with each week to a maximum of 52 or 53. MMWR week #1 of an\nMMWR year is the first week of the year that has at least four days in\nthe calendar year. This package provides functionality to convert Dates\nto MMWR day, week, and year and the reverse.",
            "name": "r-mmwrweek"
        },
        {
            "description": "The Multivariate Normal and t Distributions, and Their Truncated\nVersions. Functions are provided for computing the density and the\ndistribution function of multivariate normal and \"t\" random variables,\nand for generating random vectors sampled from these distributions.\nProbabilities are computed via non-Monte Carlo methods; different\nroutines are used in the case d=1, d=2, d>2, if d denotes the number of\ndimensions.",
            "name": "r-mnormt"
        },
        {
            "description": "Mocking Library for R. The two main functionalities of this package are\ncreating mock objects (functions) and selectively intercepting calls to\na given function that originate in some other function. It can be used\nwith any testing framework available for R. Mock objects can be injected\nwith either this package's own stub() function or a similar with_mock()\nfacility present in the 'testthat' package.",
            "name": "r-mockery"
        },
        {
            "description": "Rapid Calculation of Model Metrics. Collection of metrics for evaluating\nmodels written in C++ using 'Rcpp'. Popular metrics include area under\nthe curve, log loss, root mean square error, etc.",
            "name": "r-modelmetrics"
        },
        {
            "description": "Modelling Functions that Work with the Pipe. Functions for modelling\nthat help you seamlessly integrate modelling into a pipeline of data\nmanipulation and visualisation.",
            "name": "r-modelr"
        },
        {
            "description": "Tools and Classes for Statistical Models. A collection of tools to deal\nwith statistical models. The functionality is experimental and the user\ninterface is likely to change in the future. The documentation is rather\nterse, but packages `coin' and `party' have some working examples.\nHowever, if you find the implemented ideas interesting we would be very\ninterested in a discussion of this proposal. Contributions are more than\nwelcome!",
            "name": "r-modeltools"
        },
        {
            "description": "Multivariate Projection Methods. Exploratory graphical analysis of\nmultivariate data, specifically gene expression data with different\nprojection methods: principal component analysis, correspondence\nanalysis, spectral map analysis.",
            "name": "r-mpm"
        },
        {
            "description": "Two Sample Mendelian Randomization using Robust Adjusted Profile Score.\nMendelian randomization is a method of identifying and estimating a\nconfounded causal effect using genetic instrumental variables. This\npackages implements methods for two-sample Mendelian randomization with\nsummary statistics by using Robust Adjusted Profile Score (RAPS).\nReferences: Qingyuan Zhao, Jingshu Wang, Jack Bowden, Dylan S. Small.\nStatistical inference in two-sample summary-data Mendelian randomization\nusing robust adjusted profile score. <arXiv:1801.09652>.",
            "name": "r-mr-raps"
        },
        {
            "description": "Data sources for genetic instruments to be used in MR. Datasets of\neQTLs, GWAS catalogs, etc.",
            "name": "r-mrinstruments"
        },
        {
            "description": "Mendelian Randomization Analysis Using Mixture Models (MRMix). This\npackage gives robust estimation of causal effects by conducting\nMendelian randomization analysis using a mixture model approach.",
            "name": "r-mrmix"
        },
        {
            "description": "Performs the Mendelian Randomization Pleiotropy RESidual Sum and Outlier\n(MR-PRESSO) test. MR-PRESSO (Mendelian Randomization Pleiotropy RESidual\nSum and Outlier) is a framework that allows for the evaluation of\npleiotropy in multi-instrument Mendelian Randomization utilizing genome-\nwide summary association statistics.",
            "name": "r-mrpresso"
        },
        {
            "description": "Core Utils for Mass Spectrometry Data. MsCoreUtils defines low-level\nfunctions for mass spectrometry data and is independent of any high-\nlevel data structures. These functions include mass spectra processing\nfunctions (noise estimation, smoothing, binning), quantitative\naggregation functions (median polish, robust summarisation, ...),\nmissing data imputation, data normalisation (quantiles, vsn, ...) as\nwell as misc helper functions, that are used across high-level data\nstructure within the R for Mass Spectrometry packages.",
            "name": "r-mscoreutils"
        },
        {
            "description": "Base Functions and Classes for Mass Spectrometry and Proteomics. MSnbase\nprovides infrastructure for manipulation, processing and visualisation\nof mass spectrometry and proteomics data, ranging from raw to\nquantitative and annotated data.",
            "name": "r-msnbase"
        },
        {
            "description": "Simultaneous Inference in General Parametric Models. Simultaneous tests\nand confidence intervals for general linear hypotheses in parametric\nmodels, including linear, generalized linear, linear mixed effects, and\nsurvival models. The package includes demos reproducing analyzes\npresented in the book \"Multiple Comparisons Using R\" (Bretz, Hothorn,\nWestfall, 2010, CRC Press).",
            "name": "r-multcomp"
        },
        {
            "description": "Visualizations of Paired Comparisons. Convert a logical vector or a\nvector of p-values or a correlation, difference, or distance matrix into\na display identifying the pairs for which the differences were not\nsignificantly different. Designed for use in conjunction with the output\nof functions like TukeyHSD, dist{stats}, simint, simtest, csimint,\ncsimtest{multcomp}, friedmanmc, kruskalmc{pgirmess}.",
            "name": "r-multcompview"
        },
        {
            "description": "Permutations of multisets in cool-lex order. A set of tools to permute\nmultisets without loops or hash tables and to generate integer\npartitions. The permutation functions are based on C code from Aaron\nWilliams. Cool-lex order is similar to colexicographical order. The\nalgorithm is described in Williams, A. (2009)\n<DOI:10.1145/1496770.1496877> Loopless Generation of Multiset\nPermutations by Prefix Shifts. Symposium on Discrete Algorithms, New\nYork, United States. The permutation code is distributed without\nrestrictions. The code for stable and efficient computation of\nmultinomial coefficients comes from Dave Barber. The code can be\ndownload from <http://tamivox.org/dave/multinomial/code.html> and is\ndistributed without conditions. The package also generates the integer\npartitions of a positive, non-zero integer n. The C++ code for this is\nbased on Python code from Jerome Kelleher which can be found here\n<https://jeromekelleher.net/tag/integer-partitions.html>. The C++ code\nand Python code are distributed without conditions.",
            "name": "r-multicool"
        },
        {
            "description": "Spectral Analysis Tools using the Multitaper Method. Implements\nmultitaper spectral analysis using discrete prolate spheroidal sequences\n(Slepians) and sine tapers. It includes an adaptive weighted multitaper\nspectral estimate, a coherence estimate, Thomson's Harmonic F-test, and\ncomplex demodulation. The Slepians sequences are generated efficiently\nusing a tridiagonal matrix solution, and jackknifed confidence intervals\nare available for most estimates. This package is an implementation of\nthe method described in D.J. Thomson (1982) \"Spectrum estimation and\nharmonic analysis\" <doi:10.1109/PROC.1982.12433>.",
            "name": "r-multitaper"
        },
        {
            "description": "Resampling-based multiple hypothesis testing. Non-parametric bootstrap\nand permutation resampling-based multiple testing procedures (including\nempirical Bayes methods) for controlling the family-wise error rate\n(FWER), generalized family-wise error rate (gFWER), tail probability of\nthe proportion of false positives (TPPFP), and false discovery rate\n(FDR). Several choices of bootstrap-based null distribution are\nimplemented (centered, centered and scaled, quantile- transformed).\nSingle-step and step-wise methods are available. Tests based on a\nvariety of t- and F-statistics (including t-statistics based on\nregression parameters from linear and survival models as well as those\nbased on correlation parameters) are included. When probing hypotheses\nwith t-statistics, users may also select a potentially faster null\ndistribution which is multivariate normal with mean zero and variance\ncovariance matrix derived from the vector influence function. Results\nare reported in terms of adjusted p-values, confidence regions and test\nstatistic cutoffs. The procedures are directly applicable to identifying\ndifferentially expressed genes in DNA microarray experiments.",
            "name": "r-multtest"
        },
        {
            "description": "Utilities for Using Munsell Colours. Provides easy access to, and\nmanipulation of, the Munsell colours. Provides a mapping between\nMunsell's original notation (e.g. \"5R 5/10\") and hexadecimal strings\nsuitable for use directly in R graphics. Also provides utilities to\nexplore slices through the Munsell colour tree, to transform Munsell\ncolours and display colour palettes.",
            "name": "r-munsell"
        },
        {
            "description": "Unified Multiple Testing Procedures. Designed to ease the application\nand comparison of multiple hypothesis testing procedures for FWER,\ngFWER, FDR and FDX. Methods are standardized and usable by the\naccompanying 'mutossGUI'.",
            "name": "r-mutoss"
        },
        {
            "description": "Multivariate Normal and t Distributions. Computes multivariate normal\nand t probabilities, quantiles, random deviates and densities.",
            "name": "r-mvtnorm"
        },
        {
            "description": "An mzIdentML parser for R. A parser for mzIdentML files implemented\nusing the XML package. The parser tries to be general and able to handle\nall types of mzIdentML files with the drawback of having less 'pretty'\noutput than a vendor specific parser. Please contact the maintainer with\nany problems and supply an mzIdentML file so the problems can be fixed\nquickly.",
            "name": "r-mzid"
        },
        {
            "description": "parser for netCDF, mzXML, mzData and mzML and mzIdentML files (mass\nspectrometry data). mzR provides a unified API to the common file\nformats and parsers available for mass spectrometry data. It comes with\na wrapper for the ISB random access parser for mass spectrometry mzXML,\nmzData and mzML files. The package contains the original code written by\nthe ISB, and a subset of the proteowizard library for mzML and\nmzIdentML. The netCDF reading code has previously been used in XCMS.",
            "name": "r-mzr"
        },
        {
            "description": "Nondetects and Data Analysis for Environmental Data. Contains methods\ndescribed by Dennis Helsel in his book \"Nondetects And Data Analysis:\nStatistics for Censored Environmental Data\".",
            "name": "r-nada"
        },
        {
            "description": "Nanosecond-Resolution Time Support for R. Full 64-bit resolution date\nand time functionality with; nanosecond granularity is provided, with\neasy transition to and from; the standard 'POSIXct' type. Three\nadditional classes offer interval,; period and duration functionality\nfor nanosecond-resolution timestamps.",
            "name": "r-nanotime"
        },
        {
            "description": "Retrieve and build NBCI taxonomic data. Making NCBI taxonomic data\nlocally available and searchable as an R object.",
            "name": "r-ncbit"
        },
        {
            "description": "Interface to Unidata netCDF (Version 4 or Earlier) Format Data Files.\nProvides a high-level R interface to data files written using Unidata's\nnetCDF library (version 4 or earlier), which are binary data files that\nare portable across platforms and include metadata information in\naddition to the data sets. Using this package, netCDF files (either\nversion 4 or \"classic\" version 3) can be opened and data sets read in\neasily. It is also easy to create new netCDF dimensions, variables, and\nfiles, in either version 3 or 4 format, and manipulate existing netCDF\nfiles. This package replaces the former ncdf package, which only worked\nwith netcdf version 3 files. For various reasons the names of the\nfunctions have had to be changed from the names in the ncdf package. The\nold ncdf package is still available at the URL given below, if you need\nto have backward compatibility. It should be possible to have both the\nncdf and ncdf4 packages installed simultaneously without a problem.\nHowever, the ncdf package does not provide an interface for netcdf\nversion 4 files.",
            "name": "r-ncdf4"
        },
        {
            "description": "Classes for Relational Data. Tools to create and modify network objects.\nThe network class can represent a range of relational data types, and\nsupports arbitrary vertex/edge/graph attributes.",
            "name": "r-network"
        },
        {
            "description": "D3 JavaScript Network Graphs from R. Creates 'D3' 'JavaScript' network,\ntree, dendrogram, and Sankey graphs from 'R'.",
            "name": "r-networkd3"
        },
        {
            "description": "Training of Neural Networks. Training of neural networks using\nbackpropagation, resilient backpropagation with (Riedmiller, 1994) or\nwithout weight backtracking (Riedmiller and Braun, 1993) or the modified\nglobally convergent version by Anastasiadis et al. (2005). The package\nallows flexible settings through custom-choice of error and activation\nfunction. Furthermore, the calculation of generalized weights (Intrator\nO & Intrator N, 1993) is implemented.",
            "name": "r-neuralnet"
        },
        {
            "description": "Parallel Analysis and Other Non Graphical Solutions to the Cattell Scree\nTest. Indices, heuristics and strategies to help determine the number of\nfactors/components to retain: 1. Acceleration factor (af with or without\nParallel Analysis); 2. Optimal Coordinates (noc with or without Parallel\nAnalysis); 3. Parallel analysis (components, factors and bootstrap); 4.\nlambda > mean(lambda) (Kaiser, CFA and related); 5. Cattell-Nelson-\nGorsuch (CNG); 6. Zoski and Jurs multiple regression (b, t and p); 7.\nZoski and Jurs standard error of the regression coeffcient (sescree); 8.\nNelson R2; 9. Bartlett khi-2; 10. Anderson khi-2; 11. Lawley khi-2 and\n12. Bentler-Yuan khi-2.",
            "name": "r-nfactors"
        },
        {
            "description": "MCMC, Particle Filtering, and Programmable Hierarchical Modeling. A\nsystem for writing hierarchical statistical models largely compatible\nwith 'BUGS' and 'JAGS', writing nimbleFunctions to operate models and do\nbasic R-style math, and compiling both models and nimbleFunctions via\ncustom-generated C++. 'NIMBLE' includes default methods for MCMC, Monte\nCarlo Expectation Maximization, and some other tools. The nimbleFunction\nsystem makes it easy to do things like implement new MCMC samplers from\nR, customize the assignment of samplers to different parts of a model\nfrom R, and compile the new samplers automatically via C++ alongside the\nsamplers 'NIMBLE' provides. 'NIMBLE' extends the 'BUGS'/'JAGS' language\nby making it extensible: New distributions and functions can be added,\nincluding as calls to external compiled code. Although most people think\nof MCMC as the main goal of the 'BUGS'/'JAGS' language for writing\nmodels, one can use 'NIMBLE' for writing arbitrary other kinds of model-\ngeneric algorithms as well. A full User Manual is available at\n<https://r-nimble.org>.",
            "name": "r-nimble"
        },
        {
            "description": "Solve Systems of Nonlinear Equations. Solve a system of nonlinear\nequations using a Broyden or a Newton method with a choice of global\nstrategies such as line search and trust region. There are options for\nusing a numerical or user supplied Jacobian, for specifying a banded\nnumerical Jacobian and for allowing a singular or ill-conditioned\nJacobian.",
            "name": "r-nleqslv"
        },
        {
            "description": "Linear and Nonlinear Mixed Effects Models. Fit and compare Gaussian\nlinear and nonlinear mixed-effects models.",
            "name": "r-nlme"
        },
        {
            "description": "R Interface to NLopt. Solve optimization problems using an R interface\nto NLopt. NLopt is a free/open-source library for nonlinear\noptimization, providing a common interface for a number of different\nfree optimization routines available online as well as original\nimplementations of various other algorithms. See\n<https://nlopt.readthedocs.io/en/latest/NLopt_Algorithms/> for more\ninformation on the available algorithms. Building from included sources\nrequires 'CMake'. On Linux and 'macOS', if a suitable system build of\nNLopt (2.7.0 or later) is found, it is used; otherwise, it is built from\nincluded sources via 'CMake'. On Windows, NLopt is obtained through\n'rwinlib' for 'R <= 4.1.x' or grabbed from the 'Rtools42 toolchain' for\n'R >= 4.2.0'.",
            "name": "r-nloptr"
        },
        {
            "description": "Algorithms and Framework for Nonnegative Matrix Factorization (NMF).\nProvides a framework to perform Non-negative Matrix Factorization (NMF).\nThe package implements a set of already published algorithms and seeding\nmethods, and provides a framework to test, develop and plug new/custom\nalgorithms. Most of the built-in algorithms have been optimized in C++,\nand the main interface function provides an easy way of performing\nparallel computations on multicore machines.",
            "name": "r-nmf"
        },
        {
            "description": "Numerical Methods and Optimization in Finance. Functions, examples and\ndata from the book \"Numerical Methods and Optimization in Finance\" by M.\nGilli, D. Maringer and E. Schumann (2011), ISBN 978-0123756626. The\npackage provides implementations of several optimisation heuristics,\nsuch as Differential Evolution, Genetic Algorithms and Threshold\nAccepting. There are also functions for the valuation of financial\ninstruments, such as bonds and options, and functions that help with\nstochastic simulations.",
            "name": "r-nmof"
        },
        {
            "description": "Feed-Forward Neural Networks and Multinomial Log-Linear Models. Software\nfor feed-forward neural networks with a single hidden layer, and for\nmultinomial log-linear models.",
            "name": "r-nnet"
        },
        {
            "description": "The Lawson-Hanson algorithm for non-negative least squares (NNLS). An R\ninterface to the Lawson-Hanson implementation of an algorithm for non-\nnegative least squares (NNLS). Also allows the combination of non-\nnegative and non-positive constraints.",
            "name": "r-nnls"
        },
        {
            "description": "Tests of Non-Nested Models. Testing non-nested models via theory\nsupplied by Vuong (1989) <doi:10.2307/1912557>. Includes tests of model\ndistinguishability and of model fit that can be applied to both nested\nand non-nested models. Also includes functionality to obtain confidence\nintervals associated with AIC and BIC. This material is partially based\non work supported by the National Science Foundation under Grant Number\nSES-1061334.",
            "name": "r-nonnest2"
        },
        {
            "description": "Normal aka Gaussian (1-d) Mixture Models (S3 Classes and Methods). One\ndimensional Normal Mixture Models Classes, for, e.g., density estimation\nor clustering algorithms research and teaching; providing the widely\nused Marron-Wand densities. Efficient random number generation and\ngraphics; now fitting to data by ML (Maximum Likelihood) or EM\nestimation.",
            "name": "r-nor1mix"
        },
        {
            "description": "Tests for Normality. Five omnibus tests for testing the composite\nhypothesis of normality.",
            "name": "r-nortest"
        },
        {
            "description": "Nonparametric Kernel Smoothing Methods for Mixed Data Types. This\npackage provides a variety of nonparametric (and semiparametric) kernel\nmethods that seamlessly handle a mix of continuous, unordered, and\nordered factor data types. We would like to gratefully acknowledge\nsupport from the Natural Sciences and Engineering Research Council of\nCanada (NSERC:www.nserc.ca), the Social Sciences and Humanities Research\nCouncil of Canada (SSHRC:www.sshrc.ca), and the Shared Hierarchical\nAcademic Research Computing Network (SHARCNET:www.sharcnet.ca).",
            "name": "r-np"
        },
        {
            "description": "Nonparametric Survival Analysis. Non-parametric survival analysis of\nexact and interval-censored observations. The methods implemented are\ndeveloped by Wang (2007) <doi:10.1111/j.1467-9868.2007.00583.x>, Wang\n(2008) <doi:10.1016/j.csda.2007.10.018>, Wang and Taylor (2013)\n<doi:10.1007/s11222-012-9341-9> and Wang and Fani (2018)\n<doi:10.1007/s11222-017-9724-z>.",
            "name": "r-npsurv"
        },
        {
            "description": "Accurate Numerical Derivatives. Methods for calculating (usually)\naccurate numerical first and second order derivatives. Accurate\ncalculations are done using 'Richardson\"s' extrapolation or, when\napplicable, a complex step derivative is available. A simple difference\nmethod is also provided. Simple difference is (usually) less accurate\nbut is much quicker than 'Richardson\"s' extrapolation and provides a\nuseful cross-check. Methods are provided for real scalar and vector\nvalued functions.",
            "name": "r-numderiv"
        },
        {
            "description": "Classes for high-throughput arrays supported by oligo and crlmm. This\npackage contains class definitions, validity checks, and initialization\nmethods for classes used by the oligo and crlmm packages.",
            "name": "r-oligoclasses"
        },
        {
            "description": "Toolkit for Encryption, Signatures and Certificates Based on OpenSSL.\nBindings to OpenSSL libssl and libcrypto, plus custom SSH pubkey\nparsers. Supports RSA, DSA and EC curves P-256, P-384 and P-521.\nCryptographic signatures can either be created and verified manually or\nvia x509 certificates. AES can be used in cbc, ctr or gcm mode for\nsymmetric encryption; RSA for asymmetric (public key) encryption or EC\nfor Diffie Hellman. High-level envelope functions combine RSA and AES\nfor encrypting arbitrary sized data. Other utilities include key\ngenerators, hash functions (md5, sha1, sha256, etc), base64 encoder, a\nsecure random number generator, and 'bignum' math methods for manually\nperforming crypto calculations on large multibyte integers.",
            "name": "r-openssl"
        },
        {
            "description": "Read, Write and Edit xlsx Files. Simplifies the creation of Excel .xlsx\nfiles by providing a high level interface to writing, styling and\nediting worksheets. Through the use of 'Rcpp', read/write times are\ncomparable to the 'xlsx' and 'XLConnect' packages with the added benefit\nof removing the dependency on Java.",
            "name": "r-openxlsx"
        },
        {
            "description": "Parallel Version of the L-BFGS-B Optimization Method. Provides a\nparallel version of the L-BFGS-B method of optim(). The main function of\nthe package is optimParallel(), which has the same usage and output as\noptim(). Using optimParallel() can significantly reduce the optimization\ntime.",
            "name": "r-optimparallel"
        },
        {
            "description": "Expanded Replacement and Extension of the 'optim' Function. Provides a\nreplacement and extension of the optim() function to call to several\nfunction minimization codes in R in a single statement. These methods\nhandle smooth, possibly box constrained functions of several or many\nparameters. Note that function 'optimr()' was prepared to simplify the\nincorporation of minimization codes going forward. Also implements some\nutility codes and some extra solvers, including safeguarded Newton\nmethods. Many methods previously separate are now included here. This is\nthe version for CRAN.",
            "name": "r-optimx"
        },
        {
            "description": "Command Line Option Parser. A command line parser inspired by Python's\n'optparse' library to be used with Rscript to write \"#!\" shebang scripts\nthat accept short and long flag/options",
            "name": "r-optparse"
        },
        {
            "description": "Regression Models for Ordinal Data. Implementation of cumulative link\n(mixed) models also known as ordered regression models, proportional\nodds models, proportional hazards models for grouped survival times and\nordered logit/probit/... models. Estimation is via maximum likelihood\nand mixed models are fitted with the Laplace approximation and adaptive\nGauss-Hermite quadrature. Multiple random effect terms are allowed and\nthey may be nested, crossed or partially nested/crossed. Restrictions of\nsymmetry and equidistance can be imposed on the thresholds (cut-\npoints/intercepts). Standard model methods are available (summary,\nanova, drop-methods, step, confint, predict etc.) in addition to profile\nmethods and slice methods for visualizing the likelihood function and\nchecking convergence.",
            "name": "r-ordinal"
        },
        {
            "description": "Genome wide annotation for Human. Genome wide annotation for Human,\nprimarily based on mapping using Entrez Gene identifiers.",
            "name": "r-org-hs-eg-db"
        },
        {
            "description": "Software to enable the smooth interfacing of different database\npackages. The package enables a simple unified interface to several\nannotation packages each of which has its own schema by taking advantage\nof the fact that each of these packages implements a select methods.",
            "name": "r-organismdbi"
        },
        {
            "description": "Quadratic Programming Solver using the 'OSQP' Library. Provides bindings\nto the 'OSQP' solver. The 'OSQP' solver is a numerical optimization\npackage or solving convex quadratic programs written in 'C' and based on\nthe alternating direction method of multipliers. See <arXiv:1711.08013>\nfor details.",
            "name": "r-osqp"
        },
        {
            "description": "A Dependency Management System for Projects and their R Package\nDependencies. Manage the R packages your project depends on in an\nisolated, portable, and reproducible way.",
            "name": "r-packrat"
        },
        {
            "description": "Package Management Tool. Tools to more conveniently perform tasks\nassociated with add-on packages. pacman conveniently wraps library and\npackage related functions and names them in an intuitive and consistent\nfashion. It seeks to combine functionality from lower level functions\nwhich can speed up workflow.",
            "name": "r-pacman"
        },
        {
            "description": "Paleontological and Phylogenetic Analyses of Evolution. Provides tools\nfor transforming, a posteriori time-scaling, and modifying phylogenies\ncontaining extinct (i.e. fossil) lineages",
            "name": "r-paleotree"
        },
        {
            "description": "Pam: Prediction Analysis for Microarrays Some functions for sample\nclassification in microarrays.",
            "name": "r-pamr"
        },
        {
            "description": "Multiple imputation for multivariate panel or clustered data. It\nprovides functions and examples for maximum likelihood estimation for\ngeneralized linear mixed models and Gibbs sampler for multivariate\nlinear mixed models with incomplete data, as described in Schafer JL\n(1997) \"Imputation of missing covariates under a multivariate linear\nmixed model\". Technical report 97-04, Dept. of Statistics, The\nPennsylvania State University.",
            "name": "r-pan"
        },
        {
            "description": "Enhancing the 'parallel' Package. Utility functions that enhance the\n'parallel' package and support the built-in parallel backends of the\n'future' package. For example, availableCores() gives the number of CPU\ncores available to your R process as given by the operating system,\n'cgroups' and Linux containers, R options, and environment variables,\nincluding those set by job schedulers on high-performance compute\nclusters. If none is set, it will fall back to parallel::detectCores().\nAnother example is makeClusterPSOCK(), which is backward compatible with\nparallel::makePSOCKcluster() while doing a better job in setting up\nremote cluster workers without the need for configuring the firewall to\ndo port-forwarding to your local computer.",
            "name": "r-parallelly"
        },
        {
            "description": "Unified Interface to Parallelization Back-Ends. Unified parallelization\nframework for multiple back-end, designed for internal package and\ninteractive usage. The main operation is a parallel \"map\" over lists.\nSupports local, multicore, mpi and BatchJobs mode. Allows \"tagging\" of\nthe parallel operation with a level name that can be later selected by\nthe user to switch on parallel execution for exactly this operation.",
            "name": "r-parallelmap"
        },
        {
            "description": "Helpers for Parameters in Black-Box Optimization, Tuning and Machine\nLearning. Functions for parameter descriptions and operations in black-\nbox optimization, tuning and machine learning. Parameters can be\ndescribed (type, constraints, defaults, etc.), combined to parameter\nsets and can in general be programmed on. A useful OptPath object\n(archive) to log function evaluations is also provided.",
            "name": "r-paramhelpers"
        },
        {
            "description": "A Laboratory for Recursive Partytioning. A computational toolbox for\nrecursive partitioning. The core of the package is ctree(), an\nimplementation of conditional inference trees which embed tree-\nstructured regression models into a well defined theory of conditional\ninference procedures. This non-parametric class of regression trees is\napplicable to all kinds of regression problems, including nominal,\nordinal, numeric, censored as well as multivariate response variables\nand arbitrary measurement scales of the covariates. Based on conditional\ninference trees, cforest() provides an implementation of Breiman's\nrandom forests. The function mob() implements an algorithm for recursive\npartitioning based on parametric models (e.g. linear models, GLMs or\nsurvival regression) employing parameter instability tests for split\nselection. Extensible functionality for visualizing tree-structured\nregression models is available. The methods are described in Hothorn et\nal. (2006) <doi:10.1198/106186006X133933>, Zeileis et al. (2008)\n<doi:10.1198/106186008X319331> and Strobl et al. (2007)\n<doi:10.1186/1471-2105-8-25>.",
            "name": "r-party"
        },
        {
            "description": "A Toolkit for Recursive Partytioning. A toolkit with infrastructure for\nrepresenting, summarizing, and visualizing tree-structured regression\nand classification models. This unified infrastructure can be used for\nreading/coercing tree models from different sources ('rpart', 'RWeka',\n'PMML') yielding objects that share functionality for\nprint()/plot()/predict() methods. Furthermore, new and improved\nreimplementations of conditional inference trees (ctree()) and model-\nbased recursive partitioning (mob()) from the 'party' package are\nprovided based on the new infrastructure. A description of this package\nwas published by Hothorn and Zeileis (2015)\n<https://jmlr.org/papers/v16/hothorn15a.html>.",
            "name": "r-partykit"
        },
        {
            "description": "The Composer of Plots. The 'ggplot2' package provides a strong API for\nsequentially building up a plot, but does not concern itself with\ncomposition of multiple plots. 'patchwork' is a package that expands the\nAPI to allow for arbitrarily complex composition of plots by, among\nothers, providing mathematical operators for combining multiple plots.\nOther packages that try to address this need (but with a different\napproach) are 'gridExtra' and 'cowplot'.",
            "name": "r-patchwork"
        },
        {
            "description": "a tool set for pathway based data integration and visualization.\nPathview is a tool set for pathway based data integration and\nvisualization. It maps and renders a wide variety of biological data on\nrelevant pathway graphs. All users need is to supply their data and\nspecify the target pathway. Pathview automatically downloads the pathway\ngraph data, parses the data file, maps user data to the pathway, and\nrender pathway graph with the mapped data. In addition, Pathview also\nseamlessly integrates with pathway and gene set (enrichment) analysis\ntools for large-scale and fully automated analysis.",
            "name": "r-pathview"
        },
        {
            "description": "Adding Progress Bar to '*apply' Functions. A lightweight package that\nadds progress bar to vectorized R functions ('*apply'). The\nimplementation can easily be added to functions where showing the\nprogress is useful (e.g. bootstrap). The type and style of the progress\nbar (with percentages or remaining time) can be set through options.\nSupports several parallel processing backends.",
            "name": "r-pbapply"
        },
        {
            "description": "Programming with Big Data -- Interface to 'ZeroMQ'. 'ZeroMQ' is a well-\nknown library for high-performance asynchronous messaging in scalable,\ndistributed applications. This package provides high level R wrapper\nfunctions to easily utilize 'ZeroMQ'. We mainly focus on interactive\nclient/server programming frameworks. For convenience, a minimal\n'ZeroMQ' library (4.1.0 rc1) is shipped with 'pbdZMQ', which can be used\nif no system installation of 'ZeroMQ' is available. A few wrapper\nfunctions compatible with 'rzmq' are also provided.",
            "name": "r-pbdzmq"
        },
        {
            "description": "Vectorized Bivariate Normal CDF. Provides a vectorized R function for\ncalculating probabilities from a standard bivariate normal CDF.",
            "name": "r-pbivnorm"
        },
        {
            "description": "Parametric Bootstrap, Kenward-Roger and Satterthwaite Based Methods for\nTest in Mixed Models. Test in mixed effects models. Attention is on\nmixed effects models as implemented in the 'lme4' package. For linear\nmixed models, this package implements (1) a parametric bootstrap test,\n(2) a Kenward-Roger-typ modification of F-tests for linear mixed effects\nmodels and (3) a Satterthwaite-type modification of F-tests for linear\nmixed effects models. The package also implements a parametric bootstrap\ntest for generalized linear mixed models. The facilities of the package\nare documented in the paper by Halehoh and Hojsgaard, (2012,\n<doi:10.18637/jss.v059.i09>). Please see 'citation(\"pbkrtest\")' for\ncitation details.",
            "name": "r-pbkrtest"
        },
        {
            "description": "A collection of PCA methods. Provides Bayesian PCA, Probabilistic PCA,\nNipals PCA, Inverse Non-Linear PCA and the conventional SVD PCA. A\ncluster based method for missing value estimation is included for\ncomparison. BPCA, PPCA and NipalsPCA may be used to perform PCA on\nincomplete data as well as for accurate missing value estimation. A set\nof methods for printing and plotting the results is also provided. All\nPCA methods make use of the same data structure (pcaRes) to provide a\ncommon interface to the PCA results. Initiated at the Max-Planck\nInstitute for Molecular Plant Physiology, Golm, Germany.",
            "name": "r-pcamethods"
        },
        {
            "description": "Provides functions for robust PCA by projection pursuit. Provides\nfunctions for robust PCA by projection pursuit. The methods are\ndescribed in Croux et al. (2006) <doi:10.2139/ssrn.968376>, Croux et al.\n(2013) <doi:10.1080/00401706.2012.727746>, Todorov and Filzmoser (2013)\n<doi:10.1007/978-3-642-33042-1_31>.",
            "name": "r-pcapp"
        },
        {
            "description": "Population and Evolutionary Genetics Analysis System. Functions for\nreading, writing, plotting, analysing, and manipulating allelic and\nhaplotypic data, including from VCF files, and for the analysis of\npopulation nucleotide sequences and micro-satellites including\ncoalescent analyses, linkage disequilibrium, population structure (Fst,\nAmova) and equilibrium (HWE), haplotype networks, minimum spanning tree\nand network, and median-joining networks.",
            "name": "r-pegas"
        },
        {
            "description": "Functions for Generating Restricted Permutations of Data. A set of\nrestricted permutation designs for freely exchangeable, line transects\n(time series), and spatial grid designs plus permutation of blocks\n(groups of samples) is provided. 'permute' also allows split-plot\ndesigns, in which the whole-plots or split-plots or both can be freely-\nexchangeable or one of the restricted designs. The 'permute' package is\nmodelled after the permutation schemes of 'Canoco 3.1' (and later) by\nCajo ter Braak.",
            "name": "r-permute"
        },
        {
            "description": "A set of protein ID mappings for PFAM. A set of protein ID mappings for\nPFAM assembled using data from public repositories.",
            "name": "r-pfam-db"
        },
        {
            "description": "Phylogenetic Reconstruction and Analysis. Allows for estimation of\nphylogenetic trees and networks using Maximum Likelihood, Maximum\nParsimony, distance methods and Hadamard conjugation. Offers methods for\ntree comparison, model selection and visualization of phylogenetic\nnetworks as described in Schliep et al. (2017)\n<doi:10.1111/2041-210X.12760>.",
            "name": "r-phangorn"
        },
        {
            "description": "Computes informative enrichment and quality measures for ChIP-seq/DNase-\nseq/FAIRE-seq/MNase-seq data. This is a modified version of r-spp to be\nused in conjunction with the phantompeakqualtools package.",
            "name": "r-phantompeakqualtools"
        },
        {
            "description": "Pretty Heatmaps. Implementation of heatmaps that offers more control\nover dimensions and appearance.",
            "name": "r-pheatmap"
        },
        {
            "description": "Similarity and Distance Quantification Between Probability Functions.\nComputes 46 optimized distance and similarity measures for comparing\nprobability functions (Drost (2018) <doi:10.21105/joss.00765>). These\ncomparisons between probability functions have their foundations in a\nbroad range of scientific disciplines from mathematics to ecology. The\naim of this package is to provide a core framework for clustering,\nclassification, statistical inference, goodness-of-fit, non-parametric\nstatistics, information theory, and machine learning tasks that are\nbased on comparing univariate or multivariate probability functions.",
            "name": "r-philentropy"
        },
        {
            "description": "Base Package for Phylogenetic Structures and Comparative Data. Provides\na base S4 class for comparative methods, incorporating one or more trees\nand trait data.",
            "name": "r-phylobase"
        },
        {
            "description": "Handling and analysis of high-throughput microbiome census data.\nphyloseq provides a set of classes and tools to facilitate the import,\nstorage, analysis, and graphical display of microbiome census data.",
            "name": "r-phyloseq"
        },
        {
            "description": "Predict and explore the age of genes using phylostratigraphic methods",
            "name": "r-phylostratr"
        },
        {
            "description": "Phylogenetic Tools for Comparative Biology (and Other Things). A wide\nrange of functions for phylogenetic analysis. Functionality is\nconcentrated in phylogenetic comparative biology, but also includes\nnumerous methods for visualizing, manipulating, reading or writing, and\neven inferring phylogenetic trees and data. Included among the functions\nin phylogenetic comparative biology are various for ancestral state\nreconstruction, model-fitting, simulation of phylogenies and data, and\nmultivariate analysis. There are a broad range of plotting methods for\nphylogenies and comparative data which include, but are not restricted\nto, methods for mapping trait evolution on trees, for projecting trees\ninto phenotypic space or a geographic map, and for visualizing\ncorrelated speciation between trees. Finally, there are a number of\nfunctions for reading, writing, analyzing, inferring, simulating, and\nmanipulating phylogenetic trees and comparative data not covered by\nother packages. For instance, there are functions for randomly or non-\nrandomly attaching species or clades to a phylogeny, for estimating\nsupertrees or consensus phylogenies from a set, for simulating trees and\nphylogenetic data under a range of models, and for a wide variety of\nother manipulations and analyses that phylogenetic biologists might find\nuseful in their research.",
            "name": "r-phytools"
        },
        {
            "description": "R tools for integrating phylogenies and ecology. Functions for phylocom\nintegration, community analyses, null-models, traits and evolution.\nImplements numerous ecophylogenetic approaches including measures of\ncommunity phylogenetic and trait diversity, phylogenetic signal,\nestimation of trait values for unobserved taxa, null models for\ncommunity and phylogeny randomizations, and utility functions for data\ninput/output and phylogeny plotting. A full description of package\nfunctionality and methods are provided by Kembel et al. (2010)\n<doi:10.1093/bioinformatics/btq166>.",
            "name": "r-picante"
        },
        {
            "description": "Managing Larger Data on a GitHub Repository Because larger (> 50 MB)\ndata files cannot easily be committed to git, a different approach is\nrequired to manage data associated with an analysis in a GitHub\nrepository. This package provides a simple work-around by allowing\nlarger (up to 2 GB) data files to piggyback on a repository as assets\nattached to individual GitHub releases. These files are not handled by\ngit in any way, but instead are uploaded, downloaded, or edited directly\nby calls through the GitHub API. These data files can be versioned\nmanually by creating different releases. This approach works equally\nwell with public or private repositories. Data can be uploaded and\ndownloaded programmatically from scripts. No authentication is required\nto download data from public repositories.",
            "name": "r-piggyback"
        },
        {
            "description": "Coloured Formatting for Columns. Provides a 'pillar' generic designed\nfor formatting columns of data using the full range of colours provided\nby modern terminals.",
            "name": "r-pillar"
        },
        {
            "description": "Sequence ('FASTA'), Annotation ('GFF') and Variants ('VCF') for 17\nSamples of 'P. Infestans\" and 1 'P. Mirabilis'. Genomic data for the\nplant pathogen \"Phytophthora infestans.\" It includes a variant file\n('VCF'), a sequence file ('FASTA') and an annotation file ('GFF'). This\npackage is intended to be used as example data for packages that work\nwith genomic data.",
            "name": "r-pinfsc50"
        },
        {
            "description": "Bitmap Images (\"Pixel Maps\"). Functions for import, export, plotting and\nother manipulations of bitmapped images.",
            "name": "r-pixmap"
        },
        {
            "description": "Find Tools Needed to Build R Packages. Provides functions used to build\nR packages. Locates compilers needed to build R packages on various\nplatforms and ensures the PATH is configured appropriately so R can use\nthem.",
            "name": "r-pkgbuild"
        },
        {
            "description": "Cache 'CRAN'-Like Metadata and R Packages. Metadata and package cache\nfor CRAN-like repositories. This is a utility package to be used by\npackage management tools that want to take advantage of caching.",
            "name": "r-pkgcache"
        },
        {
            "description": "Private Configuration for 'R' Packages. Set configuration options on a\nper-package basis. Options set by a given package only apply to that\npackage, other packages are unaffected.",
            "name": "r-pkgconfig"
        },
        {
            "description": "Package Dependency Resolution and Downloads. Find recursive dependencies\nof 'R' packages from various sources. Solve the dependencies to obtain a\nconsistent set of packages to install. Download packages, and install\nthem. It supports packages on 'CRAN', 'Bioconductor' and other 'CRAN-\nlike' repositories, 'GitHub', package 'URLs', and local package trees\nand files. It caches metadata and package files via the 'pkgcache'\npackage, and performs all 'HTTP' requests, downloads, builds and\ninstallations in parallel. 'pkgdepends' is the workhorse of the 'pak'\npackage.",
            "name": "r-pkgdepends"
        },
        {
            "description": "Make Static HTML Documentation for a Package. Generate an attractive and\nuseful website from a source package. 'pkgdown' converts your\ndocumentation, vignettes, 'README', and more to 'HTML' making it easy to\nshare information about your package online.",
            "name": "r-pkgdown"
        },
        {
            "description": "Simulate Package Installation and Attach. Simulates the process of\ninstalling a package and then attaching it. This is a key part of the\n'devtools' package as it allows you to rapidly iterate while developing\na package.",
            "name": "r-pkgload"
        },
        {
            "description": "Development Utilities for R Packages. This package provides some low-\nlevel utilities to use for package development. It currently provides\nmanagers for multiple package specific options and registries, vignette,\nunit test and bibtex related utilities. It serves as a base package for\npackages like NMF, RcppOctave, doRNG, and as an incubator package for\nother general purposes utilities, that will eventually be packaged\nseparately. It is still under heavy development and changes in the\ninterface(s) are more than likely to happen.",
            "name": "r-pkgmaker"
        },
        {
            "description": "Public Key Infrastucture functions such as verifying certificates, RSA\nencription and signing which can be used to build PKI infrastructure and\nperform cryptographic tasks.",
            "name": "r-pki"
        },
        {
            "description": "Tabulate P.L. 94-171 Redistricting Data Summary Files Tools to process\nlegacy format summary redistricting data files produced by the United\nStates Census Bureau pursuant to P.L. 94-171. These files are generally\navailable earlier but are difficult to work with as-is.",
            "name": "r-pl94171"
        },
        {
            "description": "The 'plog' C++ Logging Library. A simple header-only logging library for\nC++. Add 'LinkingTo: plogr' to 'DESCRIPTION', and '#include <plogr.h>'\nin your C++ modules to use it.",
            "name": "r-plogr"
        },
        {
            "description": "Plotting Multi-Dimensional Data. Functions for viewing 2-D and 3-D data,\nincluding perspective plots, slice plots, surface plots, scatter plots,\netc. Includes data sets from oceanography.",
            "name": "r-plot3d"
        },
        {
            "description": "Create Interactive Web Graphics via 'plotly.js'. Create interactive web\ngraphics from 'ggplot2' graphs and/or a custom interface to the (MIT-\nlicensed) JavaScript library 'plotly.js' inspired by the grammar of\ngraphics.",
            "name": "r-plotly"
        },
        {
            "description": "Plot a Model's Residuals, Response, and Partial Dependence Plots. Plot\nmodel surfaces for a wide variety of models using partial dependence\nplots and other techniques. Also plot model residuals and other\ninformation on the model.",
            "name": "r-plotmo"
        },
        {
            "description": "Various Plotting Functions. Lots of plots, various labeling, axis and\ncolor scaling functions.",
            "name": "r-plotrix"
        },
        {
            "description": "Partial Least Squares and Principal Component Regression. Multivariate\nregression methods Partial Least Squares Regression (PLSR), Principal\nComponent Regression (PCR) and Canonical Powered Partial Least Squares\n(CPPLS).",
            "name": "r-pls"
        },
        {
            "description": "Tools for Splitting, Applying and Combining Data. A set of tools that\nsolves a common set of problems: you need to break a big problem down\ninto manageable pieces, operate on each piece and then put all the\npieces back together. For example, you might want to fit a model to each\nspatial location or time point in your study, summarise data by panels\nor collapse high-dimensional arrays to simpler summary statistics. The\ndevelopment of 'plyr' has been generously supported by 'Becton\nDickinson'.",
            "name": "r-plyr"
        },
        {
            "description": "Calculate Pairwise Multiple Comparisons of Mean Rank Sums. Note, that\nthe 'PMCMR' package is superset by the novel 'PMCMRplus' package. The\n'PMCMRplus' package contains all functions from 'PMCMR' and many more\nparametric and non-parametric multiple comparison procedures, one-\nfactorial trend tests, as well as improved method functions, such as\nprint, summary and plot. The 'PMCMR' package is no longer maintained,\nbut kept for compatibility of reverse depending packages for some time.",
            "name": "r-pmcmr"
        },
        {
            "description": "Calculate Pairwise Multiple Comparisons of Mean Rank Sums Extended. For\none-way layout experiments the one-way ANOVA can be performed as an\nomnibus test. All-pairs multiple comparisons tests (Tukey-Kramer test,\nScheffe test, LSD-test) and many-to-one tests (Dunnett test) for\nnormally distributed residuals and equal within variance are available.\nFurthermore, all-pairs tests (Games-Howell test, Tamhane's T2 test,\nDunnett T3 test, Ury-Wiggins-Hochberg test) and many-to-one (Tamhane-\nDunnett Test) for normally distributed residuals and heterogeneous\nvariances are provided. Van der Waerden's normal scores test for\nomnibus, all-pairs and many-to-one tests is provided for non-normally\ndistributed residuals and homogeneous variances. The Kruskal-Wallis, BWS\nand Anderson-Darling omnibus test and all-pairs tests (Nemenyi test,\nDunn test, Conover test, Dwass-Steele-Critchlow- Fligner test) as well\nas many-to-one (Nemenyi test, Dunn test, U-test) are given for the\nanalysis of variance by ranks. Non-parametric trend tests (Jonckheere\ntest, Cuzick test, Johnson-Mehrotra test, Spearman test) are included.\nIn addition, a Friedman-test for one-way ANOVA with repeated measures on\nranks (CRBD) and Skillings-Mack test for unbalanced CRBD is provided\nwith consequent all-pairs tests (Nemenyi test, Siegel test, Miller test,\nConover test, Exact test) and many-to-one tests (Nemenyi test, Demsar\ntest, Exact test). A trend can be tested with Pages's test. Durbin's\ntest for a two-way balanced incomplete block design (BIBD) is given in\nthis package as well as Gore's test for CRBD with multiple observations\nper cell is given. Outlier tests, Mandel's k- and h statistic as well as\nfunctions for Type I error and Power analysis as well as generic\nsummary, print and plot methods are provided.",
            "name": "r-pmcmrplus"
        },
        {
            "description": "Read and write PNG images. This package provides an easy and simple way\nto read, write and display bitmap images stored in the PNG format. It\ncan read and write both files and in-memory raw vectors.",
            "name": "r-png"
        },
        {
            "description": "Polynomial Spline Routines. Routines for the polynomial spline fitting\nroutines hazard regression, hazard estimation with flexible tails,\nlogspline, lspec, polyclass, and polymars, by C. Kooperberg and co-\nauthors.",
            "name": "r-polspline"
        },
        {
            "description": "Polygon Clipping. R port of Angus Johnson's open source library Clipper.\nPerforms polygon clipping operations (intersection, union, set minus,\nset difference) for polygonal regions of arbitrary complexity, including\nholes. Computes offset polygons (spatial buffer zones, morphological\ndilations, Minkowski dilations) for polygonal regions and polygonal\nlines. Computes Minkowski Sum of general polygons. There is a function\nfor removing self-intersections from polygon data.",
            "name": "r-polyclip"
        },
        {
            "description": "A collection of functions to implement a class for univariate polynomial\nmanipulations.",
            "name": "r-polynom"
        },
        {
            "description": "Object Pooling. Enables the creation of object pools, which make it less\ncomputationally expensive to fetch a new object. Currently the only\nsupported pooled objects are 'DBI' connections.",
            "name": "r-pool"
        },
        {
            "description": "A Poor Man's Dependency Free Recreation of 'dplyr'. A replication of key\nfunctionality from 'dplyr' and the wider 'tidyverse' using only 'base'.",
            "name": "r-poorman"
        },
        {
            "description": "An Efficient Swiss Army Knife for Population Genomic Analyses. Provides\nefficient tools for population genomics data analysis, able to process\nindividual loci, large sets of loci, or whole genomes. PopGenome\n<DOI:10.1093/molbev/msu136> not only implements a wide range of\npopulation genetics statistics, but also facilitates the easy\nimplementation of new algorithms by other researchers. PopGenome is\noptimized for speed via the seamless integration of C code.",
            "name": "r-popgenome"
        },
        {
            "description": "Genomic Breeding Tools: Genetic Variance Prediction and Cross-\nValidation. The main attribute of 'PopVar' is the prediction of genetic\nvariance in bi-parental populations, from which the package derives its\nname. 'PopVar' contains a set of functions that use phenotypic and\ngenotypic data from a set of candidate parents to 1) predict the mean,\ngenetic variance, and superior progeny value of all, or a defined set of\npairwise bi-parental crosses, and 2) perform cross-validation to\nestimate genome-wide prediction accuracy of multiple statistical models.\nMore details are available in Mohammadi, Tiede, and Smith (2015,\n<doi:10.2135/cropsci2015.01.0030>). A dataset 'think_barley.rda' is\nincluded for reference and examples.",
            "name": "r-popvar"
        },
        {
            "description": "Tools for Working with Posterior Distributions. Provides useful tools\nfor both users and developers of packages for fitting Bayesian models or\nworking with output from Bayesian models. The primary goals of the\npackage are to: (a) Efficiently convert between many different useful\nformats of draws (samples) from posterior or prior distributions. (b)\nProvide consistent methods for operations commonly performed on draws,\nfor example, subsetting, binding, or mutating draws. (c) Provide various\nsummaries of draws in convenient formats. (d) Provide lightweight\nimplementations of state of the art posterior inference diagnostics.\nReferences: Vehtari et al. (2021) <doi:10.1214/20-BA1221>.",
            "name": "r-posterior"
        },
        {
            "description": "Analysis of Heavy Tailed Distributions. An implementation of maximum\nlikelihood estimators for a variety of heavy tailed distributions,\nincluding both the discrete and continuous power law distributions.\nAdditionally, a goodness-of-fit based approach is used to estimate the\nlower cut-off for the scaling region.",
            "name": "r-powerlaw"
        },
        {
            "description": "Functions for Clustering of Presence-Absence, Abundance and Multilocus\nGenetic Data. Distance-based parametric bootstrap tests for clustering\nwith spatial neighborhood information. Some distance measures,\nClustering of presence-absence, abundance and multilocus genetic data\nfor species delimitation, nearest neighbor based noise detection.\nGenetic distances between communities. Tests whether various distance-\nbased regressions are equal. Try package?prabclus for on overview.",
            "name": "r-prabclus"
        },
        {
            "description": "Practical Numerical Math Functions. Provides a large number of functions\nfrom numerical analysis and linear algebra, numerical optimization,\ndifferential equations, time series, plus some well-known special\nmathematical functions. Uses 'MATLAB' function names where appropriate\nto simplify porting.",
            "name": "r-pracma"
        },
        {
            "description": "Praise Users. Build friendly R packages that praise their users if they\nhave done something good, or they just need it to feel better.",
            "name": "r-praise"
        },
        {
            "description": "A collection of pre-processing functions. A library of core\npreprocessing routines.",
            "name": "r-preprocesscore"
        },
        {
            "description": "Creating Pretty Documents from R Markdown. Creating tiny yet beautiful\ndocuments and vignettes from R Markdown. The package provides the\n'html_pretty' output format as an alternative to the 'html_document' and\n'html_vignette' engines that convert R Markdown into HTML pages. Various\nthemes and syntax highlight styles are supported.",
            "name": "r-prettydoc"
        },
        {
            "description": "Pretty, Human Readable Formatting of Quantities. Pretty, human readable\nformatting of quantities. Time intervals: 1337000 -> 15d 11h 23m 20s.\nVague time intervals: 2674000 -> about a month ago. Bytes: 1337 -> 1.34\nkB.",
            "name": "r-prettyunits"
        },
        {
            "description": "Display and Analyze ROC Curves. Tools for visualizing, smoothing and\ncomparing receiver operating characteristic (ROC curves). (Partial) area\nunder the curve (AUC) can be compared with statistical tests based on\nU-statistics or bootstrap. Confidence intervals can be computed for\n(p)AUC or ROC curves.",
            "name": "r-proc"
        },
        {
            "description": "Execute and Control System Processes. Tools to run system processes in\nthe background. It can check if a background process is running; wait on\na background process to finish; get the exit status of finished\nprocesses; kill background processes. It can read the standard output\nand error of the processes, using non-blocking connections. 'processx'\ncan poll a process for standard output or error, with a timeout. It can\nalso poll several processes at once.",
            "name": "r-processx"
        },
        {
            "description": "Product-Limit Estimation for Censored Event History Analysis. Product-\nLimit Estimation for Censored Event History Analysis. Fast and user\nfriendly implementation of nonparametric estimators for censored event\nhistory (survival) analysis. Kaplan-Meier and Aalen-Johansen method.",
            "name": "r-prodlim"
        },
        {
            "description": "Interactive visualizations for profiling R code.",
            "name": "r-profvis"
        },
        {
            "description": "Terminal Progress Bars. Configurable Progress bars, they may include\npercentage, elapsed time, and/or the estimated completion time. They\nwork in terminals, in 'Emacs' 'ESS', 'RStudio', 'Windows' 'Rgui' and the\n'macOS' 'R.app'. The package also provides a 'C++' 'API', that works\nwith or without 'Rcpp'.",
            "name": "r-progress"
        },
        {
            "description": "An Inclusive, Unifying API for Progress Updates. A minimal, unifying API\nfor scripts and packages to report progress updates from anywhere\nincluding when using parallel processing. The package is designed such\nthat the developer can to focus on what progress should be reported on\nwithout having to worry about how to present it. The end user has full\ncontrol of how, where, and when to render these progress updates, e.g.\nin the terminal using utils::txtProgressBar() or\nprogress::progress_bar(), in a graphical user interface using\nutils::winProgressBar(), tcltk::tkProgressBar() or\nshiny::withProgress(), via the speakers using beep::beepr(), or on a\nfile system via the size of a file. Anyone can add additional,\ncustomized, progression handlers. The 'progressr' package uses R's\ncondition framework for signaling progress updated. Because of this,\nprogress can be reported from almost anywhere in R, e.g. from classical\nfor and while loops, from map-reduce API:s like the lapply() family of\nfunctions, 'purrr', 'plyr', and 'foreach'. It will also work with\nparallel processing via the 'future' framework, e.g.\nfuture.apply::future_lapply(), furrr::future_map(), and 'foreach' with\n'doFuture'. The package is compatible with Shiny applications.",
            "name": "r-progressr"
        },
        {
            "description": "Generic Coordinate System Transformations Using 'PROJ'. A wrapper around\nthe generic coordinate transformation software 'PROJ' that transforms\ncoordinates from one coordinate reference system ('CRS') to another.\nThis includes cartographic projections as well as geodetic\ntransformations. The intention is for this package to be used by user-\npackages such as 'reproj', and that the older 'PROJ.4' and version 5\npathways be provided by the 'proj4' package.",
            "name": "r-proj"
        },
        {
            "description": "A simple interface to the PROJ.4 cartographic projections library. A\nsimple interface to lat/long projection and datum transformation of the\nPROJ.4 cartographic projections library. It allows transformation of\ngeographic coordinates from one projection and/or datum to another.",
            "name": "r-proj4"
        },
        {
            "description": "Projection Predictive Feature Selection. Performs projection predictive\nfeature selection for generalized linear models and generalized linear\nand additive multilevel models (see, Piironen, Paasiniemi and Vehtari,\n2020, <https://projecteuclid.org/euclid.ejs/1589335310>, Catalina,\nBurkner and Vehtari, 2020, <arXiv:2010.06994>). The package is\ncompatible with the 'rstanarm' and 'brms' packages, but other reference\nmodels can also be used. See the package vignette for more information\nand examples.",
            "name": "r-projpred"
        },
        {
            "description": "Abstractions for Promise-Based Asynchronous Programming. Provides\nfundamental abstractions for doing asynchronous programming in R using\npromises. Asynchronous programming is useful for allowing a single R\nprocess to orchestrate multiple tasks in the background while also\nattending to something else. Semantics are similar to 'JavaScript'\npromises, but with a syntax that is idiomatic R.",
            "name": "r-promises"
        },
        {
            "description": "S4 generic functions for Bioconductor proteomics infrastructure. S4\ngeneric functions needed by Bioconductor proteomics packages.",
            "name": "r-protgenerics"
        },
        {
            "description": "Prototype Object-Based Programming. An object oriented system using\nobject-based, also called prototype-based, rather than class-based\nobject oriented ideas.",
            "name": "r-proto"
        },
        {
            "description": "Distance and Similarity Measures. Provides an extensible framework for\nthe efficient calculation of auto- and cross-proximities, along with\nimplementations of the most popular ones.",
            "name": "r-proxy"
        },
        {
            "description": "Tools for Computing on the Language. Useful tools to pry back the covers\nof R and understand the language at a deeper level.",
            "name": "r-pryr"
        },
        {
            "description": "List, Query, Manipulate System Processes. List, query and manipulate all\nsystem processes, on 'Windows', 'Linux' and 'macOS'.",
            "name": "r-ps"
        },
        {
            "description": "Analysis of Parent-Specific DNA Copy Numbers. Segmentation of allele-\nspecific DNA copy number data and detection of regions with abnormal\ncopy number within each parental chromosome. Both tumor-normal paired\nand tumor-only analyses are supported.",
            "name": "r-pscbs"
        },
        {
            "description": "Penalized Smoothing Splines. Smoothing splines with penalties on order m\nderivatives.",
            "name": "r-pspline"
        },
        {
            "description": "Procedures for Psychological, Psychometric, and Personality Research. A\ngeneral purpose toolbox for personality, psychometric theory and\nexperimental psychology. Functions are primarily for multivariate\nanalysis and scale construction using factor analysis, principal\ncomponent analysis, cluster analysis and reliability analysis, although\nothers provide basic descriptive statistics. Item Response Theory is\ndone using factor analysis of tetrachoric and polychoric correlations.\nFunctions for analyzing data at multiple levels include within and\nbetween group statistics, including correlations and factor analysis.\nFunctions for simulating and testing particular item and test structures\nare included. Several functions serve as a useful front end for\nstructural equation modeling. Graphical displays of path diagrams,\nfactor analysis and structural equation models are created using basic\ngraphics. Some of the functions are written to support a book on\npsychometric theory as well as publications in personality research. For\nmore information, see the <http://personality-project.org/r> web page.",
            "name": "r-psych"
        },
        {
            "description": "Parametric Time Warping. Parametric Time Warping aligns patterns, i.e.\nit aims to put corresponding features at the same locations. The\nalgorithm searches for an optimal polynomial describing the warping. It\nis possible to align one sample to a reference, several samples to the\nsame reference, or several samples to several references. One can choose\nbetween calculating individual warpings, or one global warping for a set\nof samples and one reference. Two optimization criteria are implemented:\nRMS (Root Mean Square error) and WCC (Weighted Cross Correlation). Both\nwarping of peak profiles and of peak lists are supported. A vignette for\nthe latter is contained in the inst/doc directory of the source package\n- the vignette source can be found on the package github site.",
            "name": "r-ptw"
        },
        {
            "description": "Functional Programming Tools. A complete and consistent functional\nprogramming toolkit for R.",
            "name": "r-purrr"
        },
        {
            "description": "Hierarchical Clustering with P-Values via Multiscale Bootstrap\nResampling. An implementation of multiscale bootstrap resampling for\nassessing the uncertainty in hierarchical cluster analysis. It provides\nSI (selective inference) p-value, AU (approximately unbiased) p-value\nand BP (bootstrap probability) value for each cluster in a dendrogram.",
            "name": "r-pvclust"
        },
        {
            "description": "Creates Simultaneous Testing Bands for QQ-Plots. Provides functionality\nfor creating Quantile-Quantile (QQ) and Probability-Probability (PP)\nplots with simultaneous testing bands to asses significance of sample\ndeviation from a reference distribution.",
            "name": "r-qqconf"
        },
        {
            "description": "Quick Serialization of R Objects. Provides functions for quickly writing\nand reading any R object to and from disk.",
            "name": "r-qs"
        },
        {
            "description": "Tools for Analyzing QTL Experiments. Analysis of experimental crosses to\nidentify genes (called quantitative trait loci, QTLs) contributing to\nvariation in quantitative traits. Broman et al. (2003)\n<doi:10.1093/bioinformatics/btg112>.",
            "name": "r-qtl"
        },
        {
            "description": "Functions to Solve Quadratic Programming Problems. This package contains\nroutines and documentation for solving quadratic programming problems.",
            "name": "r-quadprog"
        },
        {
            "description": "Quantitative Financial Modelling Framework. Specify, build, trade, and\nanalyse quantitative financial trading strategies.",
            "name": "r-quantmod"
        },
        {
            "description": "Quantile Regression. Estimation and inference methods for models of\nconditional quantiles: Linear and nonlinear parametric and non-\nparametric (total variation penalized) models for conditional quantiles\nof a univariate response and several methods for handling censored\nsurvival data. Portfolio selection methods based on expected shortfall\nrisk are also now included. See Koenker (2006)\n<doi:10.1017/CBO9780511754098> and Koenker et al. (2017)\n<doi:10.1201/9781315120256>.",
            "name": "r-quantreg"
        },
        {
            "description": "A test for when to use quantile normalization. A data-driven test for\nthe assumptions of quantile normalization using raw data such as objects\nthat inherit eSets (e.g. ExpressionSet, MethylSet). Group level\ninformation about each sample (such as Tumor / Normal status) must also\nbe provided because the test assesses if there are global differences in\nthe distributions between the user-defined groups.",
            "name": "r-quantro"
        },
        {
            "description": "Functions to Make Surveys Processing Easier. Set of functions to make\nthe processing and analysis of surveys easier: interactive shiny apps\nand addins for data recoding, contingency tables, dataset metadata\nhandling, and several convenience functions.",
            "name": "r-questionr"
        },
        {
            "description": "An 'R' interface to the 'QuickJS' portable 'JavaScript' engine. The\nengine and all 'R' to 'JavaScript' interoperability is bundled within\nthe package, requiring no dependencies beyond a 'C' compiler.",
            "name": "r-quickjsr"
        },
        {
            "description": "A System of Plotting Optimized for Speed and Modularity. A high-level\nplotting system, built using 'grid' graphics, that is optimized for\nspeed and modularity. This has great utility for quick visualizations\nwhen testing code, with the key benefit that visualizations are updated\nindependently of one another.",
            "name": "r-quickplot"
        },
        {
            "description": "Q-value estimation for false discovery rate control. This package takes\na list of p-values resulting from the simultaneous testing of many\nhypotheses and estimates their q-values and local FDR values. The\nq-value of a test measures the proportion of false positives incurred\n(called the false discovery rate) when that particular test is called\nsignificant. The local FDR measures the posterior probability the null\nhypothesis is true given the test's p-value. Various plots are\nautomatically generated, allowing one to make sensible significance cut-\noffs. Several mathematical results have recently been shown on the\nconservative accuracy of the estimated q-values from this software. The\nsoftware can be applied to problems in genomics, brain imaging,\nastrophysics, and data mining.",
            "name": "r-qvalue"
        },
        {
            "description": "Fast and Light-Weight Caching (Memoization) of Objects and Results to\nSpeed Up Computations. Memoization can be used to speed up repetitive\nand computational expensive function calls. The first time a function\nthat implements memoization is called the results are stored in a cache\nmemory. The next time the function is called with the same set of\nparameters, the results are momentarily retrieved from the cache\navoiding repeating the calculations. With this package, any R object can\nbe cached in a key-value storage where the key can be an arbitrary set\nof R objects. The cache memory is persistent (on the file system).",
            "name": "r-r-cache"
        },
        {
            "description": "S3 Methods Simplified. Methods that simplify the setup of S3 generic\nfunctions and S3 methods. Major effort has been made in making\ndefinition of methods as simple as possible with a minimum of\nmaintenance for package developers. For example, generic functions are\ncreated automatically, if missing, and naming conflict are automatically\nsolved, if possible. The method setMethodS3() is a good start for those\nwho in the future may want to migrate to S4. This is a cross-platform\npackage implemented in pure R that generates standard S3 methods.",
            "name": "r-r-methodss3"
        },
        {
            "description": "R Object-Oriented Programming with or without References. Methods and\nclasses for object-oriented programming in R with or without references.\nLarge effort has been made on making definition of methods as simple as\npossible with a minimum of maintenance for package developers. The\npackage has been developed since 2001 and is now considered very stable.\nThis is a cross-platform package implemented in pure R that defines\nstandard S3 classes without any tricks.",
            "name": "r-r-oo"
        },
        {
            "description": "Various Programming Utilities. Utility functions useful when programming\nand developing R packages.",
            "name": "r-r-utils"
        },
        {
            "description": "Encapsulated Classes with Reference Semantics. The R6 package allows the\ncreation of classes with reference semantics, similar to R's built-in\nreference classes. Compared to reference classes, R6 classes are simpler\nand lighter-weight, and they are not built on S4 classes so they do not\nrequire the methods package. These classes allow public and private\nmembers, and they support inheritance, even when the classes are defined\nin different packages.",
            "name": "r-r6"
        },
        {
            "description": "RadialMR. A package for implementing radial inverse variance weighted\nand MR-Egger methods.",
            "name": "r-radialmr"
        },
        {
            "description": "Graphic Devices Based on AGG. Anti-Grain Geometry (AGG) is a high-\nquality and high-performance 2D drawing library. The 'ragg' package\nprovides a set of graphic devices based on AGG to use as alternative to\nthe raster devices provided through the 'grDevices' package.",
            "name": "r-ragg"
        },
        {
            "description": "Bagplots, Boxplots and Rainbow Plots for Functional Data. Visualizing\nfunctional data and identifying functional outliers.",
            "name": "r-rainbow"
        },
        {
            "description": "Simulation and Analysis of Random Fields. Methods for the inference on\nand the simulation of Gaussian fields are provided. Furthermore, methods\nfor the simulation of extreme value random fields are provided. Main\ngeostatistical parts are based among others on the books by Christian\nLantuejoul <doi:10.1007/978-3-662-04808-5>.",
            "name": "r-randomfields"
        },
        {
            "description": "Utilities for the Simulation and Analysis of Random Fields and Genetic\nData. Various utilities are provided that might be used in spatial\nstatistics and elsewhere. It delivers a method for solving linear\nequations that checks the sparsity of the matrix before any algorithm is\nused.",
            "name": "r-randomfieldsutils"
        },
        {
            "description": "Breiman and Cutler's Random Forests for Classification and Regression.\nClassification and regression based on a forest of trees using random\ninputs.",
            "name": "r-randomforest"
        },
        {
            "description": "Random General Linear Model Prediction. The package implements a bagging\npredictor based on general linear models.",
            "name": "r-randomglm"
        },
        {
            "description": "A Fast Implementation of Random Forests. A fast implementation of Random\nForests, particularly suited for high dimensional data. Ensembles of\nclassification, regression, survival and probability prediction trees\nare supported. Data from genome-wide association studies can be analyzed\nefficiently. In addition to data frames, datasets of class 'gwaa.data'\n(R package 'GenABEL') and 'dgCMatrix' (R package 'Matrix') can be\ndirectly analyzed.",
            "name": "r-ranger"
        },
        {
            "description": "Fast Nearest Neighbour Search (Wraps ANN Library) Using L2 Metric. Finds\nthe k nearest neighbours for every point in a given dataset in O(N log\nN) time using Arya and Mount's ANN library (v1.1.3). There is support\nfor approximate as well as exact searches, fixed radius searches and\n'bd' as well as 'kd' trees. The distance is computed using the L2\n(Euclidean) metric. Please see package 'RANN.L1' for the same\nfunctionality using the L1 (Manhattan, taxicab) metric.",
            "name": "r-rann"
        },
        {
            "description": "'Rapidjson' C++ Header Files. Provides JSON parsing capability through\nthe 'Rapidjson' 'C++' header-only library.",
            "name": "r-rapidjsonr"
        },
        {
            "description": "R API Serialization. This package provides other packages with access to\nthe internal R serialization code. Access to this code is provided at\nthe C function level by using the registration of native function\nmechanism. Client packages simply include a single header file\nRApiSerializeAPI.h provided by this package. This packages builds on the\nRhpc package by Junji Nakano and Ei-ji Nakama which also includes a\n(partial) copy of the file src/main/serialize.c from R itself. The R\nCore group is the original author of the serialization code made\navailable by this package.",
            "name": "r-rapiserialize"
        },
        {
            "description": "Application Directories: Determine Where to Save Data, Caches, and Logs.\nAn easy way to determine which directories on the users computer you\nshould use to save data, caches and logs. A port of Python's 'Appdirs'\n(<https://github.com/ActiveState/appdirs>) to R.",
            "name": "r-rappdirs"
        },
        {
            "description": "Geographic Data Analysis and Modeling. Reading, writing, manipulating,\nanalyzing and modeling of spatial data. The package implements basic and\nhigh-level functions for raster data and for vector data operations such\nas intersections. See the manual and tutorials on\n<https://rspatial.org/> to get started.",
            "name": "r-raster"
        },
        {
            "description": "An interface to the BOOST graph library. A fairly extensive and\ncomprehensive interface to the graph algorithms contained in the BOOST\nlibrary.",
            "name": "r-rbgl"
        },
        {
            "description": "Convert Between Bibliography Formats. Converts between a number of\nbibliography formats, including 'BibTeX', 'BibLaTeX' and 'Bibentry'.\nIncludes a port of the 'bibutils' utilities by Chris Putnam\n<https://sourceforge.net/projects/bibutils/>. Supports all bibliography\nformats and character encodings implemented in 'bibutils'.",
            "name": "r-rbibutils"
        },
        {
            "description": "R Interface for Bokeh. A native R plotting library that provides a\nflexible declarative interface for creating interactive web-based\ngraphics, backed by the Bokeh visualization library\n<https://bokeh.pydata.org/>.",
            "name": "r-rbokeh"
        },
        {
            "description": "Run 'R CMD check' from 'R' and Capture Results. Run 'R CMD check' from\n'R' and capture the results of the individual checks. Supports running\nchecks in the background, timeouts, pretty printing and comparing check\nresults.",
            "name": "r-rcmdcheck"
        },
        {
            "description": "ColorBrewer Palettes. Provides color schemes for maps (and other\ngraphics) designed by Cynthia Brewer as described at\nhttps://colorbrewer2.org/",
            "name": "r-rcolorbrewer"
        },
        {
            "description": "Seamless R and C++ Integration. The 'Rcpp' package provides R functions\nas well as C++ classes which; offer a seamless integration of R and C++.\nMany R data types and objects can be; mapped back and forth to C++\nequivalents which facilitates both writing of new; code as well as\neasier integration of third-party libraries. Documentation; about 'Rcpp'\nis provided by several vignettes included in this package, via the;\n'Rcpp Gallery' site at <https://gallery.rcpp.org>, the paper by\nEddelbuettel and; Francois (2011, <doi:10.18637/jss.v040.i08>), the book\nby Eddelbuettel (2013,; <doi:10.1007/978-1-4614-6868-4>) and the paper\nby Eddelbuettel and Balamuta (2018,;\n<doi:10.1080/00031305.2017.1375990>); see 'citation(\"Rcpp\")' for\ndetails.",
            "name": "r-rcpp"
        },
        {
            "description": "'Rcpp' Bindings for 'Annoy', a Library for Approximate Nearest\nNeighbors. 'Annoy' is a small C++ library for Approximate Nearest\nNeighbors written for efficient memory usage as well an ability to load\nfrom / save to disk. This package provides an R interface by relying on\nthe 'Rcpp' package, exposing the same interface as the original Python\nwrapper to 'Annoy'. See <https://github.com/spotify/annoy> for more on\n'Annoy'. 'Annoy' is released under Version 2.0 of the Apache License.\nAlso included is a small Windows port of 'mmap' which is released under\nthe MIT license.",
            "name": "r-rcppannoy"
        },
        {
            "description": "'Rcpp' Integration for the 'Armadillo' Templated Linear Algebra Library.\n'Armadillo' is a templated C++ linear algebra library (by Conrad;\nSanderson) that aims towards a good balance between speed and ease of;\nuse. Integer, floating point and complex numbers are supported, as; well\nas a subset of trigonometric and statistics functions. Various; matrix\ndecompositions are provided through optional integration with; LAPACK\nand ATLAS libraries. The 'RcppArmadillo' package includes the; header\nfiles from the templated 'Armadillo' library. Thus users do; not need to\ninstall 'Armadillo' itself in order to use; 'RcppArmadillo'. From\nrelease 7.800.0 on, 'Armadillo' is licensed; under Apache License 2;\nprevious releases were under licensed as MPL; 2.0 from version 3.800.0\nonwards and LGPL-3 prior to that",
            "name": "r-rcpparmadillo"
        },
        {
            "description": "'Blaze' is an open-source, high-performance C++ math library for dense\nand sparse arithmetic. With its state-of-the-art Smart Expression\nTemplate implementation 'Blaze' combines the elegance and ease of use of\na domain-specific language with 'HPC'-grade performance, making it one\nof the most intuitive and fastest C++ math libraries available. The\n'Blaze' library offers: - high performance through the integration of\n'BLAS' libraries and manually tuned 'HPC' math kernels - vectorization\nby 'SSE', 'SSE2', 'SSE3', 'SSSE3', 'SSE4', 'AVX', 'AVX2', 'AVX-512',\n'FMA', and 'SVML' - parallel execution by 'OpenMP', C++11 threads and\n'Boost' threads ('Boost' threads are disabled in 'RcppBlaze') - the\nintuitive and easy to use API of a domain specific language - unified\narithmetic with dense and sparse vectors and matrices - thoroughly\ntested matrix and vector arithmetic - completely portable, high quality\nC++ source code. The 'RcppBlaze' package includes the header files from\nthe 'Blaze' library with disabling some functionalities related to link\nto the thread and system libraries which make 'RcppBlaze' be a header-\nonly library. Therefore, users do not need to install 'Blaze' and the\ndependency 'Boost'. 'Blaze' is licensed under the New (Revised) BSD\nlicense, while 'RcppBlaze' (the 'Rcpp' bindings/bridge to 'Blaze') is\nlicensed under the GNU GPL version 2 or later, as is the rest of 'Rcpp'.\nNote that since 'Blaze' has committed to 'C++14' commit to 'C++14' which\ndoes not used by most R users from version 3.0, we will use the version\n2.6 of 'Blaze' which is 'C++98' compatible to support the most compilers\nand system.",
            "name": "r-rcppblaze"
        },
        {
            "description": "'Rcpp' Bindings for the 'CCTZ' Library. 'Rcpp' Access to the 'CCTZ'\ntimezone library is provided. 'CCTZ' is a C++ library for translating\nbetween absolute and civil times using the rules of a time zone. The\n'CCTZ' source code, released under the Apache 2.0 License, is included\nin this package. See <https://github.com/google/cctz> for more details.",
            "name": "r-rcppcctz"
        },
        {
            "description": "Read-Write Support for 'NumPy' Files via 'Rcpp'. The 'cnpy' library\nwritten by Carl Rogers provides read and write facilities for files\ncreated with (or for) the 'NumPy' extension for 'Python'. Vectors and\nmatrices of numeric types can be read or written to and from files as\nwell as compressed files. Support for integer files is available if the\npackage has been built with -std=c++11 which should be the default on\nall platforms since the release of R 3.3.0.",
            "name": "r-rcppcnpy"
        },
        {
            "description": "'date' C++ Header Library for Date and Time Functionality. 'date' is a\nC++ header library offering extensive date and time functionality for\nthe C++11, C++14 and C++17 standards written by Howard Hinnant and\nreleased under the MIT license. A slightly modified version has been\naccepted (along with 'tz.h') as part of C++20. This package regroups all\nheader files from the upstream repository by Howard Hinnant so that\nother R packages can use them in their C++ code. At present, few of the\ntypes have explicit 'Rcpp' wrapper though these may be added as needed.",
            "name": "r-rcppdate"
        },
        {
            "description": "Global Optimization by Differential Evolution in C++. An efficient C++\nbased implementation of the 'DEoptim' function which performs global\noptimization by differential evolution. Its creation was motivated by\ntrying to see if the old approximation \"easier, shorter, faster: pick\nany two\" could in fact be extended to achieving all three goals while\nmoving the code from plain old C to modern C++. The initial version did\nin fact do so, but a good part of the gain was due to an implicit code\nreview which eliminated a few inefficiencies which have since been\neliminated in 'DEoptim'.",
            "name": "r-rcppde"
        },
        {
            "description": "'Rcpp' Integration for the 'Eigen' Templated Linear Algebra Library. R\nand 'Eigen' integration using 'Rcpp'. 'Eigen' is a C++ template library\nfor linear algebra: matrices, vectors, numerical solvers and related\nalgorithms. It supports dense and sparse matrices on integer, floating\npoint and complex numbers, decompositions of such matrices, and\nsolutions of linear systems. Its performance on many algorithms is\ncomparable with some of the best implementations based on 'Lapack' and\nlevel-3 'BLAS'. The 'RcppEigen' package includes the header files from\nthe 'Eigen' C++ template library (currently version 3.2.8). Thus users\ndo not need to install 'Eigen' itself in order to use 'RcppEigen'. Since\nversion 3.1.1, 'Eigen' is licensed under the Mozilla Public License\n(version 2); earlier version were licensed under the GNU LGPL version 3\nor later. 'RcppEigen' (the 'Rcpp' bindings/bridge to 'Eigen') is\nlicensed under the GNU GPL version 2 or later, as is the rest of 'Rcpp'.",
            "name": "r-rcppeigen"
        },
        {
            "description": "Rcpp integration for the Ensmallen templated C++ mathematical\noptimization library.",
            "name": "r-rcppensmallen"
        },
        {
            "description": "'Rcpp' Integration for 'GNU GSL' Vectors and Matrices. 'Rcpp'\nintegration for 'GNU GSL' vectors and matrices The 'GNU Scientific\nLibrary' (or 'GSL') is a collection of numerical routines for scientific\ncomputing. It is particularly useful for C and C++ programs as it\nprovides a standard C interface to a wide range of mathematical\nroutines. There are over 1000 functions in total with an extensive test\nsuite. The 'RcppGSL' package provides an easy-to-use interface between\n'GSL' data structures and R using concepts from 'Rcpp' which is itself a\npackage that eases the interfaces between R and C++. This package also\nserves as a prime example of how to build a package that uses 'Rcpp' to\nconnect to another third-party library. The 'autoconf' script, 'inline'\nplugin and example package can all be used as a stanza to write a\nsimilar package against another library.",
            "name": "r-rcppgsl"
        },
        {
            "description": "'Rcpp' Bindings for 'hnswlib', a Library for Approximate\nNearestNeighbors. 'Hnswlib' is a C++ library for Approximate Nearest\nNeighbors. This ; package provides a minimal R interface by relying on\nthe 'Rcpp' package. See ; <https://github.com/nmslib/hnswlib> for more\non 'hnswlib'. 'hnswlib' is ; released under Version 2.0 of the Apache\nLicense.",
            "name": "r-rcpphnsw"
        },
        {
            "description": "Rcpp Machine Learning Library Fast machine learning algorithms including\nmatrix factorization and divisive clustering for large sparse and dense\nmatrices.",
            "name": "r-rcppml"
        },
        {
            "description": "Parallel Programming Tools for 'Rcpp'. High level functions for parallel\nprogramming with 'Rcpp'. For example, the 'parallelFor()' function can\nbe used to convert the work of a standard serial \"for\" loop into a\nparallel one and the 'parallelReduce()' function can be used for\naccumulating aggregate or other values.",
            "name": "r-rcppparallel"
        },
        {
            "description": "An Interruptible Progress Bar with OpenMP Support for C++ in R Packages.\nAllows to display a progress bar in the R console for long running\ncomputations taking place in c++ code, and support for interrupting\nthose computations even in multithreaded code, typically using OpenMP.",
            "name": "r-rcppprogress"
        },
        {
            "description": "Efficient Rolling / Windowed Operations. Provides fast and efficient\nroutines for common rolling / windowed operations. Routines for the\nefficient computation of windowed mean, median, sum, product, minimum,\nmaximum, standard deviation and variance are provided.",
            "name": "r-rcpproll"
        },
        {
            "description": "'Rcpp' Bindings to Parser for Tom's Obvious Markup Language. The\nconfiguration format defined by 'TOML' (which expands to \"Tom's Obvious\nMarkup Language\") specifies an excellent format (described at\n<https://toml.io/en/>) suitable for both human editing as well as the\ncommon uses of a machine-readable format. This package uses 'Rcpp' to\nconnect the 'cpptoml' parser written by Chase Geigle (in C++11) to R.",
            "name": "r-rcpptoml"
        },
        {
            "description": "'Rcpp' Integration of Different \"Ziggurat\" Normal RNG Implementations.\nThe Ziggurat generator for normally distributed random numbers,\noriginally proposed by Marsaglia and Tsang (2000,\n<doi:10.18637/jss.v005.i08>) has been improved upon a few times starting\nwith Leong et al (2005, <doi:10.18637/jss.v012.i07>). This package\nprovides an aggregation in order to compare different implementations in\norder to provide an 'faster but good enough' alternative for use with R\nand C++ code.",
            "name": "r-rcppziggurat"
        },
        {
            "description": "General Network (HTTP/FTP/...) Client Interface for R. A wrapper for\n'libcurl' <http://curl.haxx.se/libcurl/> Provides functions to allow one\nto compose general HTTP requests and provides convenient functions to\nfetch URIs, get & post forms, etc. and process the results returned by\nthe Web server. This provides a great deal of control over the\nHTTP/FTP/... connection and the form of the request while providing a\nhigher-level interface than is available just using R socket\nconnections. Additionally, the underlying implementation is robust and\nextensive, supporting FTP/FTPS/TFTP (uploads and downloads), SSL/HTTPS,\ntelnet, dict, ldap, and also supports cookies, redirects,\nauthentication, etc.",
            "name": "r-rcurl"
        },
        {
            "description": "Shrunken Centroids Regularized Discriminant Analysis. Shrunken Centroids\nRegularized Discriminant Analysis for the classification purpose in high\ndimensional data.",
            "name": "r-rda"
        },
        {
            "description": "Update and Manipulate Rd Documentation Objects. Functions for\nmanipulation of R documentation objects, including functions reprompt()\nand ereprompt() for updating 'Rd' documentation for functions, methods\nand classes; 'Rd' macros for citations and import of references from\n'bibtex' files for use in 'Rd' files and 'roxygen2' comments; 'Rd'\nmacros for evaluating and inserting snippets of 'R' code and the results\nof its evaluation or creating graphics on the fly; and many functions\nfor manipulation of references and Rd files.",
            "name": "r-rdpack"
        },
        {
            "description": "Simple Unified Interface to Read Bitmap Images (BMP,JPEG,PNG,TIFF).\nIdentifies and reads Windows BMP, JPEG, PNG, and TIFF format bitmap\nimages. Identification defaults to the use of the magic number embedded\nin the file rather than the file extension. Reading of JPEG and PNG\nimage depends on libjpg and libpng libraries. See file INSTALL for\ndetails if necessary.",
            "name": "r-readbitmap"
        },
        {
            "description": "Read Rectangular Text Data. The goal of 'readr' is to provide a fast and\nfriendly way to read rectangular data (like 'csv', 'tsv', and 'fwf'). It\nis designed to flexibly parse many types of data found in the wild,\nwhile still cleanly failing when data unexpectedly changes.",
            "name": "r-readr"
        },
        {
            "description": "Read Excel Files. Import excel files into R. Supports '.xls' via the\nembedded 'libxls' C library <https://sourceforge.net/projects/libxls/>\nand '.xlsx' via the embedded 'RapidXML' C++ library\n<https://rapidxml.sourceforge.net>. Works on Windows, Mac and Linux\nwithout external dependencies.",
            "name": "r-readxl"
        },
        {
            "description": "Resampling-Based Adaptive Model Selection. Resampling methods for\nadaptive linear model selection. These can be thought of as extensions\nof the Akaike information criterion that account for searching among\ncandidate models.",
            "name": "r-reams"
        },
        {
            "description": "Preprocessing Tools to Create Design Matrices. An extensible framework\nto create and preprocess design matrices. Recipes consist of one or more\ndata manipulation and analysis \"steps\". Statistical parameters for the\nsteps can be estimated from an initial data set and then applied to\nother data sets. The resulting design matrices can then be used as\ninputs into statistical or machine learning models.",
            "name": "r-recipes"
        },
        {
            "description": "Infrastructure for R Package Registries. Provides a generic\ninfrastructure for creating and using registries.",
            "name": "r-registry"
        },
        {
            "description": "Match Regular Expressions with a Nicer 'API'. A small wrapper on\n'regexpr' to extract the matches and captured groups from the match of a\nregular expression to a character vector.",
            "name": "r-rematch"
        },
        {
            "description": "Tidy Output from Regular Expression Matching. Wrappers on 'regexpr' and\n'gregexpr' to return the match results in tidy data frames.",
            "name": "r-rematch2"
        },
        {
            "description": "R Package Installation from Remote Repositories, Including 'GitHub'.\nDownload and install R packages stored in 'GitHub', 'BitBucket', or\nplain 'subversion' or 'git' repositories. This package provides the\n'install_*' functions in 'devtools'. Indeed most of the code was copied\nover from 'devtools'.",
            "name": "r-remotes"
        },
        {
            "description": "Project Environments for R packages. A dependency management toolkit for\nR. Using 'renv', you can create and manage project-local R libraries,\nsave the state of these libraries to a 'lockfile', and later restore\nyour library as required. Together, these tools can help make your\nprojects more isolated, portable, and reproducible.",
            "name": "r-renv"
        },
        {
            "description": "Reordering the dendrogram according to the class labels. Tools for\nperforming the leaf reordering for the dendrogram that preserves the\nhierarchical clustering result and at the same time tries to group\ninstances from the same class together.",
            "name": "r-reordercluster"
        },
        {
            "description": "Tools for making reports in various formats. The ReportingTools software\npackage enables users to easily display reports of analysis results\ngenerated from sources such as microarray and sequencing data. The\npackage allows users to create HTML pages that may be viewed on a web\nbrowser such as Safari, or in other formats readable by programs such as\nExcel. Users can generate tables with sortable and filterable columns,\nmake and display plots, and link table entries to other data sources\nsuch as NCBI or larger plots within the HTML page. Using the package,\nusers can also produce a table of contents page to link various reports\ntogether for a particular project that can be viewed in a web browser.\nFor more examples, please visit our site: http:// research-\npub.gene.com/ReportingTools.",
            "name": "r-reportingtools"
        },
        {
            "description": "Serializable Representations. String and binary representations of\nobjects for several formats and mime types.",
            "name": "r-repr"
        },
        {
            "description": "Prepare Reproducible Example Code via the Clipboard. Convenience wrapper\nthat uses the 'rmarkdown' package to render small snippets of code to\ntarget formats that include both code and output. The goal is to\nencourage the sharing of small, reproducible, and runnable examples on\ncode-oriented websites, such as <https://stackoverflow.com/> and\n<https://github.com>, or in email. 'reprex' also extracts clean,\nrunnable R code from various common formats, such as copy/paste from an\nR session.",
            "name": "r-reprex"
        },
        {
            "description": "A Set of Tools that Enhance Reproducibility Beyond Package Management.\nCollection of high-level, machine- and OS-independent tools for making\ndeeply reproducible and reusable content in R. The two workhorse\nfunctions are Cache and prepInputs; these allow for: nested caching,\nrobust to environments, and objects with environments (like functions);\nand data retrieval and processing in continuous workflow environments.\nIn all cases, efforts are made to make the first and subsequent calls of\nfunctions have the same result, but vastly faster at subsequent times by\nway of checksums and digesting. Several features are still under active\ndevelopment, including cloud storage of cached objects, allowing for\nsharing between users. Several advanced options are available, see\n?reproducibleOptions.",
            "name": "r-reproducible"
        },
        {
            "description": "Installing and Loading R Packages for Reproducible Workflows. A single\nkey function, 'Require' that wraps 'install.packages',\n'remotes::install_github', 'versions::install.versions', and\n'base::require' that allows for reproducible workflows. As with other\nfunctions in a reproducible workflow, this package emphasizes functions\nthat return the same result whether it is the first or subsequent times\nrunning the function. Maturing.",
            "name": "r-require"
        },
        {
            "description": "Flexibly Reshape Data. Flexibly restructure and aggregate data using\njust two functions: melt and cast.",
            "name": "r-reshape"
        },
        {
            "description": "Flexibly Reshape Data: A Reboot of the Reshape Package. Flexibly\nrestructure and aggregate data using just two functions: melt and dcast\n(or acast).",
            "name": "r-reshape2"
        },
        {
            "description": "R Interface to RESTful Web Services. Models a RESTful service as if it\nwere a nested R list.",
            "name": "r-restfulr"
        },
        {
            "description": "Interface to 'Python'. Interface to 'Python' modules, classes, and\nfunctions. When calling into 'Python', R data types are automatically\nconverted to their equivalent 'Python' types. When values are returned\nfrom 'Python' to R they are converted back to R types. Compatible with\nall versions of 'Python' >= 2.7.",
            "name": "r-reticulate"
        },
        {
            "description": "Friendly Regular Expressions. A friendly interface for the construction\nof regular expressions.",
            "name": "r-rex"
        },
        {
            "description": "A Collection of Efficient and Extremely Fast R Functions. A collection\nof fast (utility) functions for data analysis. Column- and row- wise\nmeans, medians, variances, minimums, maximums, many t, F and G-square\ntests, many regressions (normal, logistic, Poisson), are some of the\nmany fast functions. References: a) Tsagris M., Papadakis M. (2018).\nTaking R to its limits: 70+ tips. PeerJ Preprints 6:e26605v1\n<doi:10.7287/peerj.preprints.26605v1>. b) Tsagris M. and Papadakis M.\n(2018). Forward regression in R: from the extreme slow to the extreme\nfast. Journal of Data Science, 16(4): 771-780.\n<doi:10.6339/JDS.201810_16(4).00006>.",
            "name": "r-rfast"
        },
        {
            "description": "Random Ferns Classifier. Provides the random ferns classifier by\nOzuysal, Calonder, Lepetit and Fua (2009) <doi:10.1109/TPAMI.2009.23>,\nmodified for generic and multi-label classification and featuring OOB\nerror approximation and importance measure as introduced in Kursa (2014)\n<doi:10.18637/jss.v061.i10>.",
            "name": "r-rferns"
        },
        {
            "description": "Bindings for the 'Geospatial' Data Abstraction Library. Provides\nbindings to the 'Geospatial' Data Abstraction Library ('GDAL') (>=\n1.11.4) and access to projection/transformation operations from the\n'PROJ' library. Use is made of classes defined in the 'sp' package.\nRaster and vector map data can be imported into R, and raster and vector\n'sp' objects exported. The 'GDAL' and 'PROJ' libraries are external to\nthe package, and, when installing the package from source, must be\ncorrectly installed first; it is important that 'GDAL' < 3 be matched\nwith 'PROJ' < 6. From 'rgdal' 1.5-8, installed with to 'GDAL' >=3,\n'PROJ' >=6 and 'sp' >= 1.4, coordinate reference systems use 'WKT2_2019'\nstrings, not 'PROJ' strings. 'Windows' and 'macOS' binaries (including\n'GDAL', 'PROJ' and their dependencies) are provided on 'CRAN'.",
            "name": "r-rgdal"
        },
        {
            "description": "R Version of GENetic Optimization Using Derivatives. A genetic algorithm\nplus derivative optimizer.",
            "name": "r-rgenoud"
        },
        {
            "description": "Interface to Geometry Engine - Open Source ('GEOS'). Interface to\nGeometry Engine - Open Source ('GEOS') using the C 'API' for topology\noperations on geometries. The 'GEOS' library is external to the package,\nand, when installing the package from source, must be correctly\ninstalled first. Windows and Mac Intel OS X binaries are provided on\n'CRAN'. ('rgeos' >= 0.5-1): Up to and including 'GEOS' 3.7.1,\ntopological operations succeeded with some invalid geometries for which\nthe same operations fail from and including 'GEOS' 3.7.2. The\n'checkValidity=' argument defaults and structure have been changed, from\ndefault FALSE to integer default '0L' for 'GEOS' < 3.7.2 (no check),\n'1L' 'GEOS' >= 3.7.2 (check and warn). A value of '2L' is also provided\nthat may be used, assigned globally using 'set_RGEOS_CheckValidity(2L)',\nor locally using the 'checkValidity=2L' argument, to attempt zero-width\nbuffer repair if invalid geometries are found. The previous default\n(FALSE, now '0L') is fastest and used for 'GEOS' < 3.7.2, but will not\nwarn users of possible problems before the failure of topological\noperations that previously succeeded. From 'GEOS' 3.8.0, repair of\ngeometries may also be attempted using 'gMakeValid()', which may,\nhowever, return a collection of geometries of different types.",
            "name": "r-rgeos"
        },
        {
            "description": "Build, Import and Export GEXF Graph Files. Create, read and write GEXF\n(Graph Exchange XML Format) graph files (used in Gephi and others).\nUsing the XML package, it allows the user to easily build/read graph\nfiles including attributes, GEXF viz attributes (such as color, size,\nand position), network dynamics (for both edges and nodes) and edge\nweighting. Users can build/handle graphs element-by-element or massively\nthrough data-frames, visualize the graph on a web browser through\n\"sigmajs\" (a javascript library) and interact with the igraph package.",
            "name": "r-rgexf"
        },
        {
            "description": "3D Visualization Using OpenGL. Provides medium to high level functions\nfor 3D interactive graphics, including functions modelled on base\ngraphics (plot3d(), etc.) as well as functions for constructing\nrepresentations of geometric objects (cube3d(), etc.). Output may be on\nscreen using OpenGL, or to various standard 3D file formats including\nWebGL, PLY, OBJ, STL as well as 2D image formats, including PNG,\nPostscript, SVG, PGF.",
            "name": "r-rgl"
        },
        {
            "description": "Overlays on Static Maps. This package serves two purposes: (i) Provide a\ncomfortable R interface to query the Google server for static maps, and\n(ii) Use the map as a background image to overlay plots within R. This\nrequires proper coordinate scaling.",
            "name": "r-rgooglemaps"
        },
        {
            "description": "Provides plotting capabilities for R graph objects. Interfaces R with\nthe AT and T graphviz library for plotting R graph objects from the\ngraph package.",
            "name": "r-rgraphviz"
        },
        {
            "description": "R Interface to HDF5. This package provides an interface between HDF5 and\nR. HDF5's main features are the ability to store and access very large\nand/or complex datasets and a wide variety of metadata on mass storage\n(disk) through a completely portable file format. The rhdf5 package is\nthus suited for the exchange of large and/or complex datasets between R\nand other software package, and for letting R applications work on\ndatasets that are larger than the available RAM.",
            "name": "r-rhdf5"
        },
        {
            "description": "HDF5 Compression Filters. Provides a collection of compression filters\nfor use with HDF5 datasets.",
            "name": "r-rhdf5filters"
        },
        {
            "description": "hdf5 library as an R package. Provides C and C++ hdf5 libraries.",
            "name": "r-rhdf5lib"
        },
        {
            "description": "Utilities Parsing 'HMMER' Results. 'HMMER' is a profile hidden Markov\nmodel tool used primarily for sequence analysis in bioinformatics\n(<http://hmmer.org/>). 'rhmmer' provides utilities for parsing the\n'HMMER' output into tidy data frames.",
            "name": "r-rhmmer"
        },
        {
            "description": "HTSlib high-throughput sequencing library as an R package. This package\nprovides version 1.7 of the 'HTSlib' C library for high- throughput\nsequence analysis. The package is primarily useful to developers of\nother R packages who wish to make use of HTSlib. Motivation and\ninstructions for use of this package are in the vignette,\nvignette(package=\"Rhtslib\", \"Rhtslib\").",
            "name": "r-rhtslib"
        },
        {
            "description": "C++ Classes to Embed R in C++ (and C) Applications. C++ classes to embed\nR in C++ applications The 'RInside' packages makes it easier to have \"R\ninside\" your C++ application by providing a C++ wrapperclass providing\nthe R interpreter. As R itself is embedded into your application, a\nshared library build of R is required. This works on Linux, OS X and\neven on Windows provided you use the same tools used to build R itself.\nNumerous examples are provided in the eight subdirectories of the\nexamples/ directory of the installed package: standard, mpi (for\nparallel computing) qt (showing how to embed 'RInside' inside a Qt GUI\napplication), wt (showing how to build a \"web-application\" using the Wt\ntoolkit), armadillo (for 'RInside' use with 'RcppArmadillo') and eigen\n(for 'RInside' use with 'RcppEigen'). The example use GNUmakefile(s)\nwith GNU extensions, so a GNU make is required (and will use the\nGNUmakefile automatically). Doxygen-generated documentation of the C++\nclasses is available at the 'RInside' website as well.",
            "name": "r-rinside"
        },
        {
            "description": "A Swiss-Army Knife for Data I/O. Streamlined data import and export by\nmaking assumptions that the user is probably willing to make: 'import()'\nand 'export()' determine the data structure from the file extension,\nreasonable defaults are used for data import and export (e.g.,\n'stringsAsFactors=FALSE'), web-based import is natively supported\n(including from SSL/HTTPS), compressed files can be read directly\nwithout explicit decompression, and fast import packages are used where\nappropriate. An additional convenience function, 'convert()', provides a\nsimple method for converting between file types.",
            "name": "r-rio"
        },
        {
            "description": "Bayesian Graphical Models using MCMC. Interface to the JAGS MCMC\nlibrary.",
            "name": "r-rjags"
        },
        {
            "description": "Low-Level R to Java Interface. Low-level interface to Java VM very much\nlike .C/.Call and friends. Allows creation of objects, calling methods\nand accessing fields.",
            "name": "r-rjava"
        },
        {
            "description": "JSON for R. Converts R object into JSON objects and vice-versa.",
            "name": "r-rjson"
        },
        {
            "description": "Serialize R Objects to JSON, JavaScript Object Notation. This is a\npackage that allows conversion to and from data in Javascript object\nnotation (JSON) format. This allows R objects to be inserted into\nJavascript/ECMAScript/ActionScript code and allows R programmers to read\nand convert JSON content to R objects. This is an alternative to rjson\npackage. Originally, that was too slow for converting large R objects to\nJSON and was not extensible. rjson's performance is now similar to this\npackage, and perhaps slightly faster in some cases. This package uses\nmethods and is readily extensible by defining methods for different\nclasses, vectorized operations, and C code and callbacks to R functions\nfor deserializing JSON objects to R. The two packages intentionally\nshare the same basic interface. This package (RJSONIO) has many\nadditional options to allow customizing the generation and processing of\nJSON content. This package uses libjson rather than implementing yet\nanother JSON parser. The aim is to support other general projects by\nbuilding on their work, providing feedback and benefit from their\nongoing development.",
            "name": "r-rjsonio"
        },
        {
            "description": "Functions for Base Types and Core R and 'Tidyverse' Features. A toolbox\nfor working with base types, core R features like the condition system,\nand core 'Tidyverse' features like tidy evaluation.",
            "name": "r-rlang"
        },
        {
            "description": "R package to read and write las and laz files used to store LiDAR data",
            "name": "r-rlas"
        },
        {
            "description": "Common Functions for Run-Length Encoded Vectors. Common 'base' and\n'stats' methods for 'rle' objects, aiming to make it possible to treat\nthem transparently as vectors.",
            "name": "r-rle"
        },
        {
            "description": "Provides a set of functions for data manipulation with list objects,\nincluding mapping, filtering, grouping, sorting, updating, searching,\nand other useful functions. Most functions are designed to be pipeline\nfriendly so that data processing with lists can be chained.",
            "name": "r-rlist"
        },
        {
            "description": "Database Interface and 'MariaDB' Driver. Implements a 'DBI'-compliant\ninterface to 'MariaDB' (<https://mariadb.org/>) and 'MySQL'\n(<https://www.mysql.com/>) databases.",
            "name": "r-rmariadb"
        },
        {
            "description": "Dynamic Documents for R. Convert R Markdown documents into a variety of\nformats.",
            "name": "r-rmarkdown"
        },
        {
            "description": "Data Mining Classification and Regression Methods. Facilitates the use\nof data mining algorithms in classification and regression (including\ntime series forecasting) tasks by presenting a short and coherent set of\nfunctions. Versions: 1.4.6 / 1.4.5 / 1.4.4 new automated machine\nlearning (AutoML) and ensembles, via improved fit(), mining() and\nmparheuristic() functions, and new categorical preprocessing, via\nimproved delevels() function; 1.4.3 new metrics (e.g., macro precision,\nexplained variance), new \"lssvm\" model and improved mparheuristic()\nfunction; 1.4.2 new \"NMAE\" metric, \"xgboost\" and \"cv.glmnet\" models (16\nclassification and 18 regression models); 1.4.1 new tutorial and more\nrobust version; 1.4 - new classification and regression models, with a\ntotal of 14 classification and 15 regression methods, including:\nDecision Trees, Neural Networks, Support Vector Machines, Random\nForests, Bagging and Boosting; 1.3 and 1.3.1 - new classification and\nregression metrics; 1.2 - new input importance methods via improved\nImportance() function; 1.0 - first version.",
            "name": "r-rminer"
        },
        {
            "description": "R MPFR - Multiple Precision Floating-Point Reliable. Arithmetic (via S4\nclasses and methods) for arbitrary precision floating point numbers,\nincluding transcendental (\"special\") functions. To this end, Rmpfr\ninterfaces to the LGPL'ed MPFR (Multiple Precision Floating-Point\nReliable) Library which itself is based on the GMP (GNU Multiple\nPrecision) Library.",
            "name": "r-rmpfr"
        },
        {
            "description": "Interface (Wrapper) to MPI (Message-Passing Interface). An interface\n(wrapper) to MPI APIs. It also provides interactive R manager and worker\nenvironment.",
            "name": "r-rmpi"
        },
        {
            "description": "Regression Modeling Strategies. Regression modeling, testing,\nestimation, validation, graphics, prediction, and typesetting by storing\nenhanced model design attributes in the fit. 'rms' is a collection of\nfunctions that assist with and streamline modeling. It also contains\nfunctions for binary and ordinal logistic regression models, ordinal\nmodels for continuous Y with a variety of distribution families, and the\nBuckley-James multiple regression model for right-censored responses,\nand implements penalized maximum likelihood estimation for logistic and\nordinary linear models. 'rms' works with almost any regression model,\nbut it was especially written to work with binary or ordinal regression\nmodels, Cox regression, accelerated failure time models, ordinary linear\nmodels, the Buckley-James model, generalized least squares for serially\nor spatially correlated observations, generalized linear models, and\nquantile regression.",
            "name": "r-rms"
        },
        {
            "description": "Utilities for Nonlinear Regression and Repeated MeasurementsModels. A\ntoolkit of functions for nonlinear regression and repeated measurements\nnot to be used by itself but called by other Lindsey packages such as\n'gnlm', 'stable', 'growth', 'repeated', and 'event' (available at\n<https://www.commanster.eu/rcode.html>).",
            "name": "r-rmutil"
        },
        {
            "description": "Database Interface and 'MySQL' Driver for R. Legacy 'DBI' interface to\n'MySQL' / 'MariaDB' based on old code ported from S-PLUS. A modern\n'MySQL' client based on 'Rcpp' is available from the 'RMariaDB' package.",
            "name": "r-rmysql"
        },
        {
            "description": "rnaSeq secondary analyses. The rnaSeqMap library provides classes and\nfunctions to analyze the RNA- sequencing data using the coverage\nprofiles in multiple samples at a time",
            "name": "r-rnaseqmap"
        },
        {
            "description": "An Interface to the Nexus Class Library. An interface to the Nexus Class\nLibrary which allows parsing of NEXUS, Newick and other phylogenetic\ntree file formats. It provides elements of the file that can be used to\nbuild phylogenetic objects such as ape's 'phylo' or phylobase's\n'phylo4(d)'. This functionality is demonstrated with\n'read_newick_phylo()' and 'read_nexus_phylo()'.",
            "name": "r-rncl"
        },
        {
            "description": "Semantically Rich I/O for the 'NeXML' Format. Provides access to\nphyloinformatic data in 'NeXML' format. The package should add new\nfunctionality to R such as the possibility to manipulate 'NeXML' objects\nin more various and refined way and compatibility with 'ape' objects.",
            "name": "r-rnexml"
        },
        {
            "description": "Utility Functions for Working with Random Number Generators. Provides a\nset of functions for working with Random Number Generators (RNGs). In\nparticular, a generic S4 framework is defined for getting/setting the\ncurrent RNG, or RNG data that are embedded into objects for\nreproducibility. Notably, convenient default methods greatly facilitate\nthe way current RNG settings can be changed.",
            "name": "r-rngtools"
        },
        {
            "description": "'NOAA' Weather Data from R. Client for many 'NOAA' data sources\nincluding the 'NCDC' climate 'API' at <https://www.ncdc.noaa.gov/cdo-\nweb/webservices/v2>, with functions for each of the 'API' 'endpoints':\ndata, data categories, data sets, data types, locations, location\ncategories, and stations. In addition, we have an interface for 'NOAA'\nsea ice data, the 'NOAA' severe weather inventory, 'NOAA' Historical\nObserving 'Metadata' Repository ('HOMR') data, 'NOAA' storm data via\n'IBTrACS', tornado data via the 'NOAA' storm prediction center, and\nmore.",
            "name": "r-rnoaa"
        },
        {
            "description": "Port of the S+ Robust Library. Methods for robust statistics, a state of\nthe art in the early 2000s, notably for robust regression and robust\nmultivariate analysis.",
            "name": "r-robust"
        },
        {
            "description": "Basic Robust Statistics. \"Essential\" Robust Statistics. Tools allowing\nto analyze data with robust methods. This includes regression\nmethodology including model selections and multivariate statistics where\nwe strive to cover the book \"Robust Statistics, Theory and Methods\" by\n'Maronna, Martin and Yohai'; Wiley 2006.",
            "name": "r-robustbase"
        },
        {
            "description": "utilities for ROC, with microarray focus. Provide utilities for ROC,\nwith microarray focus.",
            "name": "r-roc"
        },
        {
            "description": "Visualizing the Performance of Scoring Classifiers. ROC graphs,\nsensitivity/specificity curves, lift charts, and precision/recall plots\nare popular examples of trade-off visualizations for specific pairs of\nperformance measures. ROCR is a flexible tool for creating cutoff-\nparameterized 2D performance curves by freely combining two from over 25\nperformance measures (new performance measures can be added using a\nstandard interface). Curves from different cross-validation or\nbootstrapping runs can be averaged by different methods, and standard\ndeviations, standard errors or box plots can be used to visualize the\nvariability across the runs. The parameterization can be visualized by\nprinting cutoff values at the corresponding curve positions, or by\ncoloring the curve according to cutoff. All components of a performance\nplot can be quickly adjusted using a flexible parameter dispatching\nmechanism. Despite its flexibility, ROCR is easy to use, with only three\ncommands and reasonable default values for all optional parameters.",
            "name": "r-rocr"
        },
        {
            "description": "ODBC Database Access. An ODBC database interface.",
            "name": "r-rodbc"
        },
        {
            "description": "Rook - a web server interface for R. This package contains the Rook\nspecification and convenience software for building and running Rook\napplications. To get started, be sure and read the 'Rook' help file\nfirst.",
            "name": "r-rook"
        },
        {
            "description": "Reproducibility-Optimized Test Statistic. Calculates the\nReproducibility-Optimized Test Statistic (ROTS) for differential testing\nin omics data.",
            "name": "r-rots"
        },
        {
            "description": "In-Line Documentation for R. Generate your Rd documentation, 'NAMESPACE'\nfile, and collation field using specially formatted comments. Writing\ndocumentation in-line with code makes it easier to keep your\ndocumentation up-to-date as your requirements change. 'Roxygen2' is\ninspired by the 'Doxygen' system for C++.",
            "name": "r-roxygen2"
        },
        {
            "description": "Recursive Partitioning and Regression Trees. Recursive partitioning for\nclassification, regression and survival trees. An implementation of most\nof the functionality of the 1984 book by Breiman, Friedman, Olshen and\nStone.",
            "name": "r-rpart"
        },
        {
            "description": "Plot 'rpart' Models: An Enhanced Version of 'plot.rpart'. Plot 'rpart'\nmodels. Extends plot.rpart() and text.rpart() in the 'rpart' package.",
            "name": "r-rpart-plot"
        },
        {
            "description": "Recursively Partitioned Mixture Model. Recursively Partitioned Mixture\nModel for Beta and Gaussian Mixtures. This is a model-based clustering\nalgorithm that returns a hierarchy of classes, similar to hierarchical\nclustering, but also similar to finite mixture models.",
            "name": "r-rpmm"
        },
        {
            "description": "'Rcpp' Interface to 'PostgreSQL'. Fully 'DBI'-compliant 'Rcpp'-backed\ninterface to 'PostgreSQL' <https://www.postgresql.org/>, an open-source\nrelational database.",
            "name": "r-rpostgres"
        },
        {
            "description": "R Interface to the 'PostgreSQL' Database System. Database interface and\nPostgreSQL driver for R This package provides a Database Interface (DBI)\ncompliant driver for R to access PostgreSQL database systems. In order\nto build and install this package from source, PostgreSQL itself must be\npresent your system to provide PostgreSQL functionality via its\nlibraries and header files. These files are provided as postgresql-devel\npackage under some Linux distributions. On Microsoft Windows system the\nattached libpq library source will be used. A wiki and issue tracking\nsystem for the package are available at Google Code at\nhttps://code.google.com/p/rpostgresql/.",
            "name": "r-rpostgresql"
        },
        {
            "description": "Finding Files in Project Subdirectories. Robust, reliable and flexible\npaths to files below a project root. The 'root' of a project is defined\nas a directory that matches a certain criterion, e.g., it contains a\ncertain regular file.",
            "name": "r-rprojroot"
        },
        {
            "description": "Statistics for psychiatric research. The rpsychi offers a number of\nfunctions for psychiatry, psychiatric nursing, clinical psychology.\nFunctions are primarily for statistical significance testing using\npublished work. For example, you can conduct a factorial analysis of\nvariance (ANOVA), which requires only the mean, standard deviation, and\nsample size for each cell, rather than the individual data. This package\ncovers fundamental statistical tests such as t-test, chi-square test,\nanalysis of variance, and multiple regression analysis. With some\nexceptions, you can obtain effect size and its confidence interval.\nThese functions help you to obtain effect size from published work, and\nthen to conduct a priori power analysis or meta-analysis, even if a\nresearcher do not report effect size in a published work.",
            "name": "r-rpsychi"
        },
        {
            "description": "Ridge Regression and Other Kernels for Genomic Selection. Software for\ngenomic prediction with the RR-BLUP mixed model (Endelman 2011,\n<doi:10.3835/plantgenome2011.08.0024>). One application is to estimate\nmarker effects by ridge regression; alternatively, BLUPs can be\ncalculated based on an additive relationship matrix or a Gaussian\nkernel.",
            "name": "r-rrblup"
        },
        {
            "description": "Scalable Robust Estimators with High Breakdown Point. Robust Location\nand Scatter Estimation and Robust Multivariate Analysis with High\nBreakdown Point: principal component analysis (Filzmoser and Todorov\n(2013), <doi:10.1016/j.ins.2012.10.017>), linear and quadratic\ndiscriminant analysis (Todorov and Pires (2007)), multivariate tests\n(Todorov and Filzmoser (2010) <doi:10.1016/j.csda.2009.08.015>), outlier\ndetection (Todorov et al. (2010) <doi:10.1007/s11634-010-0075-2>). See\nalso Todorov and Filzmoser (2009) <ISBN-13:978-3838108148>, Todorov and\nFilzmoser (2010) <doi:10.18637/jss.v032.i03> and Boudt et al. (2019)\n<doi:10.1007/s11222-019-09869-x>.",
            "name": "r-rrcov"
        },
        {
            "description": "Linear Model Evaluation with Randomized Residuals in a Permutation\nProcedure. Linear model calculations are made for many random versions\nof data. Using residual randomization in a permutation procedure, sums\nof squares are calculated over many permutations to generate empirical\nprobability distributions for evaluating model effects. This packaged is\ndescribed by Collyer & Adams (2018) <doi:10.1111/2041-210X.13029>.\nAdditionally, coefficients, statistics, fitted values, and residuals\ngenerated over many permutations can be used for various procedures\nincluding pairwise tests, prediction, classification, and model\ncomparison. This package should provide most tools one could need for\nthe analysis of high-dimensional data, especially in ecology and\nevolutionary biology, but certainly other fields, as well.",
            "name": "r-rrpp"
        },
        {
            "description": "Binary alignment (BAM), FASTA, variant call (BCF), and tabix file\nimport. This package provides an interface to the 'samtools',\n'bcftools', and 'tabix' utilities for manipulating SAM (Sequence\nAlignment / Map), FASTA, binary variant call (BCF) and compressed\nindexed tab-delimited (tabix) files.",
            "name": "r-rsamtools"
        },
        {
            "description": "Deployment Interface for R Markdown Documents and Shiny Applications.\nProgrammatic deployment interface for 'RPubs', 'shinyapps.io', and\n'RStudio Connect'. Supported content types include R Markdown documents,\nShiny applications, Plumber APIs, plots, and static web content.",
            "name": "r-rsconnect"
        },
        {
            "description": "Neural Networks using the Stuttgart Neural Network Simulator (SNNS). The\nStuttgart Neural Network Simulator (SNNS) is a library containing many\nstandard implementations of neural networks. This package wraps the SNNS\nfunctionality to make it available from within R. Using the RSNNS low-\nlevel interface, all of the algorithmic functionality and flexibility of\nSNNS can be accessed. Furthermore, the package contains a convenient\nhigh-level interface, so that the most common neural network topologies\nand learning algorithms integrate seamlessly into R.",
            "name": "r-rsnns"
        },
        {
            "description": "General Non-Linear Optimization. General Non-linear Optimization Using\nAugmented Lagrange Multiplier Method.",
            "name": "r-rsolnp"
        },
        {
            "description": "Solvers for Large-Scale Eigenvalue and SVD Problems. R interface to the\n'Spectra' library <https://spectralib.org/> for large-scale eigenvalue\nand SVD problems. It is typically used to compute a few\neigenvalues/vectors of an n by n matrix, e.g., the k largest\neigenvalues, which is usually more efficient than eigen() if k << n.\nThis package provides the 'eigs()' function that does the similar job as\nin 'Matlab', 'Octave', 'Python SciPy' and 'Julia'. It also provides the\n'svds()' function to calculate the largest k singular values and\ncorresponding singular vectors of a real matrix. The matrix to be\ncomputed on can be dense, sparse, or in the form of an operator defined\nby the user.",
            "name": "r-rspectra"
        },
        {
            "description": "'SQLite' Interface for R. This package embeds the SQLite database engine\nin R and provides an interface compliant with the DBI package. The\nsource for the SQLite engine (version 3.8.6) is included.",
            "name": "r-rsqlite"
        },
        {
            "description": "R Interface to Stan. User-facing R functions are provided to parse,\ncompile, test, estimate, and analyze Stan models by accessing the\nheader-only Stan library provided by the 'StanHeaders' package. The Stan\nproject develops a probabilistic programming language that implements\nfull Bayesian statistical inference via Markov Chain Monte Carlo, rough\nBayesian inference via variational approximation, and (optionally\npenalized) maximum likelihood estimation via optimization. In all three\ncases, automatic differentiation is used to quickly and accurately\nevaluate gradients without burdening the user with the need to derive\nthe partial derivatives.",
            "name": "r-rstan"
        },
        {
            "description": "Tools for Developing R Packages Interfacing with 'Stan'. Provides\nvarious tools for developers of R packages interfacing with 'Stan'\n<https://mc-stan.org>, including functions to set up the required\npackage structure, S3 generics and default methods to unify function\nnaming across 'Stan'-based R packages, and vignettes with\nrecommendations for developers.",
            "name": "r-rstantools"
        },
        {
            "description": "Pipe-Friendly Framework for Basic Statistical Tests. Provides a simple\nand intuitive pipe-friendly framework, coherent with the 'tidyverse'\ndesign philosophy, for performing basic statistical tests, including\nt-test, Wilcoxon test, ANOVA, Kruskal-Wallis and correlation analyses.\nThe output of each test is automatically transformed into a tidy data\nframe to facilitate visualization. Additional functions are available\nfor reshaping, reordering, manipulating and visualizing correlation\nmatrix. Functions are also included to facilitate the analysis of\nfactorial experiments, including purely 'within-Ss' designs (repeated\nmeasures), purely 'between-Ss' designs, and mixed 'within-and-between-\nSs' designs. It's also possible to compute several effect size metrics,\nincluding \"eta squared\" for ANOVA, \"Cohen's d\" for t-test and 'Cramer V'\nfor the association between categorical variables. The package contains\nhelper functions for identifying univariate and multivariate outliers,\nassessing normality and homogeneity of variances.",
            "name": "r-rstatix"
        },
        {
            "description": "Safely Access the RStudio API. Access the RStudio API (if available) and\nprovide informative error messages when it's not.",
            "name": "r-rstudioapi"
        },
        {
            "description": "Mapping, quantification and variant analysis of sequencing data",
            "name": "r-rsubread"
        },
        {
            "description": "Randomized Singular Value Decomposition. Low-rank matrix decompositions\nare fundamental tools and widely used for data analysis, dimension\nreduction, and data compression. Classically, highly accurate\ndeterministic matrix algorithms are used for this task. However, the\nemergence of large-scale data has severely challenged our computational\nability to analyze big data. The concept of randomness has been\ndemonstrated as an effective strategy to quickly produce approximate\nanswers to familiar problems such as the singular value decomposition\n(SVD). The rsvd package provides several randomized matrix algorithms\nsuch as the randomized singular value decomposition (rsvd), randomized\nprincipal component analysis (rpca), randomized robust principal\ncomponent analysis (rrpca), randomized interpolative decomposition\n(rid), and the randomized CUR decomposition (rcur). In addition several\nplot functions are provided. The methods are discussed in detail by\nErichson et al. (2016) <arXiv:1608.02148>.",
            "name": "r-rsvd"
        },
        {
            "description": "R interface to genome annotation files and the UCSC genome browser.\nExtensible framework for interacting with multiple genome browsers\n(currently UCSC built-in) and manipulating annotation tracks in various\nformats (currently GFF, BED, bedGraph, BED15, WIG, BigWig and 2bit\nbuilt-in). The user may export/import tracks to/from the supported\nbrowsers, as well as query and modify the browser state, such as the\ncurrent viewport.",
            "name": "r-rtracklayer"
        },
        {
            "description": "T-Distributed Stochastic Neighbor Embedding using a Barnes-Hut\nImplementation. An R wrapper around the fast T-distributed Stochastic\nNeighbor Embedding implementation.",
            "name": "r-rtsne"
        },
        {
            "description": "R Unit Test Framework. R functions implementing a standard Unit Testing\nframework, with additional code inspection and report generation tools.",
            "name": "r-runit"
        },
        {
            "description": "Interface Utilities, Model Templates, Parallel Computing Methods and\nAdditional Distributions for MCMC Models in JAGS. User-friendly\ninterface utilities for MCMC models via Just Another Gibbs Sampler\n(JAGS), facilitating the use of parallel (or distributed) processors for\nmultiple chains, automated control of convergence and sample length\ndiagnostics, and evaluation of the performance of a model using drop-k\nvalidation or against simulated data. Template model specifications can\nbe generated using a standard lme4-style formula interface to assist\nusers less familiar with the BUGS syntax. A JAGS extension module\nprovides additional distributions including the Pareto family of\ndistributions, the DuMouchel prior and the half-Cauchy prior.",
            "name": "r-runjags"
        },
        {
            "description": "Detect and Remove Unwanted Variation using Negative Controls. Implements\nthe 'RUV' (Remove Unwanted Variation) algorithms. These algorithms\nattempt to adjust for systematic errors of unknown origin in high-\ndimensional data. The algorithms were originally developed for use with\ngenomic data, especially microarray data, but may be useful with other\ntypes of high-dimensional data as well. These algorithms were proposed\nin Gagnon-Bartsch and Speed (2012) <doi:10.1093/nar/gkz433>, Gagnon-\nBartsch, Jacob and Speed (2013), and Molania, et. al. (2019)\n<doi:10.1093/nar/gkz433>. The algorithms require the user to specify a\nset of negative control variables, as described in the references. The\nalgorithms included in this package are 'RUV-2', 'RUV-4', 'RUV-inv',\n'RUV-rinv', 'RUV-I', and RUV-III', along with various supporting\nalgorithms.",
            "name": "r-ruv"
        },
        {
            "description": "R/Package Version Check. Check latest release version of R and R package\n(both in 'CRAN', 'Bioconductor' or 'Github').",
            "name": "r-rvcheck"
        },
        {
            "description": "Query 'R' Versions, Including 'r-release' and 'r-oldrel'. Query the main\n'R' 'SVN' repository to find the versions 'r-release' and 'r-oldrel'\nrefer to, and also all previous 'R' versions and their release dates.",
            "name": "r-rversions"
        },
        {
            "description": "Easily Harvest (Scrape) Web Pages. Wrappers around the 'xml2' and 'httr'\npackages to make it easy to download, then manipulate, HTML and XML.",
            "name": "r-rvest"
        },
        {
            "description": "'ViennaCL' C++ Header Files. 'ViennaCL' is a free open-source linear\nalgebra library for computations on many-core architectures (GPUs, MIC)\nand multi-core CPUs. The library is written in C++ and supports 'CUDA',\n'OpenCL', and 'OpenMP' (including switches at runtime). I have placed\nthese libraries in this package as a more efficient distribution system\nfor CRAN. The idea is that you can write a package that depends on the\n'ViennaCL' library and yet you do not need to distribute a copy of this\ncode with your package.",
            "name": "r-rviennacl"
        },
        {
            "description": "R Bindings for 'ZeroMQ'. Interface to the 'ZeroMQ' lightweight messaging\nkernel (see <http://www.zeromq.org/> for more information).",
            "name": "r-rzmq"
        },
        {
            "description": "Spherical Geometry Operators Using the S2 Geometry Library. Provides R\nbindings for Google's s2 library for geometric calculations on the\nsphere. High-performance constructors and exporters provide high\ncompatibility with existing spatial packages, transformers construct new\ngeometries from existing geometries, predicates provide a means to\nselect geometries based on spatial relationships, and accessors extract\ninformation about geometries.",
            "name": "r-s2"
        },
        {
            "description": "Foundation of vector-like and list-like containers in Bioconductor. The\nS4Vectors package defines the Vector and List virtual classes and a set\nof generic functions that extend the semantic of ordinary vectors and\nlists in R. Package developers can easily implement vector-like or list-\nlike objects as concrete subclasses of Vector or List. In addition, a\nfew low-level concrete subclasses of general interest (e.g. DataFrame,\nRle, and Hits) are implemented in the S4Vectors package itself (many\nmore are implemented in the IRanges package and in other Bioconductor\ninfrastructure packages).",
            "name": "r-s4vectors"
        },
        {
            "description": "SAM: Significance Analysis of Microarrays. Significance Analysis of\nMicroarrays for differential expression analysis, RNAseq data and\nrelated problems.",
            "name": "r-samr"
        },
        {
            "description": "Robust Covariance Matrix Estimators. Object-oriented software for model-\nrobust covariance matrix estimators. Starting out from the basic robust\nEicker-Huber-White sandwich covariance methods include:\nheteroscedasticity-consistent (HC) covariances for cross-section data;\nheteroscedasticity- and autocorrelation-consistent (HAC) covariances for\ntime series data (such as Andrews' kernel HAC, Newey-West, and WEAVE\nestimators); clustered covariances (one-way and multi-way); panel and\npanel-corrected covariances; outer-product-of-gradients covariances; and\n(clustered) bootstrap covariances. All methods are applicable to\n(generalized) linear model objects fitted by lm() and glm() but can also\nbe adapted to other classes through S3 methods. Details can be found in\nZeileis et al. (2020) <doi:10.18637/jss.v095.i01>, Zeileis (2004)\n<doi:10.18637/jss.v011.i10> and Zeileis (2006)\n<doi:10.18637/jss.v016.i09>.",
            "name": "r-sandwich"
        },
        {
            "description": "Syntactically Awesome Style Sheets ('Sass'). An 'SCSS' compiler, powered\nby the 'LibSass' library. With this, R developers can use variables,\ninheritance, and functions to generate dynamic style sheets. The package\nuses the 'Sass CSS' extension language, which is stable, powerful, and\nCSS compatible.",
            "name": "r-sass"
        },
        {
            "description": "Handling and Manipulating Remote Sensing Data. Herein, we provide a\nbroad variety of functions which are useful for handling, manipulating,\nand visualizing satellite-based remote sensing data. These operations\nrange from mere data import and layer handling (eg subsetting), over\nRaster* typical data wrangling (eg crop, extend), to more sophisticated\n(pre-)processing tasks typically applied to satellite imagery (eg\natmospheric and topographic correction). This functionality is\ncomplemented by a full access to the satellite layers' metadata at any\nstage and the documentation of performed actions in a separate log file.\nCurrently available sensors include Landsat 4-5 (TM), 7 (ETM+), and 8\n(OLI/TIRS Combined), and additional compatibility is ensured for the\nLandsat Global Land Survey data set.",
            "name": "r-satellite"
        },
        {
            "description": "Creating a DelayedMatrix of Scaled and Centered Values. Provides delayed\ncomputation of a matrix of scaled and centered values. The result is\nequivalent to using the scale() function but avoids explicit realization\nof a dense matrix during block processing. This permits greater\nefficiency in common operations, most notably matrix multiplication.",
            "name": "r-scaledmatrix"
        },
        {
            "description": "Scale Functions for Visualization. Graphical scales map data to\naesthetics, and provide methods for automatically determining breaks and\nlabels for axes and legends.",
            "name": "r-scales"
        },
        {
            "description": "Single-Cell Analysis Toolkit for Gene Expression Data in R. A collection\nof tools for doing various analyses of single-cell RNA-seq gene\nexpression data, with a focus on quality control and visualization.",
            "name": "r-scater"
        },
        {
            "description": "Scatterplots with More Points. C-based conversion of large scatterplot\ndata to rasters. Speeds up plotting of data with millions of points.",
            "name": "r-scattermore"
        },
        {
            "description": "Scatter Pie Plot. Creates scatterpie plots, especially useful for\nplotting pies on a map.",
            "name": "r-scatterpie"
        },
        {
            "description": "3D Scatter Plot. Plots a three dimensional (3D) point cloud.",
            "name": "r-scatterplot3d"
        },
        {
            "description": "The scDblFinder package gathers various methods for the detection and\nhandling of doublets/multiplets in single-cell sequencing data (i.e.\nmultiple cells captured within the same droplet or reaction volume). It\nincludes methods formerly found in the scran package, the new fast and\ncomprehensive scDblFinder method, and a reimplementation of the Amulet\ndetection method for single-cell ATAC-seq.",
            "name": "r-scdblfinder"
        },
        {
            "description": "Methods for Single-Cell RNA-Seq Data Analysis. Implements miscellaneous\nfunctions for interpretation of single-cell RNA-seq data. Methods are\nprovided for assignment of cell cycle phase, detection of highly\nvariable and significantly correlated genes, identification of marker\ngenes, and other common tasks in routine single-cell analysis workflows.",
            "name": "r-scran"
        },
        {
            "description": "Analysis of High-Dimensional Categorical Data Such as SNP Data. Tools\nfor the analysis of high-dimensional data developed/implemented at the\ngroup \"Statistical Complexity Reduction In Molecular Epidemiology\"\n(SCRIME). Main focus is on SNP data. But most of the functions can also\nbe applied to other types of categorical data.",
            "name": "r-scrime"
        },
        {
            "description": "Splitting Conic Solver. Solves convex cone programs via operator\nsplitting. Can solve: linear programs ('LPs'), second-order cone\nprograms ('SOCPs'), semidefinite programs ('SDPs'), exponential cone\nprograms ('ECPs'), and power cone programs ('PCPs'), or problems with\nany combination of those cones. 'SCS' uses 'AMD' (a set of routines for\npermuting sparse matrices prior to factorization) and 'LDL' (a sparse\n'LDL' factorization and solve package) from 'SuiteSparse'\n(<https://people.engr.tamu.edu/davis/suitesparse.html>).",
            "name": "r-scs"
        },
        {
            "description": "Variance Stabilizing Transformations for Single Cell UMI Data. A\nnormalization method for single-cell UMI count data using a variance\nstabilizing transformation. The transformation is based on a negative\nbinomial regression model with regularized parameters. As part of the\nsame regression framework, this package also provides functions for\nbatch correction, and data correction. See Hafemeister and Satija 2019\n<doi:10.1101/576827> for more details.",
            "name": "r-sctransform"
        },
        {
            "description": "Single-Cell RNA-Seq Analysis Utilities. Provides basic utility functions\nfor performing single-cell analyses, focusing on simple normalization,\nquality control and data transformations. Also provides some helper\nfunctions to assist development of other packages.",
            "name": "r-scuttle"
        },
        {
            "description": "Species Distribution Modelling Tools: Tools for processing data\nassociated with species distribution modelling exercises. This packages\nprovides a set of tools for post processing the outcomes of species\ndistribution modeling exercises. It includes novel methods for comparing\nmodels and tracking changes in distributions through time. It further\nincludes methods for visualizing outcomes, selecting thresholds,\ncalculating measures of accuracy and landscape fragmentation statistics,\netc.. This package was made possible in part by financial support from\nthe Australian Research Council & ARC Research Network for Earth System\nScience.",
            "name": "r-sdmtools"
        },
        {
            "description": "Regression Models with Break-Points / Change-Points Estimation. Given a\nregression model, segmented 'updates' it by adding one or more segmented\n(i.e., piece-wise linear) relationships. Several variables with multiple\nbreakpoints are allowed. The estimation method is discussed in Muggeo\n(2003, <doi:10.1002/sim.1545>) and illustrated in Muggeo (2008,\n<https://www.r-project.org/doc/Rnews/Rnews_2008-1.pdf>). An approach for\nhypothesis testing is presented in Muggeo (2016,\n<doi:10.1080/00949655.2016.1149855>), and interval estimation for the\nbreakpoint is discussed in Muggeo (2017, <doi:10.1111/anzs.12200>).",
            "name": "r-segmented"
        },
        {
            "description": "Translate CSS Selectors to XPath Expressions. Translates a CSS3 selector\ninto an equivalent XPath expression. This allows us to use CSS selectors\nwhen working with the XML package as it can only evaluate XPath\nexpressions. Also provided are convenience functions useful for using\nCSS selectors on XML nodes. This package is a port of the Python package\n'cssselect' (<https://cssselect.readthedocs.io/>).",
            "name": "r-selectr"
        },
        {
            "description": "Biological Sequences Retrieval and Analysis. Exploratory data analysis\nand data visualization for biological sequence (DNA and protein) data.\nSeqinr includes utilities for sequence data management under the ACNUC\nsystem described in Gouy, M. et al. (1984) Nucleic Acids Res. 12:121-127\n<doi:10.1093/nar/12.1Part1.121>.",
            "name": "r-seqinr"
        },
        {
            "description": "Sequence logos for DNA sequence alignments. seqLogo takes the position\nweight matrix of a DNA sequence motif and plots the corresponding\nsequence logo as introduced by Schneider and Stephens (1990).",
            "name": "r-seqlogo"
        },
        {
            "description": "A Simple HTTP Server to Serve Static Files or Dynamic Documents. Start\nan HTTP server in R to serve static files, or dynamic documents that can\nbe converted to HTML files (e.g., R Markdown) under a given directory.",
            "name": "r-servr"
        },
        {
            "description": "R Session Information. Query and print information about the current R\nsession. It is similar to 'utils::sessionInfo()', but includes more\ninformation about packages, and where they were installed from.",
            "name": "r-sessioninfo"
        },
        {
            "description": "Sets, Generalized Sets, Customizable Sets and Intervals Data structures\nand basic operations for ordinary sets, generalizations such as fuzzy\nsets, multisets, and fuzzy multisets, customizable sets, and intervals.",
            "name": "r-sets"
        },
        {
            "description": "Tools for Single Cell Genomics. A toolkit for quality control, analysis,\nand exploration of single cell RNA sequencing data. 'Seurat' aims to\nenable users to identify and interpret sources of heterogeneity from\nsingle cell transcriptomic measurements, and to integrate diverse types\nof single cell data. See Satija R, Farrell J, Gennert D, et al (2015)\n<doi:10.1038/nbt.3192>, Macosko E, Basu A, Satija R, et al (2015)\n<doi:10.1016/j.cell.2015.05.002>, and Stuart T, Butler A, et al (2019)\n<doi:10.1016/j.cell.2019.05.031> for more details.",
            "name": "r-seurat"
        },
        {
            "description": "Data Structures for Single Cell Data. Defines S4 classes for single-cell\ngenomic data and associated information, such as dimensionality\nreduction embeddings, nearest-neighbor graphs, and spatially-resolved\ncoordinates. Provides data access methods and R-native hooks to ensure\nthe Seurat object is familiar to other R users. See Satija R, Farrell J,\nGennert D, et al (2015) <doi:10.1038/nbt.3192>, Macosko E, Basu A,\nSatija R, et al (2015) <doi:10.1016/j.cell.2015.05.002>, and Stuart T,\nButler A, et al (2019) <doi:10.1016/j.cell.2019.05.031> for more\ndetails.",
            "name": "r-seuratobject"
        },
        {
            "description": "Simple Features for R. Support for simple features, a standardized way\nto encode spatial vector data. Binds to 'GDAL' for reading and writing\ndata, to 'GEOS' for geometrical operations, and to 'PROJ' for projection\nconversions and datum transformations. Optionally uses the 's2' package\nfor spherical geometry operations on geographic coordinates.",
            "name": "r-sf"
        },
        {
            "description": "Converts Between R Objects and Simple Feature Objects. Converts between\nR and Simple Feature 'sf' objects, without depending on the Simple\nFeature library. Conversion functions are available at both the R level,\nand through 'Rcpp'.",
            "name": "r-sfheaders"
        },
        {
            "description": "Utilities from 'Seminar fuer Statistik' ETH Zurich. Useful utilities\n['goodies'] from Seminar fuer Statistik ETH Zurich, some of which were\nported from S-plus in the 1990s.; For graphics, have pretty (Log-scale)\naxes, an enhanced Tukey-Anscombe plot, combining histogram and boxplot,\n2d-residual plots, a 'tachoPlot()', pretty arrows, etc.; For robustness,\nhave a robust F test and robust range().; For system support, notably on\nLinux, provides 'Sys.*()' functions with more access to system and CPU\ninformation.; Finally, miscellaneous utilities such as simple efficient\nprime numbers, integer codes, Duplicated(), toLatex.numeric() and\nis.whole().",
            "name": "r-sfsmisc"
        },
        {
            "description": "Classes and Methods for Simple Feature Objects that Have a Time Column.\nClasses and methods for spatial objects that have a registered time\ncolumn, in particular for irregular spatiotemporal data. The time column\ncan be of any type, but needs to be ordinal. Regularly laid out\nspatiotemporal data (vector or raster data cubes) are handled by package\n'stars'.",
            "name": "r-sftime"
        },
        {
            "description": "Shadow Text Grob and Layer. Implement shadowtextGrob() for 'grid' and\ngeom_shadowtext() layer for 'ggplot2'. These functions create/draw text\ngrob with background shadow.",
            "name": "r-shadowtext"
        },
        {
            "description": "Functions for Plotting Graphical Shapes, Colors. Functions for plotting\ngraphical shapes such as ellipses, circles, cylinders, arrows, ...",
            "name": "r-shape"
        },
        {
            "description": "Web Application Framework for R. Makes it incredibly easy to build\ninteractive web applications with R. Automatic \"reactive\" binding\nbetween inputs and outputs and extensive pre-built widgets make it\npossible to build beautiful, responsive, and powerful applications with\nminimal effort.",
            "name": "r-shiny"
        },
        {
            "description": "Create Dashboards with 'Shiny'. Create dashboards with 'Shiny'. This\npackage provides a theme on top of 'Shiny', making it easy to create\nattractive dashboards.",
            "name": "r-shinydashboard"
        },
        {
            "description": "A Server-Side File System Viewer for Shiny. Provides functionality for\nclient-side navigation of the server side file system in shiny apps. In\ncase the app is running locally this gives the user direct access to the\nfile system without the need to \"download\" files to a temporary\nlocation. Both file and folder selection as well as file saving is\navailable.",
            "name": "r-shinyfiles"
        },
        {
            "description": "Easily Improve the User Experience of Your Shiny Apps in Seconds.\nPerform common useful JavaScript operations in Shiny apps that will\ngreatly improve your apps without having to know any JavaScript.\nExamples include: hiding an element, disabling an input, resetting an\ninput back to its original value, delaying code execution by a few\nseconds, and many more useful functions for both the end user and the\ndeveloper. 'shinyjs' can also be used to easily call your own custom\nJavaScript functions from R.",
            "name": "r-shinyjs"
        },
        {
            "description": "Interactive Visual and Numerical Diagnostics and Posterior Analysis for\nBayesian Models. A graphical user interface for interactive Markov chain\nMonte Carlo (MCMC) diagnostics and plots and tables helpful for\nanalyzing a posterior sample. The interface is powered by the 'Shiny'\nweb application framework from 'RStudio' and works with the output of\nMCMC programs written in any programming language (and has extended\nfunctionality for 'Stan' models fit using the 'rstan' and 'rstanarm'\npackages).",
            "name": "r-shinystan"
        },
        {
            "description": "Themes for Shiny. Themes for use with Shiny. Includes several Bootstrap\nthemes from <https://bootswatch.com/>, which are packaged for use with\nShiny applications.",
            "name": "r-shinythemes"
        },
        {
            "description": "FASTQ input and manipulation. This package implements sampling,\niteration, and input of FASTQ files. The package includes functions for\nfiltering and trimming reads, and for generating a quality assessment\nreport. Data are represented as DNAStringSet-derived objects, and easily\nmanipulated for a diversity of purposes. The package also contains\nlegacy support for early single-end, ungapped alignment formats.",
            "name": "r-shortread"
        },
        {
            "description": "Multiple Testing using SAM and Efron's Empirical Bayes Approaches.\nIdentification of differentially expressed genes and estimation of the\nFalse Discovery Rate (FDR) using both the Significance Analysis of\nMicroarrays (SAM) and the Empirical Bayes Analyses of Microarrays\n(EBAM).",
            "name": "r-siggenes"
        },
        {
            "description": "Analysis of Single-Cell Chromatin Data. A framework for the analysis and\nexploration of single-cell chromatin data. The 'Signac' package contains\nfunctions for quantifying single-cell chromatin data, computing per-cell\nquality control metrics, dimension reduction and normalization,\nvisualization, and DNA sequence motif analysis. Reference: Stuart et al.\n(2021) <doi:10.1038/s41592-021-01282-5>.",
            "name": "r-signac"
        },
        {
            "description": "Very simple high level analysis of Affymetrix data. Provides high level\nfunctions for reading Affy .CEL files, phenotypic data, and then\ncomputing simple things with it, such as t-tests, fold changes and the\nlike. Makes heavy use of the affy library. Also has some basic scatter\nplot functions and mechanisms for generating high resolution journal\nfigures...",
            "name": "r-simpleaffy"
        },
        {
            "description": "S4 Classes for Single Cell Data. Defines a S4 class for storing data\nfrom single-cell experiments. This includes specialized methods to store\nand retrieve spike-in information, dimensionality reduction coordinates\nand size factors for each cell, along with the usual metadata for genes\nand libraries.",
            "name": "r-singlecellexperiment"
        },
        {
            "description": "Parallel Pseudo Random Number Generator (PPRNG) 'sitmo' Header Files.\nProvided within are two high quality and fast PPRNGs that may be used in\nan 'OpenMP' parallel environment. In addition, there is a generator for\none dimensional low-discrepancy sequence. The objective of this library\nto consolidate the distribution of the 'sitmo' (C++98 & C++11),\n'threefry' and 'vandercorput' (C++11-only) engines on CRAN by enabling\nothers to link to the header files inside of 'sitmo' instead of\nincluding a copy of each engine within their individual package. Lastly,\nthe package contains example implementations using the 'sitmo' package\nand three accompanying vignette that provide additional information.",
            "name": "r-sitmo"
        },
        {
            "description": "Smoothing Methods for Nonparametric Regression and Density Estimation.\nThis is software linked to the book 'Applied Smoothing Techniques for\nData Analysis - The Kernel Approach with S-Plus Illustrations' Oxford\nUniversity Press.",
            "name": "r-sm"
        },
        {
            "description": "Single and Multi-Objective Optimization Test Functions. Provides\ngenerators for a high number of both single- and multi- objective test\nfunctions which are frequently used for the benchmarking of (numerical)\noptimization algorithms. Moreover, it offers a set of convenient\nfunctions to generate, plot and work with objective functions.",
            "name": "r-smoof"
        },
        {
            "description": "The Skew-Normal and Related Distributions Such as the Skew-t. Build and\nmanipulate probability distributions of the skew-normal family and some\nrelated ones, notably the skew-t family, and provide related statistical\nmethods for data fitting and diagnostics, in the univariate and the\nmultivariate case.",
            "name": "r-sn"
        },
        {
            "description": "Convert Strings into any Case. A consistent, flexible and easy to use\ntool to parse and convert strings into cases like snake or camel among\nothers.",
            "name": "r-snakecase"
        },
        {
            "description": "Simple Network of Workstations. Support for simple parallel computing in\nR.",
            "name": "r-snow"
        },
        {
            "description": "Easier cluster computing (based on snow). Usability wrapper around snow\nfor easier development of parallel R programs. This package offers e.g.\nextended error checks, and additional functions. All functions work in\nsequential mode, too, if no cluster is present or wished. Package is\nalso designed as connector to the cluster management tool sfCluster, but\ncan also used without it.",
            "name": "r-snowfall"
        },
        {
            "description": "Parallel Computing Toolset for Relatedness and Principal Component\nAnalysis of SNP Data. Genome-wide association studies (GWAS) are widely\nused to investigate the genetic basis of diseases and traits, but they\npose many computational challenges. We developed an R package SNPRelate\nto provide a binary format for single-nucleotide polymorphism (SNP) data\nin GWAS utilizing CoreArray Genomic Data Structure (GDS) data files. The\nGDS format offers the efficient operations specifically designed for\nintegers with two bits, since a SNP could occupy only two bits.\nSNPRelate is also designed to accelerate two key computations on SNP\ndata using parallel computing for multi-core symmetric multiprocessing\ncomputer architectures: Principal Component Analysis (PCA) and\nrelatedness analysis using Identity-By-Descent measures. The SNP GDS\nformat is also used by the GWASTools package with the support of S4\nclasses and generic functions. The extended GDS format is implemented in\nthe SeqArray package to support the storage of single nucleotide\nvariations (SNVs), insertion/deletion polymorphism (indel) and\nstructural variation calls.",
            "name": "r-snprelate"
        },
        {
            "description": "SnpMatrix and XSnpMatrix classes and methods. Classes and statistical\nmethods for large SNP association studies. This extends the earlier\nsnpMatrix package, allowing for uncertainty in genotypes.",
            "name": "r-snpstats"
        },
        {
            "description": "Self-Organizing Map. Self-Organizing Map (with application in gene\nclustering).",
            "name": "r-som"
        },
        {
            "description": "Somatic Signatures. The SomaticSignatures package identifies mutational\nsignatures of single nucleotide variants (SNVs). It provides a\ninfrastructure related to the methodology described in Nik-Zainal (2012,\nCell), with flexibility in the matrix decomposition algorithms.",
            "name": "r-somaticsignatures"
        },
        {
            "description": "Tools for Reading, Tokenizing and Parsing R Code. Tools for the reading\nand tokenization of R code. The 'sourcetools' package provides both an R\nand C++ interface for the tokenization of R code, and helpers for\ninteracting with the tokenized representation of R code.",
            "name": "r-sourcetools"
        },
        {
            "description": "Classes and Methods for Spatial Data. Classes and methods for spatial\ndata; the classes document where the spatial location information\nresides, for 2D or 3D data. Utility functions are provided, e.g. for\nplotting data as maps, spatial selection, as well as methods for\nretrieving coordinates, for subsetting, print, summary, etc.",
            "name": "r-sp"
        },
        {
            "description": "Classes and Methods for Spatio-Temporal Data. Classes and methods for\nspatio-temporal data, including space-time regular lattices, sparse\nlattices, irregular data, and trajectories; utility functions for\nplotting data as map sequences (lattice or animation) or multiple time\nseries; methods for spatial and temporal selection and subsetting, as\nwell as for spatial/temporal/spatio-temporal matching or aggregation,\nretrieving coordinates, print, summary, etc.",
            "name": "r-spacetime"
        },
        {
            "description": "Develop and Run Spatially Explicit Discrete Event Simulation Models.\nMetapackage for implementing a variety of event-based models, with a\nfocus on spatially explicit models. These include raster-based, event-\nbased, and agent-based models. The core simulation components (provided\nby 'SpaDES.core') are built upon a discrete event simulation (DES; see\nMatloff (2011) ch 7.8.3 <https://nostarch.com/artofr.htm>) framework\nthat facilitates modularity, and easily enables the user to include\nadditional functionality by running user-built simulation modules (see\nalso 'SpaDES.tools'). Included are numerous tools to visualize rasters\nand other maps (via 'quickPlot'), and caching methods for reproducible\nsimulations (via 'reproducible'). Tools for running simulation\nexperiments are provided by 'SpaDES.experiment'. Additional\nfunctionality is provided by the 'SpaDES.addins' and 'SpaDES.shiny'\npackages.",
            "name": "r-spades"
        },
        {
            "description": "Development Tools for 'SpaDES' and 'SpaDES' Modules. Provides 'RStudio'\naddins for 'SpaDES' packages and 'SpaDES' module development. See\n'?SpaDES.addins' for an overview of the tools provided.",
            "name": "r-spades-addins"
        },
        {
            "description": "Utilities for Developing and Running Spatially Explicit Discrete Event\nModels. Provides the core framework for a discrete event system (DES) to\nimplement acomplete data-to-decisions, reproducible workflow. The core\nDES components facilitate modularity, and easily enable the user to\ninclude additional functionality by running user-built modules. Includes\nconditional scheduling, restart after interruption, packaging of\nreusable modules, tools for developing arbitrary automated workflows,\nautomated interweaving of modules of different temporal resolution, and\ntools for visualizing and understanding the DES project.",
            "name": "r-spades-core"
        },
        {
            "description": "Tools for Spatially Explicit Discrete Event Simulation (SpaDES) Models.\nProvides GIS and map utilities, plus additional modeling tools for\ndeveloping cellular automata, dynamic raster models, and agent based\nmodels in 'SpaDES'. Included are various methods for spatial spreading,\nspatial agents, GIS operations, random map generation, and others. See\n'?SpaDES.tools' for an categorized overview of these additional tools.",
            "name": "r-spades-tools"
        },
        {
            "description": "SPArse Matrix. Set of functions for sparse matrix algebra. Differences\nwith other sparse matrix packages are: (1) we only support (essentially)\none sparse matrix format, (2) based on transparent and simple\nstructure(s), (3) tailored for MCMC calculations within G(M)RF. (4) and\nit is fast and scalable (with the extension package spam64).\nDocumentation about 'spam' is provided by vignettes included in this\npackage, see also Furrer and Sain (2010) <doi:10.18637/jss.v036.i10>;\nsee 'citation(\"spam\")' for details.",
            "name": "r-spam"
        },
        {
            "description": "Sparse Linear Algebra. Some basic linear algebra functionality for\nsparse matrices is provided: including Cholesky decomposition and\nbacksolving as well as standard R subsetting and Kronecker products.",
            "name": "r-sparsem"
        },
        {
            "description": "Summary Statistics for Rows and Columns of Sparse Matrices. High\nperformance functions for row and column operations on sparse matrices.\nFor example: col / rowMeans2, col / rowMedians, col / rowVars etc.\nCurrently, the optimizations are limited to data in the column sparse\nformat. This package is inspired by the matrixStats package by Henrik\nBengtsson.",
            "name": "r-sparsematrixstats"
        },
        {
            "description": "Functions for Kriging and Point Pattern Analysis. Functions for kriging\nand point pattern analysis.",
            "name": "r-spatial"
        },
        {
            "description": "Spatial Analysis and Modelling Utilities. Utilities to support spatial\ndata manipulation, query, sampling and modelling. Functions include\nmodels for species population density, download utilities for climate\nand global deforestation spatial products, spatial smoothing,\nmultivariate separability, point process model for creating pseudo-\nabsences and sub-sampling, polygon and point-distance landscape metrics,\nauto-logistic model, sampling models, cluster optimization, statistical\nexploratory tools and raster-based metrics.",
            "name": "r-spatialeco"
        },
        {
            "description": "Tools to assess the association between two spatial processes. Tools to\nassess the association between two spatial processes. Currently, several\nmethodologies are implemented: A modified t-test to perform hypothesis\ntesting about the independence between the processes, a suitable\nnonparametric correlation coefficient, the codispersion coefficient, and\nan F test for assessing the multiple correlation between one spatial\nprocess and several others. Functions for image processing and computing\nthe spatial association between images are also provided.",
            "name": "r-spatialpack"
        },
        {
            "description": "Spatial Regression Analysis. A collection of all the estimation\nfunctions for spatial cross-sectional models (on lattice/areal data\nusing spatial weights matrices) contained up to now in 'spdep', 'sphet'\nand 'spse'. These model fitting functions include maximum likelihood\nmethods for cross-sectional models proposed by 'Cliff' and 'Ord' (1973,\nISBN:0850860369) and (1981, ISBN:0850860814), fitting methods initially\ndescribed by 'Ord' (1975) <doi:10.1080/01621459.1975.10480272>. The\nmodels are further described by 'Anselin' (1988)\n<doi:10.1007/978-94-015-7799-1>. Spatial two stage least squares and\nspatial general method of moment models initially proposed by 'Kelejian'\nand 'Prucha' (1998) <doi:10.1023/A:1007707430416> and (1999)\n<doi:10.1111/1468-2354.00027> are provided. Impact methods and MCMC\nfitting methods proposed by 'LeSage' and 'Pace' (2009)\n<doi:10.1201/9781420064254> are implemented for the family of cross-\nsectional spatial regression models. Methods for fitting the log\ndeterminant term in maximum likelihood and MCMC fitting are compared by\n'Bivand et al.' (2013) <doi:10.1111/gean.12008>, and model fitting\nmethods by 'Bivand' and 'Piras' (2015) <doi:10.18637/jss.v063.i18>; both\nof these articles include extensive lists of references. 'spatialreg' >=\n1.1-* correspond to 'spdep' >= 1.1-1, in which the model fitting\nfunctions are deprecated and pass through to 'spatialreg', but will mask\nthose in 'spatialreg'. From versions 1.2-*, the functions will be made\ndefunct in 'spdep'.",
            "name": "r-spatialreg"
        },
        {
            "description": "Spatial Point Pattern Analysis, Model-Fitting, Simulation, Tests.\nComprehensive open-source toolbox for analysing Spatial Point Patterns.\nFocused mainly on two-dimensional point patterns, including\nmultitype/marked points, in any spatial region. Also supports three-\ndimensional point patterns, space-time point patterns in any number of\ndimensions, point patterns on a linear network, and patterns of other\ngeometrical objects. Supports spatial covariate data such as pixel\nimages. Contains over 2000 functions for plotting spatial data,\nexploratory data analysis, model-fitting, simulation, spatial sampling,\nmodel diagnostics, and formal inference. Data types include point\npatterns, line segment patterns, spatial windows, pixel images,\ntessellations, and linear networks. Exploratory methods include quadrat\ncounts, K-functions and their simulation envelopes, nearest neighbour\ndistance and empty space statistics, Fry plots, pair correlation\nfunction, kernel smoothed intensity, relative risk estimation with\ncross-validated bandwidth selection, mark correlation functions,\nsegregation indices, mark dependence diagnostics, and kernel estimates\nof covariate effects. Formal hypothesis tests of random pattern (chi-\nsquared, Kolmogorov-Smirnov, Monte Carlo, Diggle-Cressie-Loosmore-Ford,\nDao-Genton, two-stage Monte Carlo) and tests for covariate effects (Cox-\nBerman-Waller-Lawson, Kolmogorov-Smirnov, ANOVA) are also supported.\nParametric models can be fitted to point pattern data using the\nfunctions ppm(), kppm(), slrm(), dppm() similar to glm(). Types of\nmodels include Poisson, Gibbs and Cox point processes, Neyman-Scott\ncluster processes, and determinantal point processes. Models may involve\ndependence on covariates, inter-point interaction, cluster formation and\ndependence on marks. Models are fitted by maximum likelihood, logistic\nregression, minimum contrast, and composite likelihood methods. A model\ncan be fitted to a list of point patterns (replicated point pattern\ndata) using the function mppm(). The model can include random effects\nand fixed effects depending on the experimental design, in addition to\nall the features listed above. Fitted point process models can be\nsimulated, automatically. Formal hypothesis tests of a fitted model are\nsupported (likelihood ratio test, analysis of deviance, Monte Carlo\ntests) along with basic tools for model selection (stepwise(), AIC())\nand variable selection (sdr). Tools for validating the fitted model\ninclude simulation envelopes, residuals, residual plots and Q-Q plots,\nleverage and influence diagnostics, partial residuals, and added\nvariable plots.",
            "name": "r-spatstat"
        },
        {
            "description": "Core Functionality of the 'spatstat' Family. Functionality for data\nanalysis and modelling of spatial data, mainly spatial point patterns,\nin the 'spatstat' family of packages. (Excludes analysis of spatial data\non a linear network, which is covered by the separate package\n'spatstat.linnet'.) Exploratory methods include quadrat counts,\nK-functions and their simulation envelopes, nearest neighbour distance\nand empty space statistics, Fry plots, pair correlation function, kernel\nsmoothed intensity, relative risk estimation with cross-validated\nbandwidth selection, mark correlation functions, segregation indices,\nmark dependence diagnostics, and kernel estimates of covariate effects.\nFormal hypothesis tests of random pattern (chi-squared, Kolmogorov-\nSmirnov, Monte Carlo, Diggle-Cressie-Loosmore-Ford, Dao-Genton, two-\nstage Monte Carlo) and tests for covariate effects (Cox-Berman-Waller-\nLawson, Kolmogorov-Smirnov, ANOVA) are also supported. Parametric models\ncan be fitted to point pattern data using the functions ppm(), kppm(),\nslrm(), dppm() similar to glm(). Types of models include Poisson, Gibbs\nand Cox point processes, Neyman-Scott cluster processes, and\ndeterminantal point processes. Models may involve dependence on\ncovariates, inter-point interaction, cluster formation and dependence on\nmarks. Models are fitted by maximum likelihood, logistic regression,\nminimum contrast, and composite likelihood methods. A model can be\nfitted to a list of point patterns (replicated point pattern data) using\nthe function mppm(). The model can include random effects and fixed\neffects depending on the experimental design, in addition to all the\nfeatures listed above. Fitted point process models can be simulated,\nautomatically. Formal hypothesis tests of a fitted model are supported\n(likelihood ratio test, analysis of deviance, Monte Carlo tests) along\nwith basic tools for model selection (stepwise(), AIC()) and variable\nselection (sdr). Tools for validating the fitted model include\nsimulation envelopes, residuals, residual plots and Q-Q plots, leverage\nand influence diagnostics, partial residuals, and added variable plots.",
            "name": "r-spatstat-core"
        },
        {
            "description": "Datasets for 'spatstat' Family. Contains all the datasets for the\n'spatstat' family of packages.",
            "name": "r-spatstat-data"
        },
        {
            "description": "Exploratory Data Analysis for the 'spatstat' Family. Functionality for\nexploratory data analysis and nonparametric analysis of spatial data,\nmainly spatial point patterns, in the 'spatstat' family of packages.\n(Excludes analysis of spatial data on a linear network, which is covered\nby the separate package 'spatstat.linnet'.) Methods include quadrat\ncounts, K-functions and their simulation envelopes, nearest neighbour\ndistance and empty space statistics, Fry plots, pair correlation\nfunction, kernel smoothed intensity, relative risk estimation with\ncross-validated bandwidth selection, mark correlation functions,\nsegregation indices, mark dependence diagnostics, and kernel estimates\nof covariate effects. Formal hypothesis tests of random pattern (chi-\nsquared, Kolmogorov-Smirnov, Monte Carlo, Diggle-Cressie-Loosmore-Ford,\nDao-Genton, two-stage Monte Carlo) and tests for covariate effects (Cox-\nBerman-Waller-Lawson, Kolmogorov-Smirnov, ANOVA) are also supported.",
            "name": "r-spatstat-explore"
        },
        {
            "description": "Geometrical Functionality of the 'spatstat' Family. Defines spatial data\ntypes and supports geometrical operations on them. Data types include\npoint patterns, windows (domains), pixel images, line segment patterns,\ntessellations and hyperframes. Capabilities include creation and\nmanipulation of data (using command line or graphical interaction),\nplotting, geometrical operations (rotation, shift, rescale, affine\ntransformation), convex hull, discretisation and pixellation, Dirichlet\ntessellation, Delaunay triangulation, pairwise distances, nearest-\nneighbour distances, distance transform, morphological operations\n(erosion, dilation, closing, opening), quadrat counting, geometrical\nmeasurement, geometrical covariance, colour maps, calculus on spatial\ndomains, Gaussian blur, level sets of images, transects of images,\nintersections between objects, minimum distance matching. (Excludes\nspatial data on a network, which are supported by the package\n'spatstat.linnet'.)",
            "name": "r-spatstat-geom"
        },
        {
            "description": "Linear Networks Functionality of the 'spatstat' Family. Defines types of\nspatial data on a linear network and provides functionality for\ngeometrical operations, data analysis and modelling of data on a linear\nnetwork, in the 'spatstat' family of packages. Contains definitions and\nsupport for linear networks, including creation of networks, geometrical\nmeasurements, topological connectivity, geometrical operations such as\ninserting and deleting vertices, intersecting a network with another\nobject, and interactive editing of networks. Data types defined on a\nnetwork include point patterns, pixel images, functions, and\ntessellations. Exploratory methods include kernel estimation of\nintensity on a network, K-functions and pair correlation functions on a\nnetwork, simulation envelopes, nearest neighbour distance and empty\nspace distance, relative risk estimation with cross-validated bandwidth\nselection. Formal hypothesis tests of random pattern (chi-squared,\nKolmogorov-Smirnov, Monte Carlo, Diggle-Cressie-Loosmore-Ford, Dao-\nGenton, two-stage Monte Carlo) and tests for covariate effects (Cox-\nBerman-Waller-Lawson, Kolmogorov-Smirnov, ANOVA) are also supported.\nParametric models can be fitted to point pattern data using the function\nlppm() similar to glm(). Only Poisson models are implemented so far.\nModels may involve dependence on covariates and dependence on marks.\nModels are fitted by maximum likelihood. Fitted point process models can\nbe simulated, automatically. Formal hypothesis tests of a fitted model\nare supported (likelihood ratio test, analysis of deviance, Monte Carlo\ntests) along with basic tools for model selection (stepwise(), AIC())\nand variable selection (sdr). Tools for validating the fitted model\ninclude simulation envelopes, residuals, residual plots and Q-Q plots,\nleverage and influence diagnostics, partial residuals, and added\nvariable plots. Random point patterns on a network can be generated\nusing a variety of models.",
            "name": "r-spatstat-linnet"
        },
        {
            "description": "Parametric Statistical Modelling and Inference for the 'spatstat'\nFamily. Functionality for parametric statistical modelling and inference\nfor spatial data, mainly spatial point patterns, in the 'spatstat'\nfamily of packages. (Excludes analysis of spatial data on a linear\nnetwork, which is covered by the separate package 'spatstat.linnet'.)\nSupports parametric modelling, formal statistical inference, and model\nvalidation. Parametric models include Poisson point processes, Cox point\nprocesses, Neyman-Scott cluster processes, Gibbs point processes and\ndeterminantal point processes. Models can be fitted to data using\nmaximum likelihood, maximum pseudolikelihood, maximum composite\nlikelihood and the method of minimum contrast. Fitted models can be\nsimulated and predicted. Formal inference includes hypothesis tests\n(quadrat counting tests, Cressie-Read tests, Clark-Evans test, Berman\ntest, Diggle-Cressie-Loosmore-Ford test, scan test, studentised\npermutation test, segregation test, ANOVA tests of fitted models,\nadjusted composite likelihood ratio test, envelope tests, Dao-Genton\ntest, balanced independent two-stage test), confidence intervals for\nparameters, and prediction intervals for point counts. Model validation\ntechniques include leverage, influence, partial residuals, added\nvariable plots, diagnostic plots, pseudoscore residual plots, model\ncompensators and Q-Q plots.",
            "name": "r-spatstat-model"
        },
        {
            "description": "Random Generation Functionality for the 'spatstat' Family. Functionality\nfor random generation of spatial data in the 'spatstat' family of\npackages. Generates random spatial patterns of points according to many\nsimple rules (complete spatial randomness, Poisson, binomial, random\ngrid, systematic, cell), randomised alteration of patterns (thinning,\nrandom shift, jittering), simulated realisations of random point\nprocesses (simple sequential inhibition, Matern inhibition models,\nMatern cluster process, Neyman-Scott cluster processes, log-Gaussian Cox\nprocesses, product shot noise cluster processes) and simulation of Gibbs\npoint processes (Metropolis-Hastings birth-death-shift algorithm,\nalternating Gibbs sampler). Also generates random spatial patterns of\nline segments, random tessellations, and random images (random noise,\nrandom mosaics). Excludes random generation on a linear network, which\nis covered by the separate package 'spatstat.linnet'.",
            "name": "r-spatstat-random"
        },
        {
            "description": "Sparse Three-Dimensional Arrays and Linear Algebra Utilities. Defines\nsparse three-dimensional arrays and supports standard operations on\nthem. The package also includes utility functions for matrix\ncalculations that are common in statistics, such as quadratic forms.",
            "name": "r-spatstat-sparse"
        },
        {
            "description": "Estimation of one-dimensional probability distributions including kernel\ndensity estimation, weighted empirical cumulative distribution\nfunctions, Kaplan-Meier and reduced-sample estimators for right-censored\ndata, heat kernels, kernel properties, quantiles and integration.",
            "name": "r-spatstat-univar"
        },
        {
            "description": "Utility Functions for 'spatstat'. Contains utility functions for the\n'spatstat' package which may also be useful for other purposes.",
            "name": "r-spatstat-utils"
        },
        {
            "description": "Datasets for Spatial Analysis. Diverse spatial datasets for\ndemonstrating, benchmarking and teaching spatial data analysis. It\nincludes R data of class sf (defined by the package 'sf'), Spatial\n('sp'), and nb ('spdep'). Unlike other spatial data packages such as\n'rnaturalearth' and 'maps', it also contains data stored in a range of\nfile formats including GeoJSON, ESRI Shapefile and GeoPackage. Some of\nthe datasets are designed to illustrate specific analysis techniques.\ncycle_hire() and cycle_hire_osm(), for example, is designed to\nillustrate point pattern analysis techniques.",
            "name": "r-spdata"
        },
        {
            "description": "Spatial Dependence: Weighting Schemes, Statistics. A collection of\nfunctions to create spatial weights matrix objects from polygon\n'contiguities', from point patterns by distance and tessellations, for\nsummarizing these objects, and for permitting their use in spatial data\nanalysis, including regional aggregation by minimum spanning tree; a\ncollection of tests for spatial 'autocorrelation', including global\n'Morans I' and 'Gearys C' proposed by 'Cliff' and 'Ord' (1973, ISBN:\n0850860369) and (1981, ISBN: 0850860814), 'Hubert/Mantel' general cross\nproduct statistic, Empirical Bayes estimates and 'Assuncao/Reis' (1999)\n<doi:10.1002/(SICI)1097-0258(19990830)18:16%3C2147::AID-SIM179%3E3.0.CO",
            "name": "r-spdep"
        },
        {
            "description": "Fitting Linear and Generalized Linear Models to Large Data Sets. Fitting\nlinear models and generalized linear models to large data sets by\nupdating algorithms.",
            "name": "r-speedglm"
        },
        {
            "description": "S-system parameter estimation method. This package can optimize the\nparameter in S-system models given time series data",
            "name": "r-spem"
        },
        {
            "description": "Spatial and Space-Time Point Pattern Analysis. The Splancs package was\nwritten as an enhancement to S-Plus for display and analysis of spatial\npoint pattern data; it has been ported to R and is in \"maintenance\nmode\".",
            "name": "r-splancs"
        },
        {
            "description": "Constructs basis functions of B-splines, M-splines, I-splines, convex\nsplines (C-splines), periodic splines, natural cubic splines,\ngeneralized Bernstein polynomials, their derivatives, and integrals\n(except C-splines) by closed-form recursive formulas. It also contains a\nC++ head-only library integrated with Rcpp. See Wang and Yan (2021)\n<doi:10.6339/21-JDS1020> for details.",
            "name": "r-splines2"
        },
        {
            "description": "Stack and Reshape Datasets After Splitting Concatenated Values. Online\ndata collection tools like Google Forms often export multiple-response\nquestions with data concatenated in cells. The concat.split (cSplit)\nfamily of functions splits such data into separate cells. The package\nalso includes functions to stack groups of columns and to reshape wide\ndata, even when the data are \"unbalanced\" something which reshape (from\nbase R) does not handle, and which melt and dcast from reshape2 do not\neasily handle.",
            "name": "r-splitstackshape"
        },
        {
            "description": "Manipulate R Data Frames Using SQL. The sqldf() function is typically\npassed a single argument which is an SQL select statement where the\ntable names are ordinary R data frame names. sqldf() transparently sets\nup a database, imports the data frames into that database, performs the\nSQL select or other statement and returns the result using a heuristic\nto determine which class to assign to each column of the returned data\nframe. The sqldf() or read.csv.sql() functions can also be used to read\nfiltered files into R even if the original files are larger than R\nitself can handle. 'RSQLite', 'RH2', 'RMySQL' and 'RPostgreSQL' backends\nare supported.",
            "name": "r-sqldf"
        },
        {
            "description": "Squared Extrapolation Methods for Accelerating EM-Like Monotone\nAlgorithms. Algorithms for accelerating the convergence of slow,\nmonotone sequences from smooth, contraction mapping such as the EM\nalgorithm. It can be used to accelerate any smooth, linearly convergent\nacceleration scheme. A tutorial style introduction to this package is\navailable in a vignette on the CRAN download page or, when the package\nis loaded in an R session, with vignette(\"SQUAREM\"). Refer to the J Stat\nSoftware article: <doi:10.18637/jss.v092.i07>.",
            "name": "r-squarem"
        },
        {
            "description": "Color-Based Plots for Multivariate Visualization. Functions for color-\nbased visualization of multivariate data, i.e. colorgrams or heatmaps.\nLower-level functions map numeric values to colors, display a matrix as\nan array of colors, and draw color keys. Higher-level plotting functions\ngenerate a bivariate histogram, a dendrogram aligned with a color-coded\nmatrix, a triangular distance matrix, and more.",
            "name": "r-squash"
        },
        {
            "description": "Shrinkage estimation of dispersion in Negative Binomial models for RNA-\nseq experiments with small sample size. The purpose of this package is\nto discover the genes that are differentially expressed between two\nconditions in RNA-seq experiments. Gene expression is measured in counts\nof transcripts and modeled with the Negative Binomial (NB) distribution\nusing a shrinkage approach for dispersion estimation. The method of\nmoment (MM) estimates for dispersion are shrunk towards an estimated\ntarget, which minimizes the average squared difference between the\nshrinkage estimates and the initial estimates. The exact per-gene\nprobability under the NB model is calculated, and used to test the\nhypothesis that the expected expression of a gene in two conditions\nidentically follow a NB distribution.",
            "name": "r-sseq"
        },
        {
            "description": "Stable Distribution Functions. Density, Probability and Quantile\nfunctions, and random number generation for (skew) stable distributions,\nusing the parametrizations of Nolan.",
            "name": "r-stabledist"
        },
        {
            "description": "C++ Header Files for Stan. The C++ header files of the Stan project are\nprovided by this package, but it contains no R code, vignettes, or\nfunction documentation. There is a shared object containing part of the\nCVODES library, but it is not accessible from R. StanHeaders is only\nuseful for developers who want to utilize the LinkingTo directive of\ntheir package's DESCRIPTION file to build on the Stan library without\nincurring unnecessary dependencies. The Stan project develops a\nprobabilistic programming language that implements full or approximate\nBayesian statistical inference via Markov Chain Monte Carlo or\nvariational methods and implements (optionally penalized) maximum\nlikelihood estimation via optimization. The Stan library includes an\nadvanced automatic differentiation scheme, templated statistical and\nlinear algebra functions that can handle the automatically\ndifferentiable scalar types (and doubles, ints, etc.), and a parser for\nthe Stan language. The 'rstan' package provides user-facing R functions\nto parse, compile, test, estimate, and analyze Stan models.",
            "name": "r-stanheaders"
        },
        {
            "description": "Well-Formatted Regression and Summary Statistics Tables. Produces LaTeX\ncode, HTML/CSS code and ASCII text for well-formatted tables that hold\nregression analysis results from several models side-by-side, as well as\nsummary statistics.",
            "name": "r-stargazer"
        },
        {
            "description": "Spatiotemporal Arrays, Raster and Vector Data Cubes. Reading,\nmanipulating, writing and plotting spatiotemporal arrays (raster and\nvector data cubes) in 'R', using 'GDAL' bindings provided by 'sf', and\n'NetCDF' bindings by 'ncmeta' and 'RNetCDF'.",
            "name": "r-stars"
        },
        {
            "description": "Statistical Modeling. A collection of algorithms and functions to aid\nstatistical modeling. Includes limiting dilution analysis (aka ELDA),\ngrowth curve comparisons, mixed linear models, heteroscedastic\nregression, inverse-Gaussian probability calculations, Gauss quadrature\nand a secure convergence algorithm for nonlinear models. Also includes\nadvanced generalized linear model functions including Tweedie and\nDigamma distributional families and a secure convergence algorithm.",
            "name": "r-statmod"
        },
        {
            "description": "Common R Scripts and Utilities Used by the Statnet Project Software.\nNon-statistical utilities used by the software developed by the Statnet\nProject. They may also be of use to others.",
            "name": "r-statnet-common"
        },
        {
            "description": "Alt String Implementation. Provides an extendable, performant and\nmultithreaded 'alt-string' implementation backed by 'C++' vectors and\nstrings.",
            "name": "r-stringfish"
        },
        {
            "description": "Character String Processing Facilities. A multitude of character\nstring/text/natural language processing tools: pattern searching (e.g.,\nwith 'Java'-like regular expressions or the 'Unicode' collation\nalgorithm), random string generation, case mapping, string\ntransliteration, concatenation, sorting, padding, wrapping, Unicode\nnormalisation, date-time formatting and parsing, and many more. They are\nfast, consistent, convenient, and - owing to the use of the 'ICU'\n(International Components for Unicode) library - portable across all\nlocales and platforms.",
            "name": "r-stringi"
        },
        {
            "description": "Simple, Consistent Wrappers for Common String Operations. A consistent,\nsimple and easy to use set of wrappers around the fantastic 'stringi'\npackage. All function and argument names (and positions) are consistent,\nall functions deal with \"NA\"'s and zero length vectors in the same way,\nand the output from one function is easy to feed into the input of\nanother.",
            "name": "r-stringr"
        },
        {
            "description": "Testing, Monitoring, and Dating Structural Changes. Testing, monitoring\nand dating structural changes in (linear) regression models. strucchange\nfeatures tests/methods from the generalized fluctuation test framework\nas well as from the F test (Chow test) framework. This includes methods\nto fit, plot and test fluctuation processes (e.g., CUSUM, MOSUM,\nrecursive/moving estimates) and F statistics, respectively. It is\npossible to monitor incoming data online using fluctuation processes.\nFinally, the breakpoints in regression models with structural changes\ncan be estimated together with confidence intervals. Emphasis is always\ngiven to methods for visualizing the data.",
            "name": "r-strucchange"
        },
        {
            "description": "Testing, Monitoring, and Dating Structural Changes: C++ Version. A fast\nimplementation with additional experimental features for testing,\nmonitoring and dating structural changes in (linear) regression models.\n'strucchangeRcpp' features tests/methods from the generalized\nfluctuation test framework as well as from the F test (Chow test)\nframework. This includes methods to fit, plot and test fluctuation\nprocesses (e.g. cumulative/moving sum, recursive/moving estimates) and F\nstatistics, respectively. These methods are described in Zeileis et al.\n(2002) <doi:10.18637/jss.v007.i02>. Finally, the breakpoints in\nregression models with structural changes can be estimated together with\nconfidence intervals, and their magnitude as well as the model fit can\nbe evaluated using a variety of statistical measures.",
            "name": "r-strucchangercpp"
        },
        {
            "description": "Non-Invasive Pretty Printing of R Code. Pretty-prints R code without\nchanging the user's formatting intent.",
            "name": "r-styler"
        },
        {
            "description": "Unconstrained Optimization using the Subplex Algorithm. The subplex\nalgorithm for unconstrained optimization, developed by Tom Rowan\n<https://www.netlib.org/opt/subplex.tgz>.",
            "name": "r-subplex"
        },
        {
            "description": "SummarizedExperiment container. The SummarizedExperiment container\ncontains one or more assays, each represented by a matrix-like object of\nnumeric or other mode. The rows typically represent genomic ranges of\ninterest and the columns represent samples.",
            "name": "r-summarizedexperiment"
        },
        {
            "description": "Supplementary Distributions. Ten distributions supplementing those built\ninto R. Inverse Gauss, Kruskal-Wallis, Kendall's Tau, Friedman's chi\nsquared, Spearman's rho, maximum F ratio, the Pearson product moment\ncorrelation coefficient, Johnson distributions, normal scores and\ngeneralized hypergeometric distributions.",
            "name": "r-suppdists"
        },
        {
            "description": "Analysis of Complex Survey Samples. Summary statistics, two-sample\ntests, rank tests, generalised linear models, cumulative link models,\nCox models, loglinear models, and general maximum pseudolikelihood\nestimation for multistage stratified, cluster-sampled, unequally\nweighted survey samples. Variances by Taylor series linearisation or\nreplicate weights. Post-stratification, calibration, and raking. Two-\nphase subsampling designs. Graphics. PPS sampling without replacement.\nPrincipal components, factor analysis.",
            "name": "r-survey"
        },
        {
            "description": "Survival Analysis. Contains the core survival analysis routines,\nincluding definition of Surv objects, Kaplan-Meier and Aalen-Johansen\n(multi-state) curves, Cox models, and parametric accelerated failure\ntime models.",
            "name": "r-survival"
        },
        {
            "description": "Surrogate Variable Analysis. The sva package contains functions for\nremoving batch effects and other unwanted variation in high-throughput\nexperiment. Specifically, the sva package contains functions for the\nidentifying and building surrogate variables for high-dimensional data\nsets. Surrogate variables are covariates constructed directly from high-\ndimensional data (like gene expression/RNA sequencing/methylation/brain\nimaging data) that can be used in subsequent analyses to adjust for\nunknown, unmodeled, or latent sources of noise. The sva package can be\nused to remove artifacts in three ways: (1) identifying and estimating\nsurrogate variables for unknown sources of variation in high-throughput\nexperiments (Leek and Storey 2007 PLoS Genetics,2008 PNAS), (2) directly\nremoving known batch effects using ComBat (Johnson et al. 2007\nBiostatistics) and (3) removing batch effects with known control probes\n(Leek 2014 biorXiv). Removing batch effects and using surrogate\nvariables in differential expression analysis have been shown to reduce\ndependence, stabilize error rate estimates, and improve reproducibility,\nsee (Leek and Storey 2007 PLoS Genetics, 2008 PNAS or Leek et al. 2011\nNat. Reviews Genetics).",
            "name": "r-sva"
        },
        {
            "description": "An 'SVG' Graphics Device. A graphics device for R that produces\n'Scalable Vector Graphics'. 'svglite' is a fork of the older\n'RSvgDevice' package.",
            "name": "r-svglite"
        },
        {
            "description": "Powerful and Reliable Tools for Running System Commands in R. Drop-in\nreplacements for the base system2() function with fine control and\nconsistent behavior across platforms. Supports clean interruption,\ntimeout, background tasks, and streaming STDIN / STDOUT / STDERR over\nbinary or text connections. Arguments on Windows automatically get\nencoded and quoted to work on different locales.",
            "name": "r-sys"
        },
        {
            "description": "System Native Font Finding. Provides system native access to the font\ncatalogue. As font handling varies between systems it is difficult to\ncorrectly locate installed fonts across different operating systems. The\n'systemfonts' package provides bindings to the native libraries on\nWindows, macOS and Linux for finding font files that can then be used\nfurther by e.g. graphic devices. The main use is intended to be from\ncompiled code but 'systemfonts' also provides access from R.",
            "name": "r-systemfonts"
        },
        {
            "description": "Collection of Utility and Convenience Functions. A collection of various\nutility and convenience functions.",
            "name": "r-tarifx"
        },
        {
            "description": "Tools for Working with 'Taxonomic' Databases. Tools for working with\n'taxonomic' databases, including utilities for downloading databases,\nloading them into various 'SQL' databases, cleaning up files, and\nproviding a 'SQL' connection that can be used to do 'SQL' queries\ndirectly or used in 'dplyr'.",
            "name": "r-taxizedb"
        },
        {
            "description": "Robust Trimmed Clustering. Provides functions for robust trimmed\nclustering. The methods are described in Garcia-Escudero (2008)\n<doi:10.1214/07-AOS515>, Fritz et al. (2012)\n<doi:10.18637/jss.v047.i12>, Garcia-Escudero et al. (2011)\n<doi:10.1007/s11222-010-9194-z> and others.",
            "name": "r-tclust"
        },
        {
            "description": "Demonstrations for Teaching and Learning. Demonstration functions that\ncan be used in a classroom to demonstrate statistical concepts, or on\nyour own to better understand the concepts or the programming.",
            "name": "r-teachingdemos"
        },
        {
            "description": "Tensor product of arrays. The tensor product of two arrays is notionally\nan outer product of the arrays collapsed in specific extents by summing\nalong the appropriate diagonals.",
            "name": "r-tensor"
        },
        {
            "description": "Advanced Tensor Arithmetic with Named Indices. Provides convenience\nfunctions for advanced linear algebra with tensors and computation with\ndata sets of tensors on a higher level abstraction. It includes Einstein\nand Riemann summing conventions, dragging, co- and contravariate\nindices, parallel computations on sequences of tensors.",
            "name": "r-tensora"
        },
        {
            "description": "Spatial Data Analysis. Methods for spatial data analysis with raster and\nvector data. Raster methods allow for low-level data manipulation as\nwell as high-level global, local, zonal, and focal computation. The\npredict and interpolate methods facilitate the use of regression type\n(interpolation, machine learning) models for spatial prediction,\nincluding with satellite remote sensing data. Processing of very large\nfiles is supported. See the manual and tutorials on\n<https://rspatial.org/terra/> to get started. 'terra' is very similar to\nthe 'raster' package; but 'terra' can do more, is easier to use, and it\nis faster.",
            "name": "r-terra"
        },
        {
            "description": "Tests and checks characteristics of R objects. tester allows you to test\ncharacteristics of common R objects.",
            "name": "r-tester"
        },
        {
            "description": "A Simple Package for Testing R Packages. Provides two convenience\nfunctions assert() and test_pkg() to facilitate testing R packages.",
            "name": "r-testit"
        },
        {
            "description": "Unit Testing for R. Software testing is important, but, in part because\nit is frustrating and boring, many of us avoid it. 'testthat' is a\ntesting framework for R that is easy to learn and use, and integrates\nwith your existing 'workflow'.",
            "name": "r-testthat"
        },
        {
            "description": "Bindings to the 'HarfBuzz' and 'Fribidi' Libraries for Text Shaping.\nProvides access to the text shaping functionality in the 'HarfBuzz'\nlibrary and the bidirectional algorithm in the 'Fribidi' library.\n'textshaping' is a low-level utility package mainly for graphic devices\nthat expands upon the font tool-set provided by the 'systemfonts'\npackage.",
            "name": "r-textshaping"
        },
        {
            "description": "Software Package for Transcription Factor Binding Site (TFBS) Analysis.\nTFBSTools is a package for the analysis and manipulation of\ntranscription factor binding sites. It includes matrices conversion\nbetween Position Frequency Matirx (PFM), Position Weight Matirx (PWM)\nand Information Content Matrix (ICM). It can also scan putative TFBS\nfrom sequence/alignment, query JASPAR database and provides a wrapper of\nde novo motif discovery software.",
            "name": "r-tfbstools"
        },
        {
            "description": "Optimal Thresholding Fisher's P-Value Combination Method. We provide the\ncumulative distribution function (CDF), quantile, and statistical power\ncalculator for a collection of thresholding Fisher's p-value combination\nmethods, including Fisher's p-value combination method, truncated\nproduct method and, in particular, soft-thresholding Fisher's p-value\ncombination method which is proven to be optimal in some context of\nsignal detection. The p-value calculator for the omnibus version of\nthese tests are also included. For reference, please see Hong Zhang and\nZheyang Wu. \"TFisher Tests: Optimal and Adaptive Thresholding for\nCombining p-Values\", submitted.",
            "name": "r-tfisher"
        },
        {
            "description": "Efficient and Accurate P-Value Computation for Position Weight Matrices.\nIn putative Transcription Factor Binding Sites (TFBSs) identification\nfrom sequence/alignments, we are interested in the significance of\ncertain match score. TFMPvalue provides the accurate calculation of\nP-value with score threshold for Position Weight Matrices, or the score\nwith given P-value. This package is an interface to code originally made\navailable by Helene Touzet and Jean-Stephane Varre, 2007, Algorithms Mol\nBiol:2, 15.",
            "name": "r-tfmpvalue"
        },
        {
            "description": "TH's Data Archive. Contains data sets used in other packages Torsten\nHothorn maintains.",
            "name": "r-th-data"
        },
        {
            "description": "Interactive 3D Scatter Plots, Networks and Globes. Create interactive 3D\nscatter plots, network plots, and globes using the 'three.js'\nvisualization library (\"https://threejs.org/\").",
            "name": "r-threejs"
        },
        {
            "description": "Simple Data Frames. Provides a 'tbl_df' class (the 'tibble') that\nprovides stricter checking and better formatting than the traditional\ndata frame.",
            "name": "r-tibble"
        },
        {
            "description": "Functions for timing R scripts, as well as implementations of Stack and\nList structures. This package provides the timing functions 'tic' and\n'toc' that can be nested. One can record all timings while a complex\nscript is running, and examine the values later. It is also possible to\ninstrument the timing calls with custom callbacks. In addition, this\npackage provides class 'Stack', implemented as a vector, and class\n'List', implemented as a list, both of which support operations 'push',\n'pop', 'first', 'last' and 'clear'.",
            "name": "r-tictoc"
        },
        {
            "description": "Load US Census Boundary and Attribute Data as 'tidyverse' and 'sf'-Ready\nData Frames. An integrated R interface to the decennial US Census and\nAmerican Community Survey APIs and the US Census Bureau's geographic\nboundary files. Allows R users to return Census and ACS data as\ntidyverse-ready data frames, and optionally returns a list-column with\nfeature geometry for all Census geographies.",
            "name": "r-tidycensus"
        },
        {
            "description": "A Tidy API for Graph Manipulation. A graph, while not \"tidy\" in itself,\ncan be thought of as two tidy data frames describing node and edge data\nrespectively. 'tidygraph' provides an approach to manipulate these two\nvirtual data frames using the API defined in the 'dplyr' package, as\nwell as provides tidy interfaces to a lot of common graph algorithms.",
            "name": "r-tidygraph"
        },
        {
            "description": "Tidy Messy Data. Tools to help to create tidy data, where each column is\na variable, each row is an observation, and each cell contains a single\nvalue. 'tidyr' contains tools for changing the shape (pivoting) and\nhierarchy (nesting and 'unnesting') of a dataset, turning deeply nested\nlists into rectangular data frames ('rectangling'), and extracting\nvalues out of string columns. It also includes tools for working with\nmissing values (both implicit and explicit).",
            "name": "r-tidyr"
        },
        {
            "description": "Select from a Set of Strings. A backend for the selecting functions of\nthe 'tidyverse'. It makes it easy to implement select-like functions in\nyour own packages in a way that is consistent with other 'tidyverse'\ninterfaces for selection.",
            "name": "r-tidyselect"
        },
        {
            "description": "A Tidy Tool for Phylogenetic Tree Data Manipulation. Phylogenetic tree\ngenerally contains multiple components including node, edge, branch and\nassociated data. 'tidytree' provides an approach to convert tree object\nto tidy data frame as well as provides tidy interfaces to manipulate\ntree data.",
            "name": "r-tidytree"
        },
        {
            "description": "Easily Install and Load the 'Tidyverse'. The 'tidyverse' is a set of\npackages that work in harmony because they share common data\nrepresentations and 'API' design. This package is designed to make it\neasy to install and load multiple 'tidyverse' packages in a single step.\nLearn more about the 'tidyverse' at <https://tidyverse.org>.",
            "name": "r-tidyverse"
        },
        {
            "description": "Read and write TIFF images. This package provides an easy and simple way\nto read, write and display bitmap images stored in the TIFF format. It\ncan read and write both files and in-memory raw vectors.",
            "name": "r-tiff"
        },
        {
            "description": "Load Census TIGER/Line Shapefiles. Download TIGER/Line shapefiles from\nthe United States Census Bureau and load into R as 'SpatialDataFrame' or\n'sf' objects.",
            "name": "r-tigris"
        },
        {
            "description": "Efficient Manipulation of Date-Times. Efficient routines for\nmanipulation of date-time objects while accounting for time-zones and\ndaylight saving times. The package includes utilities for updating of\ndate-time components (year, month, day etc.), modification of time-\nzones, rounding of date-times, period addition and subtraction etc.\nParts of the 'CCTZ' source code, released under the Apache 2.0 License,\nare included in this package. See <https://github.com/google/cctz> for\nmore details.",
            "name": "r-timechange"
        },
        {
            "description": "Rmetrics - Chronological and Calendar Objects. The 'timeDate' class\nfulfils the conventions of the ISO 8601 standard as well as of the ANSI\nC and POSIX standards. Beyond these standards it provides the \"Financial\nCenter\" concept which allows to handle data records collected in\ndifferent time zones and mix them up to have always the proper time\nstamps with respect to your personal financial center, or alternatively\nto the GMT reference time. It can thus also handle time stamps from\nhistorical data records from the same time zone, even if the financial\ncenters changed day light saving times at different calendar dates.",
            "name": "r-timedate"
        },
        {
            "description": "Helper Functions to Install and Maintain TeX Live, and Compile LaTeX\nDocuments. Helper functions to install and maintain the 'LaTeX'\ndistribution named 'TinyTeX' (<https://yihui.name/tinytex/>), a\nlightweight, cross-platform, portable, and easy-to-maintain version of\n'TeX Live'. This package also contains helper functions to compile\n'LaTeX' documents, and install missing 'LaTeX' packages automatically.",
            "name": "r-tinytex"
        },
        {
            "description": "Lightweight Interface to TIGER/Line Shapefiles Download geographic\nshapes from the United States Census Bureau TIGER/Line Shapefiles\n<https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-\nline-file.html>. Functions support downloading and reading in geographic\nboundary data. All downloads can be set up with a cache to avoid\nmultiple downloads. Data is available back to 2000 for most geographies.",
            "name": "r-tinytiger"
        },
        {
            "description": "Time Series Clustering of Gene Expression with Gaussian Mixed-Effects\nModels and Smoothing Splines. Implementation of a clustering method for\ntime series gene expression data based on mixed-effects models with\nGaussian variables and non- parametric cubic splines estimation. The\nmethod can robustly account for the high levels of noise present in\ntypical gene expression time series datasets.",
            "name": "r-tmixclust"
        },
        {
            "description": "Truncated Multivariate Normal Simulation. Importance sampling from the\ntruncated multivariate normal using the GHK (Geweke-Hajivassiliou-Keane)\nsimulator. Unlike Gibbs sampling which can get stuck in one truncation\nsub-region depending on initial values, this package allows truncation\nbased on disjoint regions that are created by truncation of absolute\nvalues. The GHK algorithm uses simple Cholesky transformation followed\nby recursive simulation of univariate truncated normals hence there are\nalso no convergence issues. Importance sample is returned along with\nsampling weights, based on which, one can calculate integrals over\ntruncated regions for multivariate normals.",
            "name": "r-tmvnsim"
        },
        {
            "description": "Enrichment Analysis for Gene Ontology. topGO package provides tools for\ntesting GO terms while accounting for the topology of the GO graph.\nDifferent test statistics and different methods for eliminating local\nsimilarities and dependencies between GO terms can be implemented and\napplied.",
            "name": "r-topgo"
        },
        {
            "description": "Base Classes and Functions for Phylogenetic Tree Input and Output.\n'treeio' is an R package to make it easier to import and store\nphylogenetic tree with associated data; and to link external data from\ndifferent sources to phylogeny. It also supports exporting phylogenetic\ntree with heterogeneous associated data to a single tree file and can be\nserved as a platform for merging tree with associated data and\nconverting file formats.",
            "name": "r-treeio"
        },
        {
            "description": "'Radix' Trees in 'Rcpp'. 'Radix trees', or 'tries', are key-value data\nstructures optimised for efficient lookups, similar in purpose to hash\ntables. 'triebeard' provides an implementation of 'radix trees' for use\nin R programming and in developing packages with 'Rcpp'.",
            "name": "r-triebeard"
        },
        {
            "description": "Cluster analysis with trimming. Trimmed k-means clustering. The method\nis described in Cuesta-Albertos et al. (1997)\n<doi:10.1214/aos/1031833664>.",
            "name": "r-trimcluster"
        },
        {
            "description": "Truncated Random Variables. A collection of tools to evaluate\nprobability density functions, cumulative distribution functions,\nquantile functions and random numbers for truncated random variables.\nThese functions are provided to also compute the expected value and\nvariance. Nadarajah and Kotz (2006) developed most of the functions. QQ\nplots can be produced. All the probability functions in the stats,\nstats4 and evd packages are automatically available for truncation.",
            "name": "r-truncdist"
        },
        {
            "description": "Truncated Normal Distribution. Density, probability, quantile and random\nnumber generation functions for the truncated normal distribution.",
            "name": "r-truncnorm"
        },
        {
            "description": "Trust Region Optimization. Does local optimization using two derivatives\nand trust regions. Guaranteed to converge to local minimum of objective\nfunction.",
            "name": "r-trust"
        },
        {
            "description": "Time series analysis and computational finance.",
            "name": "r-tseries"
        },
        {
            "description": "T-Distributed Stochastic Neighbor Embedding for R (t-SNE). A \"pure R\"\nimplementation of the t-SNE algorithm.",
            "name": "r-tsne"
        },
        {
            "description": "Technical Trading Rules. A collection of over 50 technical indicators\nfor creating technical trading rules. The package also provides fast\nimplementations of common rolling-window functions, and several\nvolatility calculations.",
            "name": "r-ttr"
        },
        {
            "description": "Interpolate Data for Smooth Animations. In order to create smooth\nanimation between states of data, tweening is necessary. This package\nprovides a range of functions for creating tweened data that can be used\nas basis for animation. Furthermore it adds a number of vectorized\ninterpolaters for common R data types such as numeric, date and colour.",
            "name": "r-tweenr"
        },
        {
            "description": "Two Sample MR functions and interface to MR Base database. A package for\nperforming Mendelian randomization using GWAS summary data. It uses the\nIEU GWAS database to obtain data automatically, and a wide range of\nmethods to run the analysis. You can use the MR-Base web app to try out\na limited range of the functionality in this package, but for any\nserious work we strongly recommend using this R package.",
            "name": "r-twosamplemr"
        },
        {
            "description": "Annotation package for TxDb object(s). Exposes an annotation databases\ngenerated from UCSC by exposing these as TxDb objects",
            "name": "r-txdb-hsapiens-ucsc-hg18-knowngene"
        },
        {
            "description": "Annotation package for TxDb object(s). Exposes an annotation databases\ngenerated from UCSC by exposing these as TxDb objects.",
            "name": "r-txdb-hsapiens-ucsc-hg19-knowngene"
        },
        {
            "description": "Transcript Quantification Import with Automatic Metadata Transcript\nquantification import from Salmon and alevin with automatic attachment\nof transcript ranges and release information, and other associated\nmetadata. De novo transcriptomes can be linked to the appropriate\nsources with linkedTxomes and shared for computational reproducibility.",
            "name": "r-tximeta"
        },
        {
            "description": "Import and summarize transcript-level estimates for transcript- and\ngene-level analysis. Imports transcript-level abundance, estimated\ncounts and transcript lengths, and summarizes into matrices for use with\ndownstream gene-level analysis packages. Average transcript length,\nweighted by sample- specific transcript abundance estimates, is provided\nas a matrix which can be used as an offset for different expression of\ngene-level counts.",
            "name": "r-tximport"
        },
        {
            "description": "Import and summarize transcript-level estimates for transcript- and\ngene-level analysis. Imports transcript-level abundance, estimated\ncounts and transcript lengths, and summarizes into matrices for use with\ndownstream gene-level analysis packages. Average transcript length,\nweighted by sample-specific transcript abundance estimates, is provided\nas a matrix which can be used as an offset for different expression of\ngene-level counts.",
            "name": "r-tximportdata"
        },
        {
            "description": "Time Zone Database Information. Provides an up-to-date copy of the\nInternet Assigned Numbers Authority (IANA) Time Zone Database. It is\nupdated periodically to reflect changes made by political bodies to time\nzone boundaries, UTC offsets, and daylight saving time rules.\nAdditionally, this package provides a C++ interface for working with the\n'date' library. 'date' provides comprehensive support for working with\ndates and date-times, which this package exposes to make it easier for\nother R packages to utilize. Headers are provided for calendar specific\ncalculations, along with a limited interface for time zone\nmanipulations.",
            "name": "r-tzdb"
        },
        {
            "description": "General-Purpose Unconstrained Non-Linear Optimization. An algorithm for\ngeneral-purpose unconstrained non-linear optimization. The algorithm is\nof quasi-Newton type with BFGS updating of the inverse Hessian and soft\nline search with a trust region type monitoring of the input to the line\nsearch algorithm. The interface of 'ucminf' is designed for easy\ninterchange with 'optim'.",
            "name": "r-ucminf"
        },
        {
            "description": "Udunits-2 Bindings for R. Provides simple bindings to Unidata's udunits\nlibrary.",
            "name": "r-udunits2"
        },
        {
            "description": "Measurement Units for R Vectors. Support for measurement units in R\nvectors, matrices and arrays: automatic propagation, conversion,\nderivation and simplification of units; raising errors in case of unit\nincompatibility. Compatible with the POSIXct, Date and difftime classes.\nUses the UNIDATA udunits library and unit database for unit\ncompatibility checking and conversion. Documentation about 'units' is\nprovided in the paper by Pebesma, Mailund & Hiebert (2016,\n<doi:10.32614/RJ-2016-061>), included in this package as a vignette; see\n'citation(\"units\")' for details.",
            "name": "r-units"
        },
        {
            "description": "A More Scalable Alternative to Venn and Euler Diagrams for Visualizing\nIntersecting Sets. Creates visualizations of intersecting sets using a\nnovel matrix design, along with visualizations of several common set,\nelement and attribute related tasks (Conway 2017)\n<doi:10.1093/bioinformatics/btx364>.",
            "name": "r-upsetr"
        },
        {
            "description": "Unit Root and Cointegration Tests for Time Series Data. Unit root and\ncointegration tests encountered in applied econometric analysis are\nimplemented.",
            "name": "r-urca"
        },
        {
            "description": "Run CRAN URL Checks from Older R Versions. Provide the URL checking\ntools available in R 4.1+ as a package for earlier versions of R. Also\nuses concurrent requests so can be much faster than the serial versions.",
            "name": "r-urlchecker"
        },
        {
            "description": "Vectorised Tools for URL Handling and Parsing. A toolkit for all URL-\nhandling needs, including encoding and decoding, parsing, parameter\nextraction and modification. All functions are designed to be both fast\nand entirely vectorised. It is intended to be useful for people dealing\nwith web-related datasets, such as server-side logs, although may be\nuseful for other situations involving large sets of URLs.",
            "name": "r-urltools"
        },
        {
            "description": "Automate Package and Project Setup. Automate package and project setup\ntasks that are otherwise performed manually. This includes setting up\nunit testing, test coverage, continuous integration, Git, 'GitHub',\nlicenses, 'Rcpp', 'RStudio' projects, and more.",
            "name": "r-usethis"
        },
        {
            "description": "Unicode Text Processing. Process and print 'UTF-8' encoded international\ntext (Unicode). Input, validate, normalize, encode, format, and display.",
            "name": "r-utf8"
        },
        {
            "description": "Tools for Generating and Handling of UUIDs. Tools for generating and\nhandling of UUIDs (Universally Unique Identifiers).",
            "name": "r-uuid"
        },
        {
            "description": "The Uniform Manifold Approximation and Projection (UMAP) Method for\nDimensionality Reduction. An implementation of the Uniform Manifold\nApproximation and Projection dimensionality reduction by McInnes et al.\n(2018) <arXiv:1802.03426>. It also provides means to transform new data\nand to carry out supervised dimensionality reduction. An implementation\nof the related LargeVis method of Tang et al. (2016) <arXiv:1602.00370>\nis also provided. This is a complete re-implementation in R (and C++,\nvia the 'Rcpp' package): no Python installation is required. See the\nuwot website (<https://github.com/jlmelville/uwot>) for more\ndocumentation and examples.",
            "name": "r-uwot"
        },
        {
            "description": "Embedded JavaScript and WebAssembly Engine for R. An R interface to V8:\nGoogle's open source JavaScript and WebAssembly engine. This package can\nbe compiled either with V8 version 6 and up or NodeJS when built as a\nshared library.",
            "name": "r-v8"
        },
        {
            "description": "Annotation of Genetic Variants. Annotate variants, compute amino acid\ncoding changes, predict coding outcomes.",
            "name": "r-variantannotation"
        },
        {
            "description": "Variable Selection using Random Forests. Variable selection from random\nforests using both backwards variable elimination (for the selection of\nsmall sets of non-redundant variables) and selection based on the\nimportance spectrum (somewhat similar to scree plots; for the selection\nof large, potentially highly-correlated variables). Main applications in\nhigh-dimensional data (e.g., microarray data, and other genomics and\nproteomics applications).",
            "name": "r-varselrf"
        },
        {
            "description": "Visualizing Categorical Data. Visualization techniques, data sets,\nsummary and inference procedures aimed particularly at categorical data.\nSpecial emphasis is given to highly extensible grid graphics. The\npackage was package was originally inspired by the book \"Visualizing\nCategorical Data\" by Michael Friendly and is now the main support\npackage for a new book, \"Discrete Data Analysis with R\" by Michael\nFriendly and David Meyer (2015).",
            "name": "r-vcd"
        },
        {
            "description": "Manipulate and Visualize VCF Data. Facilitates easy manipulation of\nvariant call format (VCF) data. Functions are provided to rapidly read\nfrom and write to VCF files. Once VCF data is read into R a parser\nfunction extracts matrices of data. This information can then be used\nfor quality control or other purposes. Additional functions provide\nvisualization of genomic data. Once processing is complete data may be\nwritten to a VCF file (*.vcf.gz). It also may be converted into other\npopular R objects (e.g., genlight, DNAbin). VcfR provides a link between\nVCF data and familiar R software.",
            "name": "r-vcfr"
        },
        {
            "description": "Vector Helpers. Defines new notions of prototype and size that are used\nto provide tools for consistent and well-founded type-coercion and size-\nrecycling, and are in turn connected to ideas of type- and size-\nstability useful for analyzing function interfaces.",
            "name": "r-vctrs"
        },
        {
            "description": "Community Ecology Package. Ordination methods, diversity analysis and\nother functions for community and vegetation ecologists.",
            "name": "r-vegan"
        },
        {
            "description": "Vegetated Filter Strip and Erosion Model. Empirical models for runoff,\nerosion, and phosphorus loss across a vegetated filter strip, given\nslope, soils, climate, and vegetation (Gall et al., 2018)\n<doi:10.1007/s00477-017-1505-x>. It also includes functions for deriving\nclimate parameters from measured daily weather data, and for simulating\nrainfall. Models implemented include MUSLE (Williams, 1975) and APLE\n(Vadas et al., 2009 <doi:10.2134/jeq2008.0337>).",
            "name": "r-vfs"
        },
        {
            "description": "Vector Generalized Linear and Additive Models. An implementation of\nabout 6 major classes of statistical regression models. The central\nalgorithm is Fisher scoring and iterative reweighted least squares. At\nthe heart of this package are the vector generalized linear and additive\nmodel (VGLM/VGAM) classes. VGLMs can be loosely thought of as\nmultivariate GLMs. VGAMs are data-driven VGLMs that use smoothing. The\nbook \"Vector Generalized Linear and Additive Models: With an\nImplementation in R\" (Yee, 2015) <DOI:10.1007/978-1-4939-2818-7> gives\ndetails of the statistical framework and the package. Currently only\nfixed-effects models are implemented. Many (150+) models and\ndistributions are estimated by maximum likelihood estimation (MLE) or\npenalized MLE. The other classes are RR-VGLMs (reduced-rank VGLMs),\nquadratic RR-VGLMs, reduced-rank VGAMs, RCIMs (row-column interaction\nmodels)---these classes perform constrained and unconstrained quadratic\nordination (CQO/UQO) models in ecology, as well as constrained additive\nordination (CAO). Hauck-Donner effect detection is implemented. Note\nthat these functions are subject to change; see the NEWS and ChangeLog\nfiles for latest changes.",
            "name": "r-vgam"
        },
        {
            "description": "Violin Plot. A violin plot is a combination of a box plot and a kernel\ndensity plot. This package allows extensive customisation of violin\nplots.",
            "name": "r-vioplot"
        },
        {
            "description": "Plot Categorical Data Using Quasirandom Noise and Density Estimates.\nGenerate a violin point plot, a combination of a violin/histogram plot\nand a scatter plot by offsetting points within a category based on their\ndensity using quasirandom noise.",
            "name": "r-vipor"
        },
        {
            "description": "Colorblind-Friendly Color Maps for R. Color maps designed to improve\ngraph readability for readers with common forms of color blindness\nand/or color vision deficiency. The color maps are also perceptually-\nuniform, both in regular form and also when converted to black-and-white\nfor printing. This package also contains 'ggplot2' bindings for discrete\nand continuous color and fill scales. A lean version of the package\ncalled 'viridisLite' that does not include the 'ggplot2' bindings can be\nfound at <https://cran.r-project.org/package=viridisLite>.",
            "name": "r-viridis"
        },
        {
            "description": "Colorblind-Friendly Color Maps (Lite Version). Color maps designed to\nimprove graph readability for readers with common forms of color\nblindness and/or color vision deficiency. The color maps are also\nperceptually-uniform, both in regular form and also when converted to\nblack-and-white for printing. This is the 'lite' version of the\n'viridis' package that also contains 'ggplot2' bindings for discrete and\ncontinuous color and fill scales and can be found at\n<https://cran.r-project.org/package=viridis>.",
            "name": "r-viridislite"
        },
        {
            "description": "Network Visualization using 'vis.js' Library. Provides an R interface to\nthe 'vis.js' JavaScript charting library. It allows an interactive\nvisualization of networks.",
            "name": "r-visnetwork"
        },
        {
            "description": "Read and Write Rectangular Text Data Quickly. The goal of 'vroom' is to\nread and write data (like 'csv', 'tsv' and 'fwf') quickly. When reading\nit uses a quick initial indexing step, then reads the values lazily , so\nonly the data you actually use needs to be read. The writer formats the\ndata in parallel and writes to disk asynchronously from formatting.",
            "name": "r-vroom"
        },
        {
            "description": "Variance stabilization and calibration for microarray data. The package\nimplements a method for normalising microarray intensities, and works\nfor single- and multiple-color arrays. It can also be used for data from\nother technologies, as long as they have similar format. The method uses\na robust variant of the maximum-likelihood estimator for an additive-\nmultiplicative error model and affine calibration. The model\nincorporates data calibration step (a.k.a. normalization), a model for\nthe dependence of the variance on the mean intensity and a variance\nstabilizing data transformation. Differences between transformed\nintensities are analogous to \"normalized log-ratios\". However, in\ncontrast to the latter, their variance is independent of the mean, and\nthey are usually more sensitive and specific in detecting differential\ntranscription.",
            "name": "r-vsn"
        },
        {
            "description": "Find Differences Between R Objects. Compare complex R objects and reveal\nthe key differences. Designed particularly for use in testing packages\nwhere being able to quickly isolate key differences makes understanding\ntest failures much easier.",
            "name": "r-waldo"
        },
        {
            "description": "Illumina 450 methylation array normalization and metrics. 15 flavours of\nbetas and three performance metrics, with methods for objects produced\nby methylumi and minfi packages.",
            "name": "r-watermelon"
        },
        {
            "description": "Take Screenshots of Web Pages. Takes screenshots of web pages, including\nShiny applications and R Markdown documents.",
            "name": "r-webshot"
        },
        {
            "description": "Weighted Correlation Network Analysis. Functions necessary to perform\nWeighted Correlation Network Analysis on high-dimensional data as\noriginally described in Horvath and Zhang (2005)\n<doi:10.2202/1544-6115.1128> and Langfelder and Horvath (2008)\n<doi:10.1186/1471-2105-9-559>. Includes functions for rudimentary data\ncleaning, construction of correlation networks, module identification,\nsummarization, and relating of variables and modules to sample traits.\nAlso includes a number of utility functions for data manipulation and\nvisualization.",
            "name": "r-wgcna"
        },
        {
            "description": "{{mustache}} for R, Logicless Templating. Implements 'Mustache'\nlogicless templating.",
            "name": "r-whisker"
        },
        {
            "description": "Run Code 'With' Temporarily Modified Global State. A set of functions to\nrun code 'with' safely and temporarily modified global state. Many of\nthese functions were originally a part of the 'devtools' package, this\nprovides a simple package with limited dependencies to provide access to\nthese functions.",
            "name": "r-withr"
        },
        {
            "description": "Lightweight Well-Known Geometry Parsing. Provides a minimal R and C++\nAPI for parsing well-known binary and well-known text representation of\ngeometries to and from R-native formats. Well-known binary is compact\nand fast to parse; well-known text is human-readable and is useful for\nwriting tests. These formats are only useful in R if the information\nthey contain can be accessed in R, for which high-performance functions\nare provided here.",
            "name": "r-wk"
        },
        {
            "description": "Zero-dependency data frame to xlsx exporter based on 'libxlsxwriter'.\nFast and no Java or Excel required.",
            "name": "r-writexl"
        },
        {
            "description": "Who are You? Bayesian Prediction of Racial Category Using Surname, First\nName, Middle Name, and Geolocation Predicts individual race/ethnicity\nusing surname, first name, middle name, geolocation, and other\nattributes, such as gender and age. The method utilizes Bayes' Rule\n(with optional measurement error correction) to compute the posterior\nprobability of each racial category for any given individual. The\npackage implements methods described in Imai and Khanna (2016)\n\"Improving Ecological Inference by Predicting Individual Ethnicity from\nVoter Registration Records\" Political Analysis <doi:10.1093/pan/mpw001>.",
            "name": "r-wru"
        },
        {
            "description": "a Bayesian hierarchical model for cross-study analysis of differential\ngene expression. Multi-level model for cross-study detection of\ndifferential gene expression.",
            "name": "r-xde"
        },
        {
            "description": "Supporting Functions for Packages Maintained by 'Yihui Xie'.\nMiscellaneous functions commonly used in other packages maintained by\n'Yihui Xie'.",
            "name": "r-xfun"
        },
        {
            "description": "Extreme Gradient Boosting. Extreme Gradient Boosting, which is an\nefficient implementation of gradient boosting framework. This package is\nits R interface. The package includes efficient linear model solver and\ntree learning algorithms. The package can automatically do parallel\ncomputation on a single machine which could be more than 10 times faster\nthan existing gradient boosting packages. It supports various objective\nfunctions, including regression, classification and ranking. The package\nis made to be extensible, so that users are also allowed to define their\nown objectives easily.",
            "name": "r-xgboost"
        },
        {
            "description": "Excel Connector for R. Provides comprehensive functionality to read,\nwrite and format Excel data.",
            "name": "r-xlconnect"
        },
        {
            "description": "JAR Dependencies for the XLConnect Package. Provides external JAR\ndependencies for the XLConnect package.",
            "name": "r-xlconnectjars"
        },
        {
            "description": "Read, Write, Format Excel 2007 and Excel 97/2000/XP/2003 Files. Provide\nR functions to read/write/format Excel 2007 and Excel 97/2000/XP/2003\nfile formats.",
            "name": "r-xlsx"
        },
        {
            "description": "Package required POI jars for the xlsx package. The xlsxjars package\ncollects all the external jars required for the xlxs package. This\nrelease corresponds to POI 3.10.1.",
            "name": "r-xlsxjars"
        },
        {
            "description": "Export plotting files to the xmapBridge for visualisation in X:Map.\nxmapBridge can plot graphs in the X:Map genome browser. This package\nexports plotting files in a suitable format.",
            "name": "r-xmapbridge"
        },
        {
            "description": "Tools for Parsing and Generating XML Within R and S-Plus. Many\napproaches for both reading and creating XML (and HTML) documents\n(including DTDs), both local and accessible via HTTP or FTP. Also offers\naccess to an 'XPath' \"interpreter\".",
            "name": "r-xml"
        },
        {
            "description": "Package required POI jars for the xlsx package. Work with XML files\nusing a simple, consistent interface. Built on top of the 'libxml2' C\nlibrary.",
            "name": "r-xml2"
        },
        {
            "description": "Exact Goodness-of-Fit Test for Multinomial Data with Fixed\nProbabilities. Tests whether a set of counts fit a given expected ratio.\nFor example, a genetic cross might be expected to produce four types in\nthe relative frequencies of 9:3:3:1. To see whether a set of observed\ncounts fits this expectation, one can examine all possible outcomes with\nxmulti() or a random sample of them with xmonte() and find the\nprobability of an observation deviating from the expectation by at least\nas much as the observed. As a measure of deviation from the expected,\none can use the log-likelihood ratio, the multinomial probability, or\nthe classic chi-square statistic. A histogram of the test statistic can\nalso be plotted and compared with the asymptotic curve.",
            "name": "r-xnomial"
        },
        {
            "description": "Open System Files, 'URLs', Anything. Cross platform solution to open\nfiles, directories or 'URLs' with their associated programs.",
            "name": "r-xopen"
        },
        {
            "description": "Export Tables to LaTeX or HTML. Coerce data to LaTeX and HTML tables.",
            "name": "r-xtable"
        },
        {
            "description": "eXtensible Time Series. Provide for uniform handling of R's different\ntime-based data classes by extending zoo, maximizing native format\ninformation preservation and allowing for user level customization and\nextension, while simplifying cross-class interoperability.",
            "name": "r-xts"
        },
        {
            "description": "Foundation of external vector representation and manipulation in\nBioconductor. Provides memory efficient S4 classes for storing sequences\n\"externally\" (e.g. behind an R external pointer, or on disk).",
            "name": "r-xvector"
        },
        {
            "description": "Nearest Neighbor Observation Imputation and Evaluation Tools. Performs\nnearest neighbor-based imputation using one or more alternative\napproaches to processing multivariate data. These include methods based\non canonical correlation analysis, canonical correspondence analysis,\nand a multivariate adaptation of the random forest classification and\nregression techniques of Leo Breiman and Adele Cutler. Additional\nmethods are also offered. The package includes functions for comparing\nthe results from running alternative techniques, detecting imputation\ntargets that are notably distant from reference observations, detecting\nand correcting for bias, bootstrapping and building ensemble\nimputations, and mapping results.",
            "name": "r-yaimpute"
        },
        {
            "description": "Methods to Convert R Data to YAML and Back. Implements the 'libyaml'\n'YAML' 1.1 parser and emitter (<https://pyyaml.org/wiki/LibYAML>) for R.",
            "name": "r-yaml"
        },
        {
            "description": "Yet Another Package for Signature Analysis. This package provides\nfunctions and routines useful in the analysis of somatic signatures (cf.\nL. Alexandrov et al., Nature 2013). In particular, functions to perform\na signature analysis with known signatures (LCD = linear combination\ndecomposition) and a signature analysis on stratified mutational\ncatalogue (SMC = stratify mutational catalogue) are provided.",
            "name": "r-yapsa"
        },
        {
            "description": "Affymetrix expression data quality control and reproducibility analysis.\nQuality control of Affymetrix GeneChip expression data and\nreproducibility analysis of human whole genome chips with the MAQC\nreference datasets.",
            "name": "r-yaqcaffy"
        },
        {
            "description": "Robust Multi-Condition RNA-Seq Preprocessing and Normalization. Expedite\nlarge RNA-Seq analyses using a combination of previously developed\ntools. YARN is meant to make it easier for the user in performing basic\nmis-annotation quality control, filtering, and condition-aware\nnormalization. YARN leverages many Bioconductor tools and statistical\ntechniques to account for the large heterogeneity and sparsity found in\nvery large RNA-seq experiments.",
            "name": "r-yarn"
        },
        {
            "description": "Supporting Functions for Packages Maintained by 'YuLab-SMU'.\nMiscellaneous functions commonly used by 'YuLab-SMU'.",
            "name": "r-yulab-utils"
        },
        {
            "description": "Treatment of Zeros, Left-Censored and Missing Values in Compositional\nData Sets. Principled methods for the imputation of zeros, left-censored\nand missing data in compositional data sets (Palarea-Albaladejo and\nMartin-Fernandez (2015) <doi:10.1016/j.chemolab.2015.02.019>).",
            "name": "r-zcompositions"
        },
        {
            "description": "Multiple, Unpacking, and Destructuring Assignment. Provides a %<-%\noperator to perform multiple, unpacking, and destructuring assignment in\nR. The operator unpacks the right-hand side of an assignment into\nmultiple values and assigns these values to variables on the left-hand\nside of the assignment.",
            "name": "r-zeallot"
        },
        {
            "description": "Cross-Platform 'zip' Compression. Cross-Platform 'zip' Compression\nLibrary. A replacement for the 'zip' function, that does not require any\nadditional external tools on any platform.",
            "name": "r-zip"
        },
        {
            "description": "An R packaged zlib-1.2.5. This package uses the source code of\nzlib-1.2.5 to create libraries for systems that do not have these\navailable via other means (most Linux and Mac users should have system-\nlevel access to zlib, and no direct need for this package). See the\nvignette for instructions on use.",
            "name": "r-zlibbioc"
        },
        {
            "description": "S3 Infrastructure for Regular and Irregular Time Series (Z's Ordered\nObservations). An S3 class with methods for totally ordered indexed\nobservations. It is particularly aimed at irregular time series of\nnumeric vectors/matrices and factors. zoo's key design goals are\nindependence of a particular index/date/time class and consistency with\nts and base R by providing methods to extend standard generics.",
            "name": "r-zoo"
        },
        {
            "description": "Rapid large-scale prokaryote pan genome analysis",
            "name": "roary"
        },
        {
            "description": "ROOT is a data analysis framework.",
            "name": "root"
        },
        {
            "description": "RSEM is a software package for estimating gene and isoform expression\nlevels from RNA-Seq data.",
            "name": "rsem"
        },
        {
            "description": "RStudio is an integrated development environment (IDE) for R.",
            "name": "rstudio"
        },
        {
            "description": "Library for the Systems Biology Markup Language",
            "name": "sbml"
        },
        {
            "description": "SEACR (Sparse Enrichment Analysis for CUT&RUN) is intended to call peaks\nand enriched regions from sparse CUT&RUN or chromatin profiling data in\nwhich the background is dominated by zeros",
            "name": "seacr"
        },
        {
            "description": "A pipeline to generate a phylogenetic tree from huge SNP data",
            "name": "snphylo"
        },
        {
            "description": "TEtranscripts: Tools for estimating differential enrichment of\nTransposable Elements and other highly repetitive regions.",
            "name": "tetranscripts"
        },
        {
            "description": "Trinity, developed at the Broad Institute and the Hebrew University of\nJerusalem, represents a novel method for the efficient and robust de\nnovo reconstruction of transcriptomes from RNA-seq data. Trinity\ncombines three independent software modules: Inchworm, Chrysalis, and\nButterfly, applied sequentially to process large volumes of RNA-seq\nreads. Trinity partitions the sequence data into many individual de\nBruijn graphs, each representing the transcriptional complexity at a\ngiven gene or locus, and then processes each graph independently to\nextract full-length splicing isoforms and to tease apart transcripts\nderived from paralogous genes.",
            "name": "trinity"
        },
        {
            "description": "Turbine: The Swift/T runtime",
            "name": "turbine"
        },
        {
            "description": "\"VEGAS2 is an extension that uses 1,000 Genomes data to model SNP\ncorrelations across the autosomes and chromosome X",
            "name": "vegas2"
        }
    ],
    "description": "R is 'GNU S', a freely available language and environment for\nstatistical computing and graphics which provides a wide variety of\nstatistical and graphical techniques: linear and nonlinear modelling,\nstatistical tests, time series analysis, classification, clustering,\netc. Please consult the R project homepage for further information.\n",
    "homepage": "https://www.r-project.org",
    "latest_version": "4.5.1",
    "maintainers": [],
    "name": "r",
    "patches": [
        {
            "level": 1,
            "owner": "builtin.r",
            "relative_path": "zlib.patch",
            "reverse": false,
            "sha256": "006c2b3e0bfdfd3c904bca29c974cc270ee24e2e6891e69753e7f95d780969f4",
            "version": "@:3.3.2",
            "working_dir": "."
        },
        {
            "level": 1,
            "owner": "builtin.r",
            "relative_path": "change_optflags_tmp.patch",
            "reverse": false,
            "sha256": "de4e12e779a2f4b342d8153726be3c59a23d27dc9699c9fe8d5a07462d06c14f",
            "version": "%fj@4.1.0",
            "working_dir": "."
        },
        {
            "level": 1,
            "owner": "builtin.r",
            "relative_path": "relocate-which.patch",
            "reverse": false,
            "sha256": "abc572d093cdcbba347ebf55f5b7c219f9941e4f8509ecb061148b408938edc5",
            "version": "",
            "working_dir": "."
        },
        {
            "level": 1,
            "owner": "builtin.r",
            "reverse": false,
            "sha256": "56c77763cb104aa9cb63420e585da63cb2c23bc03fa3ef9d088044eeff9d7380",
            "url": "https://github.com/r-devel/r-svn/commit/f7c46500f455eb4edfc3656c3fa20af61b16abb7.patch?full_index=1",
            "version": "@3.5.0:4.3.3",
            "working_dir": "."
        }
    ],
    "resources": [],
    "variants": [
        {
            "default": false,
            "description": "Enable X11 support (TCLTK, PNG, JPEG, TIFF, CAIRO)",
            "name": "X"
        },
        {
            "default": "autotools",
            "description": "Build systems supported by the package",
            "name": "build_system"
        },
        {
            "default": false,
            "description": "Enable memory profiling",
            "name": "memory_profiling"
        },
        {
            "default": false,
            "description": "Build standalone Rmath library",
            "name": "rmath"
        }
    ],
    "versions": [
        {
            "name": "4.5.1",
            "sha256": "b42a7921400386645b10105b91c68728787db5c4c83c9f6c30acdce632e1bb70"
        },
        {
            "name": "4.5.0",
            "sha256": "3b33ea113e0d1ddc9793874d5949cec2c7386f66e4abfb1cef9aec22846c3ce1"
        },
        {
            "name": "4.4.3",
            "sha256": "0d93d224442dea253c2b086f088db6d0d3cfd9b592cd5496e8cb2143e90fc9e8"
        },
        {
            "name": "4.4.2",
            "sha256": "1578cd603e8d866b58743e49d8bf99c569e81079b6a60cf33cdf7bdffeb817ec"
        },
        {
            "name": "4.4.1",
            "sha256": "b4cb675deaaeb7299d3b265d218cde43f192951ce5b89b7bb1a5148a36b2d94d"
        },
        {
            "name": "4.4.0",
            "sha256": "ace4125f9b976d2c53bcc5fca30c75e30d4edc401584859cbadb080e72b5f030"
        },
        {
            "name": "4.3.3",
            "sha256": "80851231393b85bf3877ee9e39b282e750ed864c5ec60cbd68e6e139f0520330"
        },
        {
            "name": "4.3.2",
            "sha256": "b3f5760ac2eee8026a3f0eefcb25b47723d978038eee8e844762094c860c452a"
        },
        {
            "name": "4.3.1",
            "sha256": "8dd0bf24f1023c6f618c3b317383d291b4a494f40d73b983ac22ffea99e4ba99"
        },
        {
            "name": "4.3.0",
            "sha256": "45dcc48b6cf27d361020f77fde1a39209e997b81402b3663ca1c010056a6a609"
        },
        {
            "name": "4.2.3",
            "sha256": "55e4a9a6d43be314e2c03d0266a6fa5444afdce50b303bfc3b82b3979516e074"
        },
        {
            "name": "4.2.2",
            "sha256": "0ff62b42ec51afa5713caee7c4fde7a0c45940ba39bef8c5c9487fef0c953df5"
        },
        {
            "name": "4.2.1",
            "sha256": "4d52db486d27848e54613d4ee977ad952ec08ce17807e1b525b10cd4436c643f"
        },
        {
            "name": "4.2.0",
            "sha256": "38eab7719b7ad095388f06aa090c5a2b202791945de60d3e2bb0eab1f5097488"
        },
        {
            "name": "4.1.3",
            "sha256": "15ff5b333c61094060b2a52e9c1d8ec55cc42dd029e39ca22abdaa909526fed6"
        },
        {
            "name": "4.1.2",
            "sha256": "2036225e9f7207d4ce097e54972aecdaa8b40d7d9911cd26491fac5a0fab38af"
        },
        {
            "name": "4.1.1",
            "sha256": "515e03265752257d0b7036f380f82e42b46ed8473f54f25c7b67ed25bbbdd364"
        },
        {
            "name": "4.1.0",
            "sha256": "e8e68959d7282ca147360fc9644ada9bd161bab781bab14d33b8999a95182781"
        },
        {
            "name": "4.0.5",
            "sha256": "0a3ee079aa772e131fe5435311ab627fcbccb5a50cabc54292e6f62046f1ffef"
        },
        {
            "name": "4.0.4",
            "sha256": "523f27d69744a08c8f0bd5e1e6c3d89a4db29ed983388ba70963a3cd3a4a802e"
        },
        {
            "name": "4.0.3",
            "sha256": "09983a8a78d5fb6bc45d27b1c55f9ba5265f78fa54a55c13ae691f87c5bb9e0d"
        },
        {
            "name": "4.0.2",
            "sha256": "d3bceab364da0876625e4097808b42512395fdf41292f4915ab1fd257c1bbe75"
        },
        {
            "name": "4.0.1",
            "sha256": "95fe24a4d8d8f8f888460c8f5fe4311cec656e7a1722d233218bc03861bc6f32"
        },
        {
            "name": "4.0.0",
            "sha256": "06beb0291b569978484eb0dcb5d2339665ec745737bdfb4e873e7a5a75492940"
        },
        {
            "name": "3.6.3",
            "sha256": "89302990d8e8add536e12125ec591d6951022cf8475861b3690bc8bf1cefaa8f"
        },
        {
            "name": "3.6.2",
            "sha256": "bd65a45cddfb88f37370fbcee4ac8dd3f1aebeebe47c2f968fd9770ba2bbc954"
        },
        {
            "name": "3.6.1",
            "sha256": "5baa9ebd3e71acecdcc3da31d9042fb174d55a42829f8315f2457080978b1389"
        },
        {
            "name": "3.6.0",
            "sha256": "36fcac3e452666158e62459c6fc810adc247c7109ed71c5b6c3ad5fc2bf57509"
        },
        {
            "name": "3.5.3",
            "sha256": "2bfa37b7bd709f003d6b8a172ddfb6d03ddd2d672d6096439523039f7a8e678c"
        },
        {
            "name": "3.5.2",
            "sha256": "e53d8c3cf20f2b8d7a9c1631b6f6a22874506fb392034758b3bb341c586c5b62"
        },
        {
            "name": "3.5.1",
            "sha256": "0463bff5eea0f3d93fa071f79c18d0993878fd4f2e18ae6cf22c1639d11457ed"
        },
        {
            "name": "3.5.0",
            "sha256": "fd1725535e21797d3d9fea8963d99be0ba4c3aecadcf081b43e261458b416870"
        },
        {
            "name": "3.4.4",
            "sha256": "b3e97d2fab7256d1c655c4075934725ba1cd7cb9237240a11bb22ccdad960337"
        },
        {
            "name": "3.4.3",
            "sha256": "7a3cb831de5b4151e1f890113ed207527b7d4b16df9ec6b35e0964170007f426"
        },
        {
            "name": "3.4.2",
            "sha256": "971e30c2436cf645f58552905105d75788bd9733bddbcb7c4fbff4c1a6d80c64"
        },
        {
            "name": "3.4.1",
            "sha256": "02b1135d15ea969a3582caeb95594a05e830a6debcdb5b85ed2d5836a6a3fc78"
        },
        {
            "name": "3.4.0",
            "sha256": "288e9ed42457c47720780433b3d5c3c20983048b789291cc6a7baa11f9428b91"
        },
        {
            "name": "3.3.3",
            "sha256": "5ab768053a275084618fb669b4fbaadcc39158998a87e8465323829590bcfc6c"
        },
        {
            "name": "3.3.2",
            "sha256": "d294ad21e9f574fb4828ebb3a94b8cb34f4f304a41687a994be00dd41a4e514c"
        },
        {
            "name": "3.3.1",
            "sha256": "3dc59ae5831f5380f83c169bac2103ad052efe0ecec4ffa74bde4d85a0fda9e2"
        },
        {
            "name": "3.3.0",
            "sha256": "9256b154b1a5993d844bee7b1955cd49c99ad72cef03cce3cd1bdca1310311e4"
        },
        {
            "name": "3.2.5",
            "sha256": "60745672dce5ddc201806fa59f6d4e0ba6554d8ed78d0f9f0d79a629978f80b5"
        },
        {
            "name": "3.2.3",
            "sha256": "b93b7d878138279234160f007cb9b7f81b8a72c012a15566e9ec5395cfd9b6c1"
        },
        {
            "name": "3.2.2",
            "sha256": "9c9152e74134b68b0f3a1c7083764adc1cb56fd8336bec003fd0ca550cd2461d"
        },
        {
            "name": "3.2.1",
            "sha256": "d59dbc3f04f4604a5cf0fb210b8ea703ef2438b3ee65fd5ab536ec5234f4c982"
        },
        {
            "name": "3.2.0",
            "sha256": "f5ae953f18ba6f3d55b46556bbbf73441350f9fd22625402b723a2b81ff64f35"
        },
        {
            "name": "3.1.3",
            "sha256": "07e98323935baa38079204bfb9414a029704bb9c0ca5ab317020ae521a377312"
        },
        {
            "name": "3.1.2",
            "sha256": "bcd150afcae0e02f6efb5f35a6ab72432be82e849ec52ce0bb89d8c342a8fa7a"
        }
    ],
    "versions_deprecated": []
}