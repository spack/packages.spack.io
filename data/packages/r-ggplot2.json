{
    "aliases": [],
    "build_system": "RPackage",
    "conflicts": [],
    "dependencies": [
        {
            "description": "R is 'GNU S', a freely available language and environment for\nstatistical computing and graphics which provides a wide variety of\nstatistical and graphical techniques: linear and nonlinear modelling,\nstatistical tests, time series analysis, classification, clustering,\netc. Please consult the R project homepage for further information.",
            "name": "r"
        },
        {
            "description": "Helpers for Developing Command Line Interfaces. A suite of tools to\nbuild attractive command line interfaces ('CLIs'), from semantic\nelements: headings, lists, alerts, paragraphs, etc. Supports custom\nthemes via a 'CSS'-like language. It also contains a number of lower\nlevel 'CLI' elements: rules, boxes, trees, and 'Unicode' symbols with\n'ASCII' alternatives. It integrates with the 'crayon' package to support\n'ANSI' terminal colors.",
            "name": "r-cli"
        },
        {
            "description": "Create Compact Hash Digests of R Objects. Implementation of a function\n'digest()' for the creation of hash digests of arbitrary R objects\n(using the md5, sha-1, sha-256, crc32, xxhash and murmurhash algorithms)\npermitting easy comparison of R language objects, as well as a function\n'hmac()' to create hash-based message authentication code. The md5\nalgorithm by Ron Rivest is specified in RFC 1321, the sha-1 and sha-256\nalgorithms are specified in FIPS-180-1 and FIPS-180-2, and the crc32\nalgorithm is described in\nftp://ftp.rocksoft.com/cliens/rocksoft/papers/crc_v3.txt. For md5,\nsha-1, sha-256 and aes, this package uses small standalone\nimplementations that were provided by Christophe Devine. For crc32, code\nfrom the zlib library is used. For sha-512, an implementation by Aaron\nD. Gifford is used. For xxhash, the implementation by Yann Collet is\nused. For murmurhash, an implementation by Shane Day is used. Please\nnote that this package is not meant to be deployed for cryptographic\npurposes for which more comprehensive (and widely tested) libraries such\nas OpenSSL should be used.",
            "name": "r-digest"
        },
        {
            "description": "Interpreted String Literals. An implementation of interpreted string\nliterals, inspired by Python's Literal String Interpolation\n<https://www.python.org/dev/peps/pep-0498/> and Docstrings\n<https://www.python.org/dev/peps/pep-0257/> and Julia's Triple-Quoted\nString Literals <https://docs.julialang.org/en/stable/\nmanual/strings/#triple-quoted-string-literals>.",
            "name": "r-glue"
        },
        {
            "description": "Arrange 'Grobs' in Tables. Tools to make it easier to work with \"tables\"\nof 'grobs'. The 'gtable' package defines a 'gtable' grob class that\nspecifies a grid along with a list of grobs and their placement in the\ngrid. Further the package makes it easy to manipulate and combine\n'gtable' objects so that complex compositions can be build up\nsequentially.",
            "name": "r-gtable"
        },
        {
            "description": "Generate Isolines and Isobands from Regularly Spaced Elevation Grids. A\nfast C++ implementation to generate contour lines (isolines) and contour\npolygons (isobands) from regularly spaced grids containing elevation\ndata.",
            "name": "r-isoband"
        },
        {
            "description": "Lazy (Non-Standard) Evaluation. An alternative approach to non-standard\nevaluation using formulas. Provides a full implementation of LISP style\n'quasiquotation', making it easier to generate code with other code.",
            "name": "r-lazyeval"
        },
        {
            "description": "Manage the Life Cycle of your Package Functions. Manage the life cycle\nof your exported functions with shared conventions, documentation\nbadges, and non-invasive deprecation warnings. The 'lifecycle' package\ndefines four development stages (experimental, maturing, stable, and\nquestioning) and three deprecation stages (soft-deprecated, deprecated,\nand defunct). It makes it easy to insert badges corresponding to these\nstages in your documentation. Usage of deprecated functions are\nsignalled with increasing levels of non-invasive verbosity.",
            "name": "r-lifecycle"
        },
        {
            "description": "Support Functions and Datasets for Venables and Ripley's MASS. Functions\nand datasets to support Venables and Ripley, \"Modern Applied Statistics\nwith S\" (4th edition, 2002).",
            "name": "r-mass"
        },
        {
            "description": "Mixed GAM Computation Vehicle with Automatic Smoothness Estimation.\nGeneralized additive (mixed) models, some of their extensions and other\ngeneralized ridge regression with multiple smoothing parameter\nestimation by (Restricted) Marginal Likelihood, Generalized Cross\nValidation and similar, or using iterated nested Laplace approximation\nfor fully Bayesian inference. See Wood (2017)\n<doi:10.1201/9781315370279> for an overview. Includes a gam() function,\na wide variety of smoothers, 'JAGS' support and distributions beyond the\nexponential family.",
            "name": "r-mgcv"
        },
        {
            "description": "Tools for Splitting, Applying and Combining Data. A set of tools that\nsolves a common set of problems: you need to break a big problem down\ninto manageable pieces, operate on each piece and then put all the\npieces back together. For example, you might want to fit a model to each\nspatial location or time point in your study, summarise data by panels\nor collapse high-dimensional arrays to simpler summary statistics. The\ndevelopment of 'plyr' has been generously supported by 'Becton\nDickinson'.",
            "name": "r-plyr"
        },
        {
            "description": "Flexibly Reshape Data: A Reboot of the Reshape Package. Flexibly\nrestructure and aggregate data using just two functions: melt and dcast\n(or acast).",
            "name": "r-reshape2"
        },
        {
            "description": "Functions for Base Types and Core R and 'Tidyverse' Features. A toolbox\nfor working with base types, core R features like the condition system,\nand core 'Tidyverse' features like tidy evaluation.",
            "name": "r-rlang"
        },
        {
            "description": "Scale Functions for Visualization. Graphical scales map data to\naesthetics, and provide methods for automatically determining breaks and\nlabels for axes and legends.",
            "name": "r-scales"
        },
        {
            "description": "Simple Data Frames. Provides a 'tbl_df' class (the 'tibble') that\nprovides stricter checking and better formatting than the traditional\ndata frame.",
            "name": "r-tibble"
        },
        {
            "description": "Vector Helpers. Defines new notions of prototype and size that are used\nto provide tools for consistent and well-founded type-coercion and size-\nrecycling, and are in turn connected to ideas of type- and size-\nstability useful for analyzing function interfaces.",
            "name": "r-vctrs"
        },
        {
            "description": "Colorblind-Friendly Color Maps (Lite Version). Color maps designed to\nimprove graph readability for readers with common forms of color\nblindness and/or color vision deficiency. The color maps are also\nperceptually-uniform, both in regular form and also when converted to\nblack-and-white for printing. This is the 'lite' version of the\n'viridis' package that also contains 'ggplot2' bindings for discrete and\ncontinuous color and fill scales and can be found at\n<https://cran.r-project.org/package=viridis>.",
            "name": "r-viridislite"
        },
        {
            "description": "Run Code 'With' Temporarily Modified Global State. A set of functions to\nrun code 'with' safely and temporarily modified global state. Many of\nthese functions were originally a part of the 'devtools' package, this\nprovides a simple package with limited dependencies to provide access to\nthese functions.",
            "name": "r-withr"
        }
    ],
    "dependent_to": [
        {
            "description": "Exploratory Analysis of Genetic and Genomic Data. Toolset for the\nexploration of genetic and genomic data. Adegenet provides formal (S4)\nclasses for storing and handling various genetic data, including genetic\nmarkers with varying ploidy and hierarchical population structure\n('genind' class), alleles counts by populations ('genpop'), and genome-\nwide SNP data ('genlight'). It also implements original multivariate\nmethods (DAPC, sPCA), graphics, statistical tests, simulation tools,\ndistance and similarity measures, and several spatial methods. A range\nof both empirical and simulated datasets is also provided to illustrate\nvarious methods.",
            "name": "r-adegenet"
        },
        {
            "description": "Functions useful for those doing repetitive analyses with Affymetrix\nGeneChips. Various wrapper functions that have been written to\nstreamline the more common analyses that a core Biostatistician might\nsee.",
            "name": "r-affycoretools"
        },
        {
            "description": "Analysis of amplicon enrichment panels. The package provides tools and\nreports for the analysis of amplicon sequencing panels, such as AmpliSeq",
            "name": "r-ampliqueso"
        },
        {
            "description": "Statistical analysis of sequins. The project is intended to support the\nuse of sequins (synthetic sequencing spike-in controls) owned and made\navailable by the Garvan Institute of Medical Research. The goal is to\nprovide a standard open source library for quantitative analysis,\nmodelling and visualization of spike-in controls.",
            "name": "r-anaquin"
        },
        {
            "description": "Analysis of Copy Number Variation in Single-Cell-Sequencing Data.\nAneuFinder implements functions for copy-number detection, breakpoint\ndetection, and karyotype and heterogeneity analysis in single-cell whole\ngenome sequencing and strand-seq data.",
            "name": "r-aneufinder"
        },
        {
            "description": "Decorate a 'ggplot' with Associated Information. For many times, we are\nnot just aligning plots as what 'cowplot' and 'patchwork' did. Users\nwould like to align associated information that requires axes to be\nexactly matched in subplots, e.g. hierarchical clustering with a\nheatmap. This package provides utilities to aligns associated subplots\nto a main plot at different sides (left, right, top and bottom) with\naxes exactly matched.",
            "name": "r-aplot"
        },
        {
            "description": "ASReml-R is a statistical package that fits linear mixed models using\nResidual Maximum Likelihood (REML) in the R environment.",
            "name": "r-asreml"
        },
        {
            "description": "Automatic Interpolation Package. An automatic interpolation is done by\nautomatically estimating the variogram and then calling gstat. An\noverview is given by Hiemstra et al (2008)\n<doi:10.1016/j.cageo.2008.10.011>.",
            "name": "r-automap"
        },
        {
            "description": "Plotting for Bayesian Models. Plotting functions for posterior analysis,\nMCMC diagnostics, prior and posterior predictive checks, and other\nvisualizations to support the applied Bayesian workflow advocated in\nGabry, Simpson, Vehtari, Betancourt, and Gelman (2019)\n<doi:10.1111/rssa.12378>. The package is designed not only to provide\nconvenient functionality for users, but also a common set of functions\nthat can be easily used by developers working on a variety of R packages\nfor Bayesian modeling, particularly (but not exclusively) packages\ninterfacing with 'Stan'.",
            "name": "r-bayesplot"
        },
        {
            "description": "Bayesian Regression Models using 'Stan'. Fit Bayesian generalized\n(non-)linear multivariate multilevel models using 'Stan' for full\nBayesian inference. A wide range of distributions and link functions are\nsupported, allowing users to fit - among others - linear, robust linear,\ncount data, survival, response times, ordinal, zero-inflated, hurdle,\nand even self-defined mixture models all in a multilevel context.\nFurther modeling options include non-linear and smooth terms, auto-\ncorrelation structures, censored data, meta-analytic standard errors,\nand quite a few more. In addition, all parameters of the response\ndistribution can be predicted in order to perform distributional\nregression. Prior specifications are flexible and explicitly encourage\nusers to apply prior distributions that actually reflect their beliefs.\nModel fit can easily be assessed and compared with posterior predictive\nchecks and leave-one-out cross-validation. References: Burkner (2017)\n<doi:10.18637/jss.v080.i01>; Burkner (2018) <doi:10.32614/RJ-2018-017>;\nCarpenter et al. (2017) <doi:10.18637/jss.v076.i01>.",
            "name": "r-brms"
        },
        {
            "description": "Convert Statistical Objects into Tidy Tibbles. Summarizes key\ninformation about statistical objects in tidy tibbles. This makes it\neasy to report results, create plots and consistently work with large\nnumbers of models at once. Broom provides three verbs that each provide\ndifferent types of information about a model. tidy() summarizes\ninformation about model components such as coefficients of a regression.\nglance() reports information about an entire model, such as goodness of\nfit measures like AIC and BIC. augment() adds information about\nindividual observations to a dataset, such as fitted values or influence\nmeasures.",
            "name": "r-broom"
        },
        {
            "description": "Classification and Regression Training. Misc functions for training and\nplotting classification and regression models.",
            "name": "r-caret"
        },
        {
            "description": "Ensembles of Caret Models. Functions for creating ensembles of caret\nmodels: caretList() and caretStack(). caretList() is a convenience\nfunction for fitting multiple caret::train() models to the same dataset.\ncaretStack() will make linear or non-linear combinations of these\nmodels, using a caret::train() model as a meta-model, and\ncaretEnsemble() will make a robust linear combination of models using a\nGLM.",
            "name": "r-caretensemble"
        },
        {
            "description": "Chip Analysis Methylation Pipeline for Illumina HumanMethylation450 and\nEPIC. The package includes quality control metrics, a selection of\nnormalization methods and novel methods to identify differentially\nmethylated regions and to highlight copy number alterations.",
            "name": "r-champ"
        },
        {
            "description": "statistical analysis and visualization of functional profiles for genes\nand gene clusters. This package implements methods to analyze and\nvisualize functional profiles (GO and KEGG) of gene and gene clusters.",
            "name": "r-clusterprofiler"
        },
        {
            "description": "CNE Detection and Visualization. Large-scale identification and advanced\nvisualization of sets of conserved noncoding elements.",
            "name": "r-cner"
        },
        {
            "description": "A Colour Picker Tool for Shiny and for Selecting Colours in Plots. A\ncolour picker that can be used as an input in 'Shiny' apps or Rmarkdown\ndocuments. The colour picker supports alpha opacity, custom colour\npalettes, and many more options. A Plot Colour Helper tool is available\nas an 'RStudio' Addin, which helps you pick colours to use in your\nplots. A more generic Colour Picker 'RStudio' Addin is also provided to\nlet you select colours to use in your R code.",
            "name": "r-colourpicker"
        },
        {
            "description": "Streamlined Plot Theme and Plot Annotations for 'ggplot2'. Provides\nvarious features that help with creating publication-quality figures\nwith 'ggplot2', such as a set of themes, functions to align plots and\narrange them into complex compound figures, and functions that make it\neasy to annotate plots and or mix plots with images. The package was\noriginally written for internal use in the Wilke lab, hence the name\n(Claus O. Wilke's plot package). It has also been used extensively in\nthe book Fundamentals of Data Visualization.",
            "name": "r-cowplot"
        },
        {
            "description": "Inter-Widget Interactivity for HTML Widgets. Provides building blocks\nfor allowing HTML widgets to communicate with each other, with Shiny or\nwithout (i.e. static .html files). Currently supports linked brushing\nand filtering.",
            "name": "r-crosstalk"
        },
        {
            "description": "Accurate sample inference from amplicon data with single nucleotide\nresolution",
            "name": "r-dada2"
        },
        {
            "description": "Extending 'Dendrogram' Functionality in R. Offers a set of functions for\nextending 'dendrogram' objects in R, letting you visualize and compare\ntrees of 'hierarchical clusterings'. You can (1) Adjust a tree's\ngraphical parameters - the color, size, type, etc of its branches, nodes\nand labels. (2) Visually and statistically compare different\n'dendrograms' to one another.",
            "name": "r-dendextend"
        },
        {
            "description": "Differential gene expression analysis based on the negative binomial\ndistribution. Estimate variance-mean dependence in count data from high-\nthroughput sequencing assays and test for differential expression based\non a model using the negative binomial distribution.",
            "name": "r-deseq2"
        },
        {
            "description": "Functions for Base Types and Core R and 'Tidyverse' Features. Vectorised\ndistribution objects with tools for manipulating, visualising, and using\nprobability distributions. Designed to allow model prediction outputs to\nreturn distributions rather than their parameters, allowing users to\ndirectly interact with predictive distributions in a data-oriented\nworkflow. In addition to providing generic replacements for p/d/q/r\nfunctions, other useful statistics can be computed including means,\nvariances, intervals, and highest density regions.",
            "name": "r-distributional"
        },
        {
            "description": "Groupwise Statistics, LSmeans, Linear Estimates, Utilities. Utility\npackage containing: 1) Facilities for working with grouped data: 'do'\nsomething to data stratified 'by' some variables. 2) LSmeans (least-\nsquares means), general linear estimates. 3) Restrict functions to a\nsmaller domain. 4) Miscellaneous other utilities.",
            "name": "r-doby"
        },
        {
            "description": "Disease Ontology Semantic and Enrichment analysis. This package\nimplements five methods proposed by Resnik, Schlicker, Jiang, Lin and\nWang respectively for measuring semantic similarities among DO terms and\ngene products. Enrichment analyses including hypergeometric model and\ngene set enrichment analysis are also implemented for discovering\ndisease associations of high-throughput biological data.",
            "name": "r-dose"
        },
        {
            "description": "Visualization of Functional Enrichment Result. The 'enrichplot' package\nimplements several visualization methods for interpreting functional\nenrichment results obtained from ORA or GSEA analysis. All the\nvisualization methods are developed based on 'ggplot2' graphics.",
            "name": "r-enrichplot"
        },
        {
            "description": "Package for Environmental Statistics, Including US EPA Guidance.\nGraphical and statistical analyses of environmental data, with focus on\nanalyzing chemical concentrations and physical parameters, usually in\nthe context of mandated environmental monitoring. Major environmental\nstatistical methods found in the literature and regulatory guidance\ndocuments, with extensive help that explains what these methods do, how\nto use them, and where to find them in the literature. Numerous built-in\ndata sets from regulatory guidance documents and environmental\nstatistics literature. Includes scripts reproducing analyses presented\nin the book \"EnvStats: An R Package for Environmental Statistics\"\n(Millard, 2013, Springer, ISBN 978-1-4614-8455-4,\n<https://www.springer.com/book/9781461484554>).",
            "name": "r-envstats"
        },
        {
            "description": "Extract and Visualize the Results of Multivariate Data Analyses.\nProvides some easy-to-use functions to extract and visualize the output\nof multivariate data analyses, including 'PCA' (Principal Component\nAnalysis), 'CA' (Correspondence Analysis), 'MCA' (Multiple\nCorrespondence Analysis), 'FAMD' (Factor Analysis of Mixed Data), 'MFA'\n(Multiple Factor Analysis) and 'HMFA' (Hierarchical Multiple Factor\nAnalysis) functions from different R packages. It contains also\nfunctions for simplifying some clustering analysis steps and provides\n'ggplot2' - based elegant data visualization.",
            "name": "r-factoextra"
        },
        {
            "description": "Multivariate Exploratory Data Analysis and Data Mining. Exploratory data\nanalysis methods to summarize, visualize and describe datasets. The main\nprincipal component methods are available, those with the largest\npotential in terms of applications: principal component analysis (PCA)\nwhen variables are quantitative, correspondence analysis (CA) and\nmultiple correspondence analysis (MCA) when variables are categorical,\nMultiple Factor Analysis when variables are structured in groups, etc.\nand hierarchical cluster analysis. F. Husson, S. Le and J. Pages (2017).",
            "name": "r-factominer"
        },
        {
            "description": "Fast Gene Set Enrichment Analysis. The package implements an algorithm\nfor fast gene set enrichment analysis. Using the fast algorithm allows\nto make more permutations and get more fine grained p-values, which\nallows to use accurate stantard approaches to multiple hypothesis\ncorrection.",
            "name": "r-fgsea"
        },
        {
            "description": "Forecasting Functions for Time Series and Linear Models. Methods and\ntools for displaying and analysing univariate time series forecasts\nincluding exponential smoothing via state space models and automatic\nARIMA modelling.",
            "name": "r-forecast"
        },
        {
            "description": "Geometric Morphometric Analyses of 2D/3D Landmark Data. Read,\nmanipulate, and digitize landmark data, generate shape variables via\nProcrustes analysis for points, curves and surfaces, perform shape\nanalyses, and provide graphical depictions of shapes and patterns of\nshape variation.",
            "name": "r-geomorph"
        },
        {
            "description": "Extension to 'ggplot2'. The R package 'ggplot2' is a plotting system\nbased on the grammar of graphics. 'GGally' extends 'ggplot2' by adding\nseveral functions to reduce the complexity of combining geometric\nobjects with transformed data. Some of these functions include a\npairwise plot matrix, a two group pairwise plot matrix, a parallel\ncoordinates plot, a survival plot, and several functions to plot\nnetworks.",
            "name": "r-ggally"
        },
        {
            "description": "Categorical Scatter (Violin Point) Plots. Provides two methods of\nplotting categorical scatter plots such that the arrangement of points\nwithin a category reflects the density of data at that region, and\navoids over-plotting.",
            "name": "r-ggbeeswarm"
        },
        {
            "description": "Visualization tools for genomic data. The ggbio package extends and\nspecializes the grammar of graphics for biological data. The graphics\nare designed to answer common scientific questions, in particular those\noften asked of high throughput genomics data. All core Bioconductor data\nstructures are supported, where appropriate. The package supports\ndetailed views of particular genomic regions, as well as genome-wide\noverviews. Supported overviews include ideograms and grand linear views.\nHigh-level plots include sequence fragment length, edge-linked interval\nto data view, mismatch pileup, and several splicing summaries.",
            "name": "r-ggbio"
        },
        {
            "description": "Create Dendrograms and Tree Diagrams Using 'ggplot2'. This is a set of\ntools for dendrograms and tree plots using 'ggplot2'. The 'ggplot2'\nphilosophy is to clearly separate data from the presentation.\nUnfortunately the plot method for dendrograms plots directly to a plot\ndevice without exposing the data. The 'ggdendro' package resolves this\nby making available functions that extract the dendrogram plot data. The\npackage provides implementations for tree, rpart, as well as diana and\nagnes cluster diagrams.",
            "name": "r-ggdendro"
        },
        {
            "description": "Accelerating 'ggplot2'. The aim of 'ggplot2' is to aid in visual data\ninvestigations. This focus has led to a lack of facilities for composing\nspecialised plots. 'ggforce' aims to be a collection of mainly new stats\nand geoms that fills this gap. All additional functionality is aimed to\ncome through the official extension system so using 'ggforce' should be\na stable experience.",
            "name": "r-ggforce"
        },
        {
            "description": "Miscellaneous Functions for 'ggplot2'. Useful functions to edit 'ggplot'\nobject (e.g., setting fonts for theme and layers, adding rounded\nrectangle as background for each of the legends).",
            "name": "r-ggfun"
        },
        {
            "description": "Joyplots in 'ggplot2'. Joyplots provide a convenient way of visualizing\nchanges in distributions over time or space.",
            "name": "r-ggjoy"
        },
        {
            "description": "Spatial Visualization with ggplot2. A collection of functions to\nvisualize spatial data and models on top of static maps from various\nonline sources (e.g Google Maps and Stamen Maps). It includes tools\ncommon to those tasks, including functions for geolocation and routing.",
            "name": "r-ggmap"
        },
        {
            "description": "Multiple Fill and Colour Scales in 'ggplot2'. Use multiple fill and\ncolour scales in 'ggplot2'.",
            "name": "r-ggnewscale"
        },
        {
            "description": "Convert Plot to 'grob' or 'ggplot' Object. Convert plot function call\n(using expression or formula) to 'grob' or 'ggplot' object that\ncompatible to the 'grid' and 'ggplot2' ecosystem. With this package, we\nare able to e.g. using 'cowplot' to align plots produced by 'base'\ngraphics, 'ComplexHeatmap', 'eulerr', 'grid', 'lattice', 'magick',\n'pheatmap', 'vcd' etc. by converting them to 'ggplot' objects.",
            "name": "r-ggplotify"
        },
        {
            "description": "'ggplot2' Based Publication Ready Plots. The 'ggplot2' package is\nexcellent and flexible for elegant data visualization in R. However the\ndefault generated plots requires some formatting before we can send them\nfor publication. Furthermore, to customize a 'ggplot', the syntax is\nopaque and this raises the level of difficulty for researchers with no\nadvanced R programming skills. 'ggpubr' provides some easy-to-use\nfunctions for creating and customizing 'ggplot2'- based publication\nready plots.",
            "name": "r-ggpubr"
        },
        {
            "description": "An Implementation of Grammar of Graphics for Graphs and Networks. The\ngrammar of graphics as implemented in ggplot2 is a poor fit for graph\nand network visualizations due to its reliance on tabular data input.\nggraph is an extension of the ggplot2 API tailored to graph\nvisualizations and provides the same flexible approach to building up\nplots layer by layer.",
            "name": "r-ggraph"
        },
        {
            "description": "Rasterize Layers for 'ggplot2'. Rasterize only specific layers of a\n'ggplot2' plot while simultaneously keeping all labels and text in\nvector format. This allows users to keep plots within the reasonable\nsize limit without loosing vector properties of the scale-sensitive\ninformation.",
            "name": "r-ggrastr"
        },
        {
            "description": "Repulsive Text and Label Geoms for 'ggplot2'. Provides text and label\ngeoms for 'ggplot2' that help to avoid overlapping text labels. Labels\nrepel away from each other and away from the data points.",
            "name": "r-ggrepel"
        },
        {
            "description": "Ridgeline Plots in 'ggplot2'. Ridgeline plots provide a convenient way\nof visualizing changes in distributions over time or space. This package\nenables the creation of such plots in 'ggplot2'.",
            "name": "r-ggridges"
        },
        {
            "description": "Scientific Journal and Sci-Fi Themed Color Palettes for 'ggplot2'.\ncollection of 'ggplot2' color palettes inspired by plots in scientific\njournals, data visualization libraries, science fiction movies, and TV\nshows.",
            "name": "r-ggsci"
        },
        {
            "description": "Significance Brackets for 'ggplot2'. Enrich your 'ggplots' with group-\nwise comparisons. This package provides an easy way to indicate if two\ngroups are significantly different. Commonly this is shown by a bracket\non top connecting the groups of interest which itself is annotated with\nthe level of significance (NS, *, **, ***). The package provides a\nsingle layer (geom_signif()) that takes the groups for comparison and\nthe test (t.test(), wilcox.text() etc.) as arguments and adds the\nannotation to the plot.",
            "name": "r-ggsignif"
        },
        {
            "description": "Provides new statistics, new geometries and new positions for 'ggplot2'\nand a suite of functions to facilitate the creation of statistical\nplots.",
            "name": "r-ggstats"
        },
        {
            "description": "Extra Themes, Scales and Geoms for 'ggplot2'. Some extra themes, geoms,\nand scales for 'ggplot2'. Provides 'ggplot2' themes and scales that\nreplicate the look of plots by Edward Tufte, Stephen Few,\n'Fivethirtyeight', 'The Economist', 'Stata', 'Excel', and 'The Wall\nStreet Journal', among others. Provides 'geoms' for Tufte's box plot and\nrange frame.",
            "name": "r-ggthemes"
        },
        {
            "description": "an R package for visualization of tree and annotation data. 'ggtree'\nextends the 'ggplot2' plotting system which implemented the grammar of\ngraphics. 'ggtree' is designed for visualization and annotation of\nphylogenetic trees and other tree-like structures with their annotation\ndata.",
            "name": "r-ggtree"
        },
        {
            "description": "Visualization of Functional Analysis Data. Implementation of\nmultilayered visualizations for enhanced graphical representation of\nfunctional analysis data. It combines and integrates omics data derived\nfrom expression and functional annotation enrichment analyses. Its\nplotting functions have been developed with an hierarchical structure in\nmind: starting from a general overview to identify the most enriched\ncategories (modified bar plot, bubble plot) to a more detailed one\ndisplaying different types of relevant information for the molecules in\na given set of categories (circle plot, chord plot, cluster plot, Venn\ndiagram, heatmap).",
            "name": "r-goplot"
        },
        {
            "description": "Highest Density Regions and Conditional Density Estimation. Computation\nof highest density regions in one and two dimensions, kernel estimation\nof univariate density functions conditional on one covariate,and\nmultimodal regression.",
            "name": "r-hdrcde"
        },
        {
            "description": "Harrell Miscellaneous. Contains many functions useful for data analysis,\nhigh-level graphics, utility operations, functions for computing sample\nsize and power, importing and annotating datasets, imputing missing\nvalues, advanced table making, variable clustering, character string\nmanipulation, conversion of R objects to LaTeX and html code, and\nrecoding variables.",
            "name": "r-hmisc"
        },
        {
            "description": "Tests in Linear Mixed Effects Models. Provides p-values in type I, II or\nIII anova and summary tables for lmer model fits (cf. lme4) via\nSatterthwaite's degrees of freedom method. A Kenward-Roger method is\nalso available via the pbkrtest package. Model selection methods include\nstep, drop1 and anova-like tables for random effects (ranova). Methods\nfor Least-Square means (LS-means) and tests of linear contrasts of fixed\neffects are also available.",
            "name": "r-lmertest"
        },
        {
            "description": "Mendelian Randomization Package. Encodes several methods for performing\nMendelian randomization analyses with summarized data. Summarized data\non genetic associations with the exposure and with the outcome can be\nobtained from large consortia. These data can be used for obtaining\ncausal estimates using instrumental variable methods.",
            "name": "r-mendelianrandomization"
        },
        {
            "description": "Handle Illumina methylation data. This package provides classes for\nholding and manipulating Illumina methylation data. Based on eSet, it\ncan contain MIAME information, sample information, feature information,\nand multiple matrices of data. An \"intelligent\" import function,\nmethylumiR can read the Illumina text files and create a MethyLumiSet.\nmethylumIDAT can directly read raw IDAT files from HumanMethylation27\nand HumanMethylation450 microarrays. Normalization, background\ncorrection, and quality control features for GoldenGate, Infinium, and\nInfinium HD arrays are also included.",
            "name": "r-methylumi"
        },
        {
            "description": "Machine Learning in R. Interface to a large number of classification and\nregression techniques, including machine-readable parameter\ndescriptions. There is also an experimental extension for survival\nanalysis, clustering and general, example-specific cost-sensitive\nlearning. Generic resampling, including cross-validation, bootstrapping\nand subsampling. Hyperparameter tuning with modern optimization\ntechniques, for single- and multi-objective problems. Filter and wrapper\nmethods for feature selection. Extension of basic learners with\nadditional operations common in machine learning, also allowing for easy\nnested resampling. Most operations can be parallelized.",
            "name": "r-mlr"
        },
        {
            "description": "Base Functions and Classes for Mass Spectrometry and Proteomics. MSnbase\nprovides infrastructure for manipulation, processing and visualisation\nof mass spectrometry and proteomics data, ranging from raw to\nquantitative and annotated data.",
            "name": "r-msnbase"
        },
        {
            "description": "Algorithms and Framework for Nonnegative Matrix Factorization (NMF).\nProvides a framework to perform Non-negative Matrix Factorization (NMF).\nThe package implements a set of already published algorithms and seeding\nmethods, and provides a framework to test, develop and plug new/custom\nalgorithms. Most of the built-in algorithms have been optimized in C++,\nand the main interface function provides an easy way of performing\nparallel computations on multicore machines.",
            "name": "r-nmf"
        },
        {
            "description": "The Composer of Plots. The 'ggplot2' package provides a strong API for\nsequentially building up a plot, but does not concern itself with\ncomposition of multiple plots. 'patchwork' is a package that expands the\nAPI to allow for arbitrarily complex composition of plots by, among\nothers, providing mathematical operators for combining multiple plots.\nOther packages that try to address this need (but with a different\napproach) are 'gridExtra' and 'cowplot'.",
            "name": "r-patchwork"
        },
        {
            "description": "Handling and analysis of high-throughput microbiome census data.\nphyloseq provides a set of classes and tools to facilitate the import,\nstorage, analysis, and graphical display of microbiome census data.",
            "name": "r-phyloseq"
        },
        {
            "description": "Predict and explore the age of genes using phylostratigraphic methods",
            "name": "r-phylostratr"
        },
        {
            "description": "Create Interactive Web Graphics via 'plotly.js'. Create interactive web\ngraphics from 'ggplot2' graphs and/or a custom interface to the (MIT-\nlicensed) JavaScript library 'plotly.js' inspired by the grammar of\ngraphics.",
            "name": "r-plotly"
        },
        {
            "description": "Projection Predictive Feature Selection. Performs projection predictive\nfeature selection for generalized linear models and generalized linear\nand additive multilevel models (see, Piironen, Paasiniemi and Vehtari,\n2020, <https://projecteuclid.org/euclid.ejs/1589335310>, Catalina,\nBurkner and Vehtari, 2020, <arXiv:2010.06994>). The package is\ncompatible with the 'rstanarm' and 'brms' packages, but other reference\nmodels can also be used. See the package vignette for more information\nand examples.",
            "name": "r-projpred"
        },
        {
            "description": "A test for when to use quantile normalization. A data-driven test for\nthe assumptions of quantile normalization using raw data such as objects\nthat inherit eSets (e.g. ExpressionSet, MethylSet). Group level\ninformation about each sample (such as Tumor / Normal status) must also\nbe provided because the test assesses if there are global differences in\nthe distributions between the user-defined groups.",
            "name": "r-quantro"
        },
        {
            "description": "A System of Plotting Optimized for Speed and Modularity. A high-level\nplotting system, built using 'grid' graphics, that is optimized for\nspeed and modularity. This has great utility for quick visualizations\nwhen testing code, with the key benefit that visualizations are updated\nindependently of one another.",
            "name": "r-quickplot"
        },
        {
            "description": "Q-value estimation for false discovery rate control. This package takes\na list of p-values resulting from the simultaneous testing of many\nhypotheses and estimates their q-values and local FDR values. The\nq-value of a test measures the proportion of false positives incurred\n(called the false discovery rate) when that particular test is called\nsignificant. The local FDR measures the posterior probability the null\nhypothesis is true given the test's p-value. Various plots are\nautomatically generated, allowing one to make sensible significance cut-\noffs. Several mathematical results have recently been shown on the\nconservative accuracy of the estimated q-values from this software. The\nsoftware can be applied to problems in genomics, brain imaging,\nastrophysics, and data mining.",
            "name": "r-qvalue"
        },
        {
            "description": "RadialMR. A package for implementing radial inverse variance weighted\nand MR-Egger methods.",
            "name": "r-radialmr"
        },
        {
            "description": "R Interface for Bokeh. A native R plotting library that provides a\nflexible declarative interface for creating interactive web-based\ngraphics, backed by the Bokeh visualization library\n<https://bokeh.pydata.org/>.",
            "name": "r-rbokeh"
        },
        {
            "description": "Tools for making reports in various formats. The ReportingTools software\npackage enables users to easily display reports of analysis results\ngenerated from sources such as microarray and sequencing data. The\npackage allows users to create HTML pages that may be viewed on a web\nbrowser such as Safari, or in other formats readable by programs such as\nExcel. Users can generate tables with sortable and filterable columns,\nmake and display plots, and link table entries to other data sources\nsuch as NCBI or larger plots within the HTML page. Using the package,\nusers can also produce a table of contents page to link various reports\ntogether for a particular project that can be viewed in a web browser.\nFor more examples, please visit our site: http:// research-\npub.gene.com/ReportingTools.",
            "name": "r-reportingtools"
        },
        {
            "description": "Regression Modeling Strategies. Regression modeling, testing,\nestimation, validation, graphics, prediction, and typesetting by storing\nenhanced model design attributes in the fit. 'rms' is a collection of\nfunctions that assist with and streamline modeling. It also contains\nfunctions for binary and ordinal logistic regression models, ordinal\nmodels for continuous Y with a variety of distribution families, and the\nBuckley-James multiple regression model for right-censored responses,\nand implements penalized maximum likelihood estimation for logistic and\nordinary linear models. 'rms' works with almost any regression model,\nbut it was especially written to work with binary or ordinal regression\nmodels, Cox regression, accelerated failure time models, ordinary linear\nmodels, the Buckley-James model, generalized least squares for serially\nor spatially correlated observations, generalized linear models, and\nquantile regression.",
            "name": "r-rms"
        },
        {
            "description": "'NOAA' Weather Data from R. Client for many 'NOAA' data sources\nincluding the 'NCDC' climate 'API' at <https://www.ncdc.noaa.gov/cdo-\nweb/webservices/v2>, with functions for each of the 'API' 'endpoints':\ndata, data categories, data sets, data types, locations, location\ncategories, and stations. In addition, we have an interface for 'NOAA'\nsea ice data, the 'NOAA' severe weather inventory, 'NOAA' Historical\nObserving 'Metadata' Repository ('HOMR') data, 'NOAA' storm data via\n'IBTrACS', tornado data via the 'NOAA' storm prediction center, and\nmore.",
            "name": "r-rnoaa"
        },
        {
            "description": "Linear Model Evaluation with Randomized Residuals in a Permutation\nProcedure. Linear model calculations are made for many random versions\nof data. Using residual randomization in a permutation procedure, sums\nof squares are calculated over many permutations to generate empirical\nprobability distributions for evaluating model effects. This packaged is\ndescribed by Collyer & Adams (2018) <doi:10.1111/2041-210X.13029>.\nAdditionally, coefficients, statistics, fitted values, and residuals\ngenerated over many permutations can be used for various procedures\nincluding pairwise tests, prediction, classification, and model\ncomparison. This package should provide most tools one could need for\nthe analysis of high-dimensional data, especially in ecology and\nevolutionary biology, but certainly other fields, as well.",
            "name": "r-rrpp"
        },
        {
            "description": "R Interface to Stan. User-facing R functions are provided to parse,\ncompile, test, estimate, and analyze Stan models by accessing the\nheader-only Stan library provided by the 'StanHeaders' package. The Stan\nproject develops a probabilistic programming language that implements\nfull Bayesian statistical inference via Markov Chain Monte Carlo, rough\nBayesian inference via variational approximation, and (optionally\npenalized) maximum likelihood estimation via optimization. In all three\ncases, automatic differentiation is used to quickly and accurately\nevaluate gradients without burdening the user with the need to derive\nthe partial derivatives.",
            "name": "r-rstan"
        },
        {
            "description": "Detect and Remove Unwanted Variation using Negative Controls. Implements\nthe 'RUV' (Remove Unwanted Variation) algorithms. These algorithms\nattempt to adjust for systematic errors of unknown origin in high-\ndimensional data. The algorithms were originally developed for use with\ngenomic data, especially microarray data, but may be useful with other\ntypes of high-dimensional data as well. These algorithms were proposed\nin Gagnon-Bartsch and Speed (2012) <doi:10.1093/nar/gkz433>, Gagnon-\nBartsch, Jacob and Speed (2013), and Molania, et. al. (2019)\n<doi:10.1093/nar/gkz433>. The algorithms require the user to specify a\nset of negative control variables, as described in the references. The\nalgorithms included in this package are 'RUV-2', 'RUV-4', 'RUV-inv',\n'RUV-rinv', 'RUV-I', and RUV-III', along with various supporting\nalgorithms.",
            "name": "r-ruv"
        },
        {
            "description": "Single-Cell Analysis Toolkit for Gene Expression Data in R. A collection\nof tools for doing various analyses of single-cell RNA-seq gene\nexpression data, with a focus on quality control and visualization.",
            "name": "r-scater"
        },
        {
            "description": "Scatterplots with More Points. C-based conversion of large scatterplot\ndata to rasters. Speeds up plotting of data with millions of points.",
            "name": "r-scattermore"
        },
        {
            "description": "Scatter Pie Plot. Creates scatterpie plots, especially useful for\nplotting pies on a map.",
            "name": "r-scatterpie"
        },
        {
            "description": "Variance Stabilizing Transformations for Single Cell UMI Data. A\nnormalization method for single-cell UMI count data using a variance\nstabilizing transformation. The transformation is based on a negative\nbinomial regression model with regularized parameters. As part of the\nsame regression framework, this package also provides functions for\nbatch correction, and data correction. See Hafemeister and Satija 2019\n<doi:10.1101/576827> for more details.",
            "name": "r-sctransform"
        },
        {
            "description": "Tools for Single Cell Genomics. A toolkit for quality control, analysis,\nand exploration of single cell RNA sequencing data. 'Seurat' aims to\nenable users to identify and interpret sources of heterogeneity from\nsingle cell transcriptomic measurements, and to integrate diverse types\nof single cell data. See Satija R, Farrell J, Gennert D, et al (2015)\n<doi:10.1038/nbt.3192>, Macosko E, Basu A, Satija R, et al (2015)\n<doi:10.1016/j.cell.2015.05.002>, and Stuart T, Butler A, et al (2019)\n<doi:10.1016/j.cell.2019.05.031> for more details.",
            "name": "r-seurat"
        },
        {
            "description": "Shadow Text Grob and Layer. Implement shadowtextGrob() for 'grid' and\ngeom_shadowtext() layer for 'ggplot2'. These functions create/draw text\ngrob with background shadow.",
            "name": "r-shadowtext"
        },
        {
            "description": "Interactive Visual and Numerical Diagnostics and Posterior Analysis for\nBayesian Models. A graphical user interface for interactive Markov chain\nMonte Carlo (MCMC) diagnostics and plots and tables helpful for\nanalyzing a posterior sample. The interface is powered by the 'Shiny'\nweb application framework from 'RStudio' and works with the output of\nMCMC programs written in any programming language (and has extended\nfunctionality for 'Stan' models fit using the 'rstan' and 'rstanarm'\npackages).",
            "name": "r-shinystan"
        },
        {
            "description": "Analysis of Single-Cell Chromatin Data. A framework for the analysis and\nexploration of single-cell chromatin data. The 'Signac' package contains\nfunctions for quantifying single-cell chromatin data, computing per-cell\nquality control metrics, dimension reduction and normalization,\nvisualization, and DNA sequence motif analysis. Reference: Stuart et al.\n(2021) <doi:10.1038/s41592-021-01282-5>.",
            "name": "r-signac"
        },
        {
            "description": "Single and Multi-Objective Optimization Test Functions. Provides\ngenerators for a high number of both single- and multi- objective test\nfunctions which are frequently used for the benchmarking of (numerical)\noptimization algorithms. Moreover, it offers a set of convenient\nfunctions to generate, plot and work with objective functions.",
            "name": "r-smoof"
        },
        {
            "description": "Somatic Signatures. The SomaticSignatures package identifies mutational\nsignatures of single nucleotide variants (SNVs). It provides a\ninfrastructure related to the methodology described in Nik-Zainal (2012,\nCell), with flexibility in the matrix decomposition algorithms.",
            "name": "r-somaticsignatures"
        },
        {
            "description": "Easily Install and Load the 'Tidyverse'. The 'tidyverse' is a set of\npackages that work in harmony because they share common data\nrepresentations and 'API' design. This package is designed to make it\neasy to install and load multiple 'tidyverse' packages in a single step.\nLearn more about the 'tidyverse' at <https://tidyverse.org>.",
            "name": "r-tidyverse"
        },
        {
            "description": "Two Sample MR functions and interface to MR Base database. A package for\nperforming Mendelian randomization using GWAS summary data. It uses the\nIEU GWAS database to obtain data automatically, and a wide range of\nmethods to run the analysis. You can use the MR-Base web app to try out\na limited range of the functionality in this package, but for any\nserious work we strongly recommend using this R package.",
            "name": "r-twosamplemr"
        },
        {
            "description": "A More Scalable Alternative to Venn and Euler Diagrams for Visualizing\nIntersecting Sets. Creates visualizations of intersecting sets using a\nnovel matrix design, along with visualizations of several common set,\nelement and attribute related tasks (Conway 2017)\n<doi:10.1093/bioinformatics/btx364>.",
            "name": "r-upsetr"
        },
        {
            "description": "Colorblind-Friendly Color Maps for R. Color maps designed to improve\ngraph readability for readers with common forms of color blindness\nand/or color vision deficiency. The color maps are also perceptually-\nuniform, both in regular form and also when converted to black-and-white\nfor printing. This package also contains 'ggplot2' bindings for discrete\nand continuous color and fill scales. A lean version of the package\ncalled 'viridisLite' that does not include the 'ggplot2' bindings can be\nfound at <https://cran.r-project.org/package=viridisLite>.",
            "name": "r-viridis"
        },
        {
            "description": "Variance stabilization and calibration for microarray data. The package\nimplements a method for normalising microarray intensities, and works\nfor single- and multiple-color arrays. It can also be used for data from\nother technologies, as long as they have similar format. The method uses\na robust variant of the maximum-likelihood estimator for an additive-\nmultiplicative error model and affine calibration. The model\nincorporates data calibration step (a.k.a. normalization), a model for\nthe dependence of the variance on the mean intensity and a variance\nstabilizing data transformation. Differences between transformed\nintensities are analogous to \"normalized log-ratios\". However, in\ncontrast to the latter, their variance is independent of the mean, and\nthey are usually more sensitive and specific in detecting differential\ntranscription.",
            "name": "r-vsn"
        },
        {
            "description": "Yet Another Package for Signature Analysis. This package provides\nfunctions and routines useful in the analysis of somatic signatures (cf.\nL. Alexandrov et al., Nature 2013). In particular, functions to perform\na signature analysis with known signatures (LCD = linear combination\ndecomposition) and a signature analysis on stratified mutational\ncatalogue (SMC = stratify mutational catalogue) are provided.",
            "name": "r-yapsa"
        },
        {
            "description": "Rapid large-scale prokaryote pan genome analysis",
            "name": "roary"
        }
    ],
    "description": "Create Elegant Data Visualisations Using the Grammar of Graphics. A\nsystem for 'declaratively' creating graphics, based on \"The Grammar of\nGraphics\". You provide the data, tell 'ggplot2' how to map variables to\naesthetics, what graphical primitives to use, and it takes care of the\ndetails.\n",
    "homepage": "https://cloud.r-project.org/package=ggplot2",
    "latest_version": "3.5.1",
    "maintainers": [],
    "name": "r-ggplot2",
    "patches": [],
    "resources": [],
    "variants": [
        {
            "default": "generic",
            "description": "Build systems supported by the package",
            "name": "build_system"
        }
    ],
    "versions": [
        {
            "name": "3.5.1",
            "sha256": "7c58b424f99b3634038e6f6d1fe4b0241b8aecb50e9c50466d5590f7e3144721"
        },
        {
            "name": "3.5.0",
            "sha256": "07fa1cd4e02d409ade32e69a9088d9209f864c6ddd70fa2f904769dec21090e2"
        },
        {
            "name": "3.4.4",
            "sha256": "2d76ec065d3e604d019506f45b3b713ae20f38e47dbebfb5ba1648b47fe63e46"
        },
        {
            "name": "3.4.3",
            "sha256": "5ce29ace6be7727be434506a1c759dfc322f65b17eabeec863b93be10f91a543"
        },
        {
            "name": "3.4.2",
            "sha256": "70230aa70a2c6f844fc41dd93e5f62af6859dfed390026ae58f223637e5283ca"
        },
        {
            "name": "3.4.0",
            "sha256": "a82f9e52f974389439765f71a8206ec26e3be30a8864d2c784d5ea8abcb0473e"
        },
        {
            "name": "3.3.6",
            "sha256": "bfcb4eb92a0fcd3fab713aca4bb25e916e05914f2540271a45522ad7e43943a9"
        },
        {
            "name": "3.3.5",
            "sha256": "b075294faf3af31b18e415f260c62d6000b218770e430484fe38819bdc3224ea"
        },
        {
            "name": "3.3.3",
            "sha256": "45c29e2348dbd195bbde1197a52db7764113e57f463fd3770fb899acc33423cc"
        },
        {
            "name": "3.2.0",
            "sha256": "31b6897fb65acb37913ff6e2bdc1b57f652360098ae3aa660abdcf54f84d73b3"
        },
        {
            "name": "3.1.1",
            "sha256": "bfde297f3b4732e7f560078f4ce131812a70877e6b5b1d41a772c394939e0c79"
        },
        {
            "name": "2.2.1",
            "sha256": "5fbc89fec3160ad14ba90bd545b151c7a2e7baad021c0ab4b950ecd6043a8314"
        },
        {
            "name": "2.1.0",
            "sha256": "f2c323ae855d6c089e3a52138aa7bc25b9fe1429b8df9eae89d28ce3c0dd3969"
        }
    ],
    "versions_deprecated": []
}