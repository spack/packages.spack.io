{
    "name": "r-ipred",
    "aliases": [],
    "versions": [
        {
            "name": "0.9-14",
            "sha256": "81c83dc847d09c3db52ef15e36cd4dac38c50eead1008ddd458b9e89d7528f35"
        },
        {
            "name": "0.9-13",
            "sha256": "6168a062d93c2d3063c064a8f242cd3716dee99822e20363a1801261319c4c98"
        },
        {
            "name": "0.9-12",
            "sha256": "d6e1535704d39415a799d7643141ffa4f6f55597f03e763f4ccd5d8106005843"
        },
        {
            "name": "0.9-9",
            "sha256": "0da87a70730d5a60b97e46b2421088765e7d6a7cc2695757eba0f9d31d86416f"
        },
        {
            "name": "0.9-8",
            "sha256": "9c1d11c3cb0d72be7870e70a216e589e403bbfee38c796fe75cd0611d878ac07"
        },
        {
            "name": "0.9-5",
            "sha256": "3a466417808e17c4c6cd0f2b577407355d9da79a341558b42a8b76e24b6f6ba4"
        }
    ],
    "latest_version": "0.9-14",
    "build_system": "RPackage",
    "conflicts": [],
    "variants": [
        {
            "name": "build_system",
            "default": "generic",
            "description": "Build systems supported by the package"
        }
    ],
    "homepage": "https://cloud.r-project.org/package=ipred",
    "maintainers": [],
    "patches": [],
    "resources": [],
    "description": "Improved Predictors. Improved predictive models by indirect\nclassification and bagging for classification, regression and survival\nproblems as well as resampling based estimators of prediction error.\n",
    "dependencies": [
        {
            "name": "r",
            "description": "R is 'GNU S', a freely available language and environment for\nstatistical computing and graphics which provides a wide variety of\nstatistical and graphical techniques: linear and nonlinear modelling,\nstatistical tests, time series analysis, classification, clustering,\netc. Please consult the R project homepage for further information."
        },
        {
            "name": "r-rpart",
            "description": "Recursive Partitioning and Regression Trees. Recursive partitioning for\nclassification, regression and survival trees. An implementation of most\nof the functionality of the 1984 book by Breiman, Friedman, Olshen and\nStone."
        },
        {
            "name": "r-mass",
            "description": "Support Functions and Datasets for Venables and Ripley's MASS. Functions\nand datasets to support Venables and Ripley, \"Modern Applied Statistics\nwith S\" (4th edition, 2002)."
        },
        {
            "name": "r-survival",
            "description": "Survival Analysis. Contains the core survival analysis routines,\nincluding definition of Surv objects, Kaplan-Meier and Aalen-Johansen\n(multi-state) curves, Cox models, and parametric accelerated failure\ntime models."
        },
        {
            "name": "r-nnet",
            "description": "Feed-Forward Neural Networks and Multinomial Log-Linear Models. Software\nfor feed-forward neural networks with a single hidden layer, and for\nmultinomial log-linear models."
        },
        {
            "name": "r-class",
            "description": "Functions for Classification. Various functions for classification,\nincluding k-nearest neighbour, Learning Vector Quantization and Self-\nOrganizing Maps."
        },
        {
            "name": "r-prodlim",
            "description": "Product-Limit Estimation for Censored Event History Analysis. Product-\nLimit Estimation for Censored Event History Analysis. Fast and user\nfriendly implementation of nonparametric estimators for censored event\nhistory (survival) analysis. Kaplan-Meier and Aalen-Johansen method."
        }
    ],
    "dependent_to": [
        {
            "name": "r-recipes",
            "description": "Preprocessing Tools to Create Design Matrices. An extensible framework\nto create and preprocess design matrices. Recipes consist of one or more\ndata manipulation and analysis \"steps\". Statistical parameters for the\nsteps can be estimated from an initial data set and then applied to\nother data sets. The resulting design matrices can then be used as\ninputs into statistical or machine learning models."
        }
    ]
}