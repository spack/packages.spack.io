{
    "aliases": [],
    "build_system": "RPackage",
    "conflicts": [],
    "dependencies": [
        {
            "description": "The NVIDIA HPC SDK is a comprehensive suite of compilers, libraries and\ntools essential to maximizing developer productivity and the performance\nand portability of HPC applications. The NVIDIA HPC SDK C, C++, and\nFortran compilers support GPU acceleration of HPC modeling and\nsimulation applications with standard C++ and Fortran, OpenACC\ndirectives, and CUDA. GPU-accelerated math libraries maximize\nperformance on common HPC algorithms, and optimized communications\nlibraries enable standards-based multi-GPU and scalable systems\nprogramming. Performance profiling and debugging tools simplify porting\nand optimization of HPC applications.",
            "name": "c"
        },
        {
            "description": "R is 'GNU S', a freely available language and environment for\nstatistical computing and graphics which provides a wide variety of\nstatistical and graphical techniques: linear and nonlinear modelling,\nstatistical tests, time series analysis, classification, clustering,\netc. Please consult the R project homepage for further information.",
            "name": "r"
        }
    ],
    "dependent_to": [
        {
            "description": "A Program for Missing Data. A tool that \"multiply imputes\" missing data\nin a single cross-section (such as a survey), from a time series (like\nvariables collected for each year in a country), or from a time-series-\ncross-sectional data set (such as collected by years for each of several\ncountries). Amelia II implements our bootstrapping-based algorithm that\ngives essentially the same answers as the standard IP or EMis\napproaches, is usually considerably faster than existing approaches and\ncan handle many more variables. Unlike Amelia I and other statistically\nrigorous imputation software, it virtually never crashes (but please let\nus know if you find to the contrary!). The program also generalizes\nexisting approaches by allowing for trends in time series across\nobservations within a cross-sectional unit, as well as priors that allow\nexperts to incorporate beliefs they have about the values of missing\ncells in their data. Amelia II also includes useful diagnostics of the\nfit of multiple imputation models. The program works from the R command\nline or via a graphical user interface that does not require users to\nknow R.",
            "name": "r-amelia"
        },
        {
            "description": "Plotting for Bayesian Models. Plotting functions for posterior analysis,\nMCMC diagnostics, prior and posterior predictive checks, and other\nvisualizations to support the applied Bayesian workflow advocated in\nGabry, Simpson, Vehtari, Betancourt, and Gelman (2019)\n<doi:10.1111/rssa.12378>. The package is designed not only to provide\nconvenient functionality for users, but also a common set of functions\nthat can be easily used by developers working on a variety of R packages\nfor Bayesian modeling, particularly (but not exclusively) packages\ninterfacing with 'Stan'.",
            "name": "r-bayesplot"
        },
        {
            "description": "Basic graphic utilities for visualization of genomic data. The\nbiovizBase package is designed to provide a set of utilities, color\nschemes and conventions for genomic data. It serves as the base for\nvarious high-level packages for biological data visualization. This\nsaves development effort and encourages consistency.",
            "name": "r-biovizbase"
        },
        {
            "description": "A Simple S3 Class for Representing Vectors of Binary Data ('BLOBS'). R's\nraw vector is useful for storing a single binary object. What if you\nwant to put a vector of them in a data frame? The blob package provides\nthe blob object, a list of raw vectors, suitable for use as a column in\ndata frame.",
            "name": "r-blob"
        },
        {
            "description": "Bayesian Regression Models using 'Stan'. Fit Bayesian generalized\n(non-)linear multivariate multilevel models using 'Stan' for full\nBayesian inference. A wide range of distributions and link functions are\nsupported, allowing users to fit - among others - linear, robust linear,\ncount data, survival, response times, ordinal, zero-inflated, hurdle,\nand even self-defined mixture models all in a multilevel context.\nFurther modeling options include non-linear and smooth terms, auto-\ncorrelation structures, censored data, meta-analytic standard errors,\nand quite a few more. In addition, all parameters of the response\ndistribution can be predicted in order to perform distributional\nregression. Prior specifications are flexible and explicitly encourage\nusers to apply prior distributions that actually reflect their beliefs.\nModel fit can easily be assessed and compared with posterior predictive\nchecks and leave-one-out cross-validation. References: Burkner (2017)\n<doi:10.18637/jss.v080.i01>; Burkner (2018) <doi:10.32614/RJ-2018-017>;\nCarpenter et al. (2017) <doi:10.18637/jss.v076.i01>.",
            "name": "r-brms"
        },
        {
            "description": "Convert Statistical Objects into Tidy Tibbles. Summarizes key\ninformation about statistical objects in tidy tibbles. This makes it\neasy to report results, create plots and consistently work with large\nnumbers of models at once. Broom provides three verbs that each provide\ndifferent types of information about a model. tidy() summarizes\ninformation about model components such as coefficients of a regression.\nglance() reports information about an entire model, such as goodness of\nfit measures like AIC and BIC. augment() adds information about\nindividual observations to a dataset, such as fitted values or influence\nmeasures.",
            "name": "r-broom"
        },
        {
            "description": "Provides suite of functions to work with regression model\n'broom::tidy()' tibbles. The suite includes functions to group\nregression model terms by variable, insert reference and header rows for\ncategorical variables, add variable labels, and more.",
            "name": "r-broom-helpers"
        },
        {
            "description": "Custom 'Bootstrap' 'Sass' Themes for 'shiny' and 'rmarkdown'. Simplifies\ncustom 'CSS' styling of both 'shiny' and 'rmarkdown' via 'Bootstrap'\n'Sass'. Supports both 'Bootstrap' 3 and 4 as well as their various\n'Bootswatch' themes. An interactive widget is also provided for\npreviewing themes in real time.",
            "name": "r-bslib"
        },
        {
            "description": "Cache R Objects with Automatic Pruning. Key-value stores with automatic\npruning. Caches can limit either their total size or the age of the\noldest object (or both), automatically pruning objects to maintain the\nconstraints.",
            "name": "r-cachem"
        },
        {
            "description": "Ensembles of Caret Models. Functions for creating ensembles of caret\nmodels: caretList() and caretStack(). caretList() is a convenience\nfunction for fitting multiple caret::train() models to the same dataset.\ncaretStack() will make linear or non-linear combinations of these\nmodels, using a caret::train() model as a meta-model, and\ncaretEnsemble() will make a robust linear combination of models using a\nGLM.",
            "name": "r-caretensemble"
        },
        {
            "description": "Date-Time Types and Tools. Provides a comprehensive library for date-\ntime manipulations using a new family of orthogonal date-time classes\n(durations, time points, zoned-times, and calendars) that partition\nresponsibilities so that the complexities of time zones are only\nconsidered when they are really needed. Capabilities include: date-time\nparsing, formatting, arithmetic, extraction and updating of components,\nand rounding.",
            "name": "r-clock"
        },
        {
            "description": "statistical analysis and visualization of functional profiles for genes\nand gene clusters. This package implements methods to analyze and\nvisualize functional profiles (GO and KEGG) of gene and gene clusters.",
            "name": "r-clusterprofiler"
        },
        {
            "description": "An Alternative Conflict Resolution Strategy. R's default conflict\nmanagement system gives the most recently loaded package precedence.\nThis can make it hard to detect conflicts, particularly when they arise\nbecause a package update creates ambiguity that did not previously\nexist. 'conflicted' takes a different approach, making every conflict an\nerror and forcing you to choose which function to use.",
            "name": "r-conflicted"
        },
        {
            "description": "Streamlined Plot Theme and Plot Annotations for 'ggplot2'. Provides\nvarious features that help with creating publication-quality figures\nwith 'ggplot2', such as a set of themes, functions to align plots and\narrange them into complex compound figures, and functions that make it\neasy to annotate plots and or mix plots with images. The package was\noriginally written for internal use in the Wilke lab, hence the name\n(Claus O. Wilke's plot package). It has also been used extensively in\nthe book Fundamentals of Data Visualization.",
            "name": "r-cowplot"
        },
        {
            "description": "A 'dplyr' Back End for Databases. A 'dplyr' back end for databases that\nallows you to work with remote database tables as if they are in-memory\ndata frames. Basic features works with any database that has a 'DBI'\nback end; more advanced features require 'SQL' translation to be\nprovided by the package author.",
            "name": "r-dbplyr"
        },
        {
            "description": "Tools to Make Developing R Packages Easier. Collection of package\ndevelopment tools.",
            "name": "r-devtools"
        },
        {
            "description": "Graph/Network Visualization. Build graph/network structures using\nfunctions for stepwise addition and deletion of nodes and edges. Work\nwith data available in tables for bulk addition of nodes, edges, and\nassociated metadata. Use graph selections and traversals to apply\nchanges to specific nodes or edges. A wide selection of graph algorithms\nallow for the analysis of graphs. Visualize the graphs and take\nadvantage of any aesthetic properties assigned to nodes and edges.",
            "name": "r-diagrammer"
        },
        {
            "description": "Functions for Base Types and Core R and 'Tidyverse' Features. Vectorised\ndistribution objects with tools for manipulating, visualising, and using\nprobability distributions. Designed to allow model prediction outputs to\nreturn distributions rather than their parameters, allowing users to\ndirectly interact with predictive distributions in a data-oriented\nworkflow. In addition to providing generic replacements for p/d/q/r\nfunctions, other useful statistics can be computed including means,\nvariances, intervals, and highest density regions.",
            "name": "r-distributional"
        },
        {
            "description": "Groupwise Statistics, LSmeans, Linear Estimates, Utilities. Utility\npackage containing: 1) Facilities for working with grouped data: 'do'\nsomething to data stratified 'by' some variables. 2) LSmeans (least-\nsquares means), general linear estimates. 3) Restrict functions to a\nsmaller domain. 4) Miscellaneous other utilities.",
            "name": "r-doby"
        },
        {
            "description": "Syntax Highlighting and Automatic Linking. Syntax highlighting of R\ncode, specifically designed for the needs of 'RMarkdown' packages like\n'pkgdown', 'hugodown', and 'bookdown'. It includes linking of function\ncalls to their documentation on the web, and automatic translation of\nANSI escapes in output to the equivalent HTML.",
            "name": "r-downlit"
        },
        {
            "description": "A Grammar of Data Manipulation. A fast, consistent tool for working with\ndata frame like objects, both in memory and out of memory.",
            "name": "r-dplyr"
        },
        {
            "description": "Data Table Back-End for 'dplyr'. Provides a data.table backend for\n'dplyr'. The goal of 'dtplyr' is to allow you to write 'dplyr' code that\nis automatically translated to the equivalent, but usually much faster,\ndata.table code.",
            "name": "r-dtplyr"
        },
        {
            "description": "Tools for Working with ... The ellipsis is a powerful tool for extending\nfunctions. Unfortunately this power comes at a cost: misspelled\narguments will be silently ignored. The ellipsis package provides a\ncollection of functions to catch problems and alert the user.",
            "name": "r-ellipsis"
        },
        {
            "description": "Visualization of Functional Enrichment Result. The 'enrichplot' package\nimplements several visualization methods for interpreting functional\nenrichment results obtained from ORA or GSEA analysis. All the\nvisualization methods are developed based on 'ggplot2' graphics.",
            "name": "r-enrichplot"
        },
        {
            "description": "Fit, Simulate and Diagnose Exponential-Family Models for Networks. An\nintegrated set of tools to analyze and simulate networks based on\nexponential-family random graph models (ERGMs). 'ergm' is a part of the\nStatnet suite of packages for network analysis. See Hunter, Handcock,\nButts, Goodreau, and Morris (2008) <doi:10.18637/jss.v024.i03> and\nKrivitsky, Hunter, Morris, and Klumb (2021) <arXiv:2106.04997>.",
            "name": "r-ergm"
        },
        {
            "description": "R Interface to the Europe PubMed Central RESTful Web Service. An R\nClient for the Europe PubMed Central RESTful Web Service (see\n<https://europepmc.org/RestfulWebService> for more information). It\ngives access to both metadata on life science literature and open access\nfull texts. Europe PMC indexes all PubMed content and other literature\nsources including Agricola, a bibliographic database of citations to the\nagricultural literature, or Biological Patents. In addition to\nbibliographic metadata, the client allows users to fetch citations and\nreference lists. Links between life-science literature and other EBI\ndatabases, including ENA, PDB or ChEMBL are also accessible. No\nregistration or API key is required. See the vignettes for usage\nexamples.",
            "name": "r-europepmc"
        },
        {
            "description": "Help to Fit of a Parametric Distribution to Non-Censored or Censored\nData. Extends the fitdistr() function (of the MASS package) with several\nfunctions to help the fit of a parametric distribution to non-censored\nor censored data. Censored data may contain left censored, right\ncensored and interval censored values, with several lower and upper\nbounds. In addition to maximum likelihood estimation (MLE), the package\nprovides moment matching (MME), quantile matching (QME) and maximum\ngoodness-of-fit estimation (MGE) methods (available only for non-\ncensored data). Weighted versions of MLE, MME and QME are available. See\ne.g. Casella & Berger (2002). Statistical inference. Pacific Grove.",
            "name": "r-fitdistrplus"
        },
        {
            "description": "Easily Work with 'Font Awesome' Icons. Easily and flexibly insert 'Font\nAwesome' icons into 'R Markdown' documents and 'Shiny' apps. These icons\ncan be inserted into HTML content through inline 'SVG' tags or 'i' tags.\nThere is also a utility function for exporting 'Font Awesome' icons as\n'PNG' images for those situations where raster graphics are needed.",
            "name": "r-fontawesome"
        },
        {
            "description": "Tools for Working with Categorical Variables (Factors). Helpers for\nreordering factor levels (including moving specified levels to front,\nordering by first appearance, reversing, and randomly shuffling), and\ntools for modifying factor levels (including collapsing rare levels into\nother, 'anonymising', and manually 'recoding').",
            "name": "r-forcats"
        },
        {
            "description": "Apply Mapping Functions in Parallel using Futures Implementations of the\nfamily of map() functions from 'purrr' that can be resolved using any\n'future'-supported backend, e.g. parallel on the local machine or\ndistributed on a compute cluster.",
            "name": "r-furrr"
        },
        {
            "description": "Utilities for Working with Google APIs. Provides utilities for working\nwith Google APIs <https://developers.google.com/apis-explorer>. This\nincludes functions and classes for handling common credential types and\nfor preparing, executing, and processing HTTP requests.",
            "name": "r-gargle"
        },
        {
            "description": "Extension to 'ggplot2'. The R package 'ggplot2' is a plotting system\nbased on the grammar of graphics. 'GGally' extends 'ggplot2' by adding\nseveral functions to reduce the complexity of combining geometric\nobjects with transformed data. Some of these functions include a\npairwise plot matrix, a two group pairwise plot matrix, a parallel\ncoordinates plot, a survival plot, and several functions to plot\nnetworks.",
            "name": "r-ggally"
        },
        {
            "description": "Visualization tools for genomic data. The ggbio package extends and\nspecializes the grammar of graphics for biological data. The graphics\nare designed to answer common scientific questions, in particular those\noften asked of high throughput genomics data. All core Bioconductor data\nstructures are supported, where appropriate. The package supports\ndetailed views of particular genomic regions, as well as genome-wide\noverviews. Supported overviews include ideograms and grand linear views.\nHigh-level plots include sequence fragment length, edge-linked interval\nto data view, mismatch pileup, and several splicing summaries.",
            "name": "r-ggbio"
        },
        {
            "description": "Accelerating 'ggplot2'. The aim of 'ggplot2' is to aid in visual data\ninvestigations. This focus has led to a lack of facilities for composing\nspecialised plots. 'ggforce' aims to be a collection of mainly new stats\nand geoms that fills this gap. All additional functionality is aimed to\ncome through the official extension system so using 'ggforce' should be\na stable experience.",
            "name": "r-ggforce"
        },
        {
            "description": "Miscellaneous Functions for 'ggplot2'. Useful functions to edit 'ggplot'\nobject (e.g., setting fonts for theme and layers, adding rounded\nrectangle as background for each of the legends).",
            "name": "r-ggfun"
        },
        {
            "description": "Spatial Visualization with ggplot2. A collection of functions to\nvisualize spatial data and models on top of static maps from various\nonline sources (e.g Google Maps and Stamen Maps). It includes tools\ncommon to those tasks, including functions for geolocation and routing.",
            "name": "r-ggmap"
        },
        {
            "description": "Create Elegant Data Visualisations Using the Grammar of Graphics. A\nsystem for 'declaratively' creating graphics, based on \"The Grammar of\nGraphics\". You provide the data, tell 'ggplot2' how to map variables to\naesthetics, what graphical primitives to use, and it takes care of the\ndetails.",
            "name": "r-ggplot2"
        },
        {
            "description": "'ggplot2' Based Publication Ready Plots. The 'ggplot2' package is\nexcellent and flexible for elegant data visualization in R. However the\ndefault generated plots requires some formatting before we can send them\nfor publication. Furthermore, to customize a 'ggplot', the syntax is\nopaque and this raises the level of difficulty for researchers with no\nadvanced R programming skills. 'ggpubr' provides some easy-to-use\nfunctions for creating and customizing 'ggplot2'- based publication\nready plots.",
            "name": "r-ggpubr"
        },
        {
            "description": "An Implementation of Grammar of Graphics for Graphs and Networks. The\ngrammar of graphics as implemented in ggplot2 is a poor fit for graph\nand network visualizations due to its reliance on tabular data input.\nggraph is an extension of the ggplot2 API tailored to graph\nvisualizations and provides the same flexible approach to building up\nplots layer by layer.",
            "name": "r-ggraph"
        },
        {
            "description": "Repulsive Text and Label Geoms for 'ggplot2'. Provides text and label\ngeoms for 'ggplot2' that help to avoid overlapping text labels. Labels\nrepel away from each other and away from the data points.",
            "name": "r-ggrepel"
        },
        {
            "description": "Provides new statistics, new geometries and new positions for 'ggplot2'\nand a suite of functions to facilitate the creation of statistical\nplots.",
            "name": "r-ggstats"
        },
        {
            "description": "an R package for visualization of tree and annotation data. 'ggtree'\nextends the 'ggplot2' plotting system which implemented the grammar of\ngraphics. 'ggtree' is designed for visualization and annotation of\nphylogenetic trees and other tree-like structures with their annotation\ndata.",
            "name": "r-ggtree"
        },
        {
            "description": "Interactive Grammar of Graphics. An implementation of an interactive\ngrammar of graphics, taking the best parts of 'ggplot2', combining them\nwith the reactive framework from 'shiny' and web graphics from 'vega'.",
            "name": "r-ggvis"
        },
        {
            "description": "'GitHub' 'API'. Minimal client to access the 'GitHub' 'API'.",
            "name": "r-gh"
        },
        {
            "description": "Fit a Gamma-Poisson Generalized Linear Model. Fit linear models to\noverdispersed count data. The package can estimate the overdispersion\nand fit repeated models for matrix input. It is designed to handle large\ninput datasets as they typically occur in single cell RNA-seq\nexperiments.",
            "name": "r-glmgampoi"
        },
        {
            "description": "Authenticate and Create Google APIs. Create R functions that interact\nwith OAuth2 Google APIs <https://developers.google.com/apis-explorer/>\neasily, with auto-refresh and Shiny compatibility.",
            "name": "r-googleauthr"
        },
        {
            "description": "An Interface to Google Drive. Manage Google Drive files from R.",
            "name": "r-googledrive"
        },
        {
            "description": "Access Google Sheets using the Sheets API V4. Interact with Google\nSheets through the Sheets API v4\n<https://developers.google.com/sheets/api>. \"API\" is an acronym for\n\"application programming interface\"; the Sheets API allows users to\ninteract with Google Sheets programmatically, instead of via a web\nbrowser. The \"v4\" refers to the fact that the Sheets API is currently at\nversion 4. This package can read and write both the metadata and the\ncell data in a Sheet.",
            "name": "r-googlesheets4"
        },
        {
            "description": "Base Class and Methods for 'gson' Format. Proposes a new file format\n('gson') for storing gene set and related information, and provides\nread, write and other utilities to process this file format.",
            "name": "r-gson"
        },
        {
            "description": "Arrange 'Grobs' in Tables. Tools to make it easier to work with \"tables\"\nof 'grobs'. The 'gtable' package defines a 'gtable' grob class that\nspecifies a grid along with a list of grobs and their placement in the\ngrid. Further the package makes it easy to manipulate and combine\n'gtable' objects so that complex compositions can be build up\nsequentially.",
            "name": "r-gtable"
        },
        {
            "description": "Construct Modeling Packages. Building modeling packages is hard. A large\namount of effort generally goes into providing an implementation for a\nnew method that is efficient, fast, and correct, but often less emphasis\nis put on the user interface. A good interface requires specialized\nknowledge about S3 methods and formulas, which the average package\ndeveloper might not have. The goal of 'hardhat' is to reduce the burden\naround building new modeling packages by providing functionality for\npreprocessing, predicting, and validating input.",
            "name": "r-hardhat"
        },
        {
            "description": "Import and Export 'SPSS', 'Stata' and 'SAS' Files. Import foreign\nstatistical formats into R via the embedded 'ReadStat' C library,\n<https://github.com/WizardMac/ReadStat>.",
            "name": "r-haven"
        },
        {
            "description": "Pretty Time of Day. Implements an S3 class for storing and formatting\ntime-of-day values, based on the 'difftime' class.",
            "name": "r-hms"
        },
        {
            "description": "Tools for HTML. Tools for HTML generation and output.",
            "name": "r-htmltools"
        },
        {
            "description": "Perform HTTP Requests and Process the Responses. Tools for creating and\nmodifying HTTP requests, then performing them and processing the\nresults. 'httr2' is a modern re-imagining of 'httr' that uses a pipe-\nbased interface and solves more of the problems that API wrapping\npackages face.",
            "name": "r-httr2"
        },
        {
            "description": "Network Analysis and Visualization. Routines for simple graphs and\nnetwork analysis. It can handle large graphs very well and provides\nfunctions for generating random and regular graphs, graph visualization,\ncentrality methods and much more.",
            "name": "r-igraph"
        },
        {
            "description": "Simple Tools for Examining and Cleaning Dirty Data. The main janitor\nfunctions can: perfectly format data.frame column names; provide quick\none- and two-variable tabulations (i.e., frequency tables and\ncrosstabs); and isolate duplicate records. Other janitor functions\nnicely format the tabulation results. These tabulate-and-report\nfunctions approximate popular features of SPSS and Microsoft Excel. This\npackage follows the principles of the \"tidyverse\" and works well with\nthe pipe function %>%. janitor was built with beginning-to-intermediate\nR users in mind and is optimized for user-friendliness. Advanced R users\ncan already do everything covered here, but with janitor they can do it\nfaster and save their thinking for the fun stuff.",
            "name": "r-janitor"
        },
        {
            "description": "Manipulating Labelled Data. Work with labelled data imported from 'SPSS'\nor 'Stata' with 'haven' or 'foreign'. This package provides useful\nfunctions to deal with \"haven_labelled\" and \"haven_labelled_spss\"\nclasses introduced by 'haven' package.",
            "name": "r-labelled"
        },
        {
            "description": "Utilities for Scheduling Functions to Execute Later with Event Loops.\nExecutes arbitrary R or C functions some time after the current time,\nafter the R execution stack has emptied.",
            "name": "r-later"
        },
        {
            "description": "Manage the Life Cycle of your Package Functions. Manage the life cycle\nof your exported functions with shared conventions, documentation\nbadges, and non-invasive deprecation warnings. The 'lifecycle' package\ndefines four development stages (experimental, maturing, stable, and\nquestioning) and three deprecation stages (soft-deprecated, deprecated,\nand defunct). It makes it easy to insert badges corresponding to these\nstages in your documentation. Usage of deprecated functions are\nsignalled with increasing levels of non-invasive verbosity.",
            "name": "r-lifecycle"
        },
        {
            "description": "Visualize R Data Structures with Trees. A set of tools for inspecting\nand understanding R data structures inspired by str(). Includes ast()\nfor visualizing abstract syntax trees, ref() for showing shared\nreferences, cst() for showing call stack trees, and obj_size() for\ncomputing object sizes.",
            "name": "r-lobstr"
        },
        {
            "description": "'Memoisation' of Functions. Cache the results of a function so that when\nyou call it again with the same arguments it returns the pre-computed\nvalue.",
            "name": "r-memoise"
        },
        {
            "description": "Multivariate Imputation by Chained Equations. Multiple imputation using\nFully Conditional Specification (FCS) implemented by the MICE algorithm\nas described in Van Buuren and Groothuis-Oudshoorn (2011)\n<doi:10.18637/jss.v045.i03>. Each variable has its own imputation model.\nBuilt-in imputation models are provided for continuous data (predictive\nmean matching, normal), binary data (logistic regression), unordered\ncategorical data (polytomous logistic regression) and ordered\ncategorical data (proportional odds). MICE can also impute continuous\ntwo-level data (normal model, pan, second-level variables). Passive\nimputation can be used to maintain consistency between variables.\nVarious diagnostic plots are available to inspect the quality of the\nimputations.",
            "name": "r-mice"
        },
        {
            "description": "Modelling Functions that Work with the Pipe. Functions for modelling\nthat help you seamlessly integrate modelling into a pipeline of data\nmanipulation and visualisation.",
            "name": "r-modelr"
        },
        {
            "description": "The Composer of Plots. The 'ggplot2' package provides a strong API for\nsequentially building up a plot, but does not concern itself with\ncomposition of multiple plots. 'patchwork' is a package that expands the\nAPI to allow for arbitrarily complex composition of plots by, among\nothers, providing mathematical operators for combining multiple plots.\nOther packages that try to address this need (but with a different\napproach) are 'gridExtra' and 'cowplot'.",
            "name": "r-patchwork"
        },
        {
            "description": "Predict and explore the age of genes using phylostratigraphic methods",
            "name": "r-phylostratr"
        },
        {
            "description": "Coloured Formatting for Columns. Provides a 'pillar' generic designed\nfor formatting columns of data using the full range of colours provided\nby modern terminals.",
            "name": "r-pillar"
        },
        {
            "description": "Cache 'CRAN'-Like Metadata and R Packages. Metadata and package cache\nfor CRAN-like repositories. This is a utility package to be used by\npackage management tools that want to take advantage of caching.",
            "name": "r-pkgcache"
        },
        {
            "description": "Make Static HTML Documentation for a Package. Generate an attractive and\nuseful website from a source package. 'pkgdown' converts your\ndocumentation, vignettes, 'README', and more to 'HTML' making it easy to\nshare information about your package online.",
            "name": "r-pkgdown"
        },
        {
            "description": "Simulate Package Installation and Attach. Simulates the process of\ninstalling a package and then attaching it. This is a key part of the\n'devtools' package as it allows you to rapidly iterate while developing\na package.",
            "name": "r-pkgload"
        },
        {
            "description": "Create Interactive Web Graphics via 'plotly.js'. Create interactive web\ngraphics from 'ggplot2' graphs and/or a custom interface to the (MIT-\nlicensed) JavaScript library 'plotly.js' inspired by the grammar of\ngraphics.",
            "name": "r-plotly"
        },
        {
            "description": "Object Pooling. Enables the creation of object pools, which make it less\ncomputationally expensive to fetch a new object. Currently the only\nsupported pooled objects are 'DBI' connections.",
            "name": "r-pool"
        },
        {
            "description": "Tools for Working with Posterior Distributions. Provides useful tools\nfor both users and developers of packages for fitting Bayesian models or\nworking with output from Bayesian models. The primary goals of the\npackage are to: (a) Efficiently convert between many different useful\nformats of draws (samples) from posterior or prior distributions. (b)\nProvide consistent methods for operations commonly performed on draws,\nfor example, subsetting, binding, or mutating draws. (c) Provide various\nsummaries of draws in convenient formats. (d) Provide lightweight\nimplementations of state of the art posterior inference diagnostics.\nReferences: Vehtari et al. (2021) <doi:10.1214/20-BA1221>.",
            "name": "r-posterior"
        },
        {
            "description": "Interactive visualizations for profiling R code.",
            "name": "r-profvis"
        },
        {
            "description": "Projection Predictive Feature Selection. Performs projection predictive\nfeature selection for generalized linear models and generalized linear\nand additive multilevel models (see, Piironen, Paasiniemi and Vehtari,\n2020, <https://projecteuclid.org/euclid.ejs/1589335310>, Catalina,\nBurkner and Vehtari, 2020, <arXiv:2010.06994>). The package is\ncompatible with the 'rstanarm' and 'brms' packages, but other reference\nmodels can also be used. See the package vignette for more information\nand examples.",
            "name": "r-projpred"
        },
        {
            "description": "Abstractions for Promise-Based Asynchronous Programming. Provides\nfundamental abstractions for doing asynchronous programming in R using\npromises. Asynchronous programming is useful for allowing a single R\nprocess to orchestrate multiple tasks in the background while also\nattending to something else. Semantics are similar to 'JavaScript'\npromises, but with a syntax that is idiomatic R.",
            "name": "r-promises"
        },
        {
            "description": "Functional Programming Tools. A complete and consistent functional\nprogramming toolkit for R.",
            "name": "r-purrr"
        },
        {
            "description": "Creates Simultaneous Testing Bands for QQ-Plots. Provides functionality\nfor creating Quantile-Quantile (QQ) and Probability-Probability (PP)\nplots with simultaneous testing bands to asses significance of sample\ndeviation from a reference distribution.",
            "name": "r-qqconf"
        },
        {
            "description": "Functions to Make Surveys Processing Easier. Set of functions to make\nthe processing and analysis of surveys easier: interactive shiny apps\nand addins for data recoding, contingency tables, dataset metadata\nhandling, and several convenience functions.",
            "name": "r-questionr"
        },
        {
            "description": "Read Rectangular Text Data. The goal of 'readr' is to provide a fast and\nfriendly way to read rectangular data (like 'csv', 'tsv', and 'fwf'). It\nis designed to flexibly parse many types of data found in the wild,\nwhile still cleanly failing when data unexpectedly changes.",
            "name": "r-readr"
        },
        {
            "description": "Preprocessing Tools to Create Design Matrices. An extensible framework\nto create and preprocess design matrices. Recipes consist of one or more\ndata manipulation and analysis \"steps\". Statistical parameters for the\nsteps can be estimated from an initial data set and then applied to\nother data sets. The resulting design matrices can then be used as\ninputs into statistical or machine learning models.",
            "name": "r-recipes"
        },
        {
            "description": "Prepare Reproducible Example Code via the Clipboard. Convenience wrapper\nthat uses the 'rmarkdown' package to render small snippets of code to\ntarget formats that include both code and output. The goal is to\nencourage the sharing of small, reproducible, and runnable examples on\ncode-oriented websites, such as <https://stackoverflow.com/> and\n<https://github.com>, or in email. 'reprex' also extracts clean,\nrunnable R code from various common formats, such as copy/paste from an\nR session.",
            "name": "r-reprex"
        },
        {
            "description": "A Set of Tools that Enhance Reproducibility Beyond Package Management.\nCollection of high-level, machine- and OS-independent tools for making\ndeeply reproducible and reusable content in R. The two workhorse\nfunctions are Cache and prepInputs; these allow for: nested caching,\nrobust to environments, and objects with environments (like functions);\nand data retrieval and processing in continuous workflow environments.\nIn all cases, efforts are made to make the first and subsequent calls of\nfunctions have the same result, but vastly faster at subsequent times by\nway of checksums and digesting. Several features are still under active\ndevelopment, including cloud storage of cached objects, allowing for\nsharing between users. Several advanced options are available, see\n?reproducibleOptions.",
            "name": "r-reproducible"
        },
        {
            "description": "Interface to 'Python'. Interface to 'Python' modules, classes, and\nfunctions. When calling into 'Python', R data types are automatically\nconverted to their equivalent 'Python' types. When values are returned\nfrom 'Python' to R they are converted back to R types. Compatible with\nall versions of 'Python' >= 2.7.",
            "name": "r-reticulate"
        },
        {
            "description": "Utilities Parsing 'HMMER' Results. 'HMMER' is a profile hidden Markov\nmodel tool used primarily for sequence analysis in bioinformatics\n(<http://hmmer.org/>). 'rhmmer' provides utilities for parsing the\n'HMMER' output into tidy data frames.",
            "name": "r-rhmmer"
        },
        {
            "description": "Database Interface and 'MariaDB' Driver. Implements a 'DBI'-compliant\ninterface to 'MariaDB' (<https://mariadb.org/>) and 'MySQL'\n(<https://www.mysql.com/>) databases.",
            "name": "r-rmariadb"
        },
        {
            "description": "Semantically Rich I/O for the 'NeXML' Format. Provides access to\nphyloinformatic data in 'NeXML' format. The package should add new\nfunctionality to R such as the possibility to manipulate 'NeXML' objects\nin more various and refined way and compatibility with 'ape' objects.",
            "name": "r-rnexml"
        },
        {
            "description": "In-Line Documentation for R. Generate your Rd documentation, 'NAMESPACE'\nfile, and collation field using specially formatted comments. Writing\ndocumentation in-line with code makes it easier to keep your\ndocumentation up-to-date as your requirements change. 'Roxygen2' is\ninspired by the 'Doxygen' system for C++.",
            "name": "r-roxygen2"
        },
        {
            "description": "Deployment Interface for R Markdown Documents and Shiny Applications.\nProgrammatic deployment interface for 'RPubs', 'shinyapps.io', and\n'RStudio Connect'. Supported content types include R Markdown documents,\nShiny applications, Plumber APIs, plots, and static web content.",
            "name": "r-rsconnect"
        },
        {
            "description": "'SQLite' Interface for R. This package embeds the SQLite database engine\nin R and provides an interface compliant with the DBI package. The\nsource for the SQLite engine (version 3.8.6) is included.",
            "name": "r-rsqlite"
        },
        {
            "description": "Pipe-Friendly Framework for Basic Statistical Tests. Provides a simple\nand intuitive pipe-friendly framework, coherent with the 'tidyverse'\ndesign philosophy, for performing basic statistical tests, including\nt-test, Wilcoxon test, ANOVA, Kruskal-Wallis and correlation analyses.\nThe output of each test is automatically transformed into a tidy data\nframe to facilitate visualization. Additional functions are available\nfor reshaping, reordering, manipulating and visualizing correlation\nmatrix. Functions are also included to facilitate the analysis of\nfactorial experiments, including purely 'within-Ss' designs (repeated\nmeasures), purely 'between-Ss' designs, and mixed 'within-and-between-\nSs' designs. It's also possible to compute several effect size metrics,\nincluding \"eta squared\" for ANOVA, \"Cohen's d\" for t-test and 'Cramer V'\nfor the association between categorical variables. The package contains\nhelper functions for identifying univariate and multivariate outliers,\nassessing normality and homogeneity of variances.",
            "name": "r-rstatix"
        },
        {
            "description": "R/Package Version Check. Check latest release version of R and R package\n(both in 'CRAN', 'Bioconductor' or 'Github').",
            "name": "r-rvcheck"
        },
        {
            "description": "Easily Harvest (Scrape) Web Pages. Wrappers around the 'xml2' and 'httr'\npackages to make it easy to download, then manipulate, HTML and XML.",
            "name": "r-rvest"
        },
        {
            "description": "Syntactically Awesome Style Sheets ('Sass'). An 'SCSS' compiler, powered\nby the 'LibSass' library. With this, R developers can use variables,\ninheritance, and functions to generate dynamic style sheets. The package\nuses the 'Sass CSS' extension language, which is stable, powerful, and\nCSS compatible.",
            "name": "r-sass"
        },
        {
            "description": "Scale Functions for Visualization. Graphical scales map data to\naesthetics, and provide methods for automatically determining breaks and\nlabels for axes and legends.",
            "name": "r-scales"
        },
        {
            "description": "Single-Cell Analysis Toolkit for Gene Expression Data in R. A collection\nof tools for doing various analyses of single-cell RNA-seq gene\nexpression data, with a focus on quality control and visualization.",
            "name": "r-scater"
        },
        {
            "description": "Scatter Pie Plot. Creates scatterpie plots, especially useful for\nplotting pies on a map.",
            "name": "r-scatterpie"
        },
        {
            "description": "Variance Stabilizing Transformations for Single Cell UMI Data. A\nnormalization method for single-cell UMI count data using a variance\nstabilizing transformation. The transformation is based on a negative\nbinomial regression model with regularized parameters. As part of the\nsame regression framework, this package also provides functions for\nbatch correction, and data correction. See Hafemeister and Satija 2019\n<doi:10.1101/576827> for more details.",
            "name": "r-sctransform"
        },
        {
            "description": "Tools for Single Cell Genomics. A toolkit for quality control, analysis,\nand exploration of single cell RNA sequencing data. 'Seurat' aims to\nenable users to identify and interpret sources of heterogeneity from\nsingle cell transcriptomic measurements, and to integrate diverse types\nof single cell data. See Satija R, Farrell J, Gennert D, et al (2015)\n<doi:10.1038/nbt.3192>, Macosko E, Basu A, Satija R, et al (2015)\n<doi:10.1016/j.cell.2015.05.002>, and Stuart T, Butler A, et al (2019)\n<doi:10.1016/j.cell.2019.05.031> for more details.",
            "name": "r-seurat"
        },
        {
            "description": "Data Structures for Single Cell Data. Defines S4 classes for single-cell\ngenomic data and associated information, such as dimensionality\nreduction embeddings, nearest-neighbor graphs, and spatially-resolved\ncoordinates. Provides data access methods and R-native hooks to ensure\nthe Seurat object is familiar to other R users. See Satija R, Farrell J,\nGennert D, et al (2015) <doi:10.1038/nbt.3192>, Macosko E, Basu A,\nSatija R, et al (2015) <doi:10.1016/j.cell.2015.05.002>, and Stuart T,\nButler A, et al (2019) <doi:10.1016/j.cell.2019.05.031> for more\ndetails.",
            "name": "r-seuratobject"
        },
        {
            "description": "Web Application Framework for R. Makes it incredibly easy to build\ninteractive web applications with R. Automatic \"reactive\" binding\nbetween inputs and outputs and extensive pre-built widgets make it\npossible to build beautiful, responsive, and powerful applications with\nminimal effort.",
            "name": "r-shiny"
        },
        {
            "description": "Analysis of Single-Cell Chromatin Data. A framework for the analysis and\nexploration of single-cell chromatin data. The 'Signac' package contains\nfunctions for quantifying single-cell chromatin data, computing per-cell\nquality control metrics, dimension reduction and normalization,\nvisualization, and DNA sequence motif analysis. Reference: Stuart et al.\n(2021) <doi:10.1038/s41592-021-01282-5>.",
            "name": "r-signac"
        },
        {
            "description": "Spatiotemporal Arrays, Raster and Vector Data Cubes. Reading,\nmanipulating, writing and plotting spatiotemporal arrays (raster and\nvector data cubes) in 'R', using 'GDAL' bindings provided by 'sf', and\n'NetCDF' bindings by 'ncmeta' and 'RNetCDF'.",
            "name": "r-stars"
        },
        {
            "description": "Simple, Consistent Wrappers for Common String Operations. A consistent,\nsimple and easy to use set of wrappers around the fantastic 'stringi'\npackage. All function and argument names (and positions) are consistent,\nall functions deal with \"NA\"'s and zero length vectors in the same way,\nand the output from one function is easy to feed into the input of\nanother.",
            "name": "r-stringr"
        },
        {
            "description": "Non-Invasive Pretty Printing of R Code. Pretty-prints R code without\nchanging the user's formatting intent.",
            "name": "r-styler"
        },
        {
            "description": "Tools for Working with 'Taxonomic' Databases. Tools for working with\n'taxonomic' databases, including utilities for downloading databases,\nloading them into various 'SQL' databases, cleaning up files, and\nproviding a 'SQL' connection that can be used to do 'SQL' queries\ndirectly or used in 'dplyr'.",
            "name": "r-taxizedb"
        },
        {
            "description": "Unit Testing for R. Software testing is important, but, in part because\nit is frustrating and boring, many of us avoid it. 'testthat' is a\ntesting framework for R that is easy to learn and use, and integrates\nwith your existing 'workflow'.",
            "name": "r-testthat"
        },
        {
            "description": "Simple Data Frames. Provides a 'tbl_df' class (the 'tibble') that\nprovides stricter checking and better formatting than the traditional\ndata frame.",
            "name": "r-tibble"
        },
        {
            "description": "Load US Census Boundary and Attribute Data as 'tidyverse' and 'sf'-Ready\nData Frames. An integrated R interface to the decennial US Census and\nAmerican Community Survey APIs and the US Census Bureau's geographic\nboundary files. Allows R users to return Census and ACS data as\ntidyverse-ready data frames, and optionally returns a list-column with\nfeature geometry for all Census geographies.",
            "name": "r-tidycensus"
        },
        {
            "description": "A Tidy API for Graph Manipulation. A graph, while not \"tidy\" in itself,\ncan be thought of as two tidy data frames describing node and edge data\nrespectively. 'tidygraph' provides an approach to manipulate these two\nvirtual data frames using the API defined in the 'dplyr' package, as\nwell as provides tidy interfaces to a lot of common graph algorithms.",
            "name": "r-tidygraph"
        },
        {
            "description": "Tidy Messy Data. Tools to help to create tidy data, where each column is\na variable, each row is an observation, and each cell contains a single\nvalue. 'tidyr' contains tools for changing the shape (pivoting) and\nhierarchy (nesting and 'unnesting') of a dataset, turning deeply nested\nlists into rectangular data frames ('rectangling'), and extracting\nvalues out of string columns. It also includes tools for working with\nmissing values (both implicit and explicit).",
            "name": "r-tidyr"
        },
        {
            "description": "Select from a Set of Strings. A backend for the selecting functions of\nthe 'tidyverse'. It makes it easy to implement select-like functions in\nyour own packages in a way that is consistent with other 'tidyverse'\ninterfaces for selection.",
            "name": "r-tidyselect"
        },
        {
            "description": "A Tidy Tool for Phylogenetic Tree Data Manipulation. Phylogenetic tree\ngenerally contains multiple components including node, edge, branch and\nassociated data. 'tidytree' provides an approach to convert tree object\nto tidy data frame as well as provides tidy interfaces to manipulate\ntree data.",
            "name": "r-tidytree"
        },
        {
            "description": "Easily Install and Load the 'Tidyverse'. The 'tidyverse' is a set of\npackages that work in harmony because they share common data\nrepresentations and 'API' design. This package is designed to make it\neasy to install and load multiple 'tidyverse' packages in a single step.\nLearn more about the 'tidyverse' at <https://tidyverse.org>.",
            "name": "r-tidyverse"
        },
        {
            "description": "Lightweight Interface to TIGER/Line Shapefiles Download geographic\nshapes from the United States Census Bureau TIGER/Line Shapefiles\n<https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-\nline-file.html>. Functions support downloading and reading in geographic\nboundary data. All downloads can be set up with a cache to avoid\nmultiple downloads. Data is available back to 2000 for most geographies.",
            "name": "r-tinytiger"
        },
        {
            "description": "Base Classes and Functions for Phylogenetic Tree Input and Output.\n'treeio' is an R package to make it easier to import and store\nphylogenetic tree with associated data; and to link external data from\ndifferent sources to phylogeny. It also supports exporting phylogenetic\ntree with heterogeneous associated data to a single tree file and can be\nserved as a platform for merging tree with associated data and\nconverting file formats.",
            "name": "r-treeio"
        },
        {
            "description": "Interpolate Data for Smooth Animations. In order to create smooth\nanimation between states of data, tweening is necessary. This package\nprovides a range of functions for creating tweened data that can be used\nas basis for animation. Furthermore it adds a number of vectorized\ninterpolaters for common R data types such as numeric, date and colour.",
            "name": "r-tweenr"
        },
        {
            "description": "Automate Package and Project Setup. Automate package and project setup\ntasks that are otherwise performed manually. This includes setting up\nunit testing, test coverage, continuous integration, Git, 'GitHub',\nlicenses, 'Rcpp', 'RStudio' projects, and more.",
            "name": "r-usethis"
        },
        {
            "description": "Vector Helpers. Defines new notions of prototype and size that are used\nto provide tools for consistent and well-founded type-coercion and size-\nrecycling, and are in turn connected to ideas of type- and size-\nstability useful for analyzing function interfaces.",
            "name": "r-vctrs"
        },
        {
            "description": "Read and Write Rectangular Text Data Quickly. The goal of 'vroom' is to\nread and write data (like 'csv', 'tsv' and 'fwf') quickly. When reading\nit uses a quick initial indexing step, then reads the values lazily , so\nonly the data you actually use needs to be read. The writer formats the\ndata in parallel and writes to disk asynchronously from formatting.",
            "name": "r-vroom"
        },
        {
            "description": "Find Differences Between R Objects. Compare complex R objects and reveal\nthe key differences. Designed particularly for use in testing packages\nwhere being able to quickly isolate key differences makes understanding\ntest failures much easier.",
            "name": "r-waldo"
        },
        {
            "description": "Who are You? Bayesian Prediction of Racial Category Using Surname, First\nName, Middle Name, and Geolocation Predicts individual race/ethnicity\nusing surname, first name, middle name, geolocation, and other\nattributes, such as gender and age. The method utilizes Bayes' Rule\n(with optional measurement error correction) to compute the posterior\nprobability of each racial category for any given individual. The\npackage implements methods described in Imai and Khanna (2016)\n\"Improving Ecological Inference by Predicting Individual Ethnicity from\nVoter Registration Records\" Political Analysis <doi:10.1093/pan/mpw001>.",
            "name": "r-wru"
        },
        {
            "description": "Package required POI jars for the xlsx package. Work with XML files\nusing a simple, consistent interface. Built on top of the 'libxml2' C\nlibrary.",
            "name": "r-xml2"
        },
        {
            "description": "Supporting Functions for Packages Maintained by 'YuLab-SMU'.\nMiscellaneous functions commonly used by 'YuLab-SMU'.",
            "name": "r-yulab-utils"
        }
    ],
    "description": "Functions for Base Types and Core R and 'Tidyverse' Features. A toolbox\nfor working with base types, core R features like the condition system,\nand core 'Tidyverse' features like tidy evaluation.\n",
    "homepage": "https://cloud.r-project.org/package=rlang",
    "latest_version": "1.1.4",
    "maintainers": [],
    "name": "r-rlang",
    "patches": [],
    "resources": [],
    "variants": [
        {
            "default": "generic",
            "description": "Build systems supported by the package",
            "name": "build_system"
        }
    ],
    "versions": [
        {
            "name": "1.1.4",
            "sha256": "f2d74527508bf3287102470beb27de0d234c3cbba399c28d3312f2c83c64a6e1"
        },
        {
            "name": "1.1.2",
            "sha256": "2a0ee1dc6e5c59b283c32db5e74e869922a336197cb406fe92622b6ec66f8092"
        },
        {
            "name": "1.1.1",
            "sha256": "5e5ec9a7796977216c39d94b1e342e08f0681746657067ba30de11b8fa8ada99"
        },
        {
            "name": "1.1.0",
            "sha256": "f89859d91c9edc05fd7ccf21163fe53ad58da907ee273a93d5ab004a8649335b"
        },
        {
            "name": "1.0.6",
            "sha256": "e6973d98a0ea301c0da1eeaa435e9e65d1c3f0b95ed68bdc2d6cb0c610166760"
        },
        {
            "name": "1.0.2",
            "sha256": "8de87c3e6fb0b3cce2dabc6908186f8e1528cc0c16b54de965fe02d405fdd7cc"
        },
        {
            "name": "1.0.1",
            "sha256": "e59fd5c0f7530dbe329aa01621f6ef5a6474ff3ec96de0c0d24018fc2f21ad7f"
        },
        {
            "name": "1.0.0",
            "sha256": "ab6134c97b3100613ba2a15792fde5341f485ba85432a81370c6270c73396e6a"
        },
        {
            "name": "0.4.12",
            "sha256": "2a26915738be120a56ec93e781bcb50ffa1031e11904544198b4a15c35029915"
        },
        {
            "name": "0.4.10",
            "sha256": "07530270c4c199f2b7efc5d57a476d99babd9d0c3388a02bb7d57fe312da3576"
        },
        {
            "name": "0.4.6",
            "sha256": "3a81b107765fd6ac0ad716c428d01878775ded9208ba125d43c890c73d2533ca"
        },
        {
            "name": "0.4.0",
            "sha256": "9748a4a217548bbe5631c18fd88c94811950446f798ff21fb327703aebaa150d"
        },
        {
            "name": "0.3.4",
            "sha256": "4e467f7b0dcbde91b60c292137d2c69cecaa713a6e4c9b7157ef6fd5453b7ade"
        },
        {
            "name": "0.3.1",
            "sha256": "30427b2be2288e88acd30c4ea348ee06043a649fd73623a63148b1ad96317151"
        },
        {
            "name": "0.3.0.1",
            "sha256": "29451db0a3cabd75761d32df47a5d43ccadbde07ecb693ffdd73f122a0b9f348"
        },
        {
            "name": "0.3.0",
            "sha256": "9ab10ea3e19b2d60a289602ebbefa83509f430db1c8161e523896c374241b893"
        },
        {
            "name": "0.2.2",
            "sha256": "c9119420ff0caeb6b0fcee8800e2fb1ec072e291e0e53b8acea3c4cf49420d33"
        },
        {
            "name": "0.1.4",
            "sha256": "8d9b6c962ae81b96c96ada9614c6a1ffb9eda12dd407e2aff634f7d335e7b9f4"
        },
        {
            "name": "0.1.2",
            "sha256": "90cfcd88cae6fff044fca64b24a8e6bdc09fc276163b518ff2d90268b0c785f9"
        },
        {
            "name": "0.1.1",
            "sha256": "5901f95d68728a7d9bb1c2373a20ce6e4ad222f66e397e7735e9eff987c73c3f"
        }
    ],
    "versions_deprecated": []
}