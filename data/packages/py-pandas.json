{
    "aliases": [],
    "build_system": "PythonPackage",
    "conflicts": [],
    "dependencies": [
        {
            "description": "A cross-language development platform for in-memory data. This package\ncontains the C++ bindings.",
            "name": "arrow"
        },
        {
            "description": "The NVIDIA HPC SDK is a comprehensive suite of compilers, libraries and\ntools essential to maximizing developer productivity and the performance\nand portability of HPC applications. The NVIDIA HPC SDK C, C++, and\nFortran compilers support GPU acceleration of HPC modeling and\nsimulation applications with standard C++ and Fortran, OpenACC\ndirectives, and CUDA. GPU-accelerated math libraries maximize\nperformance on common HPC algorithms, and optimized communications\nlibraries enable standards-based multi-GPU and scalable systems\nprogramming. Performance profiling and debugging tools simplify porting\nand optimization of HPC applications.",
            "name": "c"
        },
        {
            "description": "The NVIDIA HPC SDK is a comprehensive suite of compilers, libraries and\ntools essential to maximizing developer productivity and the performance\nand portability of HPC applications. The NVIDIA HPC SDK C, C++, and\nFortran compilers support GPU acceleration of HPC modeling and\nsimulation applications with standard C++ and Fortran, OpenACC\ndirectives, and CUDA. GPU-accelerated math libraries maximize\nperformance on common HPC algorithms, and optimized communications\nlibraries enable standards-based multi-GPU and scalable systems\nprogramming. Performance profiling and debugging tools simplify porting\nand optimization of HPC applications.",
            "name": "cxx"
        },
        {
            "description": "Meson is a portable open source build system meant to be both extremely\nfast, and as user friendly as possible.",
            "name": "meson"
        },
        {
            "description": "A collection of fast NumPy array functions written in Cython.",
            "name": "py-bottleneck"
        },
        {
            "description": "The Cython compiler for writing C extensions for the Python language.",
            "name": "py-cython"
        },
        {
            "description": "Meson Python build backend (PEP 517).",
            "name": "py-meson-python"
        },
        {
            "description": "NumPy aware dynamic Python compiler using LLVM",
            "name": "py-numba"
        },
        {
            "description": "Fast numerical expression evaluator for NumPy",
            "name": "py-numexpr"
        },
        {
            "description": "Fundamental package for array computing in Python.",
            "name": "py-numpy"
        },
        {
            "description": "Odfpy is a library to read and write OpenDocument v. 1.2 files.",
            "name": "py-odfpy"
        },
        {
            "description": "A Python library to read/write Excel 2010 xlsx/xlsm files",
            "name": "py-openpyxl"
        },
        {
            "description": "The PyPA recommended tool for installing Python packages.",
            "name": "py-pip"
        },
        {
            "description": "A cross-language development platform for in-memory data. This package\ncontains the Python bindings.",
            "name": "py-pyarrow"
        },
        {
            "description": "Python binding for Rust's library for reading excel and odf file -\ncalamine.",
            "name": "py-python-calamine"
        },
        {
            "description": "Extensions to the standard Python datetime module.",
            "name": "py-python-dateutil"
        },
        {
            "description": "World timezone definitions, modern and historical.",
            "name": "py-pytz"
        },
        {
            "description": "Excel 2007-2010 Binary Workbook (xlsb) parser",
            "name": "py-pyxlsb"
        },
        {
            "description": "A Python utility that aids in the process of downloading, building,\nupgrading, installing, and uninstalling Python packages.",
            "name": "py-setuptools"
        },
        {
            "description": "Provider of IANA time zone data.",
            "name": "py-tzdata"
        },
        {
            "description": "Versioneer is a tool to automatically update version strings by asking\nyour version-control system about the current tree.",
            "name": "py-versioneer"
        },
        {
            "description": "A built-package format for Python.",
            "name": "py-wheel"
        },
        {
            "description": "Library for developers to extract data from Microsoft Excel (tm)\nspreadsheet files",
            "name": "py-xlrd"
        },
        {
            "description": "XlsxWriter is a Python module for writing files in the Excel 2007+ XLSX\nfile format.",
            "name": "py-xlsxwriter"
        },
        {
            "description": "Library to create spreadsheet files compatible with MS Excel\n97/2000/XP/2003 XLS files, on any platform, with Python 2.6, 2.7, 3.3+.",
            "name": "py-xlwt"
        },
        {
            "description": "The Python programming language.",
            "name": "python"
        },
        {
            "description": "A Spack managed Python virtual environment",
            "name": "python-venv"
        }
    ],
    "dependent_to": [
        {
            "description": "AMR-Wind is a massively parallel, block-structured adaptive-mesh,\nincompressible flow sover for wind turbine and wind farm simulations.",
            "name": "amr-wind"
        },
        {
            "description": "Assesses genome assembly and annotation completeness with Benchmarking\nUniversal Single-Copy Orthologs",
            "name": "busco"
        },
        {
            "description": "CallFlow is an interactive visual analysis tool that provides a high-\nlevel overview of CCTs together with semantic refinement operations to\nprogressively explore the CCTs.",
            "name": "callflow"
        },
        {
            "description": "This is a an implementation of the CosmoFlow 3D convolutional neural\nnetwork for benchmarking. It is written in TensorFlow with the Keras API\nand uses Horovod for distributed training.",
            "name": "cosmoflow-benchmark"
        },
        {
            "description": "CosmoMC is a Fortran 2008 Markov-Chain Monte-Carlo (MCMC) engine for\nexploring cosmological parameter space, together with Fortran and python\ncode for analysing Monte-Carlo samples and importance sampling (plus a\nsuite of scripts for building grids of runs, plotting and presenting\nresults).",
            "name": "cosmomc"
        },
        {
            "description": "The CRADL proxy application captured performance metrics during\ninference on data from multiphysics codes, specifically ALE\nhydrodynamics codes.",
            "name": "cradl"
        },
        {
            "description": "CryoDRGN is a neural network based algorithm for heterogeneous cryo-EM\nreconstruction. In particular, the method models a continuous\ndistribution over 3D structures by using a neural network based\nrepresentation for the volume",
            "name": "cryodrgn"
        },
        {
            "description": "Drishti is a command-line tool to guide end-users in optimizing I/O in\ntheir applications by detecting typical I/O performance pitfalls and\nproviding a set of recommendations.",
            "name": "drishti"
        },
        {
            "description": "DXT Explorer is an interactive web-based log analysis tool to visualize\nDarshan DXT logs and help understand the I/O behavior of applications.",
            "name": "dxt-explorer"
        },
        {
            "description": "The Global Extensible Open Power Manager (GEOPM) Runtime is designed to\nenhance energy efficiency of applications through active hardware\nconfiguration.",
            "name": "geopm-runtime"
        },
        {
            "description": "GPTune is an autotuning framework that relies on multitask and transfer\nlearnings to help solve the underlying black-box optimization problem\nusing Bayesian optimization methodologies.",
            "name": "gptune"
        },
        {
            "description": "HiCOPS is a software framework for accelerating database peptide search\nworkflows on supercomputers. HiCOPS provided algorithm-independent\nparallelizations and optimizations can be extended into new HPC database\nsearch algorithms or scalably accelerate the existing ones.",
            "name": "hicops"
        },
        {
            "description": "HybPiper was designed for targeted sequence capture, in which DNA\nsequencing libraries are enriched for gene regions of interest,\nespecially for phylogenetics. HybPiper is a suite of Python scripts that\nwrap and connect bioinformatics tools in order to extract target\nsequences from high-throughput DNA sequencing reads",
            "name": "hybpiper"
        },
        {
            "description": "IsoQuant: Transcript discovery and quantification with long RNA reads",
            "name": "isoquant"
        },
        {
            "description": "ldsc is a command line tool for estimating heritability and genetic\ncorrelation from GWAS summary statistics. ldsc also computes LD scores",
            "name": "ldsc"
        },
        {
            "description": "Statistical tool that matches up grids with either gridded analyses or\npoint observations and applies configurable methods to compute\nstatistics and diagnostics",
            "name": "met"
        },
        {
            "description": "mlpack is an intuitive, fast, and flexible header-only C++ machine\nlearning library with bindings to other languages. It is meant to be a\nmachine learning analog to LAPACK, and aims to implement a wide array of\nmachine learning methods and functions as a \"swiss army knife\" for\nmachine learning researchers.",
            "name": "mlpack"
        },
        {
            "description": "PyTorch implementation for the climate segmentation benchmark, based on\nthe Exascale Deep Learning for Climate Analytics",
            "name": "mlperf-deepcam"
        },
        {
            "description": "Advanced Profiling and Analytics for AMD Hardware",
            "name": "omniperf"
        },
        {
            "description": "OpenTURNS is a scientific C++ and Python library featuring an internal\ndata model and algorithms dedicated to the treatment of uncertainties.\nThe main goal of this library is to provide all functionalities needed\nto treat uncertainties in studies with industrial applications. Targeted\nusers are all engineers who want to introduce the probabilistic\ndimension in their so far deterministic studies.",
            "name": "openturns"
        },
        {
            "description": "ParaView is an open-source, multi-platform data analysis and\nvisualization application. This package includes the Catalyst in-situ\nlibrary for versions 5.7 and greater, otherwise use the catalyst\npackage.",
            "name": "paraview"
        },
        {
            "description": "PaRSEC: the Parallel Runtime Scheduler and Execution Controller PaRSEC\nis a runtime and a programming toolbox that support the design and\nparallel execution of micro-tasks on distributed, heterogeneous systems.",
            "name": "parsec"
        },
        {
            "description": "pharokka is a rapid standardised annotation pipeline for bacteriophage\ngenomes",
            "name": "pharokka"
        },
        {
            "description": "PORTable CULLing of Invalid Splice junctions",
            "name": "portcullis"
        },
        {
            "description": "Possvm (Phylogenetic Ortholog Sorting with Species oVerlap and MCL) is a\npython tool to analyse pre-computed gene trees and identify pairs and\nclusters of orthologous genes. It takes advantage of the species overlap\nalgorithm implemented in the ETE toolkit to parse the phylogeny and\nidentify orthologous gene pairs, and MCL clustering for orthogroup\nidentification.",
            "name": "possvm"
        },
        {
            "description": "Standalone monitor for process resource consumption.",
            "name": "prmon"
        },
        {
            "description": "Python package to automate ABINIT calculations and analyze the results.",
            "name": "py-abipy"
        },
        {
            "description": "An automatic evaluator for instruction-following language models. Human-\nvalidated, high-quality, cheap, and fast.",
            "name": "py-alpaca-eval"
        },
        {
            "description": "AlpacaFarm is a simulator that enables research and development on\nlearning from feedback at a fraction of the usual cost, promoting\naccessible research on instruction following and alignment.",
            "name": "py-alpaca-farm"
        },
        {
            "description": "AlphaFold is an AI system developed by DeepMind that predicts a\nprotein's 3D structure from its amino acid sequence. It regularly\nachieves accuracy competitive with experiment.",
            "name": "py-alphafold"
        },
        {
            "description": "Declarative statistical visualization library for Python",
            "name": "py-altair"
        },
        {
            "description": "Advanced Multilanguage Interface for CVODES and IDAS",
            "name": "py-amici"
        },
        {
            "description": "AMReX Python Bindings with pybind11",
            "name": "py-amrex"
        },
        {
            "description": "anndata is a Python package for handling annotated data matrices in\nmemory and on disk, positioned between pandas and xarray.",
            "name": "py-anndata"
        },
        {
            "description": "Advanced Normalization Tools in Python.",
            "name": "py-antspyx"
        },
        {
            "description": "Anvi\u2019o is a comprehensive platform that brings together many aspects of\ntoday\u2019s cutting-edge computational strategies of data-enabled\nmicrobiology, including genomics, metagenomics, metatranscriptomics,\npangenomics, metapangenomics, phylogenomics, and microbial population\ngenetics in an integrated and easy-to-use fashion through extensive\ninteractive visualization capabilities.",
            "name": "py-anvio"
        },
        {
            "description": "ArcGIS API for Python.",
            "name": "py-arcgis"
        },
        {
            "description": "Autoregressive Conditional Heteroskedasticity (ARCH) and other tools for\nfinancial econometrics, written in Python (with Cython and/or Numba used\nto improve performance)",
            "name": "py-arch"
        },
        {
            "description": "This is the python client for Arkouda.",
            "name": "py-arkouda"
        },
        {
            "description": "Python ARM Radar Toolkit. A growing collection of weather radar\nalgorithms and utilities build on top of the Scientific Python stack and\ndistributed under the 3-Clause BSD license. Py-ART is used by the\nAtmospheric Radiation Measurement (ARM) Climate Research Facility for\nworking with data from a number of precipitation and cloud radars, but\nhas been designed so that it can be used by others in the radar and\natmospheric communities to examine, processes, and analyse data from\nmany types of weather radars.",
            "name": "py-arm-pyart"
        },
        {
            "description": "ArviZ (pronounced \"AR-vees\") is a Python package for exploratory\nanalysis of Bayesian models. Includes functions for posterior analysis,\nmodel checking, comparison and diagnostics.",
            "name": "py-arviz"
        },
        {
            "description": "The Astropy Project is a community effort to develop a single core\npackage for Astronomy in Python and foster interoperability between\nPython astronomy packages.",
            "name": "py-astropy"
        },
        {
            "description": "Adaptive experimentation is the machine-learning guided process of\niteratively exploring a (possibly infinite) parameter space in order to\nidentify optimal configurations in a resource-efficient manner. Ax\ncurrently supports Bayesian optimization and bandit optimization as\nexploration strategies. Bayesian optimization in Ax is powered by\nBoTorch, a modern library for Bayesian optimization research built on\nPyTorch.",
            "name": "py-ax-platform"
        },
        {
            "description": "Converts and organises raw MRI data-sets according to the Brain Imaging\nData Structure (BIDS).",
            "name": "py-bidscoin"
        },
        {
            "description": "The BIOM file format (canonically pronounced biome) is designed to be a\ngeneral-use format for representing biological sample by observation\ncontingency tables.",
            "name": "py-biom-format"
        },
        {
            "description": "Working with molecular structures in pandas DataFrames",
            "name": "py-biopandas"
        },
        {
            "description": "Python library to optimize and evaluate electrical models.",
            "name": "py-bluepyemodel"
        },
        {
            "description": "Bluebrain Python Optimisation Library",
            "name": "py-bluepyopt"
        },
        {
            "description": "The Brain Modeling Toolkit",
            "name": "py-bmtk"
        },
        {
            "description": "Statistical and novel interactive HTML plots for Python",
            "name": "py-bokeh"
        },
        {
            "description": "Interactive plotting for the Jupyter notebook, using d3.js and\nipywidgets.",
            "name": "py-bqplot"
        },
        {
            "description": "The carputils framework for running simulations with the openCARP\nsoftware.",
            "name": "py-carputils"
        },
        {
            "description": "A set of python tools for reading, writing and viewing Cinema databases",
            "name": "py-cinemasci"
        },
        {
            "description": "CMSeq is a set of commands to provide an interface to .bam files for\ncoverage and sequence consensus.",
            "name": "py-cmseq"
        },
        {
            "description": "A clean and simple data loading library for Continual Learning",
            "name": "py-continuum"
        },
        {
            "description": "This toolkit contains tools to extract conversational features and\nanalyze social phenomena in conversations, using a single unified\ninterface inspired by (and compatible with) scikit-learn.",
            "name": "py-convokit"
        },
        {
            "description": "Copulas is a Python library for modeling multivariate distributions and\nsampling from them using copula functions. Given a table containing\nnumerical data, we can use Copulas to learn the distribution and later\non generate new synthetic rows following the same statistical\nproperties.",
            "name": "py-copulas"
        },
        {
            "description": "A generic correction library",
            "name": "py-correctionlib"
        },
        {
            "description": "CTGAN is a collection of Deep Learning based Synthetic Data Generators\nfor single table data, which are able to learn from real data and\ngenerate synthetic clones with high fidelity.",
            "name": "py-ctgan"
        },
        {
            "description": "Built based on the Apache Arrow columnar memory format, cuDF is a GPU\nDataFrame library for loading, joining, aggregating, filtering, and\notherwise manipulating data.",
            "name": "py-cudf"
        },
        {
            "description": "Productivity Tools for Plotly + Pandas. This library binds the power of\nplotly with the flexibility of pandas for easy plotting.",
            "name": "py-cufflinks"
        },
        {
            "description": "Pre- and post-processing tools for DAMASK",
            "name": "py-damask"
        },
        {
            "description": "Python utilities to interact with Darshan log records of HPC\napplications.",
            "name": "py-darshan"
        },
        {
            "description": "Dask is a flexible parallel computing library for analytics.",
            "name": "py-dask"
        },
        {
            "description": "Dask DataFrames with query optimization.",
            "name": "py-dask-expr"
        },
        {
            "description": "Scalable Machine Learning with Dask.",
            "name": "py-dask-ml"
        },
        {
            "description": "An analysis environment for satellite and other earth observation data.",
            "name": "py-datacube"
        },
        {
            "description": "DataLad extension package for neuro/medical imaging",
            "name": "py-datalad-neuroimaging"
        },
        {
            "description": "Datasets is a lightweight library providing two main features: one-line\ndataloaders for many public datasets and efficient data pre-processing.",
            "name": "py-datasets"
        },
        {
            "description": "Datashader is a data rasterization pipeline for automating the process\nof creating meaningful representations of large amounts of data",
            "name": "py-datashader"
        },
        {
            "description": "DeepEcho is a Synthetic Data Generation Python library for mixed-type,\nmultivariate time series.",
            "name": "py-deepecho"
        },
        {
            "description": "Scalable asynchronous hyperparameter optimization, neural architecture\nsearch, and parallel ensemble of predictive models.",
            "name": "py-deephyper"
        },
        {
            "description": "deep-significance: Easy and Better Significance Testing for Deep Neural\nNetworks",
            "name": "py-deepsig"
        },
        {
            "description": "Devito is a Python package to implement optimized stencil computation.\n(e.g., finite differences, image processing, machine learning) from\nhigh-level symbolic problem definitions. Devito builds on SymPy and\nemploys automated code generation and just-in-time compilation to\nexecute optimized computational kernels on several computer platforms,\nincluding CPUs, GPUs, and clusters thereof.",
            "name": "py-devito"
        },
        {
            "description": "Library for interaction with and instrumentation of remote devices.",
            "name": "py-devlib"
        },
        {
            "description": "A Modified version of scikit-optimize a Sequential model-based\noptimization toolbox for DeepHyper. Scikit-Optimize, or skopt, is a\nsimple and efficient library to minimize (very) expensive and noisy\nblack-box functions. It implements several methods for sequential model-\nbased optimization. skopt aims to be accessible and easy to use in many\ncontexts. The library is built on top of NumPy, SciPy and Scikit-Learn.",
            "name": "py-dh-scikit-optimize"
        },
        {
            "description": "Dinosaur: differentiable dynamics for global atmospheric modeling.",
            "name": "py-dinosaur"
        },
        {
            "description": "dRep is a python program for rapidly comparing large numbers of genomes.\ndRep can also \"de-replicate\" a genome set by identifying groups of\nhighly similar genomes and choosing the best representative genome for\neach genome set.",
            "name": "py-drep"
        },
        {
            "description": "Earth-2 Model Intercomparison Project (MIP). A python framework that\nenables climate researchers and scientists to explore and experiment\nwith AI models for weather and climate.",
            "name": "py-earth2mip"
        },
        {
            "description": "Elephant is a package for analysis of electrophysiology data in Python",
            "name": "py-elephant"
        },
        {
            "description": "Embedding reader is a module to make it easy to read efficiently a large\ncollection of embeddings stored in any file system.",
            "name": "py-embedding-reader"
        },
        {
            "description": "Python package for generation of protein sequences and evolutionary\nalignments via discrete diffusion models",
            "name": "py-evodiff"
        },
        {
            "description": "You can use fastai without any installation by using Google Colab. In\nfact, every page of this documentation is also available as an\ninteractive notebook - click \"Open in colab\" at the top of any page to\nopen it (be sure to change the Colab runtime to \"GPU\" to have it run\nfast!) See the fast.ai documentation on Using Colab for more\ninformation.",
            "name": "py-fastai"
        },
        {
            "description": "Optimizing Protein Structure Prediction Model Training and Inference on\nGPU Clusters.",
            "name": "py-fastfold"
        },
        {
            "description": "fitter package provides a simple class to identify the distribution from\nwhich a data samples is generated from. It uses 80 distributions from\nScipy and allows you to plot the results to check what is the most\nprobable distribution and the best parameters.",
            "name": "py-fitter"
        },
        {
            "description": "Fast & furious GroupBy operations for dask.array.",
            "name": "py-flox"
        },
        {
            "description": "Formulaic is a high-performance implementation of Wilkinson formulas for\nPython.",
            "name": "py-formulaic"
        },
        {
            "description": "A Python package for interactive mapping using Google Earth Engine and\nipyleaflet.",
            "name": "py-geemap"
        },
        {
            "description": "Simple Client for Earth Engine Uploads with Selenium Support.",
            "name": "py-geeup"
        },
        {
            "description": "GeoPandas is an open source project to make working with geospatial data\nin python easier. GeoPandas extends the datatypes used by pandas to\nallow spatial operations on geometric types. Geometric operations are\nperformed by shapely. Geopandas further depends on fiona for file access\nand descartes and matplotlib for plotting.",
            "name": "py-geopandas"
        },
        {
            "description": "geoplot is a high-level Python geospatial plotting library. It's an\nextension to cartopy and matplotlib which makes mapping easy: like\nseaborn for geospatial.",
            "name": "py-geoplot"
        },
        {
            "description": "The Global Extensible Open Power Manager (GEOPM) Service provides a user\ninterface for accessing hardware telemetry and settings securely.",
            "name": "py-geopmpy"
        },
        {
            "description": "A toolbox for accurate single-trial estimates in fMRI time-series data.",
            "name": "py-glmsingle"
        },
        {
            "description": "GluonCV provides implementations of state-of-the-art (SOTA) deep\nlearning algorithms in computer vision. It aims to help engineers,\nresearchers, and students quickly prototype products, validate new ideas\nand learn computer vision.",
            "name": "py-gluoncv"
        },
        {
            "description": "Python scripts to find enrichment of GO terms",
            "name": "py-goatools"
        },
        {
            "description": "Python library for easily interacting with trained machine learning\nmodels",
            "name": "py-gradio"
        },
        {
            "description": "GraphCast: Learning skillful medium-range global weather forecasting.",
            "name": "py-graphcast"
        },
        {
            "description": "Cloud-native genomic dataframes and batch computing (Python API)",
            "name": "py-hail"
        },
        {
            "description": "Hatchet is a performance tool for analyzing hierarchical performance\ndata using a graph-indexed Pandas dataframe.",
            "name": "py-hatchet"
        },
        {
            "description": "Hclust2 is a handy tool for plotting heat-maps with several useful\noptions to produce high quality figures that can be used in publication.",
            "name": "py-hclust2"
        },
        {
            "description": "Machine Learning for High Energy Physics",
            "name": "py-hep-ml"
        },
        {
            "description": "hepstats is a library for statistical inference aiming to cover the\nneeds in High Energy Physics. It is part of the Scikit-HEP project.",
            "name": "py-hepstats"
        },
        {
            "description": "Composable histogram primitives for distributed data reduction.",
            "name": "py-histogrammar"
        },
        {
            "description": "A Python library designed to make data analysis and visualization\nseamless and simple.",
            "name": "py-holoviews"
        },
        {
            "description": "A high-level plotting API for pandas, dask, xarray, and networkx built\non HoloViews.",
            "name": "py-hvplot"
        },
        {
            "description": "A library for property based testing.",
            "name": "py-hypothesis"
        },
        {
            "description": "imbalanced-learn is a python package offering a number of re-sampling\ntechniques commonly used in datasets showing strong between-class\nimbalance. It is compatible with scikit-learn and is part of scikit-\nlearn-contrib projects.",
            "name": "py-imbalanced-learn"
        },
        {
            "description": "inStrain is python program for analysis of co-occurring genome\npopulations from metagenomes that allows highly accurate genome\ncomparisons, analysis of coverage, microdiversity, and linkage, and\nsensitive SNP detection with gene localization and synonymous non-\nsynonymous identification.",
            "name": "py-instrain"
        },
        {
            "description": "An interactive toolkit for assembly and analysis of restriction-site\nassociated genomic data sets (e.g., RAD, ddRAD, GBS) for population\ngenetic and phylogenetic studies.",
            "name": "py-ipyrad"
        },
        {
            "description": "Python wrapper around kallisto | bustools for scRNA-seq analysis.",
            "name": "py-kb-python"
        },
        {
            "description": "Kosh allows codes to store, query, share data via an easy-to-use Python\nAPI. Kosh lies on top of Sina and can use any database backend supported\nby Sina. In adition Kosh aims to make data access and sharing as simple\nas possible.",
            "name": "py-kosh"
        },
        {
            "description": "Survival analysis was originally developed and applied heavily by the\nactuarial and medical community. Its purpose was to answer *why do\nevents occur now versus later* under uncertainty (where *events* might\nrefer to deaths, disease remission, etc.). *lifelines* is a pure Python\nimplementation of the best parts of survival analysis.",
            "name": "py-lifelines"
        },
        {
            "description": "Lighning-UQ-Box: A toolbox for uncertainty quantification in deep\nlearning.",
            "name": "py-lightning-uq-box"
        },
        {
            "description": "Classification Schemes for Choropleth Maps.",
            "name": "py-mapclassify"
        },
        {
            "description": "Matminer is a library for performing data mining in the field of\nmaterials science.",
            "name": "py-matminer"
        },
        {
            "description": "Melissa is a file-avoiding, adaptive, fault-tolerant and elastic\nframework, to run large-scale sensitivity analysis or deep-surrogate\ntraining on supercomputers. This package builds the launcher and server\nmodules.",
            "name": "py-melissa-core"
        },
        {
            "description": "MetaPhlAn is a computational tool for profiling the composition of\nmicrobial communities (Bacteria, Archaea and Eukaryotes) from\nmetagenomic shotgun sequencing data (i.e. not 16S) with species-level.",
            "name": "py-metaphlan"
        },
        {
            "description": "Collection of tools for reading, visualizing and performing calculations\nwith weather data.",
            "name": "py-metpy"
        },
        {
            "description": "Mizani is a scales package for graphics. It is based on Hadley Wickham's\nScales package.",
            "name": "py-mizani"
        },
        {
            "description": "MLflow: A Platform for ML Development and Productionization.",
            "name": "py-mlflow"
        },
        {
            "description": "Mlxtend (machine learning extensions) is a Python library of useful\ntools for the day-to-day data science tasks.",
            "name": "py-mlxtend"
        },
        {
            "description": "MNE python project for MEG and EEG data analysis.",
            "name": "py-mne"
        },
        {
            "description": "Modin: Make your pandas code run faster by changing one line of code.",
            "name": "py-modin"
        },
        {
            "description": "Python morphology manipulation toolkit",
            "name": "py-morph-tool"
        },
        {
            "description": "The py-motmetrics library provides a Python implementation of metrics\nfor benchmarking multiple object trackers (MOT).",
            "name": "py-motmetrics"
        },
        {
            "description": "Multi-class imbalance is a common problem occurring in real-world\nsupervised classifications tasks. While there has already been some\nresearch on the specialized methods aiming to tackle that challenging\nproblem, most of them still lack coherent Python implementation that is\nsimple, intuitive and easy to use. multi-imbalance is a python package\ntackling the problem of multi-class imbalanced datasets in machine\nlearnin",
            "name": "py-multi-imbalance"
        },
        {
            "description": "Functions to extract information from Oxford Nanopore sequencing data\nand alignments",
            "name": "py-nanoget"
        },
        {
            "description": "A few simple math function for other Oxford Nanopore processing scripts",
            "name": "py-nanomath"
        },
        {
            "description": "Plotting scripts for long read sequencing data",
            "name": "py-nanoplot"
        },
        {
            "description": "Flexible metadata store for MLOps, built for research and production\nteams that run a lot of experiments.",
            "name": "py-neptune-client"
        },
        {
            "description": "Netpyne: A python package to facilitate the development, parallel\nsimulation, optimization and analysis of multiscale biological neuronal\nnetworks in NEURON.",
            "name": "py-netpyne"
        },
        {
            "description": "NetworkX is a Python package for the creation, manipulation, and study\nof the structure, dynamics, and functions of complex networks.",
            "name": "py-networkx"
        },
        {
            "description": "NeuralGCM: Hybrid ML + Physics model of Earth's atmosphere.",
            "name": "py-neuralgcm"
        },
        {
            "description": "The Python Toolbox for Neurophysiological Signal Processing. This\npackage is the continuation of NeuroKit 1. It's a user-friendly package\nproviding easy access to advanced biosignal processing routines.\nResearchers and clinicians without extensive knowledge of programming or\nbiomedical signal processing can analyze physiological data with only\ntwo lines of code.",
            "name": "py-neurokit2"
        },
        {
            "description": "Python library neuron morphology analysis",
            "name": "py-neurom"
        },
        {
            "description": "Blue Brain Nexus Forge is a domain-agnostic, generic and extensible\nPython framework enabling non-expert users to create and manage\nknowledge graphs.",
            "name": "py-nexusforge"
        },
        {
            "description": "BetaSeries Correlations implemented in Nipype.",
            "name": "py-nibetaseries"
        },
        {
            "description": "Statistical learning for neuroimaging in Python.",
            "name": "py-nilearn"
        },
        {
            "description": "Modeling and Statistical analysis of fMRI data in Python.",
            "name": "py-nistats"
        },
        {
            "description": "Common workflows for MRI (anatomical, functional, diffusion, etc)",
            "name": "py-niworkflows"
        },
        {
            "description": "Standardised ML input processing for particle physics",
            "name": "py-numl"
        },
        {
            "description": "The Open Graph Benchmark (OGB) is a collection of benchmark datasets,\ndata loaders, and evaluators for graph machine learning. Datasets cover\na variety of graph machine learning tasks and real-world applications.\nThe OGB data loaders are fully compatible with popular graph deep\nlearning frameworks, including PyTorch Geometric and Deep Graph Library\n(DGL). They provide automatic dataset downloading, standardized dataset\nsplits, and unified performance evaluation.",
            "name": "py-ogb"
        },
        {
            "description": "The OpenAI Python library provides convenient access to the OpenAI API\nfrom applications written in the Python language. It includes a pre-\ndefined set of classes for API resources that initialize themselves\ndynamically from API responses which makes it compatible with a wide\nrange of versions of the OpenAI API.",
            "name": "py-openai"
        },
        {
            "description": "OpenMC is a community-developed Monte Carlo neutron and photon transport\nsimulation code. It is capable of performing fixed source, k-eigenvalue,\nand subcritical multiplication calculations on models built using either\na constructive solid geometry or CAD representation. OpenMC supports\nboth continuous-energy and multigroup transport. The continuous-energy\nparticle interaction data is based on a native HDF5 format that can be\ngenerated from ACE files produced by NJOY. Parallelism is enabled via a\nhybrid MPI and OpenMP programming model.",
            "name": "py-openmc"
        },
        {
            "description": "MIM Installs OpenMMLab packages",
            "name": "py-openmim"
        },
        {
            "description": "Up-to-date remote data access for pandas. Works for multiple versions of\npandas",
            "name": "py-pandas-datareader"
        },
        {
            "description": "Panedr uses the Pyedr library to read a Gromacs EDR binary energy XDR\nfile and returns its contents as a pandas dataframe",
            "name": "py-panedr"
        },
        {
            "description": "A high level app and dashboarding solution for Python.",
            "name": "py-panel"
        },
        {
            "description": "Simple data dependent workflows in Python",
            "name": "py-parsl"
        },
        {
            "description": "Key-value byte store with appendable values.",
            "name": "py-partd"
        },
        {
            "description": "Ancestral character reconstruction and visualisation for rooted\nphylogenetic trees.",
            "name": "py-pastml"
        },
        {
            "description": "An open-source toolkit for computational pathology and machine learning.",
            "name": "py-pathml"
        },
        {
            "description": "pauvre: plotting package designed for nanopore and PacBio long reads",
            "name": "py-pauvre"
        },
        {
            "description": "Petastorm is a library enabling the use of Parquet storage from\nTensorflow, Pytorch, and other Python-based ML training frameworks.",
            "name": "py-petastorm"
        },
        {
            "description": "phydms enables phylogenetic analyses using deep mutational scanning data\nto inform the substitution models. It implements Experimentally informed\ncodon models (ExpCM) for phylogenetic inference and the detection of\nbiologically interesting selection.",
            "name": "py-phydms"
        },
        {
            "description": "PhyloPhlAn 3.0 is an integrated pipeline for large-scale phylogenetic\nprofiling of genomes and metagenomes.",
            "name": "py-phylophlan"
        },
        {
            "description": "A lightweight python toolkit for gluing together restartable, robust\nshell pipelines.",
            "name": "py-piper"
        },
        {
            "description": "Automated pipeline for analyses of fungal ITS from the Illumina",
            "name": "py-pipits"
        },
        {
            "description": "plotnine is an implementation of a grammar of graphics in Python, it is\nbased on ggplot2. The grammar allows users to compose plots by\nexplicitly mapping data to the visual objects that make up the plot.",
            "name": "py-plotnine"
        },
        {
            "description": "Blazingly fast DataFrame library.",
            "name": "py-polars"
        },
        {
            "description": "PubChemPy provides a way to interact with PubChem in Python. It allows\nchemical searches by name, substructure and similarity, chemical\nstandardization, conversion between chemical file formats, depiction and\nretrieval of chemical properties.",
            "name": "py-pubchempy"
        },
        {
            "description": "pyani is a Python3 module that provides support for calculating average\nnucleotide identity (ANI) and related measures for whole genome\ncomparisons, and rendering relevant graphical summary output. Where\navailable, it takes advantage of multicore systems, and can integrate\nwith SGE/OGE-type job schedulers for the sequence comparisons.",
            "name": "py-pyani"
        },
        {
            "description": "Python wrapper -- and more -- for Aaron Quinlan's BEDTools",
            "name": "py-pybedtools"
        },
        {
            "description": "bids: interface with datasets conforming to BIDS",
            "name": "py-pybids"
        },
        {
            "description": "Py-BOBYQA is a flexible package for solving bound-constrained general\nobjective minimization, without requiring derivatives of the objective.",
            "name": "py-pybobyqa"
        },
        {
            "description": "A Python interface for the Generic Mapping Tools.",
            "name": "py-pygmt"
        },
        {
            "description": "Python Materials Genomics is a robust materials analysis code that\ndefines core object representations for structures and molecules with\nsupport for many electronic structure codes. It is currently the core\nanalysis code powering the Materials Project.",
            "name": "py-pymatgen"
        },
        {
            "description": "PyMC3 is a Python package for Bayesian statistical modeling and\nProbabilistic Machine Learning focusing on advanced Markov chain Monte\nCarlo (MCMC) and variational inference (VI) algorithms. Its flexibility\nand extensibility make it applicable to a large suite of problems.",
            "name": "py-pymc3"
        },
        {
            "description": "Pyomo is a Python-based open-source software package that supports a\ndiverse set of optimization capabilities for formulating and analyzing\noptimization models.",
            "name": "py-pyomo"
        },
        {
            "description": "Sequence Elements Enrichment Analysis (SEER), python implementation",
            "name": "py-pyseer"
        },
        {
            "description": "Python bindings for Apache Spark",
            "name": "py-pyspark"
        },
        {
            "description": "RDT is a Python library used to transform data for data science\nlibraries and preserve the transformations in order to revert them as\nneeded.",
            "name": "py-rdt"
        },
        {
            "description": "River is a Python library for online machine learning. It aims to be the\nmost user-friendly library for doing machine learning on streaming data.\nRiver is the result of a merge between creme and scikit-multiflow.",
            "name": "py-river"
        },
        {
            "description": "rpy2 is a redesign and rewrite of rpy. It is providing a low-level\ninterface to R from Python, a proposed high-level interface, including\nwrappers to graphical libraries, as well as R-like structures and\nfunctions.",
            "name": "py-rpy2"
        },
        {
            "description": "Representational Similarity Analysis (RSA) in Python.",
            "name": "py-rsatoolbox"
        },
        {
            "description": "Python implementations of commonly used sensitivity analysis methods.",
            "name": "py-salib"
        },
        {
            "description": "Scanpy is a scalable toolkit for analyzing single-cell gene expression\ndata built jointly with anndata.",
            "name": "py-scanpy"
        },
        {
            "description": "The SDMetrics library provides a set of dataset-agnostic tools for\nevaluating the quality of a synthetic database by comparing it to the\nreal database that it is modeled after.",
            "name": "py-sdmetrics"
        },
        {
            "description": "The Synthetic Data Vault (SDV) is a Synthetic Data Generation ecosystem\nof libraries that allows users to easily learn single-table, multi-table\nand timeseries datasets to later on generate new Synthetic Data that has\nthe same format and statistical properties as the original dataset.",
            "name": "py-sdv"
        },
        {
            "description": "Seaborn: statistical data visualization. Seaborn is a library for making\nattractive and informative statistical graphics in Python. It is built\non top of matplotlib and tightly integrated with the PyData stack,\nincluding support for numpy and pandas data structures and statistical\nroutines from scipy and statsmodels.",
            "name": "py-seaborn"
        },
        {
            "description": "SHAP (SHapley Additive exPlanations): a unified approach to explain the\noutput of any machine learning model.",
            "name": "py-shap"
        },
        {
            "description": "Variants of the synthetic minority oversampling technique (SMOTE) for\nimbalanced learning",
            "name": "py-smote-variants"
        },
        {
            "description": "Pandas extension arrays for spatial/geometric operations.",
            "name": "py-spatialpandas"
        },
        {
            "description": "Statistical computations and models for use with SciPy",
            "name": "py-statsmodels"
        },
        {
            "description": "The fastest way to build data apps in Python.",
            "name": "py-streamlit"
        },
        {
            "description": "Load tensorboard event logs as pandas DataFrames.",
            "name": "py-tbparse"
        },
        {
            "description": "TensorFlow Estimator is a high-level API that encapsulates model\ntraining, evaluation, prediction, and exporting.",
            "name": "py-tensorflow-estimator"
        },
        {
            "description": "The TF-Keras library is a pure TensorFlow implementation of Keras, based\non the legacy tf.keras codebase. Note that the \"main\" version of Keras\nis now Keras 3 (formerly Keras Core), which is a multi-backend\nimplementation of Keras, supporting JAX, PyTorch, and TensorFlow. Keras\n3 is being developed at keras-team/keras.",
            "name": "py-tf-keras"
        },
        {
            "description": "Python framework for doing ancestral sequence reconstruction.",
            "name": "py-topiary-asr"
        },
        {
            "description": "TorchGeo: datasets, samplers, transforms, and pre-trained models for\ngeospatial data.",
            "name": "py-torchgeo"
        },
        {
            "description": "A Python Automated Machine Learning tool that optimizes machine\nlearning pipelines using genetic programming.",
            "name": "py-tpot"
        },
        {
            "description": "UCSF pyem is a collection of Python modules and command-line utilities\nfor electron microscopy of biological samples.",
            "name": "py-ucsf-pyem"
        },
        {
            "description": "Ultralytics YOLOv8, developed by Ultralytics, is a cutting-edge, state-\nof-the-art (SOTA) model that builds upon the success of previous YOLO\nversions and introduces new features and improvements to further boost\nperformance and flexibility. YOLOv8 is designed to be fast, accurate,\nand easy to use, making it an excellent choice for a wide range of\nobject detection, image segmentation and image classification tasks.",
            "name": "py-ultralytics"
        },
        {
            "description": "Tools for handling Unique Molecular Identifiers in NGS data sets",
            "name": "py-umi-tools"
        },
        {
            "description": "Xarray extension for unstructured climate and global weather data\nanalysis and visualization",
            "name": "py-uxarray"
        },
        {
            "description": "Python library for reading, writing, and manipulating large-scale\nvasculature datasets",
            "name": "py-vascpy"
        },
        {
            "description": "Workload Automation (WA) is a framework for executing workloads and\ncollecting measurements on Android and Linux devices.",
            "name": "py-workload-automation"
        },
        {
            "description": "Bioinformatics tools and a software library developed by the Oxford\nNanopore Technologies Applications group.",
            "name": "py-wub"
        },
        {
            "description": "N-D labeled arrays and datasets in Python",
            "name": "py-xarray"
        },
        {
            "description": "XGBoost is an optimized distributed gradient boosting library designed\nto be highly efficient, flexible and portable.",
            "name": "py-xgboost"
        },
        {
            "description": "Python library to read and process pulsar data in several different\nformats",
            "name": "py-your"
        },
        {
            "description": "scalable pythonic model fitting for high energy physics",
            "name": "py-zfit"
        },
        {
            "description": "REDItools: python scripts for RNA editing detection by RNA-Seq data.\nREDItools are simple python scripts conceived to facilitate the\ninvestigation of RNA editing at large-scale and devoted to research\ngroups that would to explore such phenomenon in own data but don't have\nsufficient bioinformatics skills. They work on main operating systems\n(although unix/linux-based OS are preferred), can handle reads from\nwhatever platform in the standard BAM format and implement a variety of\nfilters.",
            "name": "reditools"
        },
        {
            "description": "Rapid large-scale prokaryote pan genome analysis",
            "name": "roary"
        },
        {
            "description": "Advanced Profiling and Analytics for AMD Hardware",
            "name": "rocprofiler-compute"
        },
        {
            "description": "ROCPROFILER library for AMD HSA runtime API extension support",
            "name": "rocprofiler-dev"
        },
        {
            "description": "SGpp is a library and framework for sparse grids in different flavors.\nSGpp supports both hierarchical spatially-adaptive sparse grids and the\ndimensionally-adaptive sparse grid combination technique.",
            "name": "sgpp"
        },
        {
            "description": "The SpECTRE numerical relativity code. SpECTRE is an open-source code\nfor multi-scale, multi-physics problems in astrophysics and\ngravitational physics. In the future, we hope that it can be applied to\nproblems across discipline boundaries in fluid dynamics, geoscience,\nplasma physics, nuclear physics, and engineering. It runs at petascale\nand is designed for future exascale computers. SpECTRE is being\ndeveloped in support of our collaborative Simulating eXtreme Spacetimes\n(SXS) research program into the multi-messenger astrophysics of neutron\nstar mergers, core-collapse supernovae, and gamma-ray bursts.",
            "name": "spectre"
        },
        {
            "description": "Survey is a high level performance tool product from Trenza, Inc. The\nsurvey collector/analytics framework is a new generation, high level,\nlightweight multiplatform Linux tool set that targets metric collection\nfor high level performance analysis of applications running on both\nsingle node and on large scale platforms, including the Cray platforms.\nThe collector is designed to work on sequential, MPI, OpenMP, and hybrid\ncodes and directly leverages several interfaces available for tools\ninside current MPI implementations including: MPICH, MVAPICH, MPT, and\nOpenMPI. It also supports multiple architectures and has been tested on\nmachines based on Intel, AMD, ARM, and IBM P8/9 processors and\nintegrated AMD and NVIDIA GPUs. Survey is a licensed product with the\nsource not openly available. To access the survey source and build with\nspack please contact: Trenza Inc. via: dmont@trenzasynergy.com or\njeg@trenzasynergy.com",
            "name": "survey"
        },
        {
            "description": "Modular profiling toolkit and suite of libraries and tools for\nC/C++/Fortran/CUDA/Python",
            "name": "timemory"
        },
        {
            "description": "topaz: Pipeline for particle picking in cryo-electron microscopy images\nusing convolutional neural networks trained from positive and unlabeled\nexamples. Also featuring micrograph and tomogram denoising with DNNs.",
            "name": "topaz"
        }
    ],
    "description": "pandas is a fast, powerful, flexible and easy to use open source data\nanalysis and manipulation tool, built on top of the Python programming\nlanguage.\n",
    "homepage": "https://pandas.pydata.org/",
    "latest_version": "2.3.0",
    "maintainers": [
        "adamjstewart",
        "rgommers"
    ],
    "name": "py-pandas",
    "patches": [],
    "resources": [],
    "variants": [
        {
            "default": "python_pip",
            "description": "Build systems supported by the package",
            "name": "build_system"
        },
        {
            "default": false,
            "description": "Build with support for Excel",
            "name": "excel"
        },
        {
            "default": false,
            "description": "Build with support for Parquet",
            "name": "parquet"
        },
        {
            "default": true,
            "description": "Build recommended performance dependencies",
            "name": "performance"
        }
    ],
    "versions": [
        {
            "name": "2.3.0",
            "sha256": "34600ab34ebf1131a7613a260a61dbe8b62c188ec0ea4c296da7c9a06b004133"
        },
        {
            "name": "2.2.3",
            "sha256": "4f18ba62b61d7e192368b84517265a99b4d7ee8912f8708660fb4a366cc82667"
        },
        {
            "name": "2.2.2",
            "sha256": "9e79019aba43cb4fda9e4d983f8e88ca0373adbb697ae9c6c43093218de28b54"
        },
        {
            "name": "2.2.1",
            "sha256": "0ab90f87093c13f3e8fa45b48ba9f39181046e8f3317d3aadb2fffbb1b978572"
        },
        {
            "name": "2.2.0",
            "sha256": "30b83f7c3eb217fb4d1b494a57a2fda5444f17834f5df2de6b2ffff68dc3c8e2"
        },
        {
            "name": "2.1.4",
            "sha256": "fcb68203c833cc735321512e13861358079a96c174a61f5116a1de89c58c0ef7"
        },
        {
            "name": "2.1.3",
            "sha256": "22929f84bca106921917eb73c1521317ddd0a4c71b395bcf767a106e3494209f"
        },
        {
            "name": "2.1.2",
            "sha256": "52897edc2774d2779fbeb6880d2cfb305daa0b1a29c16b91f531a18918a6e0f3"
        },
        {
            "name": "2.1.1",
            "sha256": "fecb198dc389429be557cde50a2d46da8434a17fe37d7d41ff102e3987fd947b"
        },
        {
            "name": "2.1.0",
            "sha256": "62c24c7fc59e42b775ce0679cfa7b14a5f9bfb7643cfbe708c960699e05fb918"
        },
        {
            "name": "2.0.3",
            "sha256": "c02f372a88e0d17f36d3093a644c73cfc1788e876a7c4bcb4020a77512e2043c"
        },
        {
            "name": "2.0.2",
            "sha256": "dd5476b6c3fe410ee95926873f377b856dbc4e81a9c605a0dc05aaccc6a7c6c6"
        },
        {
            "name": "2.0.1",
            "sha256": "19b8e5270da32b41ebf12f0e7165efa7024492e9513fb46fb631c5022ae5709d"
        },
        {
            "name": "2.0.0",
            "sha256": "cda9789e61b44463c1c4fe17ef755de77bcd13b09ba31c940d20f193d63a5dc8"
        },
        {
            "name": "1.5.3",
            "sha256": "74a3fd7e5a7ec052f183273dc7b0acd3a863edf7520f5d3a1765c04ffdb3b0b1"
        },
        {
            "name": "1.5.2",
            "sha256": "220b98d15cee0b2cd839a6358bd1f273d0356bf964c1a1aeb32d47db0215488b"
        },
        {
            "name": "1.5.1",
            "sha256": "249cec5f2a5b22096440bd85c33106b6102e0672204abd2d5c014106459804ee"
        },
        {
            "name": "1.5.0",
            "sha256": "3ee61b881d2f64dd90c356eb4a4a4de75376586cd3c9341c6c0fcaae18d52977"
        },
        {
            "name": "1.4.4",
            "sha256": "ab6c0d738617b675183e5f28db32b5148b694ad9bba0a40c3ea26d96b431db67"
        },
        {
            "name": "1.4.3",
            "sha256": "2ff7788468e75917574f080cd4681b27e1a7bf36461fe968b49a87b5a54d007c"
        },
        {
            "name": "1.4.2",
            "sha256": "92bc1fc585f1463ca827b45535957815b7deb218c549b7c18402c322c7549a12"
        },
        {
            "name": "1.4.1",
            "sha256": "8db93ec98ac7cb5f8ac1420c10f5e3c43533153f253fe7fb6d891cf5aa2b80d2"
        },
        {
            "name": "1.4.0",
            "sha256": "cdd76254c7f0a1583bd4e4781fb450d0ebf392e10d3f12e92c95575942e37df5"
        },
        {
            "name": "1.3.5",
            "sha256": "1e4285f5de1012de20ca46b188ccf33521bff61ba5c5ebd78b4fb28e5416a9f1"
        },
        {
            "name": "1.3.4",
            "sha256": "a2aa18d3f0b7d538e21932f637fbfe8518d085238b429e4790a35e1e44a96ffc"
        },
        {
            "name": "1.3.3",
            "sha256": "272c8cb14aa9793eada6b1ebe81994616e647b5892a370c7135efb2924b701df"
        },
        {
            "name": "1.3.2",
            "sha256": "cbcb84d63867af3411fa063af3de64902665bb5b3d40b25b2059e40603594e87"
        },
        {
            "name": "1.3.1",
            "sha256": "341935a594db24f3ff07d1b34d1d231786aa9adfa84b76eab10bf42907c8aed3"
        },
        {
            "name": "1.3.0",
            "sha256": "c554e6c9cf2d5ea1aba5979cc837b3649539ced0e18ece186f055450c86622e2"
        },
        {
            "name": "1.2.5",
            "sha256": "14abb8ea73fce8aebbb1fb44bec809163f1c55241bcc1db91c2c780e97265033"
        },
        {
            "name": "1.2.4",
            "sha256": "649ecab692fade3cbfcf967ff936496b0cfba0af00a55dfaacd82bdda5cb2279"
        },
        {
            "name": "1.2.3",
            "sha256": "df6f10b85aef7a5bb25259ad651ad1cc1d6bb09000595cab47e718cbac250b1d"
        },
        {
            "name": "1.2.2",
            "sha256": "14ed84b463e9b84c8ff9308a79b04bf591ae3122a376ee0f62c68a1bd917a773"
        },
        {
            "name": "1.2.1",
            "sha256": "5527c5475d955c0bc9689c56865aaa2a7b13c504d6c44f0aadbf57b565af5ebd"
        },
        {
            "name": "1.2.0",
            "sha256": "e03386615b970b8b41da6a68afe717626741bb2431cec993640685614c0680e4"
        },
        {
            "name": "1.1.5",
            "sha256": "f10fc41ee3c75a474d3bdf68d396f10782d013d7f67db99c0efbfd0acb99701b"
        },
        {
            "name": "1.1.4",
            "sha256": "a979d0404b135c63954dea79e6246c45dd45371a88631cdbb4877d844e6de3b6"
        },
        {
            "name": "1.1.3",
            "sha256": "babbeda2f83b0686c9ad38d93b10516e68cdcd5771007eb80a763e98aaf44613"
        }
    ],
    "versions_deprecated": [
        {
            "name": "1.1.2",
            "sha256": "b64ffd87a2cfd31b40acd4b92cb72ea9a52a48165aec4c140e78fd69c45d1444"
        },
        {
            "name": "1.1.1",
            "sha256": "53328284a7bb046e2e885fd1b8c078bd896d7fc4575b915d4936f54984a2ba67"
        },
        {
            "name": "1.1.0",
            "sha256": "b39508562ad0bb3f384b0db24da7d68a2608b9ddc85b1d931ccaaa92d5e45273"
        },
        {
            "name": "1.0.5",
            "sha256": "69c5d920a0b2a9838e677f78f4dde506b95ea8e4d30da25859db6469ded84fa8"
        },
        {
            "name": "1.0.4",
            "sha256": "b35d625282baa7b51e82e52622c300a1ca9f786711b2af7cbe64f1e6831f4126"
        },
        {
            "name": "1.0.3",
            "sha256": "32f42e322fb903d0e189a4c10b75ba70d90958cc4f66a1781ed027f1a1d14586"
        },
        {
            "name": "1.0.2",
            "sha256": "76334ba36aa42f93b6b47b79cbc32187d3a178a4ab1c3a478c8f4198bcd93a73"
        },
        {
            "name": "1.0.1",
            "sha256": "3c07765308f091d81b6735d4f2242bb43c332cc3461cae60543df6b10967fe27"
        },
        {
            "name": "1.0.0",
            "sha256": "3ea6cc86931f57f18b1240572216f09922d91b19ab8a01cf24734394a3db3bec"
        },
        {
            "name": "0.25.3",
            "sha256": "52da74df8a9c9a103af0a72c9d5fdc8e0183a90884278db7f386b5692a2220a4"
        },
        {
            "name": "0.25.2",
            "sha256": "ca91a19d1f0a280874a24dca44aadce42da7f3a7edb7e9ab7c7baad8febee2be"
        }
    ]
}