{
    "name": "llvm-openmp",
    "aliases": [],
    "versions": [
        {
            "name": "16.0.0",
            "sha256": "e30f69c6533157ec4399193ac6b158807610815accfbed98695d72074e4bedd0"
        },
        {
            "name": "14.0.6",
            "sha256": "4f731ff202add030d9d68d4c6daabd91d3aeed9812e6a5b4968815cfdff0eb1f"
        },
        {
            "name": "12.0.1",
            "sha256": "60fe79440eaa9ebf583a6ea7f81501310388c02754dbe7dc210776014d06b091"
        },
        {
            "name": "9.0.0",
            "sha256": "9979eb1133066376cc0be29d1682bc0b0e7fb541075b391061679111ae4d3b5b"
        },
        {
            "name": "8.0.0",
            "sha256": "f7b1705d2f16c4fc23d6531f67d2dd6fb78a077dd346b02fed64f4b8df65c9d5"
        }
    ],
    "latest_version": "16.0.0",
    "build_system": "CMakePackage",
    "conflicts": [],
    "variants": [
        {
            "name": "build_system",
            "default": "cmake",
            "description": "Build systems supported by the package"
        },
        {
            "name": "build_type",
            "default": "Release",
            "description": "CMake build type"
        },
        {
            "name": "ipo",
            "default": false,
            "description": "CMake interprocedural optimization"
        },
        {
            "name": "generator",
            "default": "make",
            "description": "the build system generator to use"
        },
        {
            "name": "multicompat",
            "default": false,
            "description": "Support gomp and the Intel openMP runtime library."
        }
    ],
    "homepage": "https://openmp.llvm.org/",
    "maintainers": [],
    "patches": [],
    "resources": [
        {
            "version": "@16.0.0",
            "name": "cmake",
            "destination": "",
            "placement": null
        }
    ],
    "description": "The OpenMP subproject of LLVM contains the components required to build\nan executable OpenMP program that are outside the compiler itself.\n",
    "dependencies": [
        {
            "name": "cmake",
            "description": "A cross-platform, open-source build system. CMake is a family of tools\ndesigned to build, test and package software."
        },
        {
            "name": "gmake",
            "description": "GNU Make is a tool which controls the generation of executables and\nother non-source files of a program from the program's source files."
        },
        {
            "name": "ninja",
            "description": "Ninja is a small build system with a focus on speed. It differs from\nother build systems in two major respects: it is designed to have its\ninput files generated by a higher-level build system, and it is designed\nto run builds as fast as possible."
        },
        {
            "name": "py-lit",
            "description": "lit is a portable tool for executing LLVM and Clang style test suites,\nsummarizing their results, and providing indication of failures. lit is\ndesigned to be a lightweight testing tool with as simple a user\ninterface as possible."
        },
        {
            "name": "py-filecheck",
            "description": "Python port of LLVM's FileCheck, flexible pattern matching file\nverifier."
        }
    ],
    "dependent_to": [
        {
            "name": "fbgemm",
            "description": "FBGEMM (Facebook GEneral Matrix Multiplication) is a low-precision,\nhigh-performance matrix-matrix multiplications and convolution library\nfor server-side inference."
        },
        {
            "name": "survey",
            "description": "Survey is a high level performance tool product from Trenza, Inc. The\nsurvey collector/analytics framework is a new generation, high level,\nlightweight multiplatform Linux tool set that targets metric collection\nfor high level performance analysis of applications running on both\nsingle node and on large scale platforms, including the Cray platforms.\nThe collector is designed to work on sequential, MPI, OpenMP, and hybrid\ncodes and directly leverages several interfaces available for tools\ninside current MPI implementations including: MPICH, MVAPICH, MPT, and\nOpenMPI. It also supports multiple architectures and has been tested on\nmachines based on Intel, AMD, ARM, and IBM P8/9 processors and\nintegrated GPUs. Survey is a licensed product with the source not openly\navailable. To access the survey source and build with spack please\ncontact: Trenza Inc. via: dmont@trenzasynergy.com or\njeg@trenzasynergy.com"
        },
        {
            "name": "apcomp",
            "description": "A multi use-case image compositor"
        },
        {
            "name": "py-pennylane-lightning",
            "description": "The PennyLane-Lightning plugin provides a fast state-vector simulator\nwritten in C++."
        },
        {
            "name": "fujitsu-fftw",
            "description": "FFTW (Fujitsu Optimized version) is a comprehensive collection of fast C\nroutines for computing the Discrete Fourier Transform (DFT) and various\nspecial cases thereof. It is an open-source implementation of the Fast\nFourier transform algorithm. It can compute transforms of real and\ncomplex-values arrays of arbitrary size and dimension. Fujitsu Optimized\nFFTW is the optimized FFTW implementation targeted for A64FX CPUs. For\nsingle precision build, please use precision value as float. Example :\nspack install fujitsufftw precision=float"
        },
        {
            "name": "fftw",
            "description": "FFTW is a C subroutine library for computing the discrete Fourier\ntransform (DFT) in one or more dimensions, of arbitrary input size, and\nof both real and complex data (as well as of even/odd data, i.e. the\ndiscrete cosine/sine transforms or DCT/DST). We believe that FFTW, which\nis free software, should become the FFT library of choice for most\napplications."
        },
        {
            "name": "lbann",
            "description": "LBANN: Livermore Big Artificial Neural Network Toolkit. A distributed\nmemory, HPC-optimized, model and data parallel training toolkit for deep\nneural networks."
        },
        {
            "name": "warpx",
            "description": "WarpX is an advanced electromagnetic Particle-In-Cell code. It supports\nmany features including Perfectly-Matched Layers (PML) and mesh\nrefinement. In addition, WarpX is a highly-parallel and highly-optimized\ncode and features hybrid OpenMP/MPI parallelization, advanced\nvectorization techniques and load balancing capabilities. For WarpX'\nPython bindings and PICMI input support, see the 'py-warpx' package."
        },
        {
            "name": "opensubdiv",
            "description": "OpenSubdiv is a set of open source libraries that implement high\nperformance subdivision surface (subdiv) evaluation on massively\nparallel CPU and GPU architectures. This code path is optimized for\ndrawing deforming surfaces with static topology at interactive\nframerates."
        },
        {
            "name": "xgboost",
            "description": "XGBoost is an optimized distributed gradient boosting library designed\nto be highly efficient, flexible and portable. It implements machine\nlearning algorithms under the Gradient Boosting framework. XGBoost\nprovides a parallel tree boosting (also known as GBDT, GBM) that solve\nmany data science problems in a fast and accurate way. The same code\nruns on major distributed environment (Hadoop, SGE, MPI) and can solve\nproblems beyond billions of examples."
        },
        {
            "name": "sw4",
            "description": "This package builds SW4 with MPI, OpenMP, HDF5, FFTW, PROJ, and ZFP."
        },
        {
            "name": "dihydrogen",
            "description": "DiHydrogen is the second version of the Hydrogen fork of the well-known\ndistributed linear algebra library, Elemental. DiHydrogen aims to be a\nbasic distributed multilinear algebra interface with a particular\nemphasis on the needs of the distributed machine learning effort, LBANN."
        },
        {
            "name": "py-scikit-learn",
            "description": "A set of python modules for machine learning and data mining."
        },
        {
            "name": "py-pythran",
            "description": "Ahead of Time compiler for numeric kernels."
        },
        {
            "name": "blaspp",
            "description": "C++ API for the Basic Linear Algebra Subroutines. Developed by the\nInnovative Computing Laboratory at the University of Tennessee,\nKnoxville."
        },
        {
            "name": "hydrogen",
            "description": "Hydrogen: Distributed-memory dense and sparse-direct linear algebra and\noptimization library. Based on the Elemental library."
        },
        {
            "name": "hipace",
            "description": "Highly efficient Plasma Accelerator Emulation, quasistatic particle-in-\ncell code"
        },
        {
            "name": "vtk-m",
            "description": "VTK-m is a toolkit of scientific visualization algorithms for emerging\nprocessor architectures. VTK-m supports the fine-grained concurrency for\ndata analysis and visualization algorithms required to drive extreme\nscale computing by providing abstract models for data and execution that\ncan be applied to a variety of algorithms across many different\nprocessor architectures."
        },
        {
            "name": "py-torch",
            "description": "Tensors and Dynamic neural networks in Python with strong GPU\nacceleration."
        },
        {
            "name": "py-dgl",
            "description": "Deep Graph Library (DGL). DGL is an easy-to-use, high performance and\nscalable Python package for deep learning on graphs. DGL is framework\nagnostic, meaning if a deep graph model is a component of an end-to-end\napplication, the rest of the logics can be implemented in any major\nframeworks, such as PyTorch, Apache MXNet or TensorFlow."
        },
        {
            "name": "py-networkit",
            "description": "NetworKit is a growing open-source toolkit for large-scale network\nanalysis. Its aim is to provide tools for the analysis of large networks\nin the size range from thousands to billions of edges. For this purpose,\nit implements efficient graph algorithms, many of them parallel to\nutilize multicore architectures. These are meant to compute standard\nmeasures of network analysis, such as degree sequences, clustering\ncoefficients, and centrality measures. In this respect, NetworKit is\ncomparable to packages such as NetworkX, albeit with a focus on\nparallelism and scalability."
        },
        {
            "name": "onednn",
            "description": "oneAPI Deep Neural Network Library (oneDNN). Formerly known as Intel\nMKL-DNN and DNNL."
        },
        {
            "name": "py-pennylane-lightning-kokkos",
            "description": "The PennyLane-Lightning-Kokkos plugin provides a fast state-vector\nsimulator with Kokkos kernels."
        },
        {
            "name": "raja",
            "description": "RAJA Parallel Framework."
        },
        {
            "name": "libnetworkit",
            "description": "NetworKit is a growing open-source toolkit for large-scale network\nanalysis. Its aim is to provide tools for the analysis of large networks\nin the size range from thousands to billions of edges. For this purpose,\nit implements efficient graph algorithms, many of them parallel to\nutilize multicore architectures. These are meant to compute standard\nmeasures of network analysis, such as degree sequences, clustering\ncoefficients, and centrality measures. In this respect, NetworKit is\ncomparable to packages such as NetworkX, albeit with a focus on\nparallelism and scalability."
        },
        {
            "name": "amdfftw",
            "description": "FFTW (AMD Optimized version) is a comprehensive collection of fast C\nroutines for computing the Discrete Fourier Transform (DFT) and various\nspecial cases thereof. It is an open-source implementation of the Fast\nFourier transform algorithm. It can compute transforms of real and\ncomplex-values arrays of arbitrary size and dimension. AMD Optimized\nFFTW is the optimized FFTW implementation targeted for AMD CPUs. For\nsingle precision build, please use precision value as float. Example :\nspack install amdfftw precision=float LICENSING INFORMATION: By\ndownloading, installing and using this software, you agree to the terms\nand conditions of the AMD AOCL-FFTW license agreement. You may obtain a\ncopy of this license agreement from\nhttps://www.amd.com/en/developer/aocl/fftw/fftw-libraries-4-0-eula.html\nhttps://www.amd.com/en/developer/aocl/fftw/fftw-libraries-eula.html"
        }
    ]
}