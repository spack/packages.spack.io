{
    "aliases": [],
    "build_system": "RPackage",
    "conflicts": [],
    "dependencies": [
        {
            "description": "The NVIDIA HPC SDK is a comprehensive suite of compilers, libraries and\ntools essential to maximizing developer productivity and the performance\nand portability of HPC applications. The NVIDIA HPC SDK C, C++, and\nFortran compilers support GPU acceleration of HPC modeling and\nsimulation applications with standard C++ and Fortran, OpenACC\ndirectives, and CUDA. GPU-accelerated math libraries maximize\nperformance on common HPC algorithms, and optimized communications\nlibraries enable standards-based multi-GPU and scalable systems\nprogramming. Performance profiling and debugging tools simplify porting\nand optimization of HPC applications.",
            "name": "c"
        },
        {
            "description": "The NVIDIA HPC SDK is a comprehensive suite of compilers, libraries and\ntools essential to maximizing developer productivity and the performance\nand portability of HPC applications. The NVIDIA HPC SDK C, C++, and\nFortran compilers support GPU acceleration of HPC modeling and\nsimulation applications with standard C++ and Fortran, OpenACC\ndirectives, and CUDA. GPU-accelerated math libraries maximize\nperformance on common HPC algorithms, and optimized communications\nlibraries enable standards-based multi-GPU and scalable systems\nprogramming. Performance profiling and debugging tools simplify porting\nand optimization of HPC applications.",
            "name": "cxx"
        },
        {
            "description": "R is 'GNU S', a freely available language and environment for\nstatistical computing and graphics which provides a wide variety of\nstatistical and graphical techniques: linear and nonlinear modelling,\nstatistical tests, time series analysis, classification, clustering,\netc. Please consult the R project homepage for further information.",
            "name": "r"
        }
    ],
    "dependent_to": [
        {
            "description": "An S4 Lattice-Based Package for the Representation of Multivariate Data.\nGraphical functionalities for the representation of multivariate data.\nIt is a complete re-implementation of the functions available in the\n'ade4' package.",
            "name": "r-adegraphics"
        },
        {
            "description": "Multivariate Multiscale Spatial Analysis. Tools for the multiscale\nspatial analysis of multivariate data. Several methods are based on the\nuse of a spatial weighting matrix and its eigenvector decomposition\n(Moran's Eigenvectors Maps, MEM). Several approaches are described in\nthe review Dray et al (2012) <doi:10.1890/11-1183.1>.",
            "name": "r-adespatial"
        },
        {
            "description": "Functions useful for those doing repetitive analyses with Affymetrix\nGeneChips. Various wrapper functions that have been written to\nstreamline the more common analyses that a core Biostatistician might\nsee.",
            "name": "r-affycoretools"
        },
        {
            "description": "QC Report Generation for affyBatch objects. This package creates a QC\nreport for an AffyBatch object. The report is intended to allow the user\nto quickly assess the quality of a set of arrays in an AffyBatch object.",
            "name": "r-affyqcreport"
        },
        {
            "description": "Investigates Allele Specific Expression. Provides a framework for\nallelic specific expression investigation using RNA-seq data.",
            "name": "r-allelicimbalance"
        },
        {
            "description": "Analyses of Phylogenetics and Evolution. Functions for reading, writing,\nplotting, and manipulating phylogenetic trees, analyses of comparative\ndata in a phylogenetic framework, ancestral character analyses, analyses\nof diversification and macroevolution, computing distances from DNA\nsequences, reading and writing nucleotide sequences as well as importing\nfrom BioConductor, and several tools such as Mantel's test, generalized\nskyline plots, graphical exploration of phylogenetic data (alex, trex,\nkronoviz), estimation of absolute evolutionary rates and clock-like\ntrees using mean path lengths and penalized likelihood, dating trees\nwith non-contemporaneous sequences, translating DNA into AA sequences,\nand assessing sequence alignments. Phylogeny estimation can be done with\nthe NJ, BIONJ, ME, MVR, SDM, and triangle methods, and several methods\nhandling incomplete distance matrices (NJ*, BIONJ*, MVR*, and the\ncorresponding triangle method). Some functions call external\napplications (PhyML, Clustal, T-Coffee, Muscle) whose results are\nreturned into R.",
            "name": "r-ape"
        },
        {
            "description": "Automatic Interpolation Package. An automatic interpolation is done by\nautomatically estimating the variogram and then calling gstat. An\noverview is given by Hiemstra et al (2008)\n<doi:10.1016/j.cageo.2008.10.011>.",
            "name": "r-automap"
        },
        {
            "description": "Classification and Regression Training. Misc functions for training and\nplotting classification and regression models.",
            "name": "r-caret"
        },
        {
            "description": "Ensembles of Caret Models. Functions for creating ensembles of caret\nmodels: caretList() and caretStack(). caretList() is a convenience\nfunction for fitting multiple caret::train() models to the same dataset.\ncaretStack() will make linear or non-linear combinations of these\nmodels, using a caret::train() model as a meta-model, and\ncaretEnsemble() will make a robust linear combination of models using a\nGLM.",
            "name": "r-caretensemble"
        },
        {
            "description": "A package for analyzing chipseq data, Tools for helping process short\nread data for chipseq experiments",
            "name": "r-chipseq"
        },
        {
            "description": "Output Analysis and Diagnostics for MCMC. Provides functions for\nsummarizing and plotting the output from Markov Chain Monte Carlo (MCMC)\nsimulations, as well as diagnostic tests of convergence to the\nequilibrium distribution of the Markov chain.",
            "name": "r-coda"
        },
        {
            "description": "Multivariate Dependence with Copulas. Classes (S4) of commonly used\nelliptical, Archimedean, extreme-value and other copula families, as\nwell as their rotations, mixtures and asymmetrizations. Nested\nArchimedean copulas, related tools and special functions. Methods for\ndensity, distribution, random number generation, bivariate dependence\nmeasures, Rosenblatt transform, Kendall distribution function,\nperspective and contour plots. Fitting of copula models with potentially\npartly fixed parameters, including standard errors. Serial independence\ntests, copula specification tests (independence, exchangeability, radial\nsymmetry, extreme-value dependence, goodness-of-fit) and model selection\nbased on cross-validation. Empirical copula, smoothed versions, and non-\nparametric estimators of the Pickands dependence function.",
            "name": "r-copula"
        },
        {
            "description": "Rule- And Instance-Based Regression Modeling. Regression modeling using\nrules with added instance-based corrections.",
            "name": "r-cubist"
        },
        {
            "description": "Differential gene expression analysis based on the negative binomial\ndistribution. Estimate variance-mean dependence in count data from high-\nthroughput sequencing assays and test for differential expression based\non a model using the negative binomial distribution",
            "name": "r-deseq"
        },
        {
            "description": "Effect Displays for Linear, Generalized Linear, and Other Models.\nGraphical and tabular effect displays, e.g., of interactions, for\nvarious statistical models with linear predictors.",
            "name": "r-effects"
        },
        {
            "description": "Multivariate Exploratory Data Analysis and Data Mining. Exploratory data\nanalysis methods to summarize, visualize and describe datasets. The main\nprincipal component methods are available, those with the largest\npotential in terms of applications: principal component analysis (PCA)\nwhen variables are quantitative, correspondence analysis (CA) and\nmultiple correspondence analysis (MCA) when variables are categorical,\nMultiple Factor Analysis when variables are structured in groups, etc.\nand hierarchical cluster analysis. F. Husson, S. Le and J. Pages (2017).",
            "name": "r-factominer"
        },
        {
            "description": "Compare Fitted Models. The fit.models function and its associated\nmethods (coefficients, print, summary, plot, etc.) were originally\nprovided in the robust package to compare robustly and classically\nfitted model objects. See chapters 2, 3, and 5 in Insightful (2002)\n'Robust Library User's Guide'\n<https://robust.r-forge.r-project.org/Robust.pdf>). The aim of the\nfit.models package is to separate this fitted model object comparison\nfunctionality from the robust package and to extend it to support\nfitting methods (e.g., classical, robust, Bayesian, regularized, etc.)\nmore generally.",
            "name": "r-fit-models"
        },
        {
            "description": "Flexible Cluster Algorithms. The main function kcca implements a general\nframework for k-centroids cluster analysis supporting arbitrary distance\nmeasures and centroid computation. Further cluster methods include hard\ncompetitive learning, neural gas, and QT clustering. There are numerous\nvisualization methods for cluster results (neighborhood graphs, convex\ncluster hulls, barcharts of centroids, ...), and bootstrap methods for\nthe analysis of cluster stability.",
            "name": "r-flexclust"
        },
        {
            "description": "Flexible Mixture Modeling. A general framework for finite mixtures of\nregression models using the EM algorithm is implemented. The E-step and\nall data handling are provided, while the M-step can be supplied by the\nuser to easily define new models. Existing drivers implement mixtures of\nstandard linear models, generalized linear models and model-based\nclustering.",
            "name": "r-flexmix"
        },
        {
            "description": "Generalized Boosted Regression Models. An implementation of extensions\nto Freund and Schapire's AdaBoost algorithm and Friedman's gradient\nboosting machine. Includes regression methods for least squares,\nabsolute loss, t-distribution loss, quantile regression, logistic,\nmultinomial logistic, Poisson, Cox proportional hazards partial\nlikelihood, AdaBoost exponential loss, Huberized hinge loss, and\nLearning to Rank measures (LambdaMart). Originally developed by Greg\nRidgeway.",
            "name": "r-gbm"
        },
        {
            "description": "Graphics related functions for Bioconductor. Functions for plotting\ngenomic data.",
            "name": "r-geneplotter"
        },
        {
            "description": "Spatial and Spatio-Temporal Geostatistical Modelling, Predictionand\nSimulation. Variogram modelling; simple, ordinary and universal point or\nblock (co)kriging; spatio-temporal kriging; sequential Gaussian or\nindicator (co)simulation; variogram and variogram map plotting utility\nfunctions; supports sf and stars.",
            "name": "r-gstat"
        },
        {
            "description": "Plotting data and annotation information along genomic coordinates.\nGenomic data analyses requires integrated visualization of known genomic\ninformation and new experimental data. Gviz uses the biomaRt and the\nrtracklayer packages to perform live annotation queries to Ensembl and\nUCSC and translates this to e.g. gene/transcript structures in viewports\nof the grid graphics package. This results in genomic information\nplotted together with your data.",
            "name": "r-gviz"
        },
        {
            "description": "Hexagonal Binning Routines. Binning and plotting functions for hexagonal\nbins. Now uses and relies on grid graphics and formal (S4) classes and\nmethods.",
            "name": "r-hexbin"
        },
        {
            "description": "Statistical Analysis and Data Display: Heiberger and Holland. Support\nsoftware for Statistical Analysis and Data Display (Second Edition,\nSpringer, ISBN 978-1-4939-2121-8, 2015) and (First Edition, Springer,\nISBN 0-387-40270-5, 2004) by Richard M. Heiberger and Burt Holland. This\ncontemporary presentation of statistical methods features extensive use\nof graphical displays for exploring data and for displaying the\nanalysis. The second edition includes redesigned graphics and additional\nchapters. The authors emphasize how to construct and interpret graphs,\ndiscuss principles of graphical design, and show how accompanying\ntraditional tabular results are used to confirm the visual impressions\nderived directly from the graphs. Many of the graphical formats are\nnovel and appear here for the first time in print. All chapters have\nexercises. All functions introduced in the book are in the package. R\ncode for all examples, both graphs and tables, in the book is included\nin the scripts directory of the package.",
            "name": "r-hh"
        },
        {
            "description": "Harrell Miscellaneous. Contains many functions useful for data analysis,\nhigh-level graphics, utility operations, functions for computing sample\nsize and power, importing and annotating datasets, imputing missing\nvalues, advanced table making, variable clustering, character string\nmanipulation, conversion of R objects to LaTeX and html code, and\nrecoding variables.",
            "name": "r-hmisc"
        },
        {
            "description": "Time Series Management, Analysis and Interpolation for Hydrological\nModelling. S3 functions for management, analysis, interpolation and\nplotting of time series used in hydrology and related environmental\nsciences. In particular, this package is highly oriented to hydrological\nmodelling tasks. The focus of this package has been put in providing a\ncollection of tools useful for the daily work of hydrologists (although\nan effort was made to optimise each function as much as possible,\nfunctionality has had priority over speed). Bugs / comments / questions\n/ collaboration of any kind are very welcomed, and in particular,\ndatasets that can be included in this package for academic purposes.",
            "name": "r-hydrotsm"
        },
        {
            "description": "Extra Graphical Utilities Based on Lattice. Building on the\ninfrastructure provided by the lattice package, this package provides\nseveral new high-level functions and methods, as well as additional\nutilities such as panel and axis annotation functions.",
            "name": "r-latticeextra"
        },
        {
            "description": "Linear Mixed-Effects Models using 'Eigen' and S4. Fit linear and\ngeneralized linear mixed-effects models. The models and their components\nare represented using S4 classes and methods. The core computational\nalgorithms are implemented using the 'Eigen' C++ library for numerical\nlinear algebra and 'RcppEigen' \"glue\".",
            "name": "r-lme4"
        },
        {
            "description": "Local regression, likelihood and density estimation. Local regression,\nlikelihood and density estimation methods as described in the 1999 book\nby Loader.",
            "name": "r-locfit"
        },
        {
            "description": "BeadArray Specific Methods for Illumina Methylation and Expression\nMicroarrays. The lumi package provides an integrated solution for the\nIllumina microarray data analysis. It includes functions of Illumina\nBeadStudio (GenomeStudio) data input, quality control, BeadArray-\nspecific variance stabilization, normalization and gene annotation at\nthe probe level. It also includes the functions of processing Illumina\nmethylation microarrays, especially Illumina Infinium methylation\nmicroarrays.",
            "name": "r-lumi"
        },
        {
            "description": "Tools for Handling Spatial Objects. Set of tools for manipulating and\nreading geographic data, in particular ESRI shapefiles; C code used from\nshapelib. It includes binary access to GSHHG shoreline files. The\npackage also provides interface wrappers for exchanging spatial objects\nwith packages such as PBSmapping, spatstat, maps, RArcInfo, Stata tmap,\nWinBUGS, Mondrian, and others.",
            "name": "r-maptools"
        },
        {
            "description": "Interactive Viewing of Spatial Data in R. Quickly and conveniently\ncreate interactive visualisations of spatial data with or without\nbackground maps. Attributes of displayed features are fully queryable\nvia pop-up windows. Additional functionality includes methods to\nvisualise true- and false-color raster images and bounding boxes.",
            "name": "r-mapview"
        },
        {
            "description": "Sparse and Dense Matrix Classes and Methods. A rich hierarchy of matrix\nclasses, including triangular, symmetric, and diagonal matrices, both\ndense and sparse and with pattern, logical and numeric entries. Numerous\nmethods for and operations on these matrices, using 'LAPACK' and\n'SuiteSparse' libraries.",
            "name": "r-matrix"
        },
        {
            "description": "Markov Chain Monte Carlo (MCMC) Package. Contains functions to perform\nBayesian inference using posterior simulation for a number of\nstatistical models. Most simulation is done in compiled C++ written in\nthe Scythe Statistical Library Version 1.0.3. All models return 'coda'\nmcmc objects that can then be summarized using the 'coda' package. Some\nuseful utility functions such as density functions, pseudo-random number\ngenerators for statistical distributions, a general purpose Metropolis\nsampling algorithm, and tools for visualization are provided.",
            "name": "r-mcmcpack"
        },
        {
            "description": "Management of Survey Data and Presentation of Analysis Results. An\ninfrastructure for the management of survey data including value labels,\ndefinable missing values, recoding of variables, production of code\nbooks, and import of (subsets of) 'SPSS' and 'Stata' files is provided.\nFurther, the package allows to produce tables and data frames of\narbitrary descriptive statistics and (almost) publication-ready tables\nof regression model estimates, which can be exported to 'LaTeX' and\nHTML.",
            "name": "r-memisc"
        },
        {
            "description": "Meta-Analysis of Significance Values. The canonical way to perform meta-\nanalysis involves using effect sizes. When they are not available this\npackage provides a number of methods for meta-analysis of significance\nvalues including the methods of Edgington, Fisher, Lancaster, Stouffer,\nTippett, and Wilkinson; a number of data-sets to replicate published\nresults; and a routine for graphical display.",
            "name": "r-metap"
        },
        {
            "description": "Handle Illumina methylation data. This package provides classes for\nholding and manipulating Illumina methylation data. Based on eSet, it\ncan contain MIAME information, sample information, feature information,\nand multiple matrices of data. An \"intelligent\" import function,\nmethylumiR can read the Illumina text files and create a MethyLumiSet.\nmethylumIDAT can directly read raw IDAT files from HumanMethylation27\nand HumanMethylation450 microarrays. Normalization, background\ncorrection, and quality control features for GoldenGate, Infinium, and\nInfinium HD arrays are also included.",
            "name": "r-methylumi"
        },
        {
            "description": "Multivariate Imputation by Chained Equations. Multiple imputation using\nFully Conditional Specification (FCS) implemented by the MICE algorithm\nas described in Van Buuren and Groothuis-Oudshoorn (2011)\n<doi:10.18637/jss.v045.i03>. Each variable has its own imputation model.\nBuilt-in imputation models are provided for continuous data (predictive\nmean matching, normal), binary data (logistic regression), unordered\ncategorical data (polytomous logistic regression) and ordered\ncategorical data (proportional odds). MICE can also impute continuous\ntwo-level data (normal model, pan, second-level variables). Passive\nimputation can be used to maintain consistency between variables.\nVarious diagnostic plots are available to inspect the quality of the\nimputations.",
            "name": "r-mice"
        },
        {
            "description": "Analyze Illumina Infinium DNA methylation arrays. Tools to analyze &\nvisualize Illumina Infinium methylation arrays.",
            "name": "r-minfi"
        },
        {
            "description": "Base Functions and Classes for Mass Spectrometry and Proteomics. MSnbase\nprovides infrastructure for manipulation, processing and visualisation\nof mass spectrometry and proteomics data, ranging from raw to\nquantitative and annotated data.",
            "name": "r-msnbase"
        },
        {
            "description": "Parallel Analysis and Other Non Graphical Solutions to the Cattell Scree\nTest. Indices, heuristics and strategies to help determine the number of\nfactors/components to retain: 1. Acceleration factor (af with or without\nParallel Analysis); 2. Optimal Coordinates (noc with or without Parallel\nAnalysis); 3. Parallel analysis (components, factors and bootstrap); 4.\nlambda > mean(lambda) (Kaiser, CFA and related); 5. Cattell-Nelson-\nGorsuch (CNG); 6. Zoski and Jurs multiple regression (b, t and p); 7.\nZoski and Jurs standard error of the regression coeffcient (sescree); 8.\nNelson R2; 9. Bartlett khi-2; 10. Anderson khi-2; 11. Lawley khi-2 and\n12. Bentler-Yuan khi-2.",
            "name": "r-nfactors"
        },
        {
            "description": "Linear and Nonlinear Mixed Effects Models. Fit and compare Gaussian\nlinear and nonlinear mixed-effects models.",
            "name": "r-nlme"
        },
        {
            "description": "Procedures for Psychological, Psychometric, and Personality Research. A\ngeneral purpose toolbox for personality, psychometric theory and\nexperimental psychology. Functions are primarily for multivariate\nanalysis and scale construction using factor analysis, principal\ncomponent analysis, cluster analysis and reliability analysis, although\nothers provide basic descriptive statistics. Item Response Theory is\ndone using factor analysis of tetrachoric and polychoric correlations.\nFunctions for analyzing data at multiple levels include within and\nbetween group statistics, including correlations and factor analysis.\nFunctions for simulating and testing particular item and test structures\nare included. Several functions serve as a useful front end for\nstructural equation modeling. Graphical displays of path diagrams,\nfactor analysis and structural equation models are created using basic\ngraphics. Some of the functions are written to support a book on\npsychometric theory as well as publications in personality research. For\nmore information, see the <http://personality-project.org/r> web page.",
            "name": "r-psych"
        },
        {
            "description": "Tools for making reports in various formats. The ReportingTools software\npackage enables users to easily display reports of analysis results\ngenerated from sources such as microarray and sequencing data. The\npackage allows users to create HTML pages that may be viewed on a web\nbrowser such as Safari, or in other formats readable by programs such as\nExcel. Users can generate tables with sortable and filterable columns,\nmake and display plots, and link table entries to other data sources\nsuch as NCBI or larger plots within the HTML page. Using the package,\nusers can also produce a table of contents page to link various reports\ntogether for a particular project that can be viewed in a web browser.\nFor more examples, please visit our site: http:// research-\npub.gene.com/ReportingTools.",
            "name": "r-reportingtools"
        },
        {
            "description": "Data Mining Classification and Regression Methods. Facilitates the use\nof data mining algorithms in classification and regression (including\ntime series forecasting) tasks by presenting a short and coherent set of\nfunctions. Versions: 1.4.6 / 1.4.5 / 1.4.4 new automated machine\nlearning (AutoML) and ensembles, via improved fit(), mining() and\nmparheuristic() functions, and new categorical preprocessing, via\nimproved delevels() function; 1.4.3 new metrics (e.g., macro precision,\nexplained variance), new \"lssvm\" model and improved mparheuristic()\nfunction; 1.4.2 new \"NMAE\" metric, \"xgboost\" and \"cv.glmnet\" models (16\nclassification and 18 regression models); 1.4.1 new tutorial and more\nrobust version; 1.4 - new classification and regression models, with a\ntotal of 14 classification and 15 regression methods, including:\nDecision Trees, Neural Networks, Support Vector Machines, Random\nForests, Bagging and Boosting; 1.3 and 1.3.1 - new classification and\nregression metrics; 1.2 - new input importance methods via improved\nImportance() function; 1.0 - first version.",
            "name": "r-rminer"
        },
        {
            "description": "Regression Modeling Strategies. Regression modeling, testing,\nestimation, validation, graphics, prediction, and typesetting by storing\nenhanced model design attributes in the fit. 'rms' is a collection of\nfunctions that assist with and streamline modeling. It also contains\nfunctions for binary and ordinal logistic regression models, ordinal\nmodels for continuous Y with a variety of distribution families, and the\nBuckley-James multiple regression model for right-censored responses,\nand implements penalized maximum likelihood estimation for logistic and\nordinary linear models. 'rms' works with almost any regression model,\nbut it was especially written to work with binary or ordinal regression\nmodels, Cox regression, accelerated failure time models, ordinary linear\nmodels, the Buckley-James model, generalized least squares for serially\nor spatially correlated observations, generalized linear models, and\nquantile regression.",
            "name": "r-rms"
        },
        {
            "description": "Port of the S+ Robust Library. Methods for robust statistics, a state of\nthe art in the early 2000s, notably for robust regression and robust\nmultivariate analysis.",
            "name": "r-robust"
        },
        {
            "description": "Scalable Robust Estimators with High Breakdown Point. Robust Location\nand Scatter Estimation and Robust Multivariate Analysis with High\nBreakdown Point: principal component analysis (Filzmoser and Todorov\n(2013), <doi:10.1016/j.ins.2012.10.017>), linear and quadratic\ndiscriminant analysis (Todorov and Pires (2007)), multivariate tests\n(Todorov and Filzmoser (2010) <doi:10.1016/j.csda.2009.08.015>), outlier\ndetection (Todorov et al. (2010) <doi:10.1007/s11634-010-0075-2>). See\nalso Todorov and Filzmoser (2009) <ISBN-13:978-3838108148>, Todorov and\nFilzmoser (2010) <doi:10.18637/jss.v032.i03> and Boudt et al. (2019)\n<doi:10.1007/s11222-019-09869-x>.",
            "name": "r-rrcov"
        },
        {
            "description": "Interface Utilities, Model Templates, Parallel Computing Methods and\nAdditional Distributions for MCMC Models in JAGS. User-friendly\ninterface utilities for MCMC models via Just Another Gibbs Sampler\n(JAGS), facilitating the use of parallel (or distributed) processors for\nmultiple chains, automated control of convergence and sample length\ndiagnostics, and evaluation of the performance of a model using drop-k\nvalidation or against simulated data. Template model specifications can\nbe generated using a standard lme4-style formula interface to assist\nusers less familiar with the BUGS syntax. A JAGS extension module\nprovides additional distributions including the Pareto family of\ndistributions, the DuMouchel prior and the half-Cauchy prior.",
            "name": "r-runjags"
        },
        {
            "description": "FASTQ input and manipulation. This package implements sampling,\niteration, and input of FASTQ files. The package includes functions for\nfiltering and trimming reads, and for generating a quality assessment\nreport. Data are represented as DNAStringSet-derived objects, and easily\nmanipulated for a diversity of purposes. The package also contains\nlegacy support for early single-end, ungapped alignment formats.",
            "name": "r-shortread"
        },
        {
            "description": "Classes and Methods for Spatial Data. Classes and methods for spatial\ndata; the classes document where the spatial location information\nresides, for 2D or 3D data. Utility functions are provided, e.g. for\nplotting data as maps, spatial selection, as well as methods for\nretrieving coordinates, for subsetting, print, summary, etc.",
            "name": "r-sp"
        },
        {
            "description": "Classes and Methods for Spatio-Temporal Data. Classes and methods for\nspatio-temporal data, including space-time regular lattices, sparse\nlattices, irregular data, and trajectories; utility functions for\nplotting data as map sequences (lattice or animation) or multiple time\nseries; methods for spatial and temporal selection and subsetting, as\nwell as for spatial/temporal/spatio-temporal matching or aggregation,\nretrieving coordinates, print, summary, etc.",
            "name": "r-spacetime"
        },
        {
            "description": "Analysis of Complex Survey Samples. Summary statistics, two-sample\ntests, rank tests, generalised linear models, cumulative link models,\nCox models, loglinear models, and general maximum pseudolikelihood\nestimation for multistage stratified, cluster-sampled, unequally\nweighted survey samples. Variances by Taylor series linearisation or\nreplicate weights. Post-stratification, calibration, and raking. Two-\nphase subsampling designs. Graphics. PPS sampling without replacement.\nPrincipal components, factor analysis.",
            "name": "r-survey"
        },
        {
            "description": "Enrichment Analysis for Gene Ontology. topGO package provides tools for\ntesting GO terms while accounting for the topology of the GO graph.\nDifferent test statistics and different methods for eliminating local\nsimilarities and dependencies between GO terms can be implemented and\napplied.",
            "name": "r-topgo"
        },
        {
            "description": "Two Sample MR functions and interface to MR Base database. A package for\nperforming Mendelian randomization using GWAS summary data. It uses the\nIEU GWAS database to obtain data automatically, and a wide range of\nmethods to run the analysis. You can use the MR-Base web app to try out\na limited range of the functionality in this package, but for any\nserious work we strongly recommend using this R package.",
            "name": "r-twosamplemr"
        },
        {
            "description": "Community Ecology Package. Ordination methods, diversity analysis and\nother functions for community and vegetation ecologists.",
            "name": "r-vegan"
        },
        {
            "description": "Variance stabilization and calibration for microarray data. The package\nimplements a method for normalising microarray intensities, and works\nfor single- and multiple-color arrays. It can also be used for data from\nother technologies, as long as they have similar format. The method uses\na robust variant of the maximum-likelihood estimator for an additive-\nmultiplicative error model and affine calibration. The model\nincorporates data calibration step (a.k.a. normalization), a model for\nthe dependence of the variance on the mean intensity and a variance\nstabilizing data transformation. Differences between transformed\nintensities are analogous to \"normalized log-ratios\". However, in\ncontrast to the latter, their variance is independent of the mean, and\nthey are usually more sensitive and specific in detecting differential\ntranscription.",
            "name": "r-vsn"
        },
        {
            "description": "S3 Infrastructure for Regular and Irregular Time Series (Z's Ordered\nObservations). An S3 class with methods for totally ordered indexed\nobservations. It is particularly aimed at irregular time series of\nnumeric vectors/matrices and factors. zoo's key design goals are\nindependence of a particular index/date/time class and consistency with\nts and base R by providing methods to extend standard generics.",
            "name": "r-zoo"
        }
    ],
    "description": "Trellis Graphics for R. A powerful and elegant high-level data\nvisualization system inspired by Trellis graphics, with an emphasis on\nmultivariate data. Lattice is sufficient for typical graphics needs, and\nis also flexible enough to handle most nonstandard requirements. See\n?Lattice for an introduction.\n",
    "homepage": "https://cloud.r-project.org/package=lattice",
    "latest_version": "0.22-6",
    "maintainers": [],
    "name": "r-lattice",
    "patches": [],
    "resources": [],
    "variants": [
        {
            "default": "generic",
            "description": "Build systems supported by the package",
            "name": "build_system"
        }
    ],
    "versions": [
        {
            "name": "0.22-6",
            "sha256": "4b377211e472ece7872b9d6759f9b9c660b09594500462eb6146312a1d4d00f7"
        },
        {
            "name": "0.21-8",
            "sha256": "8ad3d6974262e6cab6cc8fec38aa279b5b2f2524adf6f3eab56f68302b60c329"
        },
        {
            "name": "0.20-45",
            "sha256": "22388d92bdb7d3959da84d7308d9026dd8226ef07580783729e8ad2f7d7507ad"
        },
        {
            "name": "0.20-44",
            "sha256": "57b908e3c7ada08a38ad857ee44f44fdf9cfa59d5d9500bda2ccc9c7e96cdb9b"
        },
        {
            "name": "0.20-41",
            "sha256": "54ca557f0cb33df60eb10b883c2ed2847e061ddd57ed9b5dd7695149609d57b5"
        },
        {
            "name": "0.20-38",
            "sha256": "fdeb5e3e50dbbd9d3c5e2fa3eef865132b3eef30fbe53a10c24c7b7dfe5c0a2d"
        },
        {
            "name": "0.20-35",
            "sha256": "0829ab0f4dec55aac6a73bc3411af68441ddb1b5b078d680a7c2643abeaa965d"
        },
        {
            "name": "0.20-34",
            "sha256": "4a1a1cafa9c6660fb9a433b3a51898b8ec8e83abf143c80f99e3e4cf92812518"
        }
    ],
    "versions_deprecated": []
}